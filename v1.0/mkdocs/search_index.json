{
    "docs": [
        {
            "location": "/", 
            "text": "Tr\u00e6f\u026ak is a modern HTTP reverse proxy and load balancer made to deploy microservices with ease.\nIt supports several backends (\nDocker\n, \nSwarm\n, \nMesos/Marathon\n, \nConsul\n, \nEtcd\n, \nZookeeper\n, \nBoltDB\n, Rest API, file...) to manage its configuration automatically and dynamically.\n\n\nOverview\n\n\nImagine that you have deployed a bunch of microservices on your infrastructure. You probably used a service registry (like etcd or consul) and/or an orchestrator (swarm, Mesos/Marathon) to manage all these services.\nIf you want your users to access some of your microservices from the Internet, you will have to use a reverse proxy and configure it using virtual hosts or prefix paths:\n\n\n\n\ndomain \napi.domain.com\n will point the microservice \napi\n in your private network\n\n\npath \ndomain.com/web\n will point the microservice \nweb\n in your private network\n\n\ndomain \nbackoffice.domain.com\n will point the microservices \nbackoffice\n in your private network, load-balancing between your multiple instances\n\n\n\n\nBut a microservices architecture is dynamic... Services are added, removed, killed or upgraded often, eventually several times a day.\n\n\nTraditional reverse-proxies are not natively dynamic. You can't change their configuration and hot-reload easily.\n\n\nHere enters Tr\u00e6f\u026ak.\n\n\n\n\nTr\u00e6f\u026ak can listen to your service registry/orchestrator API, and knows each time a microservice is added, removed, killed or upgraded, and can generate its configuration automatically.\nRoutes to your services will be created instantly.\n\n\nRun it and forget it!\n\n\nDemo\n\n\nHere is a talk (in french) given by \nEmile Vauge\n at the \nDevoxx France 2016\n conference. \nYou will learn fundamental Tr\u00e6f\u026ak features and see some demos with Docker, Mesos/Marathon and Lets'Encrypt. \n\n\n\n\nGet it\n\n\nBinary\n\n\nYou can grab the latest binary from the \nreleases\n page and just run it with the \nsample configuration file\n:\n\n\n./traefik -c traefik.toml\n\n\n\n\nDocker\n\n\nUsing the tiny Docker image:\n\n\ndocker run -d -p 8080:8080 -p 80:80 -v $PWD/traefik.toml:/etc/traefik/traefik.toml traefik\n\n\n\n\nTest it\n\n\nYou can test Tr\u00e6f\u026ak easily using \nDocker compose\n, with this \ndocker-compose.yml\n file:\n\n\ntraefik:\n  image: traefik\n  command: --web --docker --docker.domain=docker.localhost --logLevel=DEBUG\n  ports:\n    - \n80:80\n\n    - \n8080:8080\n\n  volumes:\n    - /var/run/docker.sock:/var/run/docker.sock\n    - /dev/null:/traefik.toml\n\nwhoami1:\n  image: emilevauge/whoami\n  labels:\n    - \ntraefik.backend=whoami\n\n    - \ntraefik.frontend.rule=Host:whoami.docker.localhost\n\n\nwhoami2:\n  image: emilevauge/whoami\n  labels:\n    - \ntraefik.backend=whoami\n\n    - \ntraefik.frontend.rule=Host:whoami.docker.localhost\n\n\n\n\n\nThen, start it:\n\n\ndocker-compose up -d\n\n\n\n\nFinally, test load-balancing between the two servers \nwhoami1\n and \nwhoami2\n:\n\n\n$ curl -H Host:whoami.docker.localhost http://127.0.0.1\nHostname: ef194d07634a\nIP: 127.0.0.1\nIP: ::1\nIP: 172.17.0.4\nIP: fe80::42:acff:fe11:4\nGET / HTTP/1.1\nHost: 172.17.0.4:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 172.17.0.1\nX-Forwarded-Host: 172.17.0.4:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: dbb60406010d\n\n$ curl -H Host:whoami.docker.localhost http://127.0.0.1\nHostname: 6c3c5df0c79a\nIP: 127.0.0.1\nIP: ::1\nIP: 172.17.0.3\nIP: fe80::42:acff:fe11:3\nGET / HTTP/1.1\nHost: 172.17.0.3:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 172.17.0.1\nX-Forwarded-Host: 172.17.0.3:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: dbb60406010d", 
            "title": "Getting Started"
        }, 
        {
            "location": "/#overview", 
            "text": "Imagine that you have deployed a bunch of microservices on your infrastructure. You probably used a service registry (like etcd or consul) and/or an orchestrator (swarm, Mesos/Marathon) to manage all these services.\nIf you want your users to access some of your microservices from the Internet, you will have to use a reverse proxy and configure it using virtual hosts or prefix paths:   domain  api.domain.com  will point the microservice  api  in your private network  path  domain.com/web  will point the microservice  web  in your private network  domain  backoffice.domain.com  will point the microservices  backoffice  in your private network, load-balancing between your multiple instances   But a microservices architecture is dynamic... Services are added, removed, killed or upgraded often, eventually several times a day.  Traditional reverse-proxies are not natively dynamic. You can't change their configuration and hot-reload easily.  Here enters Tr\u00e6f\u026ak.   Tr\u00e6f\u026ak can listen to your service registry/orchestrator API, and knows each time a microservice is added, removed, killed or upgraded, and can generate its configuration automatically.\nRoutes to your services will be created instantly.  Run it and forget it!", 
            "title": "Overview"
        }, 
        {
            "location": "/#demo", 
            "text": "Here is a talk (in french) given by  Emile Vauge  at the  Devoxx France 2016  conference. \nYou will learn fundamental Tr\u00e6f\u026ak features and see some demos with Docker, Mesos/Marathon and Lets'Encrypt.", 
            "title": "Demo"
        }, 
        {
            "location": "/#get-it", 
            "text": "", 
            "title": "Get it"
        }, 
        {
            "location": "/#binary", 
            "text": "You can grab the latest binary from the  releases  page and just run it with the  sample configuration file :  ./traefik -c traefik.toml", 
            "title": "Binary"
        }, 
        {
            "location": "/#docker", 
            "text": "Using the tiny Docker image:  docker run -d -p 8080:8080 -p 80:80 -v $PWD/traefik.toml:/etc/traefik/traefik.toml traefik", 
            "title": "Docker"
        }, 
        {
            "location": "/#test-it", 
            "text": "You can test Tr\u00e6f\u026ak easily using  Docker compose , with this  docker-compose.yml  file:  traefik:\n  image: traefik\n  command: --web --docker --docker.domain=docker.localhost --logLevel=DEBUG\n  ports:\n    -  80:80 \n    -  8080:8080 \n  volumes:\n    - /var/run/docker.sock:/var/run/docker.sock\n    - /dev/null:/traefik.toml\n\nwhoami1:\n  image: emilevauge/whoami\n  labels:\n    -  traefik.backend=whoami \n    -  traefik.frontend.rule=Host:whoami.docker.localhost \n\nwhoami2:\n  image: emilevauge/whoami\n  labels:\n    -  traefik.backend=whoami \n    -  traefik.frontend.rule=Host:whoami.docker.localhost   Then, start it:  docker-compose up -d  Finally, test load-balancing between the two servers  whoami1  and  whoami2 :  $ curl -H Host:whoami.docker.localhost http://127.0.0.1\nHostname: ef194d07634a\nIP: 127.0.0.1\nIP: ::1\nIP: 172.17.0.4\nIP: fe80::42:acff:fe11:4\nGET / HTTP/1.1\nHost: 172.17.0.4:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 172.17.0.1\nX-Forwarded-Host: 172.17.0.4:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: dbb60406010d\n\n$ curl -H Host:whoami.docker.localhost http://127.0.0.1\nHostname: 6c3c5df0c79a\nIP: 127.0.0.1\nIP: ::1\nIP: 172.17.0.3\nIP: fe80::42:acff:fe11:3\nGET / HTTP/1.1\nHost: 172.17.0.3:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 172.17.0.1\nX-Forwarded-Host: 172.17.0.3:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: dbb60406010d", 
            "title": "Test it"
        }, 
        {
            "location": "/basics/", 
            "text": "Concepts\n\n\nLet's take our example from the \noverview\n again:\n\n\n\n\nImagine that you have deployed a bunch of microservices on your infrastructure. You probably used a service registry (like etcd or consul) and/or an orchestrator (swarm, Mesos/Marathon) to manage all these services.\nIf you want your users to access some of your microservices from the Internet, you will have to use a reverse proxy and configure it using virtual hosts or prefix paths:\n\n\n\n\ndomain \napi.domain.com\n will point the microservice \napi\n in your private network\n\n\npath \ndomain.com/web\n will point the microservice \nweb\n in your private network\n\n\ndomain \nbackoffice.domain.com\n will point the microservices \nbackoffice\n in your private network, load-balancing between your multiple instances\n\n\n\n\n\n\n\n\nLet's zoom on Tr\u00e6f\u026ak and have an overview of its internal architecture:\n\n\n\n\n\n\nIncoming requests end on \nentrypoints\n, as the name suggests, they are the network entry points into Tr\u00e6f\u026ak (listening port, SSL, traffic redirection...).\n\n\nTraffic is then forwarded to a matching \nfrontend\n. A frontend defines routes from \nentrypoints\n to \nbackends\n.\nRoutes are created using requests fields (\nHost\n, \nPath\n, \nHeaders\n...) and can match or not a request.\n\n\nThe \nfrontend\n will then send the request to a \nbackend\n. A backend can be composed by one or more \nservers\n, and by a load-balancing strategy.\n\n\nFinally, the \nserver\n will forward the request to the corresponding microservice in the private network.\n\n\n\n\nEntrypoints\n\n\nEntrypoints are the network entry points into Tr\u00e6f\u026ak.\nThey can be defined using:\n\n\n\n\na port (80, 443...)\n\n\nSSL (Certificates. Keys...)\n\n\nredirection to another entrypoint (redirect \nHTTP\n to \nHTTPS\n)\n\n\n\n\nHere is an example of entrypoints definition:\n\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n    [entryPoints.http.redirect]\n    entryPoint = \nhttps\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile = \ntests/traefik.crt\n\n      keyFile = \ntests/traefik.key\n\n\n\n\n\n\n\nTwo entrypoints are defined \nhttp\n and \nhttps\n.\n\n\nhttp\n listens on port \n80\n and \nhttps\n on port \n443\n.\n\n\nWe enable SSL on \nhttps\n by giving a certificate and a key.\n\n\nWe also redirect all the traffic from entrypoint \nhttp\n to \nhttps\n.\n\n\n\n\nFrontends\n\n\nA frontend is a set of rules that forwards the incoming traffic from an entrypoint to a backend.\nFrontends can be defined using the following rules:\n\n\n\n\nHeaders: Content-Type, application/json\n: Headers adds a matcher for request header values. It accepts a sequence of key/value pairs to be matched.\n\n\nHeadersRegexp: Content-Type, application/(text|json)\n: Regular expressions can be used with headers as well. It accepts a sequence of key/value pairs, where the value has regex support.\n\n\nHost: traefik.io, www.traefik.io\n: Match request host with given host list.\n\n\nHostRegexp: traefik.io, {subdomain:[a-z]+}.traefik.io\n: Adds a matcher for the URL hosts. It accepts templates with zero or more URL variables enclosed by \n{}\n. Variables can define an optional regexp pattern to be matched.\n\n\nMethod: GET, POST, PUT\n: Method adds a matcher for HTTP methods. It accepts a sequence of one or more methods to be matched.\n\n\nPath: /products/, /articles/{category}/{id:[0-9]+}\n: Path adds a matcher for the URL paths. It accepts templates with zero or more URL variables enclosed by \n{}\n.\n\n\nPathStrip\n: Same as \nPath\n but strip the given prefix from the request URL's Path.\n\n\nPathPrefix\n: PathPrefix adds a matcher for the URL path prefixes. This matches if the given template is a prefix of the full URL path.\n\n\nPathPrefixStrip\n: Same as \nPathPrefix\n but strip the given prefix from the request URL's Path.\n\n\n\n\nYou can use multiple rules by separating them by \n;\n\n\nYou can optionally enable \npassHostHeader\n to forward client \nHost\n header to the backend.\n\n\nHere is an example of frontends definition:\n\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend2\n\n    [frontends.frontend1.routes.test_1]\n    rule = \nHost:test.localhost,test2.localhost\n\n  [frontends.frontend2]\n  backend = \nbackend1\n\n  passHostHeader = true\n  priority = 10\n  entrypoints = [\nhttps\n] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule = \nHost:localhost,{subdomain:[a-z]+}.localhost\n\n  [frontends.frontend3]\n  backend = \nbackend2\n\n    [frontends.frontend3.routes.test_1]\n    rule = \nHost:test3.localhost;Path:/test\n\n\n\n\n\n\n\nThree frontends are defined: \nfrontend1\n, \nfrontend2\n and \nfrontend3\n\n\nfrontend1\n will forward the traffic to the \nbackend2\n if the rule \nHost:test.localhost,test2.localhost\n is matched\n\n\nfrontend2\n will forward the traffic to the \nbackend1\n if the rule \nHost:localhost,{subdomain:[a-z]+}.localhost\n is matched (forwarding client \nHost\n header to the backend)\n\n\nfrontend3\n will forward the traffic to the \nbackend2\n if the rules \nHost:test3.localhost\n \nAND\n \nPath:/test\n are matched\n\n\n\n\nCombining multiple rules\n\n\nAs seen in the previous example, you can combine multiple rules.\nIn TOML file, you can use multiple routes:\n\n\n  [frontends.frontend3]\n  backend = \nbackend2\n\n    [frontends.frontend3.routes.test_1]\n    rule = \nHost:test3.localhost\n\n    [frontends.frontend3.routes.test_2]\n    rule = \nHost:Path:/test\n\n\n\n\n\nHere \nfrontend3\n will forward the traffic to the \nbackend2\n if the rules \nHost:test3.localhost\n \nAND\n \nPath:/test\n are matched.\nYou can also use the notation using a \n;\n separator, same result:\n\n\n  [frontends.frontend3]\n  backend = \nbackend2\n\n    [frontends.frontend3.routes.test_1]\n    rule = \nHost:test3.localhost;Path:/test\n\n\n\n\n\nFinally, you can create a rule to bind multiple domains or Path to a frontend, using the \n,\n separator:\n\n\n [frontends.frontend2]\n    [frontends.frontend2.routes.test_1]\n    rule = \nHost:test1.localhost,test2.localhost\n\n  [frontends.frontend3]\n  backend = \nbackend2\n\n    [frontends.frontend3.routes.test_1]\n    rule = \nPath:/test1,/test2\n\n\n\n\n\nPriorities\n\n\nBy default, routes will be sorted (in descending order) using rules length (to avoid path overlap):\n\nPathPrefix:/12345\n will be matched before \nPathPrefix:/1234\n that will be matched before \nPathPrefix:/1\n.\n\n\nYou can customize priority by frontend:\n\n\n  [frontends]\n    [frontends.frontend1]\n    backend = \nbackend1\n\n    priority = 10\n    passHostHeader = true\n      [frontends.frontend1.routes.test_1]\n      rule = \nPathPrefix:/to\n\n    [frontends.frontend2]\n    priority = 5\n    backend = \nbackend2\n\n    passHostHeader = true\n      [frontends.frontend2.routes.test_1]\n      rule = \nPathPrefix:/toto\n\n\n\n\n\nHere, \nfrontend1\n will be matched before \nfrontend2\n (\n10 \n 5\n).\n\n\nBackends\n\n\nA backend is responsible to load-balance the traffic coming from one or more frontends to a set of http servers.\nVarious methods of load-balancing is supported:\n\n\n\n\nwrr\n: Weighted Round Robin\n\n\ndrr\n: Dynamic Round Robin: increases weights on servers that perform better than others. It also rolls back to original weights if the servers have changed.\n\n\n\n\nA circuit breaker can also be applied to a backend, preventing high loads on failing servers.\nInitial state is Standby. CB observes the statistics and does not modify the request.\nIn case if condition matches, CB enters Tripped state, where it responds with predefines code or redirects to another frontend.\nOnce Tripped timer expires, CB enters Recovering state and resets all stats.\nIn case if the condition does not match and recovery timer expires, CB enters Standby state.\n\n\nIt can be configured using:\n\n\n\n\nMethods: \nLatencyAtQuantileMS\n, \nNetworkErrorRatio\n, \nResponseCodeRatio\n\n\nOperators:  \nAND\n, \nOR\n, \nEQ\n, \nNEQ\n, \nLT\n, \nLE\n, \nGT\n, \nGE\n\n\n\n\nFor example:\n\n\n\n\nNetworkErrorRatio() \n 0.5\n: watch error ratio over 10 second sliding window for a frontend\n\n\nLatencyAtQuantileMS(50.0) \n 50\n:  watch latency at quantile in milliseconds.\n\n\nResponseCodeRatio(500, 600, 0, 600) \n 0.5\n: ratio of response codes in range [500-600) to  [0-600)\n\n\n\n\nTo proactively prevent backends from being overwhelmed with high load, a maximum connection limit can\nalso be applied to each backend.\n\n\nMaximum connections can be configured by specifying an integer value for \nmaxconn.amount\n and\n\nmaxconn.extractorfunc\n which is a strategy used to determine how to categorize requests in order to\nevaluate the maximum connections.\n\n\nFor example:\n\n\n[backends]\n  [backends.backend1]\n    [backends.backend1.maxconn]\n       amount = 10\n       extractorfunc = \nrequest.host\n\n\n\n\n\n\n\nbackend1\n will return \nHTTP code 429 Too Many Requests\n if there are already 10 requests in progress for the same Host header.\n\n\nAnother possible value for \nextractorfunc\n is \nclient.ip\n which will categorize requests based on client source ip.\n\n\nLastly \nextractorfunc\n can take the value of \nrequest.header.ANY_HEADER\n which will categorize requests based on \nANY_HEADER\n that you provide.\n\n\n\n\nServers\n\n\nServers are simply defined using a \nURL\n. You can also apply a custom \nweight\n to each server (this will be used by load-balancing).\n\n\nHere is an example of backends and servers definition:\n\n\n[backends]\n  [backends.backend1]\n    [backends.backend1.circuitbreaker]\n      expression = \nNetworkErrorRatio() \n 0.5\n\n    [backends.backend1.servers.server1]\n    url = \nhttp://172.17.0.2:80\n\n    weight = 10\n    [backends.backend1.servers.server2]\n    url = \nhttp://172.17.0.3:80\n\n    weight = 1\n  [backends.backend2]\n    [backends.backend2.LoadBalancer]\n      method = \ndrr\n\n    [backends.backend2.servers.server1]\n    url = \nhttp://172.17.0.4:80\n\n    weight = 1\n    [backends.backend2.servers.server2]\n    url = \nhttp://172.17.0.5:80\n\n    weight = 2\n\n\n\n\n\n\nTwo backends are defined: \nbackend1\n and \nbackend2\n\n\nbackend1\n will forward the traffic to two servers: \nhttp://172.17.0.2:80\"\n with weight \n10\n and \nhttp://172.17.0.3:80\n with weight \n1\n using default \nwrr\n load-balancing strategy.\n\n\nbackend2\n will forward the traffic to two servers: \nhttp://172.17.0.4:80\"\n with weight \n1\n and \nhttp://172.17.0.5:80\n with weight \n2\n using \ndrr\n load-balancing strategy.\n\n\na circuit breaker is added on \nbackend1\n using the expression \nNetworkErrorRatio() \n 0.5\n: watch error ratio over 10 second sliding window\n\n\n\n\nLaunch\n\n\nTr\u00e6f\u026ak can be configured using a TOML file configuration, arguments, or both.\nBy default, Tr\u00e6f\u026ak will try to find a \ntraefik.toml\n in the following places:\n\n\n\n\n/etc/traefik/\n\n\n$HOME/.traefik/\n\n\n.\n \nthe working directory\n\n\n\n\nYou can override this by setting a \nconfigFile\n argument:\n\n\n$ traefik --configFile=foo/bar/myconfigfile.toml\n\n\n\n\nTr\u00e6f\u026ak uses the following precedence order. Each item takes precedence over the item below it:\n\n\n\n\narguments\n\n\nconfiguration file\n\n\ndefault\n\n\n\n\nIt means that arguments overrides configuration file.\nEach argument is described in the help section:\n\n\n$ traefik --help", 
            "title": "Basics"
        }, 
        {
            "location": "/basics/#concepts", 
            "text": "Let's take our example from the  overview  again:   Imagine that you have deployed a bunch of microservices on your infrastructure. You probably used a service registry (like etcd or consul) and/or an orchestrator (swarm, Mesos/Marathon) to manage all these services.\nIf you want your users to access some of your microservices from the Internet, you will have to use a reverse proxy and configure it using virtual hosts or prefix paths:   domain  api.domain.com  will point the microservice  api  in your private network  path  domain.com/web  will point the microservice  web  in your private network  domain  backoffice.domain.com  will point the microservices  backoffice  in your private network, load-balancing between your multiple instances     Let's zoom on Tr\u00e6f\u026ak and have an overview of its internal architecture:    Incoming requests end on  entrypoints , as the name suggests, they are the network entry points into Tr\u00e6f\u026ak (listening port, SSL, traffic redirection...).  Traffic is then forwarded to a matching  frontend . A frontend defines routes from  entrypoints  to  backends .\nRoutes are created using requests fields ( Host ,  Path ,  Headers ...) and can match or not a request.  The  frontend  will then send the request to a  backend . A backend can be composed by one or more  servers , and by a load-balancing strategy.  Finally, the  server  will forward the request to the corresponding microservice in the private network.", 
            "title": "Concepts"
        }, 
        {
            "location": "/basics/#entrypoints", 
            "text": "Entrypoints are the network entry points into Tr\u00e6f\u026ak.\nThey can be defined using:   a port (80, 443...)  SSL (Certificates. Keys...)  redirection to another entrypoint (redirect  HTTP  to  HTTPS )   Here is an example of entrypoints definition:  [entryPoints]\n  [entryPoints.http]\n  address =  :80 \n    [entryPoints.http.redirect]\n    entryPoint =  https \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile =  tests/traefik.crt \n      keyFile =  tests/traefik.key    Two entrypoints are defined  http  and  https .  http  listens on port  80  and  https  on port  443 .  We enable SSL on  https  by giving a certificate and a key.  We also redirect all the traffic from entrypoint  http  to  https .", 
            "title": "Entrypoints"
        }, 
        {
            "location": "/basics/#frontends", 
            "text": "A frontend is a set of rules that forwards the incoming traffic from an entrypoint to a backend.\nFrontends can be defined using the following rules:   Headers: Content-Type, application/json : Headers adds a matcher for request header values. It accepts a sequence of key/value pairs to be matched.  HeadersRegexp: Content-Type, application/(text|json) : Regular expressions can be used with headers as well. It accepts a sequence of key/value pairs, where the value has regex support.  Host: traefik.io, www.traefik.io : Match request host with given host list.  HostRegexp: traefik.io, {subdomain:[a-z]+}.traefik.io : Adds a matcher for the URL hosts. It accepts templates with zero or more URL variables enclosed by  {} . Variables can define an optional regexp pattern to be matched.  Method: GET, POST, PUT : Method adds a matcher for HTTP methods. It accepts a sequence of one or more methods to be matched.  Path: /products/, /articles/{category}/{id:[0-9]+} : Path adds a matcher for the URL paths. It accepts templates with zero or more URL variables enclosed by  {} .  PathStrip : Same as  Path  but strip the given prefix from the request URL's Path.  PathPrefix : PathPrefix adds a matcher for the URL path prefixes. This matches if the given template is a prefix of the full URL path.  PathPrefixStrip : Same as  PathPrefix  but strip the given prefix from the request URL's Path.   You can use multiple rules by separating them by  ;  You can optionally enable  passHostHeader  to forward client  Host  header to the backend.  Here is an example of frontends definition:  [frontends]\n  [frontends.frontend1]\n  backend =  backend2 \n    [frontends.frontend1.routes.test_1]\n    rule =  Host:test.localhost,test2.localhost \n  [frontends.frontend2]\n  backend =  backend1 \n  passHostHeader = true\n  priority = 10\n  entrypoints = [ https ] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule =  Host:localhost,{subdomain:[a-z]+}.localhost \n  [frontends.frontend3]\n  backend =  backend2 \n    [frontends.frontend3.routes.test_1]\n    rule =  Host:test3.localhost;Path:/test    Three frontends are defined:  frontend1 ,  frontend2  and  frontend3  frontend1  will forward the traffic to the  backend2  if the rule  Host:test.localhost,test2.localhost  is matched  frontend2  will forward the traffic to the  backend1  if the rule  Host:localhost,{subdomain:[a-z]+}.localhost  is matched (forwarding client  Host  header to the backend)  frontend3  will forward the traffic to the  backend2  if the rules  Host:test3.localhost   AND   Path:/test  are matched", 
            "title": "Frontends"
        }, 
        {
            "location": "/basics/#combining-multiple-rules", 
            "text": "As seen in the previous example, you can combine multiple rules.\nIn TOML file, you can use multiple routes:    [frontends.frontend3]\n  backend =  backend2 \n    [frontends.frontend3.routes.test_1]\n    rule =  Host:test3.localhost \n    [frontends.frontend3.routes.test_2]\n    rule =  Host:Path:/test   Here  frontend3  will forward the traffic to the  backend2  if the rules  Host:test3.localhost   AND   Path:/test  are matched.\nYou can also use the notation using a  ;  separator, same result:    [frontends.frontend3]\n  backend =  backend2 \n    [frontends.frontend3.routes.test_1]\n    rule =  Host:test3.localhost;Path:/test   Finally, you can create a rule to bind multiple domains or Path to a frontend, using the  ,  separator:   [frontends.frontend2]\n    [frontends.frontend2.routes.test_1]\n    rule =  Host:test1.localhost,test2.localhost \n  [frontends.frontend3]\n  backend =  backend2 \n    [frontends.frontend3.routes.test_1]\n    rule =  Path:/test1,/test2", 
            "title": "Combining multiple rules"
        }, 
        {
            "location": "/basics/#priorities", 
            "text": "By default, routes will be sorted (in descending order) using rules length (to avoid path overlap): PathPrefix:/12345  will be matched before  PathPrefix:/1234  that will be matched before  PathPrefix:/1 .  You can customize priority by frontend:    [frontends]\n    [frontends.frontend1]\n    backend =  backend1 \n    priority = 10\n    passHostHeader = true\n      [frontends.frontend1.routes.test_1]\n      rule =  PathPrefix:/to \n    [frontends.frontend2]\n    priority = 5\n    backend =  backend2 \n    passHostHeader = true\n      [frontends.frontend2.routes.test_1]\n      rule =  PathPrefix:/toto   Here,  frontend1  will be matched before  frontend2  ( 10   5 ).", 
            "title": "Priorities"
        }, 
        {
            "location": "/basics/#backends", 
            "text": "A backend is responsible to load-balance the traffic coming from one or more frontends to a set of http servers.\nVarious methods of load-balancing is supported:   wrr : Weighted Round Robin  drr : Dynamic Round Robin: increases weights on servers that perform better than others. It also rolls back to original weights if the servers have changed.   A circuit breaker can also be applied to a backend, preventing high loads on failing servers.\nInitial state is Standby. CB observes the statistics and does not modify the request.\nIn case if condition matches, CB enters Tripped state, where it responds with predefines code or redirects to another frontend.\nOnce Tripped timer expires, CB enters Recovering state and resets all stats.\nIn case if the condition does not match and recovery timer expires, CB enters Standby state.  It can be configured using:   Methods:  LatencyAtQuantileMS ,  NetworkErrorRatio ,  ResponseCodeRatio  Operators:   AND ,  OR ,  EQ ,  NEQ ,  LT ,  LE ,  GT ,  GE   For example:   NetworkErrorRatio()   0.5 : watch error ratio over 10 second sliding window for a frontend  LatencyAtQuantileMS(50.0)   50 :  watch latency at quantile in milliseconds.  ResponseCodeRatio(500, 600, 0, 600)   0.5 : ratio of response codes in range [500-600) to  [0-600)   To proactively prevent backends from being overwhelmed with high load, a maximum connection limit can\nalso be applied to each backend.  Maximum connections can be configured by specifying an integer value for  maxconn.amount  and maxconn.extractorfunc  which is a strategy used to determine how to categorize requests in order to\nevaluate the maximum connections.  For example:  [backends]\n  [backends.backend1]\n    [backends.backend1.maxconn]\n       amount = 10\n       extractorfunc =  request.host    backend1  will return  HTTP code 429 Too Many Requests  if there are already 10 requests in progress for the same Host header.  Another possible value for  extractorfunc  is  client.ip  which will categorize requests based on client source ip.  Lastly  extractorfunc  can take the value of  request.header.ANY_HEADER  which will categorize requests based on  ANY_HEADER  that you provide.", 
            "title": "Backends"
        }, 
        {
            "location": "/basics/#servers", 
            "text": "Servers are simply defined using a  URL . You can also apply a custom  weight  to each server (this will be used by load-balancing).  Here is an example of backends and servers definition:  [backends]\n  [backends.backend1]\n    [backends.backend1.circuitbreaker]\n      expression =  NetworkErrorRatio()   0.5 \n    [backends.backend1.servers.server1]\n    url =  http://172.17.0.2:80 \n    weight = 10\n    [backends.backend1.servers.server2]\n    url =  http://172.17.0.3:80 \n    weight = 1\n  [backends.backend2]\n    [backends.backend2.LoadBalancer]\n      method =  drr \n    [backends.backend2.servers.server1]\n    url =  http://172.17.0.4:80 \n    weight = 1\n    [backends.backend2.servers.server2]\n    url =  http://172.17.0.5:80 \n    weight = 2   Two backends are defined:  backend1  and  backend2  backend1  will forward the traffic to two servers:  http://172.17.0.2:80\"  with weight  10  and  http://172.17.0.3:80  with weight  1  using default  wrr  load-balancing strategy.  backend2  will forward the traffic to two servers:  http://172.17.0.4:80\"  with weight  1  and  http://172.17.0.5:80  with weight  2  using  drr  load-balancing strategy.  a circuit breaker is added on  backend1  using the expression  NetworkErrorRatio()   0.5 : watch error ratio over 10 second sliding window", 
            "title": "Servers"
        }, 
        {
            "location": "/basics/#launch", 
            "text": "Tr\u00e6f\u026ak can be configured using a TOML file configuration, arguments, or both.\nBy default, Tr\u00e6f\u026ak will try to find a  traefik.toml  in the following places:   /etc/traefik/  $HOME/.traefik/  .   the working directory   You can override this by setting a  configFile  argument:  $ traefik --configFile=foo/bar/myconfigfile.toml  Tr\u00e6f\u026ak uses the following precedence order. Each item takes precedence over the item below it:   arguments  configuration file  default   It means that arguments overrides configuration file.\nEach argument is described in the help section:  $ traefik --help", 
            "title": "Launch"
        }, 
        {
            "location": "/toml/", 
            "text": "Global configuration\n\n\nMain section\n\n\n# traefik.toml\n################################################################\n# Global configuration\n################################################################\n\n# Traefik logs file\n# If not defined, logs to stdout\n#\n# Optional\n#\n# traefikLogsFile = \nlog/traefik.log\n\n\n# Access logs file\n#\n# Optional\n#\n# accessLogsFile = \nlog/access.log\n\n\n# Log level\n#\n# Optional\n# Default: \nERROR\n\n#\n# logLevel = \nERROR\n\n\n# Backends throttle duration: minimum duration between 2 events from providers\n# before applying a new configuration. It avoids unnecessary reloads if multiples events\n# are sent in a short amount of time.\n#\n# Optional\n# Default: \n2s\n\n#\n# ProvidersThrottleDuration = \n5s\n\n\n# If non-zero, controls the maximum idle (keep-alive) to keep per-host.  If zero, DefaultMaxIdleConnsPerHost is used.\n# If you encounter 'too many open files' errors, you can either change this value, or change `ulimit` value.\n#\n# Optional\n# Default: http.DefaultMaxIdleConnsPerHost\n#\n# MaxIdleConnsPerHost = 200\n\n# Entrypoints to be used by frontends that do not specify any entrypoint.\n# Each frontend can specify its own entrypoints.\n#\n# Optional\n# Default: [\nhttp\n]\n#\n# defaultEntryPoints = [\nhttp\n, \nhttps\n]\n\n\n\n\nEntrypoints definition\n\n\n# Entrypoints definition\n#\n# Optional\n# Default:\n# [entryPoints]\n#   [entryPoints.http]\n#   address = \n:80\n\n#\n# To redirect an http entrypoint to an https entrypoint (with SNI support):\n# [entryPoints]\n#   [entryPoints.http]\n#   address = \n:80\n\n#     [entryPoints.http.redirect]\n#       entryPoint = \nhttps\n\n#   [entryPoints.https]\n#   address = \n:443\n\n#     [entryPoints.https.tls]\n#       [[entryPoints.https.tls.certificates]]\n#       CertFile = \nintegration/fixtures/https/snitest.com.cert\n\n#       KeyFile = \nintegration/fixtures/https/snitest.com.key\n\n#       [[entryPoints.https.tls.certificates]]\n#       CertFile = \nintegration/fixtures/https/snitest.org.cert\n\n#       KeyFile = \nintegration/fixtures/https/snitest.org.key\n\n#\n# To redirect an entrypoint rewriting the URL:\n# [entryPoints]\n#   [entryPoints.http]\n#   address = \n:80\n\n#     [entryPoints.http.redirect]\n#       regex = \n^http://localhost/(.*)\n\n#       replacement = \nhttp://mydomain/$1\n\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n\n\n\n\nRetry configuration\n\n\n# Enable retry sending request if network error\n#\n# Optional\n#\n[retry]\n\n# Number of attempts\n#\n# Optional\n# Default: (number servers in backend) -1\n#\n# attempts = 3\n\n\n\n\nACME (Let's Encrypt) configuration\n\n\n# Sample entrypoint configuration when using ACME\n[entryPoints]\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n\n# Enable ACME (Let's Encrypt): automatic SSL\n#\n# Optional\n#\n[acme]\n\n# Email address used for registration\n#\n# Required\n#\nemail = \ntest@traefik.io\n\n\n# File used for certificates storage.\n# WARNING, if you use Traefik in Docker, you have 2 options:\n#  - create a file on your host and mount it has a volume\n#      storageFile = \nacme.json\n\n#      $ docker run -v \n/my/host/acme.json:acme.json\n traefik\n#  - mount the folder containing the file has a volume\n#      storageFile = \n/etc/traefik/acme/acme.json\n\n#      $ docker run -v \n/my/host/acme:/etc/traefik/acme\n traefik\n#\n# Required\n#\nstorageFile = \nacme.json\n\n\n# Entrypoint to proxy acme challenge to.\n# WARNING, must point to an entrypoint on port 443\n#\n# Required\n#\nentryPoint = \nhttps\n\n\n# Enable on demand certificate. This will request a certificate from Let's Encrypt during the first TLS handshake for a hostname that does not yet have a certificate.\n# WARNING, TLS handshakes will be slow when requesting a hostname certificate for the first time, this can leads to DoS attacks.\n# WARNING, Take note that Let's Encrypt have rate limiting: https://community.letsencrypt.org/t/quick-start-guide/1631\n#\n# Optional\n#\n# onDemand = true\n\n# CA server to use\n# Uncomment the line to run on the staging let's encrypt server\n# Leave comment to go to prod\n#\n# Optional\n#\n# caServer = \nhttps://acme-staging.api.letsencrypt.org/directory\n\n\n# Domains list\n# You can provide SANs (alternative domains) to each main domain\n# All domains must have A/AAAA records pointing to Traefik\n# WARNING, Take note that Let's Encrypt have rate limiting: https://community.letsencrypt.org/t/quick-start-guide/1631\n# Each domain \n SANs will lead to a certificate request.\n#\n# [[acme.domains]]\n#   main = \nlocal1.com\n\n#   sans = [\ntest1.local1.com\n, \ntest2.local1.com\n]\n# [[acme.domains]]\n#   main = \nlocal2.com\n\n#   sans = [\ntest1.local2.com\n, \ntest2x.local2.com\n]\n# [[acme.domains]]\n#   main = \nlocal3.com\n\n# [[acme.domains]]\n#   main = \nlocal4.com\n\n[[acme.domains]]\n   main = \nlocal1.com\n\n   sans = [\ntest1.local1.com\n, \ntest2.local1.com\n]\n[[acme.domains]]\n   main = \nlocal3.com\n\n[[acme.domains]]\n   main = \nlocal4.com\n\n\n\n\n\nConfiguration backends\n\n\nFile backend\n\n\nLike any other reverse proxy, Tr\u00e6f\u026ak can be configured with a file. You have two choices:\n\n\n\n\nsimply add your configuration at the end of the global configuration file \ntraefik.toml\n :\n\n\n\n\n# traefik.toml\nlogLevel = \nDEBUG\n\ndefaultEntryPoints = [\nhttp\n, \nhttps\n]\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n    [entryPoints.http.redirect]\n      entryPoint = \nhttps\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \nintegration/fixtures/https/snitest.com.cert\n\n      KeyFile = \nintegration/fixtures/https/snitest.com.key\n\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \nintegration/fixtures/https/snitest.org.cert\n\n      KeyFile = \nintegration/fixtures/https/snitest.org.key\n\n\n[file]\n\n# rules\n[backends]\n  [backends.backend1]\n    [backends.backend1.circuitbreaker]\n      expression = \nNetworkErrorRatio() \n 0.5\n\n    [backends.backend1.servers.server1]\n    url = \nhttp://172.17.0.2:80\n\n    weight = 10\n    [backends.backend1.servers.server2]\n    url = \nhttp://172.17.0.3:80\n\n    weight = 1\n  [backends.backend2]\n    [backends.backend1.maxconn]\n      amount = 10\n      extractorfunc = \nrequest.host\n\n    [backends.backend2.LoadBalancer]\n      method = \ndrr\n\n    [backends.backend2.servers.server1]\n    url = \nhttp://172.17.0.4:80\n\n    weight = 1\n    [backends.backend2.servers.server2]\n    url = \nhttp://172.17.0.5:80\n\n    weight = 2\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend2\n\n    [frontends.frontend1.routes.test_1]\n    rule = \nHost:test.localhost\n\n  [frontends.frontend2]\n  backend = \nbackend1\n\n  passHostHeader = true\n  priority = 10\n  entrypoints = [\nhttps\n] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule = \nHost:{subdomain:[a-z]+}.localhost\n\n  [frontends.frontend3]\n  entrypoints = [\nhttp\n, \nhttps\n] # overrides defaultEntryPoints\n  backend = \nbackend2\n\n    rule = \nPath:/test\n\n\n\n\n\n\n\nor put your rules in a separate file, for example \nrules.toml\n:\n\n\n\n\n# traefik.toml\nlogLevel = \nDEBUG\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n    [entryPoints.http.redirect]\n      entryPoint = \nhttps\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \nintegration/fixtures/https/snitest.com.cert\n\n      KeyFile = \nintegration/fixtures/https/snitest.com.key\n\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \nintegration/fixtures/https/snitest.org.cert\n\n      KeyFile = \nintegration/fixtures/https/snitest.org.key\n\n\n[file]\nfilename = \nrules.toml\n\n\n\n\n\n# rules.toml\n[backends]\n  [backends.backend1]\n    [backends.backend1.circuitbreaker]\n      expression = \nNetworkErrorRatio() \n 0.5\n\n    [backends.backend1.servers.server1]\n    url = \nhttp://172.17.0.2:80\n\n    weight = 10\n    [backends.backend1.servers.server2]\n    url = \nhttp://172.17.0.3:80\n\n    weight = 1\n  [backends.backend2]\n    [backends.backend1.maxconn]\n      amount = 10\n      extractorfunc = \nrequest.host\n\n    [backends.backend2.LoadBalancer]\n      method = \ndrr\n\n    [backends.backend2.servers.server1]\n    url = \nhttp://172.17.0.4:80\n\n    weight = 1\n    [backends.backend2.servers.server2]\n    url = \nhttp://172.17.0.5:80\n\n    weight = 2\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend2\n\n    [frontends.frontend1.routes.test_1]\n    rule = \nHost:test.localhost\n\n  [frontends.frontend2]\n  backend = \nbackend1\n\n  passHostHeader = true\n  priority = 10\n  entrypoints = [\nhttps\n] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule = \nHost:{subdomain:[a-z]+}.localhost\n\n  [frontends.frontend3]\n  entrypoints = [\nhttp\n, \nhttps\n] # overrides defaultEntryPoints\n  backend = \nbackend2\n\n    rule = \nPath:/test\n\n\n\n\n\nIf you want Tr\u00e6f\u026ak to watch file changes automatically, just add:\n\n\n[file]\nwatch = true\n\n\n\n\nAPI backend\n\n\nTr\u00e6fik can be configured using a restful api.\nTo enable it:\n\n\n[web]\naddress = \n:8080\n\n\n# SSL certificate and key used\n#\n# Optional\n#\n# CertFile = \ntraefik.crt\n\n# KeyFile = \ntraefik.key\n\n#\n# Set REST API to read-only mode\n#\n# Optional\n# ReadOnly = false\n\n\n\n\n\n\n/\n: provides a simple HTML frontend of Tr\u00e6fik\n\n\n\n\n\n\n\n\n\n\n/health\n: \nGET\n json metrics\n\n\n\n\n$ curl -s \nhttp://localhost:8080/health\n | jq .\n{\n  // Tr\u00e6f\u026ak PID\n  \npid\n: 2458,\n  // Tr\u00e6f\u026ak server uptime (formated time)\n  \nuptime\n: \n39m6.885931127s\n,\n  //  Tr\u00e6f\u026ak server uptime in seconds\n  \nuptime_sec\n: 2346.885931127,\n  // current server date\n  \ntime\n: \n2015-10-07 18:32:24.362238909 +0200 CEST\n,\n  // current server date in seconds\n  \nunixtime\n: 1444235544,\n  // count HTTP response status code in realtime\n  \nstatus_code_count\n: {\n    \n502\n: 1\n  },\n  // count HTTP response status code since Tr\u00e6f\u026ak started\n  \ntotal_status_code_count\n: {\n    \n200\n: 7,\n    \n404\n: 21,\n    \n502\n: 13\n  },\n  // count HTTP response\n  \ncount\n: 1,\n  // count HTTP response\n  \ntotal_count\n: 41,\n  // sum of all response time (formated time)\n  \ntotal_response_time\n: \n35.456865605s\n,\n  // sum of all response time in seconds\n  \ntotal_response_time_sec\n: 35.456865605,\n  // average response time (formated time)\n  \naverage_response_time\n: \n864.8016ms\n,\n  // average response time in seconds\n  \naverage_response_time_sec\n: 0.8648016000000001\n}\n\n\n\n\n\n\n/api\n: \nGET\n configuration for all providers\n\n\n\n\n$ curl -s \nhttp://localhost:8080/api\n | jq .\n{\n  \nfile\n: {\n    \nfrontends\n: {\n      \nfrontend2\n: {\n        \nroutes\n: {\n          \ntest_2\n: {\n            \nrule\n: \nPath:/test\n\n          }\n        },\n        \nbackend\n: \nbackend1\n\n      },\n      \nfrontend1\n: {\n        \nroutes\n: {\n          \ntest_1\n: {\n            \nrule\n: \nHost:test.localhost\n\n          }\n        },\n        \nbackend\n: \nbackend2\n\n      }\n    },\n    \nbackends\n: {\n      \nbackend2\n: {\n        \nloadBalancer\n: {\n          \nmethod\n: \ndrr\n\n        },\n        \nservers\n: {\n          \nserver2\n: {\n            \nweight\n: 2,\n            \nURL\n: \nhttp://172.17.0.5:80\n\n          },\n          \nserver1\n: {\n            \nweight\n: 1,\n            \nurl\n: \nhttp://172.17.0.4:80\n\n          }\n        }\n      },\n      \nbackend1\n: {\n        \nloadBalancer\n: {\n          \nmethod\n: \nwrr\n\n        },\n        \ncircuitBreaker\n: {\n          \nexpression\n: \nNetworkErrorRatio() \n 0.5\n\n        },\n        \nservers\n: {\n          \nserver2\n: {\n            \nweight\n: 1,\n            \nurl\n: \nhttp://172.17.0.3:80\n\n          },\n          \nserver1\n: {\n            \nweight\n: 10,\n            \nurl\n: \nhttp://172.17.0.2:80\n\n          }\n        }\n      }\n    }\n  }\n}\n\n\n\n\n\n\n/api/providers\n: \nGET\n providers\n\n\n/api/providers/{provider}\n: \nGET\n or \nPUT\n provider\n\n\n/api/providers/{provider}/backends\n: \nGET\n backends\n\n\n/api/providers/{provider}/backends/{backend}\n: \nGET\n a backend\n\n\n/api/providers/{provider}/backends/{backend}/servers\n: \nGET\n servers in a backend\n\n\n/api/providers/{provider}/backends/{backend}/servers/{server}\n: \nGET\n a server in a backend\n\n\n/api/providers/{provider}/frontends\n: \nGET\n frontends\n\n\n/api/providers/{provider}/frontends/{frontend}\n: \nGET\n a frontend\n\n\n/api/providers/{provider}/frontends/{frontend}/routes\n: \nGET\n routes in a frontend\n\n\n/api/providers/{provider}/frontends/{frontend}/routes/{route}\n: \nGET\n a route in a frontend\n\n\n\n\nDocker backend\n\n\nTr\u00e6f\u026ak can be configured to use Docker as a backend configuration:\n\n\n################################################################\n# Docker configuration backend\n################################################################\n\n# Enable Docker configuration backend\n#\n# Optional\n#\n[docker]\n\n# Docker server endpoint. Can be a tcp or a unix socket endpoint.\n#\n# Required\n#\nendpoint = \nunix:///var/run/docker.sock\n\n\n# Default domain used.\n# Can be overridden by setting the \ntraefik.domain\n label on a container.\n#\n# Required\n#\ndomain = \ndocker.localhost\n\n\n# Enable watch docker changes\n#\n# Optional\n#\nwatch = true\n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename = \ndocker.tmpl\n\n\n# Enable docker TLS connection\n#\n#  [docker.tls]\n#  ca = \n/etc/ssl/ca.crt\n\n#  cert = \n/etc/ssl/docker.crt\n\n#  key = \n/etc/ssl/docker.key\n\n#  insecureskipverify = true\n\n\n\n\nLabels can be used on containers to override default behaviour:\n\n\n\n\ntraefik.backend=foo\n: assign the container to \nfoo\n backend\n\n\ntraefik.port=80\n: register this port. Useful when the container exposes multiples ports.\n\n\ntraefik.protocol=https\n: override the default \nhttp\n protocol\n\n\ntraefik.weight=10\n: assign this weight to the container\n\n\ntraefik.enable=false\n: disable this container in Tr\u00e6f\u026ak\n\n\ntraefik.frontend.rule=Host:test.traefik.io\n: override the default frontend rule (Default: \nHost:{containerName}.{domain}\n).\n\n\ntraefik.frontend.passHostHeader=true\n: forward client \nHost\n header to the backend.\n\n\ntraefik.frontend.priority=10\n: override default frontend priority\n\n\ntraefik.frontend.entryPoints=http,https\n: assign this frontend to entry points \nhttp\n and \nhttps\n. Overrides \ndefaultEntryPoints\n.\n\n\ntraefik.docker.network\n: Set the docker network to use for connections to this container\n\n\n\n\nMarathon backend\n\n\nTr\u00e6f\u026ak can be configured to use Marathon as a backend configuration:\n\n\n################################################################\n# Mesos/Marathon configuration backend\n################################################################\n\n# Enable Marathon configuration backend\n#\n# Optional\n#\n[marathon]\n\n# Marathon server endpoint.\n# You can also specify multiple endpoint for Marathon:\n# endpoint := \nhttp://10.241.1.71:8080,10.241.1.72:8080,10.241.1.73:8080\n\n#\n# Required\n#\nendpoint = \nhttp://127.0.0.1:8080\n\n\n# Enable watch Marathon changes\n#\n# Optional\n#\nwatch = true\n\n# Default domain used.\n#\n# Required\n#\ndomain = \nmarathon.localhost\n\n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename = \nmarathon.tmpl\n\n\n# Expose Marathon apps by default in traefik\n#\n# Optional\n# Default: false\n#\n# exposedByDefault = true\n\n# Convert Marathon groups to subdomains\n# Default behavior: /foo/bar/myapp =\n foo-bar-myapp.{defaultDomain}\n# with groupsAsSubDomains enabled: /foo/bar/myapp =\n myapp.bar.foo.{defaultDomain}\n#\n# Optional\n# Default: false\n#\n# groupsAsSubDomains = true\n\n# Enable Marathon basic authentication\n#\n# Optional\n#\n#  [marathon.basic]\n#  httpBasicAuthUser = \nfoo\n\n#  httpBasicPassword = \nbar\n\n\n# TLS client configuration. https://golang.org/pkg/crypto/tls/#Config\n#\n# Optional\n#\n# [marathon.TLS]\n# InsecureSkipVerify = true\n\n# DCOSToken for DCOS environment, This will override the Authorization header\n#\n# Optional\n#\n# dcosToken = \nxxxxxx\n\n\n\n\n\nLabels can be used on containers to override default behaviour:\n\n\n\n\ntraefik.backend=foo\n: assign the application to \nfoo\n backend\n\n\ntraefik.portIndex=1\n: register port by index in the application's ports array. Useful when the application exposes multiple ports.\n\n\ntraefik.port=80\n: register the explicit application port value. Cannot be used alongside \ntraefik.portIndex\n.\n\n\ntraefik.protocol=https\n: override the default \nhttp\n protocol\n\n\ntraefik.weight=10\n: assign this weight to the application\n\n\ntraefik.enable=false\n: disable this application in Tr\u00e6f\u026ak\n\n\ntraefik.frontend.rule=Host:test.traefik.io\n: override the default frontend rule (Default: \nHost:{containerName}.{domain}\n).\n\n\ntraefik.frontend.passHostHeader=true\n: forward client \nHost\n header to the backend.\n\n\ntraefik.frontend.priority=10\n: override default frontend priority\n\n\ntraefik.frontend.entryPoints=http,https\n: assign this frontend to entry points \nhttp\n and \nhttps\n. Overrides \ndefaultEntryPoints\n.\n\n\n\n\nKubernetes Ingress backend\n\n\nTr\u00e6f\u026ak can be configured to use Kubernetes Ingress as a backend configuration:\n\n\n################################################################\n# Kubernetes Ingress configuration backend\n################################################################\n# Enable Kubernetes Ingress configuration backend\n#\n# Optional\n#\n[kubernetes]\n\n# Kubernetes server endpoint\n#\n# When deployed as a replication controller in Kubernetes,\n# Traefik will use env variable KUBERNETES_SERVICE_HOST\n# and KUBERNETES_SERVICE_PORT_HTTPS as endpoint\n# Secure token will be found in /var/run/secrets/kubernetes.io/serviceaccount/token\n# and SSL CA cert in /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n#\n# Optional\n#\n# endpoint = \nhttp://localhost:8080\n\n# namespaces = [\ndefault\n,\nproduction\n]\n\n\n\n\nAnnotations can be used on containers to override default behaviour for the whole Ingress resource:\n\n\n\n\ntraefik.frontend.rule.type: PathPrefixStrip\n: override the default frontend rule type (Default: \nPathPrefix\n).\n\n\n\n\nYou can find here an example \ningress\n and \nreplication controller\n.\n\n\nConsul backend\n\n\nTr\u00e6f\u026ak can be configured to use Consul as a backend configuration:\n\n\n################################################################\n# Consul KV configuration backend\n################################################################\n\n# Enable Consul KV configuration backend\n#\n# Optional\n#\n[consul]\n\n# Consul server endpoint\n#\n# Required\n#\nendpoint = \n127.0.0.1:8500\n\n\n# Enable watch Consul changes\n#\n# Optional\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n#\nprefix = \ntraefik\n\n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename = \nconsul.tmpl\n\n\n# Enable consul TLS connection\n#\n# Optional\n#\n# [consul.tls]\n# ca = \n/etc/ssl/ca.crt\n\n# cert = \n/etc/ssl/consul.crt\n\n# key = \n/etc/ssl/consul.key\n\n# insecureskipverify = true\n\n\n\n\nPlease refer to the \nKey Value storage structure\n section to get documentation en traefik KV structure.\n\n\nConsul catalog backend\n\n\nTr\u00e6f\u026ak can be configured to use service discovery catalog of Consul as a backend configuration:\n\n\n################################################################\n# Consul Catalog configuration backend\n################################################################\n\n# Enable Consul Catalog configuration backend\n#\n# Optional\n#\n[consulCatalog]\n\n# Consul server endpoint\n#\n# Required\n#\nendpoint = \n127.0.0.1:8500\n\n\n# Default domain used.\n#\n# Optional\n#\ndomain = \nconsul.localhost\n\n\n# Prefix for Consul catalog tags\n#\n# Optional\n#\nprefix = \ntraefik\n\n\n\n\n\nThis backend will create routes matching on hostname based on the service name\nused in consul.\n\n\nAdditional settings can be defined using Consul Catalog tags:\n\n\n\n\ntraefik.enable=false\n: disable this container in Tr\u00e6f\u026ak\n\n\ntraefik.protocol=https\n: override the default \nhttp\n protocol\n\n\ntraefik.backend.weight=10\n: assign this weight to the container\n\n\ntraefik.backend.circuitbreaker=NetworkErrorRatio() \n 0.5\n\n\ntraefik.backend.loadbalancer=drr\n: override the default load balancing mode\n\n\ntraefik.frontend.rule=Host:test.traefik.io\n: override the default frontend rule (Default: \nHost:{containerName}.{domain}\n).\n\n\ntraefik.frontend.passHostHeader=true\n: forward client \nHost\n header to the backend.\n\n\ntraefik.frontend.priority=10\n: override default frontend priority\n\n\ntraefik.frontend.entryPoints=http,https\n: assign this frontend to entry points \nhttp\n and \nhttps\n. Overrides \ndefaultEntryPoints\n.\n\n\n\n\nEtcd backend\n\n\nTr\u00e6f\u026ak can be configured to use Etcd as a backend configuration:\n\n\n################################################################\n# Etcd configuration backend\n################################################################\n\n# Enable Etcd configuration backend\n#\n# Optional\n#\n[etcd]\n\n# Etcd server endpoint\n#\n# Required\n#\nendpoint = \n127.0.0.1:2379\n\n\n# Enable watch Etcd changes\n#\n# Optional\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n#\nprefix = \n/traefik\n\n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename = \netcd.tmpl\n\n\n# Enable etcd TLS connection\n#\n# Optional\n#\n# [etcd.tls]\n# ca = \n/etc/ssl/ca.crt\n\n# cert = \n/etc/ssl/etcd.crt\n\n# key = \n/etc/ssl/etcd.key\n\n# insecureskipverify = true\n\n\n\n\nPlease refer to the \nKey Value storage structure\n section to get documentation en traefik KV structure.\n\n\nZookeeper backend\n\n\nTr\u00e6f\u026ak can be configured to use Zookeeper as a backend configuration:\n\n\n################################################################\n# Zookeeper configuration backend\n################################################################\n\n# Enable Zookeeperconfiguration backend\n#\n# Optional\n#\n[zookeeper]\n\n# Zookeeper server endpoint\n#\n# Required\n#\nendpoint = \n127.0.0.1:2181\n\n\n# Enable watch Zookeeper changes\n#\n# Optional\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n#\nprefix = \n/traefik\n\n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename = \nzookeeper.tmpl\n\n\n\n\n\nPlease refer to the \nKey Value storage structure\n section to get documentation en traefik KV structure.\n\n\nBoltDB backend\n\n\nTr\u00e6f\u026ak can be configured to use BoltDB as a backend configuration:\n\n\n################################################################\n# BoltDB configuration backend\n################################################################\n\n# Enable BoltDB configuration backend\n#\n# Optional\n#\n[boltdb]\n\n# BoltDB file\n#\n# Required\n#\nendpoint = \n/my.db\n\n\n# Enable watch BoltDB changes\n#\n# Optional\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n#\nprefix = \n/traefik\n\n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename = \nboltdb.tmpl\n\n\n\n\n\nPlease refer to the \nKey Value storage structure\n section to get documentation en traefik KV structure.\n\n\nKey-value storage structure\n\n\nThe Keys-Values structure should look (using \nprefix = \"/traefik\"\n):\n\n\n\n\nbackend 1\n\n\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/backends/backend1/circuitbreaker/expression\n\n\nNetworkErrorRatio() \n 0.5\n\n\n\n\n\n\n/traefik/backends/backend1/servers/server1/url\n\n\nhttp://172.17.0.2:80\n\n\n\n\n\n\n/traefik/backends/backend1/servers/server1/weight\n\n\n10\n\n\n\n\n\n\n/traefik/backends/backend1/servers/server2/url\n\n\nhttp://172.17.0.3:80\n\n\n\n\n\n\n/traefik/backends/backend1/servers/server2/weight\n\n\n1\n\n\n\n\n\n\n\n\n\n\nbackend 2\n\n\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/backends/backend2/maxconn/amount\n\n\n10\n\n\n\n\n\n\n/traefik/backends/backend2/maxconn/extractorfunc\n\n\nrequest.host\n\n\n\n\n\n\n/traefik/backends/backend2/loadbalancer/method\n\n\ndrr\n\n\n\n\n\n\n/traefik/backends/backend2/servers/server1/url\n\n\nhttp://172.17.0.4:80\n\n\n\n\n\n\n/traefik/backends/backend2/servers/server1/weight\n\n\n1\n\n\n\n\n\n\n/traefik/backends/backend2/servers/server2/url\n\n\nhttp://172.17.0.5:80\n\n\n\n\n\n\n/traefik/backends/backend2/servers/server2/weight\n\n\n2\n\n\n\n\n\n\n\n\n\n\nfrontend 1\n\n\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/frontends/frontend1/backend\n\n\nbackend2\n\n\n\n\n\n\n/traefik/frontends/frontend1/routes/test_1/rule\n\n\nHost:test.localhost\n\n\n\n\n\n\n\n\n\n\nfrontend 2\n\n\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/frontends/frontend2/backend\n\n\nbackend1\n\n\n\n\n\n\n/traefik/frontends/frontend2/passHostHeader\n\n\ntrue\n\n\n\n\n\n\n/traefik/frontends/frontend2/priority\n\n\n10\n\n\n\n\n\n\n/traefik/frontends/frontend2/entrypoints\n\n\nhttp,https\n\n\n\n\n\n\n/traefik/frontends/frontend2/routes/test_2/rule\n\n\nPathPrefix:/test\n\n\n\n\n\n\n\n\nAtomic configuration changes\n\n\nThe \nEtcd\n and \nConsul\n backends do not support updating multiple keys atomically. As a result, it may be possible for Tr\u00e6f\u026ak to read an intermediate configuration state despite judicious use of the \n--providersThrottleDuration\n flag. To solve this problem, Tr\u00e6f\u026ak supports a special key called \n/traefik/alias\n. If set, Tr\u00e6f\u026ak use the value as an alternative key prefix.\n\n\nGiven the key structure below, Tr\u00e6f\u026ak will use the \nhttp://172.17.0.2:80\n as its only backend (frontend keys have been omitted for brevity).\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/alias\n\n\n/traefik_configurations/1\n\n\n\n\n\n\n/traefik_configurations/1/backends/backend1/servers/server1/url\n\n\nhttp://172.17.0.2:80\n\n\n\n\n\n\n/traefik_configurations/1/backends/backend1/servers/server1/weight\n\n\n10\n\n\n\n\n\n\n\n\nWhen an atomic configuration change is required, you may write a new configuration at an alternative prefix. Here, although the \n/traefik_configurations/2/...\n keys have been set, the old configuration is still active because the \n/traefik/alias\n key still points to \n/traefik_configurations/1\n:\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/alias\n\n\n/traefik_configurations/1\n\n\n\n\n\n\n/traefik_configurations/1/backends/backend1/servers/server1/url\n\n\nhttp://172.17.0.2:80\n\n\n\n\n\n\n/traefik_configurations/1/backends/backend1/servers/server1/weight\n\n\n10\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server1/url\n\n\nhttp://172.17.0.2:80\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server1/weight\n\n\n5\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server2/url\n\n\nhttp://172.17.0.3:80\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server2/weight\n\n\n5\n\n\n\n\n\n\n\n\nOnce the \n/traefik/alias\n key is updated, the new \n/traefik_configurations/2\n configuration becomes active atomically. Here, we have a 50% balance between the \nhttp://172.17.0.3:80\n and the \nhttp://172.17.0.4:80\n hosts while no traffic is sent to the \n172.17.0.2:80\n host:\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/alias\n\n\n/traefik_configurations/2\n\n\n\n\n\n\n/traefik_configurations/1/backends/backend1/servers/server1/url\n\n\nhttp://172.17.0.2:80\n\n\n\n\n\n\n/traefik_configurations/1/backends/backend1/servers/server1/weight\n\n\n10\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server1/url\n\n\nhttp://172.17.0.3:80\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server1/weight\n\n\n5\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server2/url\n\n\nhttp://172.17.0.4:80\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server2/weight\n\n\n5\n\n\n\n\n\n\n\n\nNote that Tr\u00e6f\u026ak \nwill not watch for key changes in the \n/traefik_configurations\n prefix\n. It will only watch for changes in the \n/traefik\n prefix. Further, if the \n/traefik/alias\n key is set, all other sibling keys with the \n/traefik\n prefix are ignored.", 
            "title": "traefik.toml"
        }, 
        {
            "location": "/toml/#global-configuration", 
            "text": "", 
            "title": "Global configuration"
        }, 
        {
            "location": "/toml/#main-section", 
            "text": "# traefik.toml\n################################################################\n# Global configuration\n################################################################\n\n# Traefik logs file\n# If not defined, logs to stdout\n#\n# Optional\n#\n# traefikLogsFile =  log/traefik.log \n\n# Access logs file\n#\n# Optional\n#\n# accessLogsFile =  log/access.log \n\n# Log level\n#\n# Optional\n# Default:  ERROR \n#\n# logLevel =  ERROR \n\n# Backends throttle duration: minimum duration between 2 events from providers\n# before applying a new configuration. It avoids unnecessary reloads if multiples events\n# are sent in a short amount of time.\n#\n# Optional\n# Default:  2s \n#\n# ProvidersThrottleDuration =  5s \n\n# If non-zero, controls the maximum idle (keep-alive) to keep per-host.  If zero, DefaultMaxIdleConnsPerHost is used.\n# If you encounter 'too many open files' errors, you can either change this value, or change `ulimit` value.\n#\n# Optional\n# Default: http.DefaultMaxIdleConnsPerHost\n#\n# MaxIdleConnsPerHost = 200\n\n# Entrypoints to be used by frontends that do not specify any entrypoint.\n# Each frontend can specify its own entrypoints.\n#\n# Optional\n# Default: [ http ]\n#\n# defaultEntryPoints = [ http ,  https ]", 
            "title": "Main section"
        }, 
        {
            "location": "/toml/#entrypoints-definition", 
            "text": "# Entrypoints definition\n#\n# Optional\n# Default:\n# [entryPoints]\n#   [entryPoints.http]\n#   address =  :80 \n#\n# To redirect an http entrypoint to an https entrypoint (with SNI support):\n# [entryPoints]\n#   [entryPoints.http]\n#   address =  :80 \n#     [entryPoints.http.redirect]\n#       entryPoint =  https \n#   [entryPoints.https]\n#   address =  :443 \n#     [entryPoints.https.tls]\n#       [[entryPoints.https.tls.certificates]]\n#       CertFile =  integration/fixtures/https/snitest.com.cert \n#       KeyFile =  integration/fixtures/https/snitest.com.key \n#       [[entryPoints.https.tls.certificates]]\n#       CertFile =  integration/fixtures/https/snitest.org.cert \n#       KeyFile =  integration/fixtures/https/snitest.org.key \n#\n# To redirect an entrypoint rewriting the URL:\n# [entryPoints]\n#   [entryPoints.http]\n#   address =  :80 \n#     [entryPoints.http.redirect]\n#       regex =  ^http://localhost/(.*) \n#       replacement =  http://mydomain/$1 \n\n[entryPoints]\n  [entryPoints.http]\n  address =  :80", 
            "title": "Entrypoints definition"
        }, 
        {
            "location": "/toml/#retry-configuration", 
            "text": "# Enable retry sending request if network error\n#\n# Optional\n#\n[retry]\n\n# Number of attempts\n#\n# Optional\n# Default: (number servers in backend) -1\n#\n# attempts = 3", 
            "title": "Retry configuration"
        }, 
        {
            "location": "/toml/#acme-lets-encrypt-configuration", 
            "text": "# Sample entrypoint configuration when using ACME\n[entryPoints]\n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n\n# Enable ACME (Let's Encrypt): automatic SSL\n#\n# Optional\n#\n[acme]\n\n# Email address used for registration\n#\n# Required\n#\nemail =  test@traefik.io \n\n# File used for certificates storage.\n# WARNING, if you use Traefik in Docker, you have 2 options:\n#  - create a file on your host and mount it has a volume\n#      storageFile =  acme.json \n#      $ docker run -v  /my/host/acme.json:acme.json  traefik\n#  - mount the folder containing the file has a volume\n#      storageFile =  /etc/traefik/acme/acme.json \n#      $ docker run -v  /my/host/acme:/etc/traefik/acme  traefik\n#\n# Required\n#\nstorageFile =  acme.json \n\n# Entrypoint to proxy acme challenge to.\n# WARNING, must point to an entrypoint on port 443\n#\n# Required\n#\nentryPoint =  https \n\n# Enable on demand certificate. This will request a certificate from Let's Encrypt during the first TLS handshake for a hostname that does not yet have a certificate.\n# WARNING, TLS handshakes will be slow when requesting a hostname certificate for the first time, this can leads to DoS attacks.\n# WARNING, Take note that Let's Encrypt have rate limiting: https://community.letsencrypt.org/t/quick-start-guide/1631\n#\n# Optional\n#\n# onDemand = true\n\n# CA server to use\n# Uncomment the line to run on the staging let's encrypt server\n# Leave comment to go to prod\n#\n# Optional\n#\n# caServer =  https://acme-staging.api.letsencrypt.org/directory \n\n# Domains list\n# You can provide SANs (alternative domains) to each main domain\n# All domains must have A/AAAA records pointing to Traefik\n# WARNING, Take note that Let's Encrypt have rate limiting: https://community.letsencrypt.org/t/quick-start-guide/1631\n# Each domain   SANs will lead to a certificate request.\n#\n# [[acme.domains]]\n#   main =  local1.com \n#   sans = [ test1.local1.com ,  test2.local1.com ]\n# [[acme.domains]]\n#   main =  local2.com \n#   sans = [ test1.local2.com ,  test2x.local2.com ]\n# [[acme.domains]]\n#   main =  local3.com \n# [[acme.domains]]\n#   main =  local4.com \n[[acme.domains]]\n   main =  local1.com \n   sans = [ test1.local1.com ,  test2.local1.com ]\n[[acme.domains]]\n   main =  local3.com \n[[acme.domains]]\n   main =  local4.com", 
            "title": "ACME (Let's Encrypt) configuration"
        }, 
        {
            "location": "/toml/#configuration-backends", 
            "text": "", 
            "title": "Configuration backends"
        }, 
        {
            "location": "/toml/#file-backend", 
            "text": "Like any other reverse proxy, Tr\u00e6f\u026ak can be configured with a file. You have two choices:   simply add your configuration at the end of the global configuration file  traefik.toml  :   # traefik.toml\nlogLevel =  DEBUG \ndefaultEntryPoints = [ http ,  https ]\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n    [entryPoints.http.redirect]\n      entryPoint =  https \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile =  integration/fixtures/https/snitest.com.cert \n      KeyFile =  integration/fixtures/https/snitest.com.key \n      [[entryPoints.https.tls.certificates]]\n      CertFile =  integration/fixtures/https/snitest.org.cert \n      KeyFile =  integration/fixtures/https/snitest.org.key \n\n[file]\n\n# rules\n[backends]\n  [backends.backend1]\n    [backends.backend1.circuitbreaker]\n      expression =  NetworkErrorRatio()   0.5 \n    [backends.backend1.servers.server1]\n    url =  http://172.17.0.2:80 \n    weight = 10\n    [backends.backend1.servers.server2]\n    url =  http://172.17.0.3:80 \n    weight = 1\n  [backends.backend2]\n    [backends.backend1.maxconn]\n      amount = 10\n      extractorfunc =  request.host \n    [backends.backend2.LoadBalancer]\n      method =  drr \n    [backends.backend2.servers.server1]\n    url =  http://172.17.0.4:80 \n    weight = 1\n    [backends.backend2.servers.server2]\n    url =  http://172.17.0.5:80 \n    weight = 2\n\n[frontends]\n  [frontends.frontend1]\n  backend =  backend2 \n    [frontends.frontend1.routes.test_1]\n    rule =  Host:test.localhost \n  [frontends.frontend2]\n  backend =  backend1 \n  passHostHeader = true\n  priority = 10\n  entrypoints = [ https ] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule =  Host:{subdomain:[a-z]+}.localhost \n  [frontends.frontend3]\n  entrypoints = [ http ,  https ] # overrides defaultEntryPoints\n  backend =  backend2 \n    rule =  Path:/test    or put your rules in a separate file, for example  rules.toml :   # traefik.toml\nlogLevel =  DEBUG \n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n    [entryPoints.http.redirect]\n      entryPoint =  https \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile =  integration/fixtures/https/snitest.com.cert \n      KeyFile =  integration/fixtures/https/snitest.com.key \n      [[entryPoints.https.tls.certificates]]\n      CertFile =  integration/fixtures/https/snitest.org.cert \n      KeyFile =  integration/fixtures/https/snitest.org.key \n\n[file]\nfilename =  rules.toml   # rules.toml\n[backends]\n  [backends.backend1]\n    [backends.backend1.circuitbreaker]\n      expression =  NetworkErrorRatio()   0.5 \n    [backends.backend1.servers.server1]\n    url =  http://172.17.0.2:80 \n    weight = 10\n    [backends.backend1.servers.server2]\n    url =  http://172.17.0.3:80 \n    weight = 1\n  [backends.backend2]\n    [backends.backend1.maxconn]\n      amount = 10\n      extractorfunc =  request.host \n    [backends.backend2.LoadBalancer]\n      method =  drr \n    [backends.backend2.servers.server1]\n    url =  http://172.17.0.4:80 \n    weight = 1\n    [backends.backend2.servers.server2]\n    url =  http://172.17.0.5:80 \n    weight = 2\n\n[frontends]\n  [frontends.frontend1]\n  backend =  backend2 \n    [frontends.frontend1.routes.test_1]\n    rule =  Host:test.localhost \n  [frontends.frontend2]\n  backend =  backend1 \n  passHostHeader = true\n  priority = 10\n  entrypoints = [ https ] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule =  Host:{subdomain:[a-z]+}.localhost \n  [frontends.frontend3]\n  entrypoints = [ http ,  https ] # overrides defaultEntryPoints\n  backend =  backend2 \n    rule =  Path:/test   If you want Tr\u00e6f\u026ak to watch file changes automatically, just add:  [file]\nwatch = true", 
            "title": "File backend"
        }, 
        {
            "location": "/toml/#api-backend", 
            "text": "Tr\u00e6fik can be configured using a restful api.\nTo enable it:  [web]\naddress =  :8080 \n\n# SSL certificate and key used\n#\n# Optional\n#\n# CertFile =  traefik.crt \n# KeyFile =  traefik.key \n#\n# Set REST API to read-only mode\n#\n# Optional\n# ReadOnly = false   / : provides a simple HTML frontend of Tr\u00e6fik      /health :  GET  json metrics   $ curl -s  http://localhost:8080/health  | jq .\n{\n  // Tr\u00e6f\u026ak PID\n   pid : 2458,\n  // Tr\u00e6f\u026ak server uptime (formated time)\n   uptime :  39m6.885931127s ,\n  //  Tr\u00e6f\u026ak server uptime in seconds\n   uptime_sec : 2346.885931127,\n  // current server date\n   time :  2015-10-07 18:32:24.362238909 +0200 CEST ,\n  // current server date in seconds\n   unixtime : 1444235544,\n  // count HTTP response status code in realtime\n   status_code_count : {\n     502 : 1\n  },\n  // count HTTP response status code since Tr\u00e6f\u026ak started\n   total_status_code_count : {\n     200 : 7,\n     404 : 21,\n     502 : 13\n  },\n  // count HTTP response\n   count : 1,\n  // count HTTP response\n   total_count : 41,\n  // sum of all response time (formated time)\n   total_response_time :  35.456865605s ,\n  // sum of all response time in seconds\n   total_response_time_sec : 35.456865605,\n  // average response time (formated time)\n   average_response_time :  864.8016ms ,\n  // average response time in seconds\n   average_response_time_sec : 0.8648016000000001\n}   /api :  GET  configuration for all providers   $ curl -s  http://localhost:8080/api  | jq .\n{\n   file : {\n     frontends : {\n       frontend2 : {\n         routes : {\n           test_2 : {\n             rule :  Path:/test \n          }\n        },\n         backend :  backend1 \n      },\n       frontend1 : {\n         routes : {\n           test_1 : {\n             rule :  Host:test.localhost \n          }\n        },\n         backend :  backend2 \n      }\n    },\n     backends : {\n       backend2 : {\n         loadBalancer : {\n           method :  drr \n        },\n         servers : {\n           server2 : {\n             weight : 2,\n             URL :  http://172.17.0.5:80 \n          },\n           server1 : {\n             weight : 1,\n             url :  http://172.17.0.4:80 \n          }\n        }\n      },\n       backend1 : {\n         loadBalancer : {\n           method :  wrr \n        },\n         circuitBreaker : {\n           expression :  NetworkErrorRatio()   0.5 \n        },\n         servers : {\n           server2 : {\n             weight : 1,\n             url :  http://172.17.0.3:80 \n          },\n           server1 : {\n             weight : 10,\n             url :  http://172.17.0.2:80 \n          }\n        }\n      }\n    }\n  }\n}   /api/providers :  GET  providers  /api/providers/{provider} :  GET  or  PUT  provider  /api/providers/{provider}/backends :  GET  backends  /api/providers/{provider}/backends/{backend} :  GET  a backend  /api/providers/{provider}/backends/{backend}/servers :  GET  servers in a backend  /api/providers/{provider}/backends/{backend}/servers/{server} :  GET  a server in a backend  /api/providers/{provider}/frontends :  GET  frontends  /api/providers/{provider}/frontends/{frontend} :  GET  a frontend  /api/providers/{provider}/frontends/{frontend}/routes :  GET  routes in a frontend  /api/providers/{provider}/frontends/{frontend}/routes/{route} :  GET  a route in a frontend", 
            "title": "API backend"
        }, 
        {
            "location": "/toml/#docker-backend", 
            "text": "Tr\u00e6f\u026ak can be configured to use Docker as a backend configuration:  ################################################################\n# Docker configuration backend\n################################################################\n\n# Enable Docker configuration backend\n#\n# Optional\n#\n[docker]\n\n# Docker server endpoint. Can be a tcp or a unix socket endpoint.\n#\n# Required\n#\nendpoint =  unix:///var/run/docker.sock \n\n# Default domain used.\n# Can be overridden by setting the  traefik.domain  label on a container.\n#\n# Required\n#\ndomain =  docker.localhost \n\n# Enable watch docker changes\n#\n# Optional\n#\nwatch = true\n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename =  docker.tmpl \n\n# Enable docker TLS connection\n#\n#  [docker.tls]\n#  ca =  /etc/ssl/ca.crt \n#  cert =  /etc/ssl/docker.crt \n#  key =  /etc/ssl/docker.key \n#  insecureskipverify = true  Labels can be used on containers to override default behaviour:   traefik.backend=foo : assign the container to  foo  backend  traefik.port=80 : register this port. Useful when the container exposes multiples ports.  traefik.protocol=https : override the default  http  protocol  traefik.weight=10 : assign this weight to the container  traefik.enable=false : disable this container in Tr\u00e6f\u026ak  traefik.frontend.rule=Host:test.traefik.io : override the default frontend rule (Default:  Host:{containerName}.{domain} ).  traefik.frontend.passHostHeader=true : forward client  Host  header to the backend.  traefik.frontend.priority=10 : override default frontend priority  traefik.frontend.entryPoints=http,https : assign this frontend to entry points  http  and  https . Overrides  defaultEntryPoints .  traefik.docker.network : Set the docker network to use for connections to this container", 
            "title": "Docker backend"
        }, 
        {
            "location": "/toml/#marathon-backend", 
            "text": "Tr\u00e6f\u026ak can be configured to use Marathon as a backend configuration:  ################################################################\n# Mesos/Marathon configuration backend\n################################################################\n\n# Enable Marathon configuration backend\n#\n# Optional\n#\n[marathon]\n\n# Marathon server endpoint.\n# You can also specify multiple endpoint for Marathon:\n# endpoint :=  http://10.241.1.71:8080,10.241.1.72:8080,10.241.1.73:8080 \n#\n# Required\n#\nendpoint =  http://127.0.0.1:8080 \n\n# Enable watch Marathon changes\n#\n# Optional\n#\nwatch = true\n\n# Default domain used.\n#\n# Required\n#\ndomain =  marathon.localhost \n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename =  marathon.tmpl \n\n# Expose Marathon apps by default in traefik\n#\n# Optional\n# Default: false\n#\n# exposedByDefault = true\n\n# Convert Marathon groups to subdomains\n# Default behavior: /foo/bar/myapp =  foo-bar-myapp.{defaultDomain}\n# with groupsAsSubDomains enabled: /foo/bar/myapp =  myapp.bar.foo.{defaultDomain}\n#\n# Optional\n# Default: false\n#\n# groupsAsSubDomains = true\n\n# Enable Marathon basic authentication\n#\n# Optional\n#\n#  [marathon.basic]\n#  httpBasicAuthUser =  foo \n#  httpBasicPassword =  bar \n\n# TLS client configuration. https://golang.org/pkg/crypto/tls/#Config\n#\n# Optional\n#\n# [marathon.TLS]\n# InsecureSkipVerify = true\n\n# DCOSToken for DCOS environment, This will override the Authorization header\n#\n# Optional\n#\n# dcosToken =  xxxxxx   Labels can be used on containers to override default behaviour:   traefik.backend=foo : assign the application to  foo  backend  traefik.portIndex=1 : register port by index in the application's ports array. Useful when the application exposes multiple ports.  traefik.port=80 : register the explicit application port value. Cannot be used alongside  traefik.portIndex .  traefik.protocol=https : override the default  http  protocol  traefik.weight=10 : assign this weight to the application  traefik.enable=false : disable this application in Tr\u00e6f\u026ak  traefik.frontend.rule=Host:test.traefik.io : override the default frontend rule (Default:  Host:{containerName}.{domain} ).  traefik.frontend.passHostHeader=true : forward client  Host  header to the backend.  traefik.frontend.priority=10 : override default frontend priority  traefik.frontend.entryPoints=http,https : assign this frontend to entry points  http  and  https . Overrides  defaultEntryPoints .", 
            "title": "Marathon backend"
        }, 
        {
            "location": "/toml/#kubernetes-ingress-backend", 
            "text": "Tr\u00e6f\u026ak can be configured to use Kubernetes Ingress as a backend configuration:  ################################################################\n# Kubernetes Ingress configuration backend\n################################################################\n# Enable Kubernetes Ingress configuration backend\n#\n# Optional\n#\n[kubernetes]\n\n# Kubernetes server endpoint\n#\n# When deployed as a replication controller in Kubernetes,\n# Traefik will use env variable KUBERNETES_SERVICE_HOST\n# and KUBERNETES_SERVICE_PORT_HTTPS as endpoint\n# Secure token will be found in /var/run/secrets/kubernetes.io/serviceaccount/token\n# and SSL CA cert in /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n#\n# Optional\n#\n# endpoint =  http://localhost:8080 \n# namespaces = [ default , production ]  Annotations can be used on containers to override default behaviour for the whole Ingress resource:   traefik.frontend.rule.type: PathPrefixStrip : override the default frontend rule type (Default:  PathPrefix ).   You can find here an example  ingress  and  replication controller .", 
            "title": "Kubernetes Ingress backend"
        }, 
        {
            "location": "/toml/#consul-backend", 
            "text": "Tr\u00e6f\u026ak can be configured to use Consul as a backend configuration:  ################################################################\n# Consul KV configuration backend\n################################################################\n\n# Enable Consul KV configuration backend\n#\n# Optional\n#\n[consul]\n\n# Consul server endpoint\n#\n# Required\n#\nendpoint =  127.0.0.1:8500 \n\n# Enable watch Consul changes\n#\n# Optional\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n#\nprefix =  traefik \n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename =  consul.tmpl \n\n# Enable consul TLS connection\n#\n# Optional\n#\n# [consul.tls]\n# ca =  /etc/ssl/ca.crt \n# cert =  /etc/ssl/consul.crt \n# key =  /etc/ssl/consul.key \n# insecureskipverify = true  Please refer to the  Key Value storage structure  section to get documentation en traefik KV structure.", 
            "title": "Consul backend"
        }, 
        {
            "location": "/toml/#consul-catalog-backend", 
            "text": "Tr\u00e6f\u026ak can be configured to use service discovery catalog of Consul as a backend configuration:  ################################################################\n# Consul Catalog configuration backend\n################################################################\n\n# Enable Consul Catalog configuration backend\n#\n# Optional\n#\n[consulCatalog]\n\n# Consul server endpoint\n#\n# Required\n#\nendpoint =  127.0.0.1:8500 \n\n# Default domain used.\n#\n# Optional\n#\ndomain =  consul.localhost \n\n# Prefix for Consul catalog tags\n#\n# Optional\n#\nprefix =  traefik   This backend will create routes matching on hostname based on the service name\nused in consul.  Additional settings can be defined using Consul Catalog tags:   traefik.enable=false : disable this container in Tr\u00e6f\u026ak  traefik.protocol=https : override the default  http  protocol  traefik.backend.weight=10 : assign this weight to the container  traefik.backend.circuitbreaker=NetworkErrorRatio()   0.5  traefik.backend.loadbalancer=drr : override the default load balancing mode  traefik.frontend.rule=Host:test.traefik.io : override the default frontend rule (Default:  Host:{containerName}.{domain} ).  traefik.frontend.passHostHeader=true : forward client  Host  header to the backend.  traefik.frontend.priority=10 : override default frontend priority  traefik.frontend.entryPoints=http,https : assign this frontend to entry points  http  and  https . Overrides  defaultEntryPoints .", 
            "title": "Consul catalog backend"
        }, 
        {
            "location": "/toml/#etcd-backend", 
            "text": "Tr\u00e6f\u026ak can be configured to use Etcd as a backend configuration:  ################################################################\n# Etcd configuration backend\n################################################################\n\n# Enable Etcd configuration backend\n#\n# Optional\n#\n[etcd]\n\n# Etcd server endpoint\n#\n# Required\n#\nendpoint =  127.0.0.1:2379 \n\n# Enable watch Etcd changes\n#\n# Optional\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n#\nprefix =  /traefik \n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename =  etcd.tmpl \n\n# Enable etcd TLS connection\n#\n# Optional\n#\n# [etcd.tls]\n# ca =  /etc/ssl/ca.crt \n# cert =  /etc/ssl/etcd.crt \n# key =  /etc/ssl/etcd.key \n# insecureskipverify = true  Please refer to the  Key Value storage structure  section to get documentation en traefik KV structure.", 
            "title": "Etcd backend"
        }, 
        {
            "location": "/toml/#zookeeper-backend", 
            "text": "Tr\u00e6f\u026ak can be configured to use Zookeeper as a backend configuration:  ################################################################\n# Zookeeper configuration backend\n################################################################\n\n# Enable Zookeeperconfiguration backend\n#\n# Optional\n#\n[zookeeper]\n\n# Zookeeper server endpoint\n#\n# Required\n#\nendpoint =  127.0.0.1:2181 \n\n# Enable watch Zookeeper changes\n#\n# Optional\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n#\nprefix =  /traefik \n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename =  zookeeper.tmpl   Please refer to the  Key Value storage structure  section to get documentation en traefik KV structure.", 
            "title": "Zookeeper backend"
        }, 
        {
            "location": "/toml/#boltdb-backend", 
            "text": "Tr\u00e6f\u026ak can be configured to use BoltDB as a backend configuration:  ################################################################\n# BoltDB configuration backend\n################################################################\n\n# Enable BoltDB configuration backend\n#\n# Optional\n#\n[boltdb]\n\n# BoltDB file\n#\n# Required\n#\nendpoint =  /my.db \n\n# Enable watch BoltDB changes\n#\n# Optional\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n#\nprefix =  /traefik \n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n#\n# filename =  boltdb.tmpl   Please refer to the  Key Value storage structure  section to get documentation en traefik KV structure.", 
            "title": "BoltDB backend"
        }, 
        {
            "location": "/toml/#key-value-storage-structure", 
            "text": "The Keys-Values structure should look (using  prefix = \"/traefik\" ):   backend 1      Key  Value      /traefik/backends/backend1/circuitbreaker/expression  NetworkErrorRatio()   0.5    /traefik/backends/backend1/servers/server1/url  http://172.17.0.2:80    /traefik/backends/backend1/servers/server1/weight  10    /traefik/backends/backend1/servers/server2/url  http://172.17.0.3:80    /traefik/backends/backend1/servers/server2/weight  1      backend 2      Key  Value      /traefik/backends/backend2/maxconn/amount  10    /traefik/backends/backend2/maxconn/extractorfunc  request.host    /traefik/backends/backend2/loadbalancer/method  drr    /traefik/backends/backend2/servers/server1/url  http://172.17.0.4:80    /traefik/backends/backend2/servers/server1/weight  1    /traefik/backends/backend2/servers/server2/url  http://172.17.0.5:80    /traefik/backends/backend2/servers/server2/weight  2      frontend 1      Key  Value      /traefik/frontends/frontend1/backend  backend2    /traefik/frontends/frontend1/routes/test_1/rule  Host:test.localhost      frontend 2      Key  Value      /traefik/frontends/frontend2/backend  backend1    /traefik/frontends/frontend2/passHostHeader  true    /traefik/frontends/frontend2/priority  10    /traefik/frontends/frontend2/entrypoints  http,https    /traefik/frontends/frontend2/routes/test_2/rule  PathPrefix:/test", 
            "title": "Key-value storage structure"
        }, 
        {
            "location": "/toml/#atomic-configuration-changes", 
            "text": "The  Etcd  and  Consul  backends do not support updating multiple keys atomically. As a result, it may be possible for Tr\u00e6f\u026ak to read an intermediate configuration state despite judicious use of the  --providersThrottleDuration  flag. To solve this problem, Tr\u00e6f\u026ak supports a special key called  /traefik/alias . If set, Tr\u00e6f\u026ak use the value as an alternative key prefix.  Given the key structure below, Tr\u00e6f\u026ak will use the  http://172.17.0.2:80  as its only backend (frontend keys have been omitted for brevity).     Key  Value      /traefik/alias  /traefik_configurations/1    /traefik_configurations/1/backends/backend1/servers/server1/url  http://172.17.0.2:80    /traefik_configurations/1/backends/backend1/servers/server1/weight  10     When an atomic configuration change is required, you may write a new configuration at an alternative prefix. Here, although the  /traefik_configurations/2/...  keys have been set, the old configuration is still active because the  /traefik/alias  key still points to  /traefik_configurations/1 :     Key  Value      /traefik/alias  /traefik_configurations/1    /traefik_configurations/1/backends/backend1/servers/server1/url  http://172.17.0.2:80    /traefik_configurations/1/backends/backend1/servers/server1/weight  10    /traefik_configurations/2/backends/backend1/servers/server1/url  http://172.17.0.2:80    /traefik_configurations/2/backends/backend1/servers/server1/weight  5    /traefik_configurations/2/backends/backend1/servers/server2/url  http://172.17.0.3:80    /traefik_configurations/2/backends/backend1/servers/server2/weight  5     Once the  /traefik/alias  key is updated, the new  /traefik_configurations/2  configuration becomes active atomically. Here, we have a 50% balance between the  http://172.17.0.3:80  and the  http://172.17.0.4:80  hosts while no traffic is sent to the  172.17.0.2:80  host:     Key  Value      /traefik/alias  /traefik_configurations/2    /traefik_configurations/1/backends/backend1/servers/server1/url  http://172.17.0.2:80    /traefik_configurations/1/backends/backend1/servers/server1/weight  10    /traefik_configurations/2/backends/backend1/servers/server1/url  http://172.17.0.3:80    /traefik_configurations/2/backends/backend1/servers/server1/weight  5    /traefik_configurations/2/backends/backend1/servers/server2/url  http://172.17.0.4:80    /traefik_configurations/2/backends/backend1/servers/server2/weight  5     Note that Tr\u00e6f\u026ak  will not watch for key changes in the  /traefik_configurations  prefix . It will only watch for changes in the  /traefik  prefix. Further, if the  /traefik/alias  key is set, all other sibling keys with the  /traefik  prefix are ignored.", 
            "title": "Atomic configuration changes"
        }, 
        {
            "location": "/user-guide/examples/", 
            "text": "Examples\n\n\nYou will find here some configuration examples of Tr\u00e6f\u026ak.\n\n\nHTTP only\n\n\ndefaultEntryPoints = [\nhttp\n]\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n\n\n\n\nHTTP + HTTPS (with SNI)\n\n\ndefaultEntryPoints = [\nhttp\n, \nhttps\n]\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \nintegration/fixtures/https/snitest.com.cert\n\n      KeyFile = \nintegration/fixtures/https/snitest.com.key\n\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \nintegration/fixtures/https/snitest.org.cert\n\n      KeyFile = \nintegration/fixtures/https/snitest.org.key\n\n\n\n\n\nHTTP redirect on HTTPS\n\n\ndefaultEntryPoints = [\nhttp\n, \nhttps\n]\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n    [entryPoints.http.redirect]\n    entryPoint = \nhttps\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile = \ntests/traefik.crt\n\n      keyFile = \ntests/traefik.key\n\n\n\n\n\nLet's Encrypt support\n\n\n[entryPoints]\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      # certs used as default certs\n      [[entryPoints.https.tls.certificates]]\n      certFile = \ntests/traefik.crt\n\n      keyFile = \ntests/traefik.key\n\n[acme]\nemail = \ntest@traefik.io\n\nstorageFile = \nacme.json\n\nonDemand = true\ncaServer = \nhttp://172.18.0.1:4000/directory\n\nentryPoint = \nhttps\n\n\n[[acme.domains]]\n  main = \nlocal1.com\n\n  sans = [\ntest1.local1.com\n, \ntest2.local1.com\n]\n[[acme.domains]]\n  main = \nlocal2.com\n\n  sans = [\ntest1.local2.com\n, \ntest2x.local2.com\n]\n[[acme.domains]]\n  main = \nlocal3.com\n\n[[acme.domains]]\n  main = \nlocal4.com\n\n\n\n\n\nOverride entrypoints in frontends\n\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend2\n\n    [frontends.frontend1.routes.test_1]\n    rule = \nHost:test.localhost\n\n  [frontends.frontend2]\n  backend = \nbackend1\n\n  passHostHeader = true\n  entrypoints = [\nhttps\n] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule = \nHost:{subdomain:[a-z]+}.localhost\n\n  [frontends.frontend3]\n  entrypoints = [\nhttp\n, \nhttps\n] # overrides defaultEntryPoints\n  backend = \nbackend2\n\n    rule = \nPath:/test", 
            "title": "Configuration examples"
        }, 
        {
            "location": "/user-guide/examples/#examples", 
            "text": "You will find here some configuration examples of Tr\u00e6f\u026ak.", 
            "title": "Examples"
        }, 
        {
            "location": "/user-guide/examples/#http-only", 
            "text": "defaultEntryPoints = [ http ]\n[entryPoints]\n  [entryPoints.http]\n  address =  :80", 
            "title": "HTTP only"
        }, 
        {
            "location": "/user-guide/examples/#http-https-with-sni", 
            "text": "defaultEntryPoints = [ http ,  https ]\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile =  integration/fixtures/https/snitest.com.cert \n      KeyFile =  integration/fixtures/https/snitest.com.key \n      [[entryPoints.https.tls.certificates]]\n      CertFile =  integration/fixtures/https/snitest.org.cert \n      KeyFile =  integration/fixtures/https/snitest.org.key", 
            "title": "HTTP + HTTPS (with SNI)"
        }, 
        {
            "location": "/user-guide/examples/#http-redirect-on-https", 
            "text": "defaultEntryPoints = [ http ,  https ]\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n    [entryPoints.http.redirect]\n    entryPoint =  https \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile =  tests/traefik.crt \n      keyFile =  tests/traefik.key", 
            "title": "HTTP redirect on HTTPS"
        }, 
        {
            "location": "/user-guide/examples/#lets-encrypt-support", 
            "text": "[entryPoints]\n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      # certs used as default certs\n      [[entryPoints.https.tls.certificates]]\n      certFile =  tests/traefik.crt \n      keyFile =  tests/traefik.key \n[acme]\nemail =  test@traefik.io \nstorageFile =  acme.json \nonDemand = true\ncaServer =  http://172.18.0.1:4000/directory \nentryPoint =  https \n\n[[acme.domains]]\n  main =  local1.com \n  sans = [ test1.local1.com ,  test2.local1.com ]\n[[acme.domains]]\n  main =  local2.com \n  sans = [ test1.local2.com ,  test2x.local2.com ]\n[[acme.domains]]\n  main =  local3.com \n[[acme.domains]]\n  main =  local4.com", 
            "title": "Let's Encrypt support"
        }, 
        {
            "location": "/user-guide/examples/#override-entrypoints-in-frontends", 
            "text": "[frontends]\n  [frontends.frontend1]\n  backend =  backend2 \n    [frontends.frontend1.routes.test_1]\n    rule =  Host:test.localhost \n  [frontends.frontend2]\n  backend =  backend1 \n  passHostHeader = true\n  entrypoints = [ https ] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule =  Host:{subdomain:[a-z]+}.localhost \n  [frontends.frontend3]\n  entrypoints = [ http ,  https ] # overrides defaultEntryPoints\n  backend =  backend2 \n    rule =  Path:/test", 
            "title": "Override entrypoints in frontends"
        }, 
        {
            "location": "/user-guide/swarm/", 
            "text": "Swarm cluster\n\n\nThis section explains how to create a multi-host \nswarm\n cluster using \ndocker-machine\n and how to deploy Tr\u00e6f\u026ak on it.\nThe cluster will be made of:\n\n\n\n\n2 servers\n\n\n1 swarm master\n\n\n2 swarm nodes\n\n\n1 \noverlay\n network (multi-host networking)\n\n\n\n\nPrerequisites\n\n\n\n\nYou will need to install \ndocker-machine\n\n\nYou will need the latest \nVirtualBox\n\n\n\n\nCluster provisioning\n\n\nWe will first follow \nthis guide\n to create the cluster.\n\n\nCreate machine \nmh-keystore\n\n\nThis machine will be the service registry of our cluster.\n\n\ndocker-machine create -d virtualbox mh-keystore\n\n\n\n\nThen we install the service registry \nConsul\n on this machine:\n\n\neval \n$(docker-machine env mh-keystore)\n\ndocker run -d \\\n    -p \n8500:8500\n \\\n    -h \nconsul\n \\\n    progrium/consul -server -bootstrap\n\n\n\n\nCreate machine \nmhs-demo0\n\n\nThis machine will have a swarm master and a swarm agent on it.\n\n\ndocker-machine create -d virtualbox \\\n    --swarm --swarm-master \\\n    --swarm-discovery=\nconsul://$(docker-machine ip mh-keystore):8500\n \\\n    --engine-opt=\ncluster-store=consul://$(docker-machine ip mh-keystore):8500\n \\\n    --engine-opt=\ncluster-advertise=eth1:2376\n \\\n    mhs-demo0\n\n\n\n\nCreate machine \nmhs-demo1\n\n\nThis machine will have a swarm agent on it.\n\n\ndocker-machine create -d virtualbox \\\n    --swarm \\\n    --swarm-discovery=\nconsul://$(docker-machine ip mh-keystore):8500\n \\\n    --engine-opt=\ncluster-store=consul://$(docker-machine ip mh-keystore):8500\n \\\n    --engine-opt=\ncluster-advertise=eth1:2376\n \\\n    mhs-demo1\n\n\n\n\nCreate the overlay Network\n\n\nCreate the overlay network on the swarm master:\n\n\neval $(docker-machine env --swarm mhs-demo0)\ndocker network create --driver overlay --subnet=10.0.9.0/24 my-net\n\n\n\n\nDeploy Tr\u00e6f\u026ak\n\n\nDeploy Tr\u00e6f\u026ak:\n\n\ndocker $(docker-machine config mhs-demo0) run \\\n    -d \\\n    -p 80:80 -p 8080:8080 \\\n    --net=my-net \\\n    -v /var/lib/boot2docker/:/ssl \\\n    traefik \\\n    -l DEBUG \\\n    -c /dev/null \\\n    --docker \\\n    --docker.domain traefik \\\n    --docker.endpoint tcp://$(docker-machine ip mhs-demo0):3376 \\\n    --docker.tls \\\n    --docker.tls.ca /ssl/ca.pem \\\n    --docker.tls.cert /ssl/server.pem \\\n    --docker.tls.key /ssl/server-key.pem \\\n    --docker.tls.insecureSkipVerify \\\n    --docker.watch  \\\n    --web\n\n\n\n\nLet's explain this command:\n\n\n\n\n-p 80:80 -p 8080:8080\n: we bind ports 80 and 8080\n\n\n--net=my-net\n: run the container on the network my-net\n\n\n-v /var/lib/boot2docker/:/ssl\n: mount the ssl keys generated by docker-machine\n\n\n-c /dev/null\n: empty config file\n\n\n--docker\n: enable docker backend\n\n\n--docker.endpoint tcp://172.18.0.1:3376\n: connect to the swarm master using the docker_gwbridge network\n\n\n--docker.tls\n: enable TLS using the docker-machine keys\n\n\n--web\n: activate the webUI on port 8080\n\n\n\n\nDeploy your apps\n\n\nWe can now deploy our app on the cluster, here \nwhoami\n, a simple web server in GO, on the network \nmy-net\n:\n\n\neval $(docker-machine env --swarm mhs-demo0)\ndocker run -d --name=whoami0 --net=my-net --env=\nconstraint:node==mhs-demo0\n emilevauge/whoami\ndocker run -d --name=whoami1 --net=my-net --env=\nconstraint:node==mhs-demo1\n emilevauge/whoami\n\n\n\n\nCheck that everything is started:\n\n\ndocker ps\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                                      NAMES\nba2c21488299        emilevauge/whoami   \n/whoamI\n                8 seconds ago       Up 9 seconds        80/tcp                                                     mhs-demo1/whoami1\n8147a7746e7a        emilevauge/whoami   \n/whoamI\n                19 seconds ago      Up 20 seconds       80/tcp                                                     mhs-demo0/whoami0\n8fbc39271b4c        traefik             \n/traefik -l DEBUG -c\n   36 seconds ago      Up 37 seconds       192.168.99.101:80-\n80/tcp, 192.168.99.101:8080-\n8080/tcp   mhs-demo0/serene_bhabha\n\n\n\n\nAccess to your apps through Tr\u00e6f\u026ak\n\n\ncurl -H Host:whoami0.traefik http://$(docker-machine ip mhs-demo0)\nHostname: 8147a7746e7a\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.3\nIP: fe80::42:aff:fe00:903\nIP: 172.18.0.3\nIP: fe80::42:acff:fe12:3\nGET / HTTP/1.1\nHost: 10.0.9.3:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.3:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c\n\ncurl -H Host:whoami1.traefik http://$(docker-machine ip mhs-demo0)\nHostname: ba2c21488299\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.4\nIP: fe80::42:aff:fe00:904\nIP: 172.18.0.2\nIP: fe80::42:acff:fe12:2\nGET / HTTP/1.1\nHost: 10.0.9.4:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.4:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c", 
            "title": "Swarm cluster"
        }, 
        {
            "location": "/user-guide/swarm/#swarm-cluster", 
            "text": "This section explains how to create a multi-host  swarm  cluster using  docker-machine  and how to deploy Tr\u00e6f\u026ak on it.\nThe cluster will be made of:   2 servers  1 swarm master  2 swarm nodes  1  overlay  network (multi-host networking)", 
            "title": "Swarm cluster"
        }, 
        {
            "location": "/user-guide/swarm/#prerequisites", 
            "text": "You will need to install  docker-machine  You will need the latest  VirtualBox", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/user-guide/swarm/#cluster-provisioning", 
            "text": "We will first follow  this guide  to create the cluster.", 
            "title": "Cluster provisioning"
        }, 
        {
            "location": "/user-guide/swarm/#create-machine-mh-keystore", 
            "text": "This machine will be the service registry of our cluster.  docker-machine create -d virtualbox mh-keystore  Then we install the service registry  Consul  on this machine:  eval  $(docker-machine env mh-keystore) \ndocker run -d \\\n    -p  8500:8500  \\\n    -h  consul  \\\n    progrium/consul -server -bootstrap", 
            "title": "Create machine mh-keystore"
        }, 
        {
            "location": "/user-guide/swarm/#create-machine-mhs-demo0", 
            "text": "This machine will have a swarm master and a swarm agent on it.  docker-machine create -d virtualbox \\\n    --swarm --swarm-master \\\n    --swarm-discovery= consul://$(docker-machine ip mh-keystore):8500  \\\n    --engine-opt= cluster-store=consul://$(docker-machine ip mh-keystore):8500  \\\n    --engine-opt= cluster-advertise=eth1:2376  \\\n    mhs-demo0", 
            "title": "Create machine mhs-demo0"
        }, 
        {
            "location": "/user-guide/swarm/#create-machine-mhs-demo1", 
            "text": "This machine will have a swarm agent on it.  docker-machine create -d virtualbox \\\n    --swarm \\\n    --swarm-discovery= consul://$(docker-machine ip mh-keystore):8500  \\\n    --engine-opt= cluster-store=consul://$(docker-machine ip mh-keystore):8500  \\\n    --engine-opt= cluster-advertise=eth1:2376  \\\n    mhs-demo1", 
            "title": "Create machine mhs-demo1"
        }, 
        {
            "location": "/user-guide/swarm/#create-the-overlay-network", 
            "text": "Create the overlay network on the swarm master:  eval $(docker-machine env --swarm mhs-demo0)\ndocker network create --driver overlay --subnet=10.0.9.0/24 my-net", 
            "title": "Create the overlay Network"
        }, 
        {
            "location": "/user-guide/swarm/#deploy-trfk", 
            "text": "Deploy Tr\u00e6f\u026ak:  docker $(docker-machine config mhs-demo0) run \\\n    -d \\\n    -p 80:80 -p 8080:8080 \\\n    --net=my-net \\\n    -v /var/lib/boot2docker/:/ssl \\\n    traefik \\\n    -l DEBUG \\\n    -c /dev/null \\\n    --docker \\\n    --docker.domain traefik \\\n    --docker.endpoint tcp://$(docker-machine ip mhs-demo0):3376 \\\n    --docker.tls \\\n    --docker.tls.ca /ssl/ca.pem \\\n    --docker.tls.cert /ssl/server.pem \\\n    --docker.tls.key /ssl/server-key.pem \\\n    --docker.tls.insecureSkipVerify \\\n    --docker.watch  \\\n    --web  Let's explain this command:   -p 80:80 -p 8080:8080 : we bind ports 80 and 8080  --net=my-net : run the container on the network my-net  -v /var/lib/boot2docker/:/ssl : mount the ssl keys generated by docker-machine  -c /dev/null : empty config file  --docker : enable docker backend  --docker.endpoint tcp://172.18.0.1:3376 : connect to the swarm master using the docker_gwbridge network  --docker.tls : enable TLS using the docker-machine keys  --web : activate the webUI on port 8080", 
            "title": "Deploy Tr\u00e6f\u026ak"
        }, 
        {
            "location": "/user-guide/swarm/#deploy-your-apps", 
            "text": "We can now deploy our app on the cluster, here  whoami , a simple web server in GO, on the network  my-net :  eval $(docker-machine env --swarm mhs-demo0)\ndocker run -d --name=whoami0 --net=my-net --env= constraint:node==mhs-demo0  emilevauge/whoami\ndocker run -d --name=whoami1 --net=my-net --env= constraint:node==mhs-demo1  emilevauge/whoami  Check that everything is started:  docker ps\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                                      NAMES\nba2c21488299        emilevauge/whoami    /whoamI                 8 seconds ago       Up 9 seconds        80/tcp                                                     mhs-demo1/whoami1\n8147a7746e7a        emilevauge/whoami    /whoamI                 19 seconds ago      Up 20 seconds       80/tcp                                                     mhs-demo0/whoami0\n8fbc39271b4c        traefik              /traefik -l DEBUG -c    36 seconds ago      Up 37 seconds       192.168.99.101:80- 80/tcp, 192.168.99.101:8080- 8080/tcp   mhs-demo0/serene_bhabha", 
            "title": "Deploy your apps"
        }, 
        {
            "location": "/user-guide/swarm/#access-to-your-apps-through-trfk", 
            "text": "curl -H Host:whoami0.traefik http://$(docker-machine ip mhs-demo0)\nHostname: 8147a7746e7a\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.3\nIP: fe80::42:aff:fe00:903\nIP: 172.18.0.3\nIP: fe80::42:acff:fe12:3\nGET / HTTP/1.1\nHost: 10.0.9.3:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.3:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c\n\ncurl -H Host:whoami1.traefik http://$(docker-machine ip mhs-demo0)\nHostname: ba2c21488299\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.4\nIP: fe80::42:aff:fe00:904\nIP: 172.18.0.2\nIP: fe80::42:acff:fe12:2\nGET / HTTP/1.1\nHost: 10.0.9.4:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.4:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c", 
            "title": "Access to your apps through Tr\u00e6f\u026ak"
        }, 
        {
            "location": "/benchmarks/", 
            "text": "Benchmarks\n\n\nConfiguration\n\n\nI would like to thanks \nvincentbernat\n from \nexoscale.ch\n who kindly provided the infrastructure needed for the benchmarks.\n\n\nI used 4 VMs for the tests with the following configuration:\n\n\n\n\n32 GB RAM\n\n\n8 CPU Cores\n\n\n10 GB SSD\n\n\nUbuntu 14.04 LTS 64-bit\n\n\n\n\nSetup\n\n\n\n\nOne VM used to launch the benchmarking tool \nwrk\n\n\nOne VM for traefik (v1.0.0-beta.416) / nginx (v1.4.6)\n\n\nTwo VMs for 2 backend servers in go \nwhoami\n\n\n\n\nEach VM has been tuned using the following limits:\n\n\nsysctl -w fs.file-max=\n9999999\n\nsysctl -w fs.nr_open=\n9999999\n\nsysctl -w net.core.netdev_max_backlog=\n4096\n\nsysctl -w net.core.rmem_max=\n16777216\n\nsysctl -w net.core.somaxconn=\n65535\n\nsysctl -w net.core.wmem_max=\n16777216\n\nsysctl -w net.ipv4.ip_local_port_range=\n1025       65535\n\nsysctl -w net.ipv4.tcp_fin_timeout=\n30\n\nsysctl -w net.ipv4.tcp_keepalive_time=\n30\n\nsysctl -w net.ipv4.tcp_max_syn_backlog=\n20480\n\nsysctl -w net.ipv4.tcp_max_tw_buckets=\n400000\n\nsysctl -w net.ipv4.tcp_no_metrics_save=\n1\n\nsysctl -w net.ipv4.tcp_syn_retries=\n2\n\nsysctl -w net.ipv4.tcp_synack_retries=\n2\n\nsysctl -w net.ipv4.tcp_tw_recycle=\n1\n\nsysctl -w net.ipv4.tcp_tw_reuse=\n1\n\nsysctl -w vm.min_free_kbytes=\n65536\n\nsysctl -w vm.overcommit_memory=\n1\n\nulimit -n 9999999\n\n\n\n\nNginx\n\n\nHere is the config Nginx file use \n/etc/nginx/nginx.conf\n:\n\n\nuser www-data;\nworker_processes auto;\nworker_rlimit_nofile 200000;\npid /var/run/nginx.pid;\n\nevents {\n    worker_connections 10000;\n    use epoll;\n    multi_accept on;\n}\n\nhttp {\n    sendfile on;\n    tcp_nopush on;\n    tcp_nodelay on;\n    keepalive_timeout 300;\n    keepalive_requests 10000;\n    types_hash_max_size 2048;\n\n    open_file_cache max=200000 inactive=300s; \n    open_file_cache_valid 300s; \n    open_file_cache_min_uses 2;\n    open_file_cache_errors on;\n\n    server_tokens off;\n    dav_methods off;\n\n    include /etc/nginx/mime.types;\n    default_type application/octet-stream;\n\n    access_log /var/log/nginx/access.log combined;\n    error_log /var/log/nginx/error.log warn;\n\n    gzip off;\n    gzip_vary off;\n\n    include /etc/nginx/conf.d/*.conf;\n    include /etc/nginx/sites-enabled/*.conf;\n}\n\n\n\n\nHere is the Nginx vhost file used:\n\n\nupstream whoami {\n    server IP-whoami1:80;\n    server IP-whoami2:80;\n    keepalive 300;\n}\n\nserver {\n    listen 8001;\n    server_name test.traefik;\n    access_log off;\n    error_log /dev/null crit;\n    if ($host != \ntest.traefik\n) {\n        return 404;\n    }\n    location / {\n        proxy_pass http://whoami;\n        proxy_http_version 1.1;\n        proxy_set_header Connection \n;\n    proxy_set_header  X-Forwarded-Host $host;\n    }\n}\n\n\n\n\nTraefik\n\n\nHere is the \ntraefik.toml\n file used:\n\n\nMaxIdleConnsPerHost = 100000\ndefaultEntryPoints = [\nhttp\n]\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:8000\n\n\n[file]\n[backends]\n  [backends.backend1]\n    [backends.backend1.servers.server1]\n    url = \nhttp://IP-whoami1:80\n\n    weight = 1\n    [backends.backend1.servers.server2]\n    url = \nhttp://IP-whoami2:80\n\n    weight = 1\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend1\n\n    [frontends.frontend1.routes.test_1]\n    rule = \nHost: test.traefik\n\n\n\n\n\nResults\n\n\nwhoami:\n\n\nwrk -t20 -c1000 -d60s -H \nHost: test.traefik\n --latency  http://IP-whoami:80/bench\nRunning 1m test @ http://IP-whoami:80/bench\n  20 threads and 1000 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency    70.28ms  134.72ms   1.91s    89.94%\n    Req/Sec     2.92k   742.42     8.78k    68.80%\n  Latency Distribution\n     50%   10.63ms\n     75%   75.64ms\n     90%  205.65ms\n     99%  668.28ms\n  3476705 requests in 1.00m, 384.61MB read\n  Socket errors: connect 0, read 0, write 0, timeout 103\nRequests/sec:  57894.35\nTransfer/sec:      6.40MB\n\n\n\n\nnginx:\n\n\nwrk -t20 -c1000 -d60s -H \nHost: test.traefik\n --latency  http://IP-nginx:8001/bench\nRunning 1m test @ http://IP-nginx:8001/bench\n  20 threads and 1000 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency   101.25ms  180.09ms   1.99s    89.34%\n    Req/Sec     1.69k   567.69     9.39k    72.62%\n  Latency Distribution\n     50%   15.46ms\n     75%  129.11ms\n     90%  302.44ms\n     99%  846.59ms\n  2018427 requests in 1.00m, 298.36MB read\n  Socket errors: connect 0, read 0, write 0, timeout 90\nRequests/sec:  33591.67\nTransfer/sec:      4.97MB\n\n\n\n\ntraefik:\n\n\nwrk -t20 -c1000 -d60s -H \nHost: test.traefik\n --latency  http://IP-traefik:8000/bench\nRunning 1m test @ http://IP-traefik:8000/bench\n  20 threads and 1000 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency    91.72ms  150.43ms   2.00s    90.50%\n    Req/Sec     1.43k   266.37     2.97k    69.77%\n  Latency Distribution\n     50%   19.74ms\n     75%  121.98ms\n     90%  237.39ms\n     99%  687.49ms\n  1705073 requests in 1.00m, 188.63MB read\n  Socket errors: connect 0, read 0, write 0, timeout 7\nRequests/sec:  28392.44\nTransfer/sec:      3.14MB\n\n\n\n\nConclusion\n\n\nTraefik is obviously slower than Nginx, but not so much: Traefik can serve 28392 requests/sec and Nginx 33591 requests/sec which gives a ratio of 85%.\nNot bad for young project :) !\n\n\nSome areas of possible improvements:\n\n\n\n\nUse \nGO_REUSEPORT\n listener\n\n\nRun a separate server instance per CPU core with \nGOMAXPROCS=1\n (it appears during benchmarks that there is a lot more context switches with traefik than with nginx)", 
            "title": "Benchmarks"
        }, 
        {
            "location": "/benchmarks/#benchmarks", 
            "text": "", 
            "title": "Benchmarks"
        }, 
        {
            "location": "/benchmarks/#configuration", 
            "text": "I would like to thanks  vincentbernat  from  exoscale.ch  who kindly provided the infrastructure needed for the benchmarks.  I used 4 VMs for the tests with the following configuration:   32 GB RAM  8 CPU Cores  10 GB SSD  Ubuntu 14.04 LTS 64-bit", 
            "title": "Configuration"
        }, 
        {
            "location": "/benchmarks/#setup", 
            "text": "One VM used to launch the benchmarking tool  wrk  One VM for traefik (v1.0.0-beta.416) / nginx (v1.4.6)  Two VMs for 2 backend servers in go  whoami   Each VM has been tuned using the following limits:  sysctl -w fs.file-max= 9999999 \nsysctl -w fs.nr_open= 9999999 \nsysctl -w net.core.netdev_max_backlog= 4096 \nsysctl -w net.core.rmem_max= 16777216 \nsysctl -w net.core.somaxconn= 65535 \nsysctl -w net.core.wmem_max= 16777216 \nsysctl -w net.ipv4.ip_local_port_range= 1025       65535 \nsysctl -w net.ipv4.tcp_fin_timeout= 30 \nsysctl -w net.ipv4.tcp_keepalive_time= 30 \nsysctl -w net.ipv4.tcp_max_syn_backlog= 20480 \nsysctl -w net.ipv4.tcp_max_tw_buckets= 400000 \nsysctl -w net.ipv4.tcp_no_metrics_save= 1 \nsysctl -w net.ipv4.tcp_syn_retries= 2 \nsysctl -w net.ipv4.tcp_synack_retries= 2 \nsysctl -w net.ipv4.tcp_tw_recycle= 1 \nsysctl -w net.ipv4.tcp_tw_reuse= 1 \nsysctl -w vm.min_free_kbytes= 65536 \nsysctl -w vm.overcommit_memory= 1 \nulimit -n 9999999", 
            "title": "Setup"
        }, 
        {
            "location": "/benchmarks/#nginx", 
            "text": "Here is the config Nginx file use  /etc/nginx/nginx.conf :  user www-data;\nworker_processes auto;\nworker_rlimit_nofile 200000;\npid /var/run/nginx.pid;\n\nevents {\n    worker_connections 10000;\n    use epoll;\n    multi_accept on;\n}\n\nhttp {\n    sendfile on;\n    tcp_nopush on;\n    tcp_nodelay on;\n    keepalive_timeout 300;\n    keepalive_requests 10000;\n    types_hash_max_size 2048;\n\n    open_file_cache max=200000 inactive=300s; \n    open_file_cache_valid 300s; \n    open_file_cache_min_uses 2;\n    open_file_cache_errors on;\n\n    server_tokens off;\n    dav_methods off;\n\n    include /etc/nginx/mime.types;\n    default_type application/octet-stream;\n\n    access_log /var/log/nginx/access.log combined;\n    error_log /var/log/nginx/error.log warn;\n\n    gzip off;\n    gzip_vary off;\n\n    include /etc/nginx/conf.d/*.conf;\n    include /etc/nginx/sites-enabled/*.conf;\n}  Here is the Nginx vhost file used:  upstream whoami {\n    server IP-whoami1:80;\n    server IP-whoami2:80;\n    keepalive 300;\n}\n\nserver {\n    listen 8001;\n    server_name test.traefik;\n    access_log off;\n    error_log /dev/null crit;\n    if ($host !=  test.traefik ) {\n        return 404;\n    }\n    location / {\n        proxy_pass http://whoami;\n        proxy_http_version 1.1;\n        proxy_set_header Connection  ;\n    proxy_set_header  X-Forwarded-Host $host;\n    }\n}", 
            "title": "Nginx"
        }, 
        {
            "location": "/benchmarks/#traefik", 
            "text": "Here is the  traefik.toml  file used:  MaxIdleConnsPerHost = 100000\ndefaultEntryPoints = [ http ]\n\n[entryPoints]\n  [entryPoints.http]\n  address =  :8000 \n\n[file]\n[backends]\n  [backends.backend1]\n    [backends.backend1.servers.server1]\n    url =  http://IP-whoami1:80 \n    weight = 1\n    [backends.backend1.servers.server2]\n    url =  http://IP-whoami2:80 \n    weight = 1\n\n[frontends]\n  [frontends.frontend1]\n  backend =  backend1 \n    [frontends.frontend1.routes.test_1]\n    rule =  Host: test.traefik", 
            "title": "Traefik"
        }, 
        {
            "location": "/benchmarks/#results", 
            "text": "", 
            "title": "Results"
        }, 
        {
            "location": "/benchmarks/#whoami", 
            "text": "wrk -t20 -c1000 -d60s -H  Host: test.traefik  --latency  http://IP-whoami:80/bench\nRunning 1m test @ http://IP-whoami:80/bench\n  20 threads and 1000 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency    70.28ms  134.72ms   1.91s    89.94%\n    Req/Sec     2.92k   742.42     8.78k    68.80%\n  Latency Distribution\n     50%   10.63ms\n     75%   75.64ms\n     90%  205.65ms\n     99%  668.28ms\n  3476705 requests in 1.00m, 384.61MB read\n  Socket errors: connect 0, read 0, write 0, timeout 103\nRequests/sec:  57894.35\nTransfer/sec:      6.40MB", 
            "title": "whoami:"
        }, 
        {
            "location": "/benchmarks/#nginx_1", 
            "text": "wrk -t20 -c1000 -d60s -H  Host: test.traefik  --latency  http://IP-nginx:8001/bench\nRunning 1m test @ http://IP-nginx:8001/bench\n  20 threads and 1000 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency   101.25ms  180.09ms   1.99s    89.34%\n    Req/Sec     1.69k   567.69     9.39k    72.62%\n  Latency Distribution\n     50%   15.46ms\n     75%  129.11ms\n     90%  302.44ms\n     99%  846.59ms\n  2018427 requests in 1.00m, 298.36MB read\n  Socket errors: connect 0, read 0, write 0, timeout 90\nRequests/sec:  33591.67\nTransfer/sec:      4.97MB", 
            "title": "nginx:"
        }, 
        {
            "location": "/benchmarks/#traefik_1", 
            "text": "wrk -t20 -c1000 -d60s -H  Host: test.traefik  --latency  http://IP-traefik:8000/bench\nRunning 1m test @ http://IP-traefik:8000/bench\n  20 threads and 1000 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency    91.72ms  150.43ms   2.00s    90.50%\n    Req/Sec     1.43k   266.37     2.97k    69.77%\n  Latency Distribution\n     50%   19.74ms\n     75%  121.98ms\n     90%  237.39ms\n     99%  687.49ms\n  1705073 requests in 1.00m, 188.63MB read\n  Socket errors: connect 0, read 0, write 0, timeout 7\nRequests/sec:  28392.44\nTransfer/sec:      3.14MB", 
            "title": "traefik:"
        }, 
        {
            "location": "/benchmarks/#conclusion", 
            "text": "Traefik is obviously slower than Nginx, but not so much: Traefik can serve 28392 requests/sec and Nginx 33591 requests/sec which gives a ratio of 85%.\nNot bad for young project :) !  Some areas of possible improvements:   Use  GO_REUSEPORT  listener  Run a separate server instance per CPU core with  GOMAXPROCS=1  (it appears during benchmarks that there is a lot more context switches with traefik than with nginx)", 
            "title": "Conclusion"
        }
    ]
}