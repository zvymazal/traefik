{
    "docs": [
        {
            "location": "/", 
            "text": "Tr\u00e6fik is a modern HTTP reverse proxy and load balancer that makes deploying microservices easy.\nTr\u00e6fik integrates with your existing infrastructure components (\nDocker\n, \nSwarm mode\n, \nKubernetes\n, \nMarathon\n, \nConsul\n, \nEtcd\n, \nRancher\n, \nAmazon ECS\n, ...) and configures itself automatically and dynamically.\nTelling Tr\u00e6fik where your orchestrator is could be the \nonly\n configuration step you need to do.\n\n\nOverview\n\n\nImagine that you have deployed a bunch of microservices with the help of an orchestrator (like Swarm or Kubernetes) or a service registry (like etcd or consul).\nNow you want users to access these microservices, and you need a reverse proxy.\n\n\nTraditional reverse-proxies require that you configure \neach\n route that will connect paths and subdomains to \neach\n microservice. In an environment where you add, remove, kill, upgrade, or scale your services \nmany\n times a day, the task of keeping the routes up to date becomes tedious. \n\n\nThis is when Tr\u00e6fik can help you!\n\n\nTr\u00e6fik listens to your service registry/orchestrator API and instantly generates the routes so your microservices are connected to the outside world -- without further intervention from your part. \n\n\nRun Tr\u00e6fik and let it do the work for you!\n \n\n(But if you'd rather configure some of your routes manually, Tr\u00e6fik supports that too!)\n\n\n\n\nFeatures\n\n\n\n\nContinuously updates its configuration (No restarts!)\n\n\nSupports multiple load balancing algorithms\n\n\nProvides HTTPS to your microservices by leveraging \nLet's Encrypt\n\n\nCircuit breakers, retry\n\n\nHigh Availability with cluster mode (beta)\n\n\nSee the magic through its clean web UI\n\n\nWebsocket, HTTP/2, GRPC ready\n\n\nProvides metrics (Rest, Prometheus, Datadog, Statsd, InfluxDB)\n\n\nKeeps access logs (JSON, CLF)\n\n\nFast\n ... which is nice\n\n\nExposes a Rest API\n\n\nPackaged as a single binary file (made with :heart: with go) and available as a \ntiny\n \nofficial\n docker image\n\n\n\n\nSupported backends\n\n\n\n\nDocker\n / \nSwarm mode\n\n\nKubernetes\n\n\nMesos\n / \nMarathon\n\n\nRancher\n (API, Metadata)\n\n\nAzure Service Fabric\n\n\nConsul Catalog\n\n\nConsul\n / \nEtcd\n / \nZookeeper\n / \nBoltDB\n\n\nEureka\n\n\nAmazon ECS\n\n\nAmazon DynamoDB\n\n\nFile\n\n\nRest\n\n\n\n\nThe Tr\u00e6fik Quickstart (Using Docker)\n\n\nIn this quickstart, we'll use \nDocker compose\n to create our demo infrastructure.\n\n\nTo save some time, you can clone \nTr\u00e6fik's repository\n and use the quickstart files located in the \nexamples/quickstart\n directory.\n\n\n1 \u2014 Launch Tr\u00e6fik \u2014 Tell It to Listen to Docker\n\n\nCreate a \ndocker-compose.yml\n file where you will define a \nreverse-proxy\n service that uses the official Tr\u00e6fik image:\n\n\nversion: '3'\n\nservices:\n  reverse-proxy:\n    image: traefik #The official Traefik docker image\n    command: --api --docker #Enables the web UI and tells Tr\u00e6fik to listen to docker\n    ports:\n      - \n80:80\n     #The HTTP port\n      - \n8080:8080\n #The Web UI (enabled by --api)\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock #So that Traefik can listen to the Docker events\n\n\n\n\nThat's it. Now you can launch Tr\u00e6fik!\n\n\nStart your \nreverse-proxy\n with the following command:\n\n\ndocker-compose up -d reverse-proxy \n\n\n\n\nYou can open a browser and go to \nhttp://localhost:8080\n to see Tr\u00e6fik's dashboard (we'll go back there once we have launched a service in step 2).\n\n\n2 \u2014 Launch a Service \u2014 Tr\u00e6fik Detects It and Creates a Route for You\n\n\nNow that we have a Tr\u00e6fik instance up and running, we will deploy new services. \n\n\nEdit your \ndocker-compose.yml\n file and add the following at the end of your file. \n\n\n# ... \n  whoami:\n    image: emilevauge/whoami #A container that exposes an API to show it's IP address\n    labels:\n      - \ntraefik.frontend.rule=Host:whoami.docker.localhost\n\n\n\n\n\nThe above defines \nwhoami\n: a simple web service that outputs information about the machine it is deployed on (its IP address, host, and so on).\n\n\nStart the \nwhoami\n service with the following command:\n\n\ndocker-compose up -d whoami\n\n\n\n\nGo back to your browser (\nhttp://localhost:8080\n) and see that Tr\u00e6fik has automatically detected the new container and updated its own configuration.\n\n\nWhen Traefik detects new services, it creates the corresponding routes so you can call them ... \nlet's see!\n  (Here, we're using curl)\n\n\ncurl -H Host:whoami.docker.localhost http://127.0.0.1\n\n\n\n\nShows the following output:\n\n\nHostname: 8656c8ddca6c\nIP: 172.27.0.3\n#...\n\n\n\n\n3 \u2014 Launch More Instances \u2014 Traefik Load Balances Them\n\n\nRun more instances of your \nwhoami\n service with the following command:\n\n\ndocker-compose up -d --scale whoami=2 \n\n\n\n\nGo back to your browser (\nhttp://localhost:8080\n) and see that Tr\u00e6fik has automatically detected the new instance of the container.\n\n\nFinally, see that Tr\u00e6fik load-balances between the two instances of your services by running twice the following command:\n\n\ncurl -H Host:whoami.docker.localhost http://127.0.0.1\n\n\n\n\nThe output will show alternatively one of the followings:\n\n\nHostname: 8656c8ddca6c\nIP: 172.27.0.3\n#...\n\n\n\n\nHostname: 8458f154e1f1\nIP: 172.27.0.4\n# ...\n\n\n\n\n4 \u2014 Enjoy Tr\u00e6fik's Magic\n\n\nNow that you have a basic understanding of how Tr\u00e6fik can automatically create the routes to your services and load balance them, it might be time to dive into \nthe documentation\n and let Tr\u00e6fik work for you! Whatever your infrastructure is, there is probably \nan available Tr\u00e6fik backend\n that will do the job. \n\n\nOur recommendation would be to see for yourself how simple it is to enable HTTPS with \nTr\u00e6fik's let's encrypt integration\n using the dedicated \nuser guide\n.\n\n\nResources\n\n\nHere is a talk given by \nEmile Vauge\n at \nGopherCon 2017\n.\nYou will learn Tr\u00e6fik basics in less than 10 minutes.\n\n\n\n\nHere is a talk given by \nEd Robinson\n at \nContainerCamp UK\n conference.\nYou will learn fundamental Tr\u00e6fik features and see some demos with Kubernetes.\n\n\n\n\nDownloads\n\n\nThe Official Binary File\n\n\nYou can grab the latest binary from the \nreleases\n page and just run it with the \nsample configuration file\n:\n\n\n./traefik -c traefik.toml\n\n\n\n\nThe Official Docker Image\n\n\nUsing the tiny Docker image:\n\n\ndocker run -d -p 8080:8080 -p 80:80 -v $PWD/traefik.toml:/etc/traefik/traefik.toml traefik", 
            "title": "Getting Started"
        }, 
        {
            "location": "/#overview", 
            "text": "Imagine that you have deployed a bunch of microservices with the help of an orchestrator (like Swarm or Kubernetes) or a service registry (like etcd or consul).\nNow you want users to access these microservices, and you need a reverse proxy.  Traditional reverse-proxies require that you configure  each  route that will connect paths and subdomains to  each  microservice. In an environment where you add, remove, kill, upgrade, or scale your services  many  times a day, the task of keeping the routes up to date becomes tedious.   This is when Tr\u00e6fik can help you!  Tr\u00e6fik listens to your service registry/orchestrator API and instantly generates the routes so your microservices are connected to the outside world -- without further intervention from your part.   Run Tr\u00e6fik and let it do the work for you!   (But if you'd rather configure some of your routes manually, Tr\u00e6fik supports that too!)", 
            "title": "Overview"
        }, 
        {
            "location": "/#features", 
            "text": "Continuously updates its configuration (No restarts!)  Supports multiple load balancing algorithms  Provides HTTPS to your microservices by leveraging  Let's Encrypt  Circuit breakers, retry  High Availability with cluster mode (beta)  See the magic through its clean web UI  Websocket, HTTP/2, GRPC ready  Provides metrics (Rest, Prometheus, Datadog, Statsd, InfluxDB)  Keeps access logs (JSON, CLF)  Fast  ... which is nice  Exposes a Rest API  Packaged as a single binary file (made with :heart: with go) and available as a  tiny   official  docker image", 
            "title": "Features"
        }, 
        {
            "location": "/#supported-backends", 
            "text": "Docker  /  Swarm mode  Kubernetes  Mesos  /  Marathon  Rancher  (API, Metadata)  Azure Service Fabric  Consul Catalog  Consul  /  Etcd  /  Zookeeper  /  BoltDB  Eureka  Amazon ECS  Amazon DynamoDB  File  Rest", 
            "title": "Supported backends"
        }, 
        {
            "location": "/#the-trfik-quickstart-using-docker", 
            "text": "In this quickstart, we'll use  Docker compose  to create our demo infrastructure.  To save some time, you can clone  Tr\u00e6fik's repository  and use the quickstart files located in the  examples/quickstart  directory.", 
            "title": "The Tr\u00e6fik Quickstart (Using Docker)"
        }, 
        {
            "location": "/#1-launch-trfik-tell-it-to-listen-to-docker", 
            "text": "Create a  docker-compose.yml  file where you will define a  reverse-proxy  service that uses the official Tr\u00e6fik image:  version: '3'\n\nservices:\n  reverse-proxy:\n    image: traefik #The official Traefik docker image\n    command: --api --docker #Enables the web UI and tells Tr\u00e6fik to listen to docker\n    ports:\n      -  80:80      #The HTTP port\n      -  8080:8080  #The Web UI (enabled by --api)\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock #So that Traefik can listen to the Docker events  That's it. Now you can launch Tr\u00e6fik!  Start your  reverse-proxy  with the following command:  docker-compose up -d reverse-proxy   You can open a browser and go to  http://localhost:8080  to see Tr\u00e6fik's dashboard (we'll go back there once we have launched a service in step 2).", 
            "title": "1 \u2014 Launch Tr\u00e6fik \u2014 Tell It to Listen to Docker"
        }, 
        {
            "location": "/#2-launch-a-service-trfik-detects-it-and-creates-a-route-for-you", 
            "text": "Now that we have a Tr\u00e6fik instance up and running, we will deploy new services.   Edit your  docker-compose.yml  file and add the following at the end of your file.   # ... \n  whoami:\n    image: emilevauge/whoami #A container that exposes an API to show it's IP address\n    labels:\n      -  traefik.frontend.rule=Host:whoami.docker.localhost   The above defines  whoami : a simple web service that outputs information about the machine it is deployed on (its IP address, host, and so on).  Start the  whoami  service with the following command:  docker-compose up -d whoami  Go back to your browser ( http://localhost:8080 ) and see that Tr\u00e6fik has automatically detected the new container and updated its own configuration.  When Traefik detects new services, it creates the corresponding routes so you can call them ...  let's see!   (Here, we're using curl)  curl -H Host:whoami.docker.localhost http://127.0.0.1  Shows the following output:  Hostname: 8656c8ddca6c\nIP: 172.27.0.3\n#...", 
            "title": "2 \u2014 Launch a Service \u2014 Tr\u00e6fik Detects It and Creates a Route for You"
        }, 
        {
            "location": "/#3-launch-more-instances-traefik-load-balances-them", 
            "text": "Run more instances of your  whoami  service with the following command:  docker-compose up -d --scale whoami=2   Go back to your browser ( http://localhost:8080 ) and see that Tr\u00e6fik has automatically detected the new instance of the container.  Finally, see that Tr\u00e6fik load-balances between the two instances of your services by running twice the following command:  curl -H Host:whoami.docker.localhost http://127.0.0.1  The output will show alternatively one of the followings:  Hostname: 8656c8ddca6c\nIP: 172.27.0.3\n#...  Hostname: 8458f154e1f1\nIP: 172.27.0.4\n# ...", 
            "title": "3 \u2014 Launch More Instances \u2014 Traefik Load Balances Them"
        }, 
        {
            "location": "/#4-enjoy-trfiks-magic", 
            "text": "Now that you have a basic understanding of how Tr\u00e6fik can automatically create the routes to your services and load balance them, it might be time to dive into  the documentation  and let Tr\u00e6fik work for you! Whatever your infrastructure is, there is probably  an available Tr\u00e6fik backend  that will do the job.   Our recommendation would be to see for yourself how simple it is to enable HTTPS with  Tr\u00e6fik's let's encrypt integration  using the dedicated  user guide .", 
            "title": "4 \u2014 Enjoy Tr\u00e6fik's Magic"
        }, 
        {
            "location": "/#resources", 
            "text": "Here is a talk given by  Emile Vauge  at  GopherCon 2017 .\nYou will learn Tr\u00e6fik basics in less than 10 minutes.   Here is a talk given by  Ed Robinson  at  ContainerCamp UK  conference.\nYou will learn fundamental Tr\u00e6fik features and see some demos with Kubernetes.", 
            "title": "Resources"
        }, 
        {
            "location": "/#downloads", 
            "text": "", 
            "title": "Downloads"
        }, 
        {
            "location": "/#the-official-binary-file", 
            "text": "You can grab the latest binary from the  releases  page and just run it with the  sample configuration file :  ./traefik -c traefik.toml", 
            "title": "The Official Binary File"
        }, 
        {
            "location": "/#the-official-docker-image", 
            "text": "Using the tiny Docker image:  docker run -d -p 8080:8080 -p 80:80 -v $PWD/traefik.toml:/etc/traefik/traefik.toml traefik", 
            "title": "The Official Docker Image"
        }, 
        {
            "location": "/basics/", 
            "text": "Basics\n\n\nConcepts\n\n\nLet's take our example from the \noverview\n again:\n\n\n\n\nImagine that you have deployed a bunch of microservices on your infrastructure. You probably used a service registry (like etcd or consul) and/or an orchestrator (swarm, Mesos/Marathon) to manage all these services.\nIf you want your users to access some of your microservices from the Internet, you will have to use a reverse proxy and configure it using virtual hosts or prefix paths:\n\n\n\n\ndomain \napi.domain.com\n will point the microservice \napi\n in your private network\n\n\npath \ndomain.com/web\n will point the microservice \nweb\n in your private network\n\n\ndomain \nbackoffice.domain.com\n will point the microservices \nbackoffice\n in your private network, load-balancing between your multiple instances\n\n\n\n\n\n\n\n\nLet's zoom on Tr\u00e6fik and have an overview of its internal architecture:\n\n\n\n\n\n\nIncoming requests end on \nentrypoints\n, as the name suggests, they are the network entry points into Tr\u00e6fik (listening port, SSL, traffic redirection...).\n\n\nTraffic is then forwarded to a matching \nfrontend\n. A frontend defines routes from \nentrypoints\n to \nbackends\n.\nRoutes are created using requests fields (\nHost\n, \nPath\n, \nHeaders\n...) and can match or not a request.\n\n\nThe \nfrontend\n will then send the request to a \nbackend\n. A backend can be composed by one or more \nservers\n, and by a load-balancing strategy.\n\n\nFinally, the \nserver\n will forward the request to the corresponding microservice in the private network.\n\n\n\n\nEntrypoints\n\n\nEntrypoints are the network entry points into Tr\u00e6fik.\nThey can be defined using:\n\n\n\n\na port (80, 443...)\n\n\nSSL (Certificates, Keys, authentication with a client certificate signed by a trusted CA...)\n\n\nredirection to another entrypoint (redirect \nHTTP\n to \nHTTPS\n)\n\n\n\n\nHere is an example of entrypoints definition:\n\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n    [entryPoints.http.redirect]\n    entryPoint = \nhttps\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile = \ntests/traefik.crt\n\n      keyFile = \ntests/traefik.key\n\n\n\n\n\n\n\nTwo entrypoints are defined \nhttp\n and \nhttps\n.\n\n\nhttp\n listens on port \n80\n and \nhttps\n on port \n443\n.\n\n\nWe enable SSL on \nhttps\n by giving a certificate and a key.\n\n\nWe also redirect all the traffic from entrypoint \nhttp\n to \nhttps\n.\n\n\n\n\nAnd here is another example with client certificate authentication:\n\n\n[entryPoints]\n  [entryPoints.https]\n  address = \n:443\n\n  [entryPoints.https.tls]\n    [entryPoints.https.tls]\n      [entryPoints.https.tls.ClientCA]\n      files = [\ntests/clientca1.crt\n, \ntests/clientca2.crt\n]\n      optional = false\n      [[entryPoints.https.tls.certificates]]\n      certFile = \ntests/traefik.crt\n\n      keyFile = \ntests/traefik.key\n\n\n\n\n\n\n\nWe enable SSL on \nhttps\n by giving a certificate and a key.\n\n\nOne or several files containing Certificate Authorities in PEM format are added.\n\n\nIt is possible to have multiple CA:s in the same file or keep them in separate files.\n\n\n\n\nFrontends\n\n\nA frontend consists of a set of rules that determine how incoming requests are forwarded from an entrypoint to a backend.\n\n\nRules may be classified in one of two groups: Modifiers and matchers.\n\n\nModifiers\n\n\nModifier rules only modify the request. They do not have any impact on routing decisions being made.\n\n\nFollowing is the list of existing modifier rules:\n\n\n\n\nAddPrefix: /products\n: Add path prefix to the existing request path prior to forwarding the request to the backend.\n\n\nReplacePath: /serverless-path\n: Replaces the path and adds the old path to the \nX-Replaced-Path\n header. Useful for mapping to AWS Lambda or Google Cloud Functions.\n\n\nReplacePathRegex: ^/api/v2/(.*) /api/$1\n: Replaces the path with a regular expression and adds the old path to the \nX-Replaced-Path\n header. Separate the regular expression and the replacement by a space.\n\n\n\n\nMatchers\n\n\nMatcher rules determine if a particular request should be forwarded to a backend.\n\n\nSeparate multiple rule values by \n,\n (comma) in order to enable ANY semantics (i.e., forward a request if any rule matches).\nDoes not work for \nHeaders\n and \nHeadersRegexp\n.\n\n\nSeparate multiple rule values by \n;\n (semicolon) in order to enable ALL semantics (i.e., forward a request if all rules match).\n\n\nFollowing is the list of existing matcher rules along with examples:\n\n\n\n\n\n\n\n\nMatcher\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nHeaders: Content-Type, application/json\n\n\nMatch HTTP header. It accepts a comma-separated key/value pair where both key and value must be literals.\n\n\n\n\n\n\nHeadersRegexp: Content-Type, application/(text/json)\n\n\nMatch HTTP header. It accepts a comma-separated key/value pair where the key must be a literal and the value may be a literal or a regular expression.\n\n\n\n\n\n\nHost: traefik.io, www.traefik.io\n\n\nMatch request host. It accepts a sequence of literal hosts.\n\n\n\n\n\n\nHostRegexp: traefik.io, {subdomain:[a-z]+}.traefik.io\n\n\nMatch request host. It accepts a sequence of literal and regular expression hosts.\n\n\n\n\n\n\nMethod: GET, POST, PUT\n\n\nMatch request HTTP method. It accepts a sequence of HTTP methods.\n\n\n\n\n\n\nPath: /products/, /articles/{category}/{id:[0-9]+}\n\n\nMatch exact request path. It accepts a sequence of literal and regular expression paths.\n\n\n\n\n\n\nPathStrip: /products/\n\n\nMatch exact path and strip off the path prior to forwarding the request to the backend. It accepts a sequence of literal paths.\n\n\n\n\n\n\nPathStripRegex: /articles/{category}/{id:[0-9]+}\n\n\nMatch exact path and strip off the path prior to forwarding the request to the backend. It accepts a sequence of literal and regular expression paths.\n\n\n\n\n\n\nPathPrefix: /products/, /articles/{category}/{id:[0-9]+}\n\n\nMatch request prefix path. It accepts a sequence of literal and regular expression prefix paths.\n\n\n\n\n\n\nPathPrefixStrip: /products/\n\n\nMatch request prefix path and strip off the path prefix prior to forwarding the request to the backend. It accepts a sequence of literal prefix paths. Starting with Traefik 1.3, the stripped prefix path will be available in the \nX-Forwarded-Prefix\n header.\n\n\n\n\n\n\nPathPrefixStripRegex: /articles/{category}/{id:[0-9]+}\n\n\nMatch request prefix path and strip off the path prefix prior to forwarding the request to the backend. It accepts a sequence of literal and regular expression prefix paths. Starting with Traefik 1.3, the stripped prefix path will be available in the \nX-Forwarded-Prefix\n header.\n\n\n\n\n\n\nQuery: foo=bar, bar=baz\n\n\nMatch Query String parameters. It accepts a sequence of key=value pairs.\n\n\n\n\n\n\n\n\nIn order to use regular expressions with Host and Path matchers, you must declare an arbitrarily named variable followed by the colon-separated regular expression, all enclosed in curly braces. Any pattern supported by \nGo's regexp package\n may be used (example: \n/posts/{id:[0-9]+}\n).\n\n\n\n\nNote\n\n\nThe variable has no special meaning; however, it is required by the \ngorilla/mux\n dependency which embeds the regular expression and defines the syntax.\n\n\n\n\nYou can optionally enable \npassHostHeader\n to forward client \nHost\n header to the backend.\nYou can also optionally enable \npassTLSCert\n to forward TLS Client certificates to the backend.\n\n\nPath Matcher Usage Guidelines\n\n\nThis section explains when to use the various path matchers.\n\n\nUse \nPath\n if your backend listens on the exact path only. For instance, \nPath: /products\n would match \n/products\n but not \n/products/shoes\n.\n\n\nUse a \n*Prefix*\n matcher if your backend listens on a particular base path but also serves requests on sub-paths.\nFor instance, \nPathPrefix: /products\n would match \n/products\n but also \n/products/shoes\n and \n/products/shirts\n.\nSince the path is forwarded as-is, your backend is expected to listen on \n/products\n.\n\n\nUse a \n*Strip\n matcher if your backend listens on the root path (\n/\n) but should be routeable on a specific prefix.\nFor instance, \nPathPrefixStrip: /products\n would match \n/products\n but also \n/products/shoes\n and \n/products/shirts\n.\n\nSince the path is stripped prior to forwarding, your backend is expected to listen on \n/\n.\n\nIf your backend is serving assets (e.g., images or Javascript files), chances are it must return properly constructed relative URLs.\n\nContinuing on the example, the backend should return \n/products/shoes/image.png\n (and not \n/images.png\n which Traefik would likely not be able to associate with the same backend).\n\nThe \nX-Forwarded-Prefix\n header (available since Traefik 1.3) can be queried to build such URLs dynamically.\n\n\nInstead of distinguishing your backends by path only, you can add a Host matcher to the mix.\nThat way, namespacing of your backends happens on the basis of hosts in addition to paths.\n\n\nExamples\n\n\nHere is an example of frontends definition:\n\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend2\n\n    [frontends.frontend1.routes.test_1]\n    rule = \nHost:test.localhost,test2.localhost\n\n  [frontends.frontend2]\n  backend = \nbackend1\n\n  passHostHeader = true\n  passTLSCert = true\n  priority = 10\n  entrypoints = [\nhttps\n] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule = \nHostRegexp:localhost,{subdomain:[a-z]+}.localhost\n\n  [frontends.frontend3]\n  backend = \nbackend2\n\n    [frontends.frontend3.routes.test_1]\n    rule = \nHost:test3.localhost;Path:/test\n\n\n\n\n\n\n\nThree frontends are defined: \nfrontend1\n, \nfrontend2\n and \nfrontend3\n\n\nfrontend1\n will forward the traffic to the \nbackend2\n if the rule \nHost:test.localhost,test2.localhost\n is matched\n\n\nfrontend2\n will forward the traffic to the \nbackend1\n if the rule \nHost:localhost,{subdomain:[a-z]+}.localhost\n is matched (forwarding client \nHost\n header to the backend)\n\n\nfrontend3\n will forward the traffic to the \nbackend2\n if the rules \nHost:test3.localhost\n \nAND\n \nPath:/test\n are matched\n\n\n\n\nCombining multiple rules\n\n\nAs seen in the previous example, you can combine multiple rules.\nIn TOML file, you can use multiple routes:\n\n\n  [frontends.frontend3]\n  backend = \nbackend2\n\n    [frontends.frontend3.routes.test_1]\n    rule = \nHost:test3.localhost\n\n    [frontends.frontend3.routes.test_2]\n    rule = \nPath:/test\n\n\n\n\n\nHere \nfrontend3\n will forward the traffic to the \nbackend2\n if the rules \nHost:test3.localhost\n \nAND\n \nPath:/test\n are matched.\n\n\nYou can also use the notation using a \n;\n separator, same result:\n\n\n  [frontends.frontend3]\n  backend = \nbackend2\n\n    [frontends.frontend3.routes.test_1]\n    rule = \nHost:test3.localhost;Path:/test\n\n\n\n\n\nFinally, you can create a rule to bind multiple domains or Path to a frontend, using the \n,\n separator:\n\n\n [frontends.frontend2]\n    [frontends.frontend2.routes.test_1]\n    rule = \nHost:test1.localhost,test2.localhost\n\n  [frontends.frontend3]\n  backend = \nbackend2\n\n    [frontends.frontend3.routes.test_1]\n    rule = \nPath:/test1,/test2\n\n\n\n\n\nRules Order\n\n\nWhen combining \nModifier\n rules with \nMatcher\n rules, it is important to remember that \nModifier\n rules \nALWAYS\n apply after the \nMatcher\n rules.\n\n\nThe following rules are both \nMatchers\n and \nModifiers\n, so the \nMatcher\n portion of the rule will apply first, and the \nModifier\n will apply later.\n\n\n\n\nPathStrip\n\n\nPathStripRegex\n\n\nPathPrefixStrip\n\n\nPathPrefixStripRegex\n\n\n\n\nModifiers\n will be applied in a pre-determined order regardless of their order in the \nrule\n configuration section.\n\n\n\n\nPathStrip\n\n\nPathPrefixStrip\n\n\nPathStripRegex\n\n\nPathPrefixStripRegex\n\n\nAddPrefix\n\n\nReplacePath\n\n\n\n\nPriorities\n\n\nBy default, routes will be sorted (in descending order) using rules length (to avoid path overlap):\n\nPathPrefix:/foo;Host:foo.com\n (length == 28) will be matched before \nPathPrefixStrip:/foobar\n (length == 23) will be matched before \nPathPrefix:/foo,/bar\n (length == 20).\n\n\nYou can customize priority by frontend. The priority value override the rule length during sorting:\n\n\n  [frontends]\n    [frontends.frontend1]\n    backend = \nbackend1\n\n    priority = 20\n    passHostHeader = true\n      [frontends.frontend1.routes.test_1]\n      rule = \nPathPrefix:/to\n\n    [frontends.frontend2]\n    backend = \nbackend2\n\n    passHostHeader = true\n      [frontends.frontend2.routes.test_1]\n      rule = \nPathPrefix:/toto\n\n\n\n\n\nHere, \nfrontend1\n will be matched before \nfrontend2\n (\n20 \n 16\n).\n\n\nCustom headers\n\n\nCustom headers can be configured through the frontends, to add headers to either requests or responses that match the frontend's rules.\nThis allows for setting headers such as \nX-Script-Name\n to be added to the request, or custom headers to be added to the response.\n\n\n\n\nWarning\n\n\nIf the custom header name is the same as one header name of the request or response, it will be replaced.\n\n\n\n\nIn this example, all matches to the path \n/cheese\n will have the \nX-Script-Name\n header added to the proxied request, and the \nX-Custom-Response-Header\n added to the response.\n\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend1\n\n    [frontends.frontend1.headers.customresponseheaders]\n    X-Custom-Response-Header = \nTrue\n\n    [frontends.frontend1.headers.customrequestheaders]\n    X-Script-Name = \ntest\n\n    [frontends.frontend1.routes.test_1]\n    rule = \nPathPrefixStrip:/cheese\n\n\n\n\n\nIn this second  example, all matches to the path \n/cheese\n will have the \nX-Script-Name\n header added to the proxied request, the \nX-Custom-Request-Header\n removed to the request and the \nX-Custom-Response-Header\n removed to the response.\n\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend1\n\n    [frontends.frontend1.headers.customresponseheaders]\n    X-Custom-Response-Header = \n\n    [frontends.frontend1.headers.customrequestheaders]\n    X-Script-Name = \ntest\n\n    X-Custom-Request-Header = \n\n    [frontends.frontend1.routes.test_1]\n    rule = \nPathPrefixStrip:/cheese\n\n\n\n\n\nSecurity headers\n\n\nSecurity related headers (HSTS headers, SSL redirection, Browser XSS filter, etc) can be added and configured per frontend in a similar manner to the custom headers above.\nThis functionality allows for some easy security features to quickly be set.\n\n\nAn example of some of the security headers:\n\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend1\n\n    [frontends.frontend1.headers]\n    FrameDeny = true\n    [frontends.frontend1.routes.test_1]\n    rule = \nPathPrefixStrip:/cheddar\n\n  [frontends.frontend2]\n  backend = \nbackend2\n\n    [frontends.frontend2.headers]\n    SSLRedirect = true\n    [frontends.frontend2.routes.test_1]\n    rule = \nPathPrefixStrip:/stilton\n\n\n\n\n\nIn this example, traffic routed through the first frontend will have the \nX-Frame-Options\n header set to \nDENY\n, and the second will only allow HTTPS request through, otherwise will return a 301 HTTPS redirect.\n\n\n\n\nNote\n\n\nThe detailed documentation for those security headers can be found in \nunrolled/secure\n.\n\n\n\n\nBackends\n\n\nA backend is responsible to load-balance the traffic coming from one or more frontends to a set of http servers.\n\n\nVarious methods of load-balancing are supported:\n\n\n\n\nwrr\n: Weighted Round Robin.\n\n\ndrr\n: Dynamic Round Robin: increases weights on servers that perform better than others.\n    It also rolls back to original weights if the servers have changed.\n\n\n\n\nA circuit breaker can also be applied to a backend, preventing high loads on failing servers.\nInitial state is Standby. CB observes the statistics and does not modify the request.\nIn case the condition matches, CB enters Tripped state, where it responds with predefined code or redirects to another frontend.\nOnce Tripped timer expires, CB enters Recovering state and resets all stats.\nIn case the condition does not match and recovery timer expires, CB enters Standby state.\n\n\nIt can be configured using:\n\n\n\n\nMethods: \nLatencyAtQuantileMS\n, \nNetworkErrorRatio\n, \nResponseCodeRatio\n\n\nOperators:  \nAND\n, \nOR\n, \nEQ\n, \nNEQ\n, \nLT\n, \nLE\n, \nGT\n, \nGE\n\n\n\n\nFor example:\n\n\n\n\nNetworkErrorRatio() \n 0.5\n: watch error ratio over 10 second sliding window for a frontend.\n\n\nLatencyAtQuantileMS(50.0) \n 50\n:  watch latency at quantile in milliseconds.\n\n\nResponseCodeRatio(500, 600, 0, 600) \n 0.5\n: ratio of response codes in ranges [500-600) and [0-600).\n\n\n\n\nTo proactively prevent backends from being overwhelmed with high load, a maximum connection limit can also be applied to each backend.\n\n\nMaximum connections can be configured by specifying an integer value for \nmaxconn.amount\n and \nmaxconn.extractorfunc\n which is a strategy used to determine how to categorize requests in order to evaluate the maximum connections.\n\n\nFor example:\n\n\n[backends]\n  [backends.backend1]\n    [backends.backend1.maxconn]\n       amount = 10\n       extractorfunc = \nrequest.host\n\n\n\n\n\n\n\nbackend1\n will return \nHTTP code 429 Too Many Requests\n if there are already 10 requests in progress for the same Host header.\n\n\nAnother possible value for \nextractorfunc\n is \nclient.ip\n which will categorize requests based on client source ip.\n\n\nLastly \nextractorfunc\n can take the value of \nrequest.header.ANY_HEADER\n which will categorize requests based on \nANY_HEADER\n that you provide.\n\n\n\n\nSticky sessions\n\n\nSticky sessions are supported with both load balancers.\n\nWhen sticky sessions are enabled, a cookie is set on the initial request.\nThe default cookie name is an abbreviation of a sha1 (ex: \n_1d52e\n).\nOn subsequent requests, the client will be directed to the backend stored in the cookie if it is still healthy.\nIf not, a new backend will be assigned.\n\n\n[backends]\n  [backends.backend1]\n    # Enable sticky session\n    [backends.backend1.loadbalancer.stickiness]\n\n    # Customize the cookie name\n    #\n    # Optional\n    # Default: a sha1 (6 chars)\n    #\n    #  cookieName = \nmy_cookie\n\n\n\n\n\nThe deprecated way:\n\n\n[backends]\n  [backends.backend1]\n    [backends.backend1.loadbalancer]\n      sticky = true\n\n\n\n\nHealth Check\n\n\nA health check can be configured in order to remove a backend from LB rotation as long as it keeps returning HTTP status codes other than \n200 OK\n to HTTP GET requests periodically carried out by Traefik.\n\nThe check is defined by a pathappended to the backend URL and an interval (given in a format understood by \ntime.ParseDuration\n) specifying how often the health check should be executed (the default being 30 seconds).\nEach backend must respond to the health check within 5 seconds.\n\nBy default, the port of the backend server is used, however, this may be overridden.\n\n\nA recovering backend returning 200 OK responses again is being returned to the\nLB rotation pool.\n\n\nFor example:\n\n\n[backends]\n  [backends.backend1]\n    [backends.backend1.healthcheck]\n    path = \n/health\n\n    interval = \n10s\n\n\n\n\n\nTo use a different port for the healthcheck:\n\n\n[backends]\n  [backends.backend1]\n    [backends.backend1.healthcheck]\n    path = \n/health\n\n    interval = \n10s\n\n    port = 8080\n\n\n\n\nServers\n\n\nServers are simply defined using a \nurl\n. You can also apply a custom \nweight\n to each server (this will be used by load-balancing).\n\n\n\n\nNote\n\n\nPaths in \nurl\n are ignored. Use \nModifier\n to specify paths instead.\n\n\n\n\nHere is an example of backends and servers definition:\n\n\n[backends]\n  [backends.backend1]\n    [backends.backend1.circuitbreaker]\n    expression = \nNetworkErrorRatio() \n 0.5\n\n    [backends.backend1.servers.server1]\n    url = \nhttp://172.17.0.2:80\n\n    weight = 10\n    [backends.backend1.servers.server2]\n    url = \nhttp://172.17.0.3:80\n\n    weight = 1\n  [backends.backend2]\n    [backends.backend2.LoadBalancer]\n    method = \ndrr\n\n    [backends.backend2.servers.server1]\n    url = \nhttp://172.17.0.4:80\n\n    weight = 1\n    [backends.backend2.servers.server2]\n    url = \nhttp://172.17.0.5:80\n\n    weight = 2\n\n\n\n\n\n\nTwo backends are defined: \nbackend1\n and \nbackend2\n\n\nbackend1\n will forward the traffic to two servers: \nhttp://172.17.0.2:80\"\n with weight \n10\n and \nhttp://172.17.0.3:80\n with weight \n1\n using default \nwrr\n load-balancing strategy.\n\n\nbackend2\n will forward the traffic to two servers: \nhttp://172.17.0.4:80\"\n with weight \n1\n and \nhttp://172.17.0.5:80\n with weight \n2\n using \ndrr\n load-balancing strategy.\n\n\na circuit breaker is added on \nbackend1\n using the expression \nNetworkErrorRatio() \n 0.5\n: watch error ratio over 10 second sliding window\n\n\n\n\nConfiguration\n\n\nTr\u00e6fik's configuration has two parts:\n\n\n\n\nThe \nstatic Tr\u00e6fik configuration\n which is loaded only at the beginning.\n\n\nThe \ndynamic Tr\u00e6fik configuration\n which can be hot-reloaded (no need to restart the process).\n\n\n\n\nStatic Tr\u00e6fik configuration\n\n\nThe static configuration is the global configuration which is setting up connections to configuration backends and entrypoints.\n\n\nTr\u00e6fik can be configured using many configuration sources with the following precedence order.\nEach item takes precedence over the item below it:\n\n\n\n\nKey-value store\n\n\nArguments\n\n\nConfiguration file\n\n\nDefault\n\n\n\n\nIt means that arguments override configuration file, and key-value store overrides arguments.\n\n\n\n\nNote\n\n\nthe provider-enabling argument parameters (e.g., \n--docker\n) set all default values for the specific provider.\n\nIt must not be used if a configuration source with less precedence wants to set a non-default provider value.\n\n\n\n\nConfiguration file\n\n\nBy default, Tr\u00e6fik will try to find a \ntraefik.toml\n in the following places:\n\n\n\n\n/etc/traefik/\n\n\n$HOME/.traefik/\n\n\n.\n \nthe working directory\n\n\n\n\nYou can override this by setting a \nconfigFile\n argument:\n\n\ntraefik --configFile=foo/bar/myconfigfile.toml\n\n\n\n\nPlease refer to the \nglobal configuration\n section to get documentation on it.\n\n\nArguments\n\n\nEach argument (and command) is described in the help section:\n\n\ntraefik --help\n\n\n\n\nNote that all default values will be displayed as well.\n\n\nKey-value stores\n\n\nTr\u00e6fik supports several Key-value stores:\n\n\n\n\nConsul\n\n\netcd\n\n\nZooKeeper\n\n\nboltdb\n\n\n\n\nPlease refer to the \nUser Guide Key-value store configuration\n section to get documentation on it.\n\n\nDynamic Tr\u00e6fik configuration\n\n\nThe dynamic configuration concerns :\n\n\n\n\nFrontends\n\n\nBackends\n\n\nServers\n\n\nHTTPS Certificates\n\n\n\n\nTr\u00e6fik can hot-reload those rules which could be provided by \nmultiple configuration backends\n.\n\n\nWe only need to enable \nwatch\n option to make Tr\u00e6fik watch configuration backend changes and generate its configuration automatically.\nRoutes to services will be created and updated instantly at any changes.\n\n\nPlease refer to the \nconfiguration backends\n section to get documentation on it.\n\n\nCommands\n\n\ntraefik\n\n\nUsage:\n\n\ntraefik [command] [--flag=flag_argument]\n\n\n\n\nList of Tr\u00e6fik available\u00a0commands with description :\n\n\n\n\nversion\n : Print\u00a0version\n\n\nstoreconfig\n : Store the static Traefik configuration into a Key-value stores.\u00a0Please refer to the \nStore Tr\u00e6fik configuration\n section to get documentation on it.\n\n\nbug\n: The easiest way to submit a pre-filled issue.\n\n\nhealthcheck\n: Calls Traefik \n/ping\n to check health.\n\n\n\n\nEach command may have related flags.\n\n\nAll those related flags will be displayed with :\n\n\ntraefik [command] --help\n\n\n\n\nEach command is described at the beginning of the help section:\n\n\ntraefik --help\n\n# or\n\ndocker run traefik[:version] --help\n# ex: docker run traefik:1.5 --help\n\n\n\n\nCommand: bug\n\n\nHere is the easiest way to submit a pre-filled issue on \nTr\u00e6fik GitHub\n.\n\n\ntraefik bug\n\n\n\n\nWatch \nthis demo\n.\n\n\nCommand: healthcheck\n\n\nThis command allows to check the health of Traefik. Its exit status is \n0\n if Traefik is healthy and \n1\n if it is unhealthy.\n\n\nThis can be used with Docker \nHEALTHCHECK\n instruction or any other health check orchestration mechanism.\n\n\n\n\nNote\n\n\nThe \nping\n must be enabled to allow the \nhealthcheck\n command to call \n/ping\n.\n\n\n\n\ntraefik healthcheck\n\n\n\n\nOK: http://:8082/ping\n\n\n\n\nCollected Data\n\n\nThis feature is disabled by default.\n\n\nYou can read the public proposal on this topic \nhere\n.\n\n\nWhy ?\n\n\nIn order to help us learn more about how Tr\u00e6fik is being used and improve it, we collect anonymous usage statistics from running instances.\nThose data help us prioritize our developments and focus on what's more important (for example, which configuration backend is used and which is not used).\n\n\nWhat ?\n\n\nOnce a day (the first call begins 10 minutes after the start of Tr\u00e6fik), we collect:\n\n\n\n\nthe Tr\u00e6fik version\n\n\na hash of the configuration\n\n\nan \nanonymous version\n of the static configuration:\n\n\ntoken, user name, password, URL, IP, domain, email, etc, are removed\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nWe do not collect the dynamic configuration (frontends \n backends).\n\n\n\n\n\n\nNote\n\n\nWe do not collect data behind the scenes to run advertising programs or to sell such data to third-party.\n\n\n\n\nHere is an example\n\n\n\n\nSource configuration:\n\n\n\n\n[entryPoints]\n    [entryPoints.http]\n       address = \n:80\n\n\n[api]\n\n[Docker]\n  endpoint = \ntcp://10.10.10.10:2375\n\n  domain = \nfoo.bir\n\n  exposedByDefault = true\n  swarmMode = true\n\n  [Docker.TLS]\n    CA = \ndockerCA\n\n    Cert = \ndockerCert\n\n    Key = \ndockerKey\n\n    InsecureSkipVerify = true\n\n[ECS]\n  Domain = \nfoo.bar\n\n  ExposedByDefault = true\n  Clusters = [\nfoo-bar\n]\n  Region = \nus-west-2\n\n  AccessKeyID = \nAccessKeyID\n\n  SecretAccessKey = \nSecretAccessKey\n\n\n\n\n\n\n\nObfuscated and anonymous configuration:\n\n\n\n\n[entryPoints]\n    [entryPoints.http]\n       address = \n:80\n\n\n[api]\n\n[Docker]\n  Endpoint = \nxxxx\n\n  Domain = \nxxxx\n\n  ExposedByDefault = true\n  SwarmMode = true\n\n  [Docker.TLS]\n    CA = \nxxxx\n\n    Cert = \nxxxx\n\n    Key = \nxxxx\n\n    InsecureSkipVerify = false\n\n[ECS]\n  Domain = \nxxxx\n\n  ExposedByDefault = true\n  Clusters = []\n  Region = \nus-west-2\n\n  AccessKeyID = \nxxxx\n\n  SecretAccessKey = \nxxxx\n\n\n\n\n\nShow me the code !\n\n\nIf you want to dig into more details, here is the source code of the collecting system: \ncollector.go\n\n\nBy default we anonymize all configuration fields, except fields tagged with \nexport=true\n.\n\n\nYou can check all fields in the \ngodoc\n.\n\n\nHow to enable this ?\n\n\nYou can enable the collecting system by:\n\n\n\n\nadding this line in the configuration TOML file:\n\n\n\n\n# Send anonymous usage data\n#\n# Optional\n# Default: false\n#\nsendAnonymousUsage = true\n\n\n\n\n\n\nadding this flag in the CLI:\n\n\n\n\n./traefik --sendAnonymousUsage=true", 
            "title": "Basics"
        }, 
        {
            "location": "/basics/#basics", 
            "text": "", 
            "title": "Basics"
        }, 
        {
            "location": "/basics/#concepts", 
            "text": "Let's take our example from the  overview  again:   Imagine that you have deployed a bunch of microservices on your infrastructure. You probably used a service registry (like etcd or consul) and/or an orchestrator (swarm, Mesos/Marathon) to manage all these services.\nIf you want your users to access some of your microservices from the Internet, you will have to use a reverse proxy and configure it using virtual hosts or prefix paths:   domain  api.domain.com  will point the microservice  api  in your private network  path  domain.com/web  will point the microservice  web  in your private network  domain  backoffice.domain.com  will point the microservices  backoffice  in your private network, load-balancing between your multiple instances     Let's zoom on Tr\u00e6fik and have an overview of its internal architecture:    Incoming requests end on  entrypoints , as the name suggests, they are the network entry points into Tr\u00e6fik (listening port, SSL, traffic redirection...).  Traffic is then forwarded to a matching  frontend . A frontend defines routes from  entrypoints  to  backends .\nRoutes are created using requests fields ( Host ,  Path ,  Headers ...) and can match or not a request.  The  frontend  will then send the request to a  backend . A backend can be composed by one or more  servers , and by a load-balancing strategy.  Finally, the  server  will forward the request to the corresponding microservice in the private network.", 
            "title": "Concepts"
        }, 
        {
            "location": "/basics/#entrypoints", 
            "text": "Entrypoints are the network entry points into Tr\u00e6fik.\nThey can be defined using:   a port (80, 443...)  SSL (Certificates, Keys, authentication with a client certificate signed by a trusted CA...)  redirection to another entrypoint (redirect  HTTP  to  HTTPS )   Here is an example of entrypoints definition:  [entryPoints]\n  [entryPoints.http]\n  address =  :80 \n    [entryPoints.http.redirect]\n    entryPoint =  https \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile =  tests/traefik.crt \n      keyFile =  tests/traefik.key    Two entrypoints are defined  http  and  https .  http  listens on port  80  and  https  on port  443 .  We enable SSL on  https  by giving a certificate and a key.  We also redirect all the traffic from entrypoint  http  to  https .   And here is another example with client certificate authentication:  [entryPoints]\n  [entryPoints.https]\n  address =  :443 \n  [entryPoints.https.tls]\n    [entryPoints.https.tls]\n      [entryPoints.https.tls.ClientCA]\n      files = [ tests/clientca1.crt ,  tests/clientca2.crt ]\n      optional = false\n      [[entryPoints.https.tls.certificates]]\n      certFile =  tests/traefik.crt \n      keyFile =  tests/traefik.key    We enable SSL on  https  by giving a certificate and a key.  One or several files containing Certificate Authorities in PEM format are added.  It is possible to have multiple CA:s in the same file or keep them in separate files.", 
            "title": "Entrypoints"
        }, 
        {
            "location": "/basics/#frontends", 
            "text": "A frontend consists of a set of rules that determine how incoming requests are forwarded from an entrypoint to a backend.  Rules may be classified in one of two groups: Modifiers and matchers.", 
            "title": "Frontends"
        }, 
        {
            "location": "/basics/#modifiers", 
            "text": "Modifier rules only modify the request. They do not have any impact on routing decisions being made.  Following is the list of existing modifier rules:   AddPrefix: /products : Add path prefix to the existing request path prior to forwarding the request to the backend.  ReplacePath: /serverless-path : Replaces the path and adds the old path to the  X-Replaced-Path  header. Useful for mapping to AWS Lambda or Google Cloud Functions.  ReplacePathRegex: ^/api/v2/(.*) /api/$1 : Replaces the path with a regular expression and adds the old path to the  X-Replaced-Path  header. Separate the regular expression and the replacement by a space.", 
            "title": "Modifiers"
        }, 
        {
            "location": "/basics/#matchers", 
            "text": "Matcher rules determine if a particular request should be forwarded to a backend.  Separate multiple rule values by  ,  (comma) in order to enable ANY semantics (i.e., forward a request if any rule matches).\nDoes not work for  Headers  and  HeadersRegexp .  Separate multiple rule values by  ;  (semicolon) in order to enable ALL semantics (i.e., forward a request if all rules match).  Following is the list of existing matcher rules along with examples:     Matcher  Description      Headers: Content-Type, application/json  Match HTTP header. It accepts a comma-separated key/value pair where both key and value must be literals.    HeadersRegexp: Content-Type, application/(text/json)  Match HTTP header. It accepts a comma-separated key/value pair where the key must be a literal and the value may be a literal or a regular expression.    Host: traefik.io, www.traefik.io  Match request host. It accepts a sequence of literal hosts.    HostRegexp: traefik.io, {subdomain:[a-z]+}.traefik.io  Match request host. It accepts a sequence of literal and regular expression hosts.    Method: GET, POST, PUT  Match request HTTP method. It accepts a sequence of HTTP methods.    Path: /products/, /articles/{category}/{id:[0-9]+}  Match exact request path. It accepts a sequence of literal and regular expression paths.    PathStrip: /products/  Match exact path and strip off the path prior to forwarding the request to the backend. It accepts a sequence of literal paths.    PathStripRegex: /articles/{category}/{id:[0-9]+}  Match exact path and strip off the path prior to forwarding the request to the backend. It accepts a sequence of literal and regular expression paths.    PathPrefix: /products/, /articles/{category}/{id:[0-9]+}  Match request prefix path. It accepts a sequence of literal and regular expression prefix paths.    PathPrefixStrip: /products/  Match request prefix path and strip off the path prefix prior to forwarding the request to the backend. It accepts a sequence of literal prefix paths. Starting with Traefik 1.3, the stripped prefix path will be available in the  X-Forwarded-Prefix  header.    PathPrefixStripRegex: /articles/{category}/{id:[0-9]+}  Match request prefix path and strip off the path prefix prior to forwarding the request to the backend. It accepts a sequence of literal and regular expression prefix paths. Starting with Traefik 1.3, the stripped prefix path will be available in the  X-Forwarded-Prefix  header.    Query: foo=bar, bar=baz  Match Query String parameters. It accepts a sequence of key=value pairs.     In order to use regular expressions with Host and Path matchers, you must declare an arbitrarily named variable followed by the colon-separated regular expression, all enclosed in curly braces. Any pattern supported by  Go's regexp package  may be used (example:  /posts/{id:[0-9]+} ).   Note  The variable has no special meaning; however, it is required by the  gorilla/mux  dependency which embeds the regular expression and defines the syntax.   You can optionally enable  passHostHeader  to forward client  Host  header to the backend.\nYou can also optionally enable  passTLSCert  to forward TLS Client certificates to the backend.", 
            "title": "Matchers"
        }, 
        {
            "location": "/basics/#path-matcher-usage-guidelines", 
            "text": "This section explains when to use the various path matchers.  Use  Path  if your backend listens on the exact path only. For instance,  Path: /products  would match  /products  but not  /products/shoes .  Use a  *Prefix*  matcher if your backend listens on a particular base path but also serves requests on sub-paths.\nFor instance,  PathPrefix: /products  would match  /products  but also  /products/shoes  and  /products/shirts .\nSince the path is forwarded as-is, your backend is expected to listen on  /products .  Use a  *Strip  matcher if your backend listens on the root path ( / ) but should be routeable on a specific prefix.\nFor instance,  PathPrefixStrip: /products  would match  /products  but also  /products/shoes  and  /products/shirts . \nSince the path is stripped prior to forwarding, your backend is expected to listen on  / . \nIf your backend is serving assets (e.g., images or Javascript files), chances are it must return properly constructed relative URLs. \nContinuing on the example, the backend should return  /products/shoes/image.png  (and not  /images.png  which Traefik would likely not be able to associate with the same backend). \nThe  X-Forwarded-Prefix  header (available since Traefik 1.3) can be queried to build such URLs dynamically.  Instead of distinguishing your backends by path only, you can add a Host matcher to the mix.\nThat way, namespacing of your backends happens on the basis of hosts in addition to paths.", 
            "title": "Path Matcher Usage Guidelines"
        }, 
        {
            "location": "/basics/#examples", 
            "text": "Here is an example of frontends definition:  [frontends]\n  [frontends.frontend1]\n  backend =  backend2 \n    [frontends.frontend1.routes.test_1]\n    rule =  Host:test.localhost,test2.localhost \n  [frontends.frontend2]\n  backend =  backend1 \n  passHostHeader = true\n  passTLSCert = true\n  priority = 10\n  entrypoints = [ https ] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule =  HostRegexp:localhost,{subdomain:[a-z]+}.localhost \n  [frontends.frontend3]\n  backend =  backend2 \n    [frontends.frontend3.routes.test_1]\n    rule =  Host:test3.localhost;Path:/test    Three frontends are defined:  frontend1 ,  frontend2  and  frontend3  frontend1  will forward the traffic to the  backend2  if the rule  Host:test.localhost,test2.localhost  is matched  frontend2  will forward the traffic to the  backend1  if the rule  Host:localhost,{subdomain:[a-z]+}.localhost  is matched (forwarding client  Host  header to the backend)  frontend3  will forward the traffic to the  backend2  if the rules  Host:test3.localhost   AND   Path:/test  are matched", 
            "title": "Examples"
        }, 
        {
            "location": "/basics/#combining-multiple-rules", 
            "text": "As seen in the previous example, you can combine multiple rules.\nIn TOML file, you can use multiple routes:    [frontends.frontend3]\n  backend =  backend2 \n    [frontends.frontend3.routes.test_1]\n    rule =  Host:test3.localhost \n    [frontends.frontend3.routes.test_2]\n    rule =  Path:/test   Here  frontend3  will forward the traffic to the  backend2  if the rules  Host:test3.localhost   AND   Path:/test  are matched.  You can also use the notation using a  ;  separator, same result:    [frontends.frontend3]\n  backend =  backend2 \n    [frontends.frontend3.routes.test_1]\n    rule =  Host:test3.localhost;Path:/test   Finally, you can create a rule to bind multiple domains or Path to a frontend, using the  ,  separator:   [frontends.frontend2]\n    [frontends.frontend2.routes.test_1]\n    rule =  Host:test1.localhost,test2.localhost \n  [frontends.frontend3]\n  backend =  backend2 \n    [frontends.frontend3.routes.test_1]\n    rule =  Path:/test1,/test2", 
            "title": "Combining multiple rules"
        }, 
        {
            "location": "/basics/#rules-order", 
            "text": "When combining  Modifier  rules with  Matcher  rules, it is important to remember that  Modifier  rules  ALWAYS  apply after the  Matcher  rules.  The following rules are both  Matchers  and  Modifiers , so the  Matcher  portion of the rule will apply first, and the  Modifier  will apply later.   PathStrip  PathStripRegex  PathPrefixStrip  PathPrefixStripRegex   Modifiers  will be applied in a pre-determined order regardless of their order in the  rule  configuration section.   PathStrip  PathPrefixStrip  PathStripRegex  PathPrefixStripRegex  AddPrefix  ReplacePath", 
            "title": "Rules Order"
        }, 
        {
            "location": "/basics/#priorities", 
            "text": "By default, routes will be sorted (in descending order) using rules length (to avoid path overlap): PathPrefix:/foo;Host:foo.com  (length == 28) will be matched before  PathPrefixStrip:/foobar  (length == 23) will be matched before  PathPrefix:/foo,/bar  (length == 20).  You can customize priority by frontend. The priority value override the rule length during sorting:    [frontends]\n    [frontends.frontend1]\n    backend =  backend1 \n    priority = 20\n    passHostHeader = true\n      [frontends.frontend1.routes.test_1]\n      rule =  PathPrefix:/to \n    [frontends.frontend2]\n    backend =  backend2 \n    passHostHeader = true\n      [frontends.frontend2.routes.test_1]\n      rule =  PathPrefix:/toto   Here,  frontend1  will be matched before  frontend2  ( 20   16 ).", 
            "title": "Priorities"
        }, 
        {
            "location": "/basics/#custom-headers", 
            "text": "Custom headers can be configured through the frontends, to add headers to either requests or responses that match the frontend's rules.\nThis allows for setting headers such as  X-Script-Name  to be added to the request, or custom headers to be added to the response.   Warning  If the custom header name is the same as one header name of the request or response, it will be replaced.   In this example, all matches to the path  /cheese  will have the  X-Script-Name  header added to the proxied request, and the  X-Custom-Response-Header  added to the response.  [frontends]\n  [frontends.frontend1]\n  backend =  backend1 \n    [frontends.frontend1.headers.customresponseheaders]\n    X-Custom-Response-Header =  True \n    [frontends.frontend1.headers.customrequestheaders]\n    X-Script-Name =  test \n    [frontends.frontend1.routes.test_1]\n    rule =  PathPrefixStrip:/cheese   In this second  example, all matches to the path  /cheese  will have the  X-Script-Name  header added to the proxied request, the  X-Custom-Request-Header  removed to the request and the  X-Custom-Response-Header  removed to the response.  [frontends]\n  [frontends.frontend1]\n  backend =  backend1 \n    [frontends.frontend1.headers.customresponseheaders]\n    X-Custom-Response-Header =  \n    [frontends.frontend1.headers.customrequestheaders]\n    X-Script-Name =  test \n    X-Custom-Request-Header =  \n    [frontends.frontend1.routes.test_1]\n    rule =  PathPrefixStrip:/cheese", 
            "title": "Custom headers"
        }, 
        {
            "location": "/basics/#security-headers", 
            "text": "Security related headers (HSTS headers, SSL redirection, Browser XSS filter, etc) can be added and configured per frontend in a similar manner to the custom headers above.\nThis functionality allows for some easy security features to quickly be set.  An example of some of the security headers:  [frontends]\n  [frontends.frontend1]\n  backend =  backend1 \n    [frontends.frontend1.headers]\n    FrameDeny = true\n    [frontends.frontend1.routes.test_1]\n    rule =  PathPrefixStrip:/cheddar \n  [frontends.frontend2]\n  backend =  backend2 \n    [frontends.frontend2.headers]\n    SSLRedirect = true\n    [frontends.frontend2.routes.test_1]\n    rule =  PathPrefixStrip:/stilton   In this example, traffic routed through the first frontend will have the  X-Frame-Options  header set to  DENY , and the second will only allow HTTPS request through, otherwise will return a 301 HTTPS redirect.   Note  The detailed documentation for those security headers can be found in  unrolled/secure .", 
            "title": "Security headers"
        }, 
        {
            "location": "/basics/#backends", 
            "text": "A backend is responsible to load-balance the traffic coming from one or more frontends to a set of http servers.  Various methods of load-balancing are supported:   wrr : Weighted Round Robin.  drr : Dynamic Round Robin: increases weights on servers that perform better than others.\n    It also rolls back to original weights if the servers have changed.   A circuit breaker can also be applied to a backend, preventing high loads on failing servers.\nInitial state is Standby. CB observes the statistics and does not modify the request.\nIn case the condition matches, CB enters Tripped state, where it responds with predefined code or redirects to another frontend.\nOnce Tripped timer expires, CB enters Recovering state and resets all stats.\nIn case the condition does not match and recovery timer expires, CB enters Standby state.  It can be configured using:   Methods:  LatencyAtQuantileMS ,  NetworkErrorRatio ,  ResponseCodeRatio  Operators:   AND ,  OR ,  EQ ,  NEQ ,  LT ,  LE ,  GT ,  GE   For example:   NetworkErrorRatio()   0.5 : watch error ratio over 10 second sliding window for a frontend.  LatencyAtQuantileMS(50.0)   50 :  watch latency at quantile in milliseconds.  ResponseCodeRatio(500, 600, 0, 600)   0.5 : ratio of response codes in ranges [500-600) and [0-600).   To proactively prevent backends from being overwhelmed with high load, a maximum connection limit can also be applied to each backend.  Maximum connections can be configured by specifying an integer value for  maxconn.amount  and  maxconn.extractorfunc  which is a strategy used to determine how to categorize requests in order to evaluate the maximum connections.  For example:  [backends]\n  [backends.backend1]\n    [backends.backend1.maxconn]\n       amount = 10\n       extractorfunc =  request.host    backend1  will return  HTTP code 429 Too Many Requests  if there are already 10 requests in progress for the same Host header.  Another possible value for  extractorfunc  is  client.ip  which will categorize requests based on client source ip.  Lastly  extractorfunc  can take the value of  request.header.ANY_HEADER  which will categorize requests based on  ANY_HEADER  that you provide.", 
            "title": "Backends"
        }, 
        {
            "location": "/basics/#sticky-sessions", 
            "text": "Sticky sessions are supported with both load balancers. \nWhen sticky sessions are enabled, a cookie is set on the initial request.\nThe default cookie name is an abbreviation of a sha1 (ex:  _1d52e ).\nOn subsequent requests, the client will be directed to the backend stored in the cookie if it is still healthy.\nIf not, a new backend will be assigned.  [backends]\n  [backends.backend1]\n    # Enable sticky session\n    [backends.backend1.loadbalancer.stickiness]\n\n    # Customize the cookie name\n    #\n    # Optional\n    # Default: a sha1 (6 chars)\n    #\n    #  cookieName =  my_cookie   The deprecated way:  [backends]\n  [backends.backend1]\n    [backends.backend1.loadbalancer]\n      sticky = true", 
            "title": "Sticky sessions"
        }, 
        {
            "location": "/basics/#health-check", 
            "text": "A health check can be configured in order to remove a backend from LB rotation as long as it keeps returning HTTP status codes other than  200 OK  to HTTP GET requests periodically carried out by Traefik. \nThe check is defined by a pathappended to the backend URL and an interval (given in a format understood by  time.ParseDuration ) specifying how often the health check should be executed (the default being 30 seconds).\nEach backend must respond to the health check within 5 seconds. \nBy default, the port of the backend server is used, however, this may be overridden.  A recovering backend returning 200 OK responses again is being returned to the\nLB rotation pool.  For example:  [backends]\n  [backends.backend1]\n    [backends.backend1.healthcheck]\n    path =  /health \n    interval =  10s   To use a different port for the healthcheck:  [backends]\n  [backends.backend1]\n    [backends.backend1.healthcheck]\n    path =  /health \n    interval =  10s \n    port = 8080", 
            "title": "Health Check"
        }, 
        {
            "location": "/basics/#servers", 
            "text": "Servers are simply defined using a  url . You can also apply a custom  weight  to each server (this will be used by load-balancing).   Note  Paths in  url  are ignored. Use  Modifier  to specify paths instead.   Here is an example of backends and servers definition:  [backends]\n  [backends.backend1]\n    [backends.backend1.circuitbreaker]\n    expression =  NetworkErrorRatio()   0.5 \n    [backends.backend1.servers.server1]\n    url =  http://172.17.0.2:80 \n    weight = 10\n    [backends.backend1.servers.server2]\n    url =  http://172.17.0.3:80 \n    weight = 1\n  [backends.backend2]\n    [backends.backend2.LoadBalancer]\n    method =  drr \n    [backends.backend2.servers.server1]\n    url =  http://172.17.0.4:80 \n    weight = 1\n    [backends.backend2.servers.server2]\n    url =  http://172.17.0.5:80 \n    weight = 2   Two backends are defined:  backend1  and  backend2  backend1  will forward the traffic to two servers:  http://172.17.0.2:80\"  with weight  10  and  http://172.17.0.3:80  with weight  1  using default  wrr  load-balancing strategy.  backend2  will forward the traffic to two servers:  http://172.17.0.4:80\"  with weight  1  and  http://172.17.0.5:80  with weight  2  using  drr  load-balancing strategy.  a circuit breaker is added on  backend1  using the expression  NetworkErrorRatio()   0.5 : watch error ratio over 10 second sliding window", 
            "title": "Servers"
        }, 
        {
            "location": "/basics/#configuration", 
            "text": "Tr\u00e6fik's configuration has two parts:   The  static Tr\u00e6fik configuration  which is loaded only at the beginning.  The  dynamic Tr\u00e6fik configuration  which can be hot-reloaded (no need to restart the process).", 
            "title": "Configuration"
        }, 
        {
            "location": "/basics/#static-trfik-configuration", 
            "text": "The static configuration is the global configuration which is setting up connections to configuration backends and entrypoints.  Tr\u00e6fik can be configured using many configuration sources with the following precedence order.\nEach item takes precedence over the item below it:   Key-value store  Arguments  Configuration file  Default   It means that arguments override configuration file, and key-value store overrides arguments.   Note  the provider-enabling argument parameters (e.g.,  --docker ) set all default values for the specific provider. \nIt must not be used if a configuration source with less precedence wants to set a non-default provider value.", 
            "title": "Static Tr\u00e6fik configuration"
        }, 
        {
            "location": "/basics/#configuration-file", 
            "text": "By default, Tr\u00e6fik will try to find a  traefik.toml  in the following places:   /etc/traefik/  $HOME/.traefik/  .   the working directory   You can override this by setting a  configFile  argument:  traefik --configFile=foo/bar/myconfigfile.toml  Please refer to the  global configuration  section to get documentation on it.", 
            "title": "Configuration file"
        }, 
        {
            "location": "/basics/#arguments", 
            "text": "Each argument (and command) is described in the help section:  traefik --help  Note that all default values will be displayed as well.", 
            "title": "Arguments"
        }, 
        {
            "location": "/basics/#key-value-stores", 
            "text": "Tr\u00e6fik supports several Key-value stores:   Consul  etcd  ZooKeeper  boltdb   Please refer to the  User Guide Key-value store configuration  section to get documentation on it.", 
            "title": "Key-value stores"
        }, 
        {
            "location": "/basics/#dynamic-trfik-configuration", 
            "text": "The dynamic configuration concerns :   Frontends  Backends  Servers  HTTPS Certificates   Tr\u00e6fik can hot-reload those rules which could be provided by  multiple configuration backends .  We only need to enable  watch  option to make Tr\u00e6fik watch configuration backend changes and generate its configuration automatically.\nRoutes to services will be created and updated instantly at any changes.  Please refer to the  configuration backends  section to get documentation on it.", 
            "title": "Dynamic Tr\u00e6fik configuration"
        }, 
        {
            "location": "/basics/#commands", 
            "text": "", 
            "title": "Commands"
        }, 
        {
            "location": "/basics/#traefik", 
            "text": "Usage:  traefik [command] [--flag=flag_argument]  List of Tr\u00e6fik available\u00a0commands with description :   version  : Print\u00a0version  storeconfig  : Store the static Traefik configuration into a Key-value stores.\u00a0Please refer to the  Store Tr\u00e6fik configuration  section to get documentation on it.  bug : The easiest way to submit a pre-filled issue.  healthcheck : Calls Traefik  /ping  to check health.   Each command may have related flags.  All those related flags will be displayed with :  traefik [command] --help  Each command is described at the beginning of the help section:  traefik --help\n\n# or\n\ndocker run traefik[:version] --help\n# ex: docker run traefik:1.5 --help", 
            "title": "traefik"
        }, 
        {
            "location": "/basics/#command-bug", 
            "text": "Here is the easiest way to submit a pre-filled issue on  Tr\u00e6fik GitHub .  traefik bug  Watch  this demo .", 
            "title": "Command: bug"
        }, 
        {
            "location": "/basics/#command-healthcheck", 
            "text": "This command allows to check the health of Traefik. Its exit status is  0  if Traefik is healthy and  1  if it is unhealthy.  This can be used with Docker  HEALTHCHECK  instruction or any other health check orchestration mechanism.   Note  The  ping  must be enabled to allow the  healthcheck  command to call  /ping .   traefik healthcheck  OK: http://:8082/ping", 
            "title": "Command: healthcheck"
        }, 
        {
            "location": "/basics/#collected-data", 
            "text": "This feature is disabled by default.  You can read the public proposal on this topic  here .", 
            "title": "Collected Data"
        }, 
        {
            "location": "/basics/#why", 
            "text": "In order to help us learn more about how Tr\u00e6fik is being used and improve it, we collect anonymous usage statistics from running instances.\nThose data help us prioritize our developments and focus on what's more important (for example, which configuration backend is used and which is not used).", 
            "title": "Why ?"
        }, 
        {
            "location": "/basics/#what", 
            "text": "Once a day (the first call begins 10 minutes after the start of Tr\u00e6fik), we collect:   the Tr\u00e6fik version  a hash of the configuration  an  anonymous version  of the static configuration:  token, user name, password, URL, IP, domain, email, etc, are removed      Note  We do not collect the dynamic configuration (frontends   backends).    Note  We do not collect data behind the scenes to run advertising programs or to sell such data to third-party.", 
            "title": "What ?"
        }, 
        {
            "location": "/basics/#here-is-an-example", 
            "text": "Source configuration:   [entryPoints]\n    [entryPoints.http]\n       address =  :80 \n\n[api]\n\n[Docker]\n  endpoint =  tcp://10.10.10.10:2375 \n  domain =  foo.bir \n  exposedByDefault = true\n  swarmMode = true\n\n  [Docker.TLS]\n    CA =  dockerCA \n    Cert =  dockerCert \n    Key =  dockerKey \n    InsecureSkipVerify = true\n\n[ECS]\n  Domain =  foo.bar \n  ExposedByDefault = true\n  Clusters = [ foo-bar ]\n  Region =  us-west-2 \n  AccessKeyID =  AccessKeyID \n  SecretAccessKey =  SecretAccessKey    Obfuscated and anonymous configuration:   [entryPoints]\n    [entryPoints.http]\n       address =  :80 \n\n[api]\n\n[Docker]\n  Endpoint =  xxxx \n  Domain =  xxxx \n  ExposedByDefault = true\n  SwarmMode = true\n\n  [Docker.TLS]\n    CA =  xxxx \n    Cert =  xxxx \n    Key =  xxxx \n    InsecureSkipVerify = false\n\n[ECS]\n  Domain =  xxxx \n  ExposedByDefault = true\n  Clusters = []\n  Region =  us-west-2 \n  AccessKeyID =  xxxx \n  SecretAccessKey =  xxxx", 
            "title": "Here is an example"
        }, 
        {
            "location": "/basics/#show-me-the-code", 
            "text": "If you want to dig into more details, here is the source code of the collecting system:  collector.go  By default we anonymize all configuration fields, except fields tagged with  export=true .  You can check all fields in the  godoc .", 
            "title": "Show me the code !"
        }, 
        {
            "location": "/basics/#how-to-enable-this", 
            "text": "You can enable the collecting system by:   adding this line in the configuration TOML file:   # Send anonymous usage data\n#\n# Optional\n# Default: false\n#\nsendAnonymousUsage = true   adding this flag in the CLI:   ./traefik --sendAnonymousUsage=true", 
            "title": "How to enable this ?"
        }, 
        {
            "location": "/configuration/commons/", 
            "text": "Global Configuration\n\n\nMain Section\n\n\n# DEPRECATED - for general usage instruction see [lifeCycle.graceTimeOut].\n#\n# If both the deprecated option and the new one are given, the deprecated one\n# takes precedence.\n# A value of zero is equivalent to omitting the parameter, causing\n# [lifeCycle.graceTimeOut] to be effective. Pass zero to the new option in\n# order to disable the grace period.\n#\n# Optional\n# Default: \n0s\n\n#\n# graceTimeOut = \n10s\n\n\n# Enable debug mode.\n# This will install HTTP handlers to expose Go expvars under /debug/vars and\n# pprof profiling data under /debug/pprof.\n# Additionally, the log level will be set to DEBUG.\n#\n# Optional\n# Default: false\n#\n# debug = true\n\n# Periodically check if a new version has been released.\n#\n# Optional\n# Default: true\n#\n# checkNewVersion = false\n\n# Backends throttle duration.\n#\n# Optional\n# Default: \n2s\n\n#\n# ProvidersThrottleDuration = \n2s\n\n\n# Controls the maximum idle (keep-alive) connections to keep per-host.\n#\n# Optional\n# Default: 200\n#\n# MaxIdleConnsPerHost = 200\n\n# If set to true invalid SSL certificates are accepted for backends.\n# This disables detection of man-in-the-middle attacks so should only be used on secure backend networks.\n#\n# Optional\n# Default: false\n#\n# InsecureSkipVerify = true\n\n# Register Certificates in the RootCA.\n#\n# Optional\n# Default: []\n#\n# RootCAs = [ \n/mycert.cert\n ]\n\n# Entrypoints to be used by frontends that do not specify any entrypoint.\n# Each frontend can specify its own entrypoints.\n#\n# Optional\n# Default: [\nhttp\n]\n#\n# defaultEntryPoints = [\nhttp\n, \nhttps\n]\n\n\n\n\n\n\n\n\ngraceTimeOut\n: Duration to give active requests a chance to finish before Traefik stops.\n\nCan be provided in a format supported by \ntime.ParseDuration\n or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.\n\n\nNote:\n in this time frame no new requests are accepted.\n\n\n\n\n\n\nProvidersThrottleDuration\n: Backends throttle duration: minimum duration in seconds between 2 events from providers before applying a new configuration.\nIt avoids unnecessary reloads if multiples events are sent in a short amount of time.\n\nCan be provided in a format supported by \ntime.ParseDuration\n or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.\n\n\n\n\n\n\nMaxIdleConnsPerHost\n: Controls the maximum idle (keep-alive) connections to keep per-host.\n\nIf zero, \nDefaultMaxIdleConnsPerHost\n from the Go standard library net/http module is used.\nIf you encounter 'too many open files' errors, you can either increase this value or change the \nulimit\n.\n\n\n\n\n\n\nInsecureSkipVerify\n : If set to true invalid SSL certificates are accepted for backends.\n\n\nNote:\n This disables detection of man-in-the-middle attacks so should only be used on secure backend networks.\n\n\n\n\n\n\nRootCAs\n: Register Certificates in the RootCA. This certificates will be use for backends calls.\n\n\nNote\n You can use file path or cert content directly\n\n\n\n\n\n\ndefaultEntryPoints\n: Entrypoints to be used by frontends that do not specify any entrypoint.\n\nEach frontend can specify its own entrypoints.\n\n\n\n\n\n\nConstraints\n\n\nIn a micro-service architecture, with a central service discovery, setting constraints limits Tr\u00e6fik scope to a smaller number of routes.\n\n\nTr\u00e6fik filters services according to service attributes/tags set in your configuration backends.\n\n\nSupported filters:\n\n\n\n\ntag\n\n\n\n\nSimple\n\n\n# Simple matching constraint\nconstraints = [\ntag==api\n]\n\n# Simple mismatching constraint\nconstraints = [\ntag!=api\n]\n\n# Globbing\nconstraints = [\ntag==us-*\n]\n\n\n\n\nMultiple\n\n\n# Multiple constraints\n#   - \ntag==\n must match with at least one tag\n#   - \ntag!=\n must match with none of tags\nconstraints = [\ntag!=us-*\n, \ntag!=asia-*\n]\n\n\n\n\nBackend-specific\n\n\nSupported backends:\n\n\n\n\nDocker\n\n\nConsul K/V\n\n\nBoltDB\n\n\nZookeeper\n\n\nEtcd\n\n\nConsul Catalog\n\n\nRancher\n\n\nMarathon\n\n\nKubernetes (using a provider-specific mechanism based on label selectors)\n\n\n\n\n# Backend-specific constraint\n[consulCatalog]\n# ...\nconstraints = [\ntag==api\n]\n\n# Backend-specific constraint\n[marathon]\n# ...\nconstraints = [\ntag==api\n, \ntag!=v*-beta\n]\n\n\n\n\nLogs Definition\n\n\nTraefik logs\n\n\n# Traefik logs file\n# If not defined, logs to stdout\n#\n# DEPRECATED - see [traefikLog] lower down\n# In case both traefikLogsFile and traefikLog.filePath are specified, the latter will take precedence.\n# Optional\n#\ntraefikLogsFile = \nlog/traefik.log\n\n\n# Log level\n#\n# Optional\n# Default: \nERROR\n\n#\n# Accepted values, in order of severity: \nDEBUG\n, \nINFO\n, \nWARN\n, \nERROR\n, \nFATAL\n, \nPANIC\n\n# Messages at and above the selected level will be logged.\n#\nlogLevel = \nERROR\n\n\n\n\n\nTraefik Logs\n\n\nBy default the Traefik log is written to stdout in text format.\n\n\nTo write the logs into a logfile specify the \nfilePath\n.\n\n\n[traefikLog]\n  filePath = \n/path/to/traefik.log\n\n\n\n\n\nTo write JSON format logs, specify \njson\n as the format:\n\n\n[traefikLog]\n  filePath = \n/path/to/traefik.log\n\n  format   = \njson\n\n\n\n\n\nAccess Logs\n\n\nAccess logs are written when \n[accessLog]\n is defined.\nBy default it will write to stdout and produce logs in the textual Common Log Format (CLF), extended with additional fields.\n\n\nTo enable access logs using the default settings just add the \n[accessLog]\n entry.\n\n\n[accessLog]\n\n\n\n\nTo write the logs into a logfile specify the \nfilePath\n.\n\n\n[accessLog]\nfilePath = \n/path/to/access.log\n\n\n\n\n\nTo write JSON format logs, specify \njson\n as the format:\n\n\n[accessLog]\nfilePath = \n/path/to/access.log\n\nformat = \njson\n\n\n\n\n\nDeprecated way (before 1.4):\n\n\n# Access logs file\n#\n# DEPRECATED - see [accessLog] lower down\n#\naccessLogsFile = \nlog/access.log\n\n\n\n\n\nLog Rotation\n\n\nTraefik will close and reopen its log files, assuming they're configured, on receipt of a USR1 signal.\nThis allows the logs to be rotated and processed by an external program, such as \nlogrotate\n.\n\n\n\n\nNote\n\n\nThis does not work on Windows due to the lack of USR signals.\n\n\n\n\nCustom Error pages\n\n\nCustom error pages can be returned, in lieu of the default, according to frontend-configured ranges of HTTP Status codes.\n\n\nIn the example below, if a 503 status is returned from the frontend \"website\", the custom error page at http://2.3.4.5/503.html is returned with the actual status code set in the HTTP header.\n\n\n\n\nNote\n\n\nThe \n503.html\n page itself is not hosted on Traefik, but some other infrastructure.\n\n\n\n\n[frontends]\n  [frontends.website]\n  backend = \nwebsite\n\n  [frontends.website.errors]\n    [frontends.website.errors.network]\n    status = [\n500-599\n]\n    backend = \nerror\n\n    query = \n/{status}.html\n\n  [frontends.website.routes.website]\n  rule = \nHost: website.mydomain.com\n\n\n[backends]\n  [backends.website]\n    [backends.website.servers.website]\n    url = \nhttps://1.2.3.4\n\n  [backends.error]\n    [backends.error.servers.error]\n    url = \nhttp://2.3.4.5\n\n\n\n\n\nIn the above example, the error page rendered was based on the status code.\nInstead, the query parameter can also be set to some generic error page like so: \nquery = \"/500s.html\"\n\n\nNow the \n500s.html\n error page is returned for the configured code range.\nThe configured status code ranges are inclusive; that is, in the above example, the \n500s.html\n page will be returned for status codes \n500\n through, and including, \n599\n.\n\n\nCustom error pages are easiest to implement using the file provider.\nFor dynamic providers, the corresponding template file needs to be customized accordingly and referenced in the Traefik configuration.\n\n\nRate limiting\n\n\nRate limiting can be configured per frontend.\n\nMultiple sets of rates can be added to each frontend, but the time periods must be unique.\n\n\n[frontends]\n    [frontends.frontend1]\n      # ...\n      [frontends.frontend1.ratelimit]\n        extractorfunc = \nclient.ip\n\n          [frontends.frontend1.ratelimit.rateset.rateset1]\n            period = \n10s\n\n            average = 100\n            burst = 200\n          [frontends.frontend1.ratelimit.rateset.rateset2]\n            period = \n3s\n\n            average = 5\n            burst = 10\n\n\n\n\nIn the above example, frontend1 is configured to limit requests by the client's ip address.\n\nAn average of 5 requests every 3 seconds is allowed and an average of 100 requests every 10 seconds.\n\nThese can \"burst\" up to 10 and 200 in each period respectively.\n\n\nRetry Configuration\n\n\n# Enable retry sending request if network error\n[retry]\n\n# Number of attempts\n#\n# Optional\n# Default: (number servers in backend) -1\n#\n# attempts = 3\n\n\n\n\nHealth Check Configuration\n\n\n# Enable custom health check options.\n[healthcheck]\n\n# Set the default health check interval.\n#\n# Optional\n# Default: \n30s\n\n#\n# interval = \n30s\n\n\n\n\n\n\n\ninterval\n set the default health check interval.\n\nWill only be effective if health check paths are defined.\n\nGiven provider-specific support, the value may be overridden on a per-backend basis.\n\nCan be provided in a format supported by \ntime.ParseDuration\n or as raw values (digits).\n\nIf no units are provided, the value is parsed assuming seconds.\n\n\n\n\nLife Cycle\n\n\nControls the behavior of Traefik during the shutdown phase.\n\n\n[lifeCycle]\n\n# Duration to keep accepting requests prior to initiating the graceful\n# termination period (as defined by the `graceTimeOut` option). This\n# option is meant to give downstream load-balancers sufficient time to\n# take Traefik out of rotation.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw values (digits).\n# If no units are provided, the value is parsed assuming seconds.\n# The zero duration disables the request accepting grace period, i.e.,\n# Traefik will immediately proceed to the grace period.\n#\n# Optional\n# Default: 0\n#\n# requestAcceptGraceTimeout = \n10s\n\n\n# Duration to give active requests a chance to finish before Traefik stops.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw values (digits).\n# If no units are provided, the value is parsed assuming seconds.\n# Note: in this time frame no new requests are accepted.\n#\n# Optional\n# Default: \n10s\n\n#\n# graceTimeOut = \n10s\n\n\n\n\n\nTimeouts\n\n\nResponding Timeouts\n\n\nrespondingTimeouts\n are timeouts for incoming requests to the Traefik instance.\n\n\n[respondingTimeouts]\n\n# readTimeout is the maximum duration for reading the entire request, including the body.\n#\n# Optional\n# Default: \n0s\n\n#\n# readTimeout = \n5s\n\n\n# writeTimeout is the maximum duration before timing out writes of the response.\n#\n# Optional\n# Default: \n0s\n\n#\n# writeTimeout = \n5s\n\n\n# idleTimeout is the maximum duration an idle (keep-alive) connection will remain idle before closing itself.\n#\n# Optional\n# Default: \n180s\n\n#\n# idleTimeout = \n360s\n\n\n\n\n\n\n\n\n\nreadTimeout\n is the maximum duration for reading the entire request, including the body.\n\nIf zero, no timeout exists.\n\nCan be provided in a format supported by \ntime.ParseDuration\n or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.\n\n\n\n\n\n\nwriteTimeout\n is the maximum duration before timing out writes of the response.\n\nIt covers the time from the end of the request header read to the end of the response write.\nIf zero, no timeout exists.\n\nCan be provided in a format supported by \ntime.ParseDuration\n or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.\n\n\n\n\n\n\nidleTimeout\n is the maximum duration an idle (keep-alive) connection will remain idle before closing itself.\n\nIf zero, no timeout exists.\n\nCan be provided in a format supported by \ntime.ParseDuration\n or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.\n\n\n\n\n\n\nForwarding Timeouts\n\n\nforwardingTimeouts\n are timeouts for requests forwarded to the backend servers.\n\n\n[forwardingTimeouts]\n\n# dialTimeout is the amount of time to wait until a connection to a backend server can be established.\n#\n# Optional\n# Default: \n30s\n\n#\n# dialTimeout = \n30s\n\n\n# responseHeaderTimeout is the amount of time to wait for a server's response headers after fully writing the request (including its body, if any).\n#\n# Optional\n# Default: \n0s\n\n#\n# responseHeaderTimeout = \n0s\n\n\n\n\n\n\n\n\n\ndialTimeout\n is the amount of time to wait until a connection to a backend server can be established.\n\nIf zero, no timeout exists.\n\nCan be provided in a format supported by \ntime.ParseDuration\n or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.\n\n\n\n\n\n\nresponseHeaderTimeout\n is the amount of time to wait for a server's response headers after fully writing the request (including its body, if any).\n\nIf zero, no timeout exists.\n\nCan be provided in a format supported by \ntime.ParseDuration\n or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.\n\n\n\n\n\n\nIdle Timeout (deprecated)\n\n\nUse \nrespondingTimeouts\n instead of \nIdleTimeout\n.\nIn the case both settings are configured, the deprecated option will be overwritten.\n\n\nIdleTimeout\n is the maximum amount of time an idle (keep-alive) connection will remain idle before closing itself.\nThis is set to enforce closing of stale client connections.\n\n\nCan be provided in a format supported by \ntime.ParseDuration\n or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.\n\n\n# IdleTimeout\n#\n# DEPRECATED - see [respondingTimeouts] section.\n#\n# Optional\n# Default: \n180s\n\n#\nIdleTimeout = \n360s\n\n\n\n\n\nOverride Default Configuration Template\n\n\n\n\nWarning\n\n\nFor advanced users only.\n\n\n\n\nSupported by all backends except: File backend, Web backend and DynamoDB backend.\n\n\n[backend_name]\n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n# Default: \n\n#\nfilename = \ncustom_config_template.tpml\n\n\n# Enable debug logging of generated configuration template.\n#\n# Optional\n# Default: false\n#\ndebugLogGeneratedTemplate = true\n\n\n\n\nExample:\n\n\n[marathon]\nfilename = \nmy_custom_config_template.tpml\n\n\n\n\n\nThe template files can be written using functions provided by:\n\n\n\n\ngo template\n\n\nsprig library\n\n\n\n\nExample:\n\n\n[backends]\n  [backends.backend1]\n  url = \nhttp://firstserver\n\n  [backends.backend2]\n  url = \nhttp://secondserver\n\n\n{{$frontends := dict \nfrontend1\n \nbackend1\n \nfrontend2\n \nbackend2\n}}\n[frontends]\n{{range $frontend, $backend := $frontends}}\n  [frontends.{{$frontend}}]\n  backend = \n{{$backend}}\n\n{{end}}", 
            "title": "Commons"
        }, 
        {
            "location": "/configuration/commons/#global-configuration", 
            "text": "", 
            "title": "Global Configuration"
        }, 
        {
            "location": "/configuration/commons/#main-section", 
            "text": "# DEPRECATED - for general usage instruction see [lifeCycle.graceTimeOut].\n#\n# If both the deprecated option and the new one are given, the deprecated one\n# takes precedence.\n# A value of zero is equivalent to omitting the parameter, causing\n# [lifeCycle.graceTimeOut] to be effective. Pass zero to the new option in\n# order to disable the grace period.\n#\n# Optional\n# Default:  0s \n#\n# graceTimeOut =  10s \n\n# Enable debug mode.\n# This will install HTTP handlers to expose Go expvars under /debug/vars and\n# pprof profiling data under /debug/pprof.\n# Additionally, the log level will be set to DEBUG.\n#\n# Optional\n# Default: false\n#\n# debug = true\n\n# Periodically check if a new version has been released.\n#\n# Optional\n# Default: true\n#\n# checkNewVersion = false\n\n# Backends throttle duration.\n#\n# Optional\n# Default:  2s \n#\n# ProvidersThrottleDuration =  2s \n\n# Controls the maximum idle (keep-alive) connections to keep per-host.\n#\n# Optional\n# Default: 200\n#\n# MaxIdleConnsPerHost = 200\n\n# If set to true invalid SSL certificates are accepted for backends.\n# This disables detection of man-in-the-middle attacks so should only be used on secure backend networks.\n#\n# Optional\n# Default: false\n#\n# InsecureSkipVerify = true\n\n# Register Certificates in the RootCA.\n#\n# Optional\n# Default: []\n#\n# RootCAs = [  /mycert.cert  ]\n\n# Entrypoints to be used by frontends that do not specify any entrypoint.\n# Each frontend can specify its own entrypoints.\n#\n# Optional\n# Default: [ http ]\n#\n# defaultEntryPoints = [ http ,  https ]    graceTimeOut : Duration to give active requests a chance to finish before Traefik stops. \nCan be provided in a format supported by  time.ParseDuration  or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.  Note:  in this time frame no new requests are accepted.    ProvidersThrottleDuration : Backends throttle duration: minimum duration in seconds between 2 events from providers before applying a new configuration.\nIt avoids unnecessary reloads if multiples events are sent in a short amount of time. \nCan be provided in a format supported by  time.ParseDuration  or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.    MaxIdleConnsPerHost : Controls the maximum idle (keep-alive) connections to keep per-host. \nIf zero,  DefaultMaxIdleConnsPerHost  from the Go standard library net/http module is used.\nIf you encounter 'too many open files' errors, you can either increase this value or change the  ulimit .    InsecureSkipVerify  : If set to true invalid SSL certificates are accepted for backends.  Note:  This disables detection of man-in-the-middle attacks so should only be used on secure backend networks.    RootCAs : Register Certificates in the RootCA. This certificates will be use for backends calls.  Note  You can use file path or cert content directly    defaultEntryPoints : Entrypoints to be used by frontends that do not specify any entrypoint. \nEach frontend can specify its own entrypoints.", 
            "title": "Main Section"
        }, 
        {
            "location": "/configuration/commons/#constraints", 
            "text": "In a micro-service architecture, with a central service discovery, setting constraints limits Tr\u00e6fik scope to a smaller number of routes.  Tr\u00e6fik filters services according to service attributes/tags set in your configuration backends.  Supported filters:   tag", 
            "title": "Constraints"
        }, 
        {
            "location": "/configuration/commons/#simple", 
            "text": "# Simple matching constraint\nconstraints = [ tag==api ]\n\n# Simple mismatching constraint\nconstraints = [ tag!=api ]\n\n# Globbing\nconstraints = [ tag==us-* ]", 
            "title": "Simple"
        }, 
        {
            "location": "/configuration/commons/#multiple", 
            "text": "# Multiple constraints\n#   -  tag==  must match with at least one tag\n#   -  tag!=  must match with none of tags\nconstraints = [ tag!=us-* ,  tag!=asia-* ]", 
            "title": "Multiple"
        }, 
        {
            "location": "/configuration/commons/#backend-specific", 
            "text": "Supported backends:   Docker  Consul K/V  BoltDB  Zookeeper  Etcd  Consul Catalog  Rancher  Marathon  Kubernetes (using a provider-specific mechanism based on label selectors)   # Backend-specific constraint\n[consulCatalog]\n# ...\nconstraints = [ tag==api ]\n\n# Backend-specific constraint\n[marathon]\n# ...\nconstraints = [ tag==api ,  tag!=v*-beta ]", 
            "title": "Backend-specific"
        }, 
        {
            "location": "/configuration/commons/#logs-definition", 
            "text": "", 
            "title": "Logs Definition"
        }, 
        {
            "location": "/configuration/commons/#traefik-logs", 
            "text": "# Traefik logs file\n# If not defined, logs to stdout\n#\n# DEPRECATED - see [traefikLog] lower down\n# In case both traefikLogsFile and traefikLog.filePath are specified, the latter will take precedence.\n# Optional\n#\ntraefikLogsFile =  log/traefik.log \n\n# Log level\n#\n# Optional\n# Default:  ERROR \n#\n# Accepted values, in order of severity:  DEBUG ,  INFO ,  WARN ,  ERROR ,  FATAL ,  PANIC \n# Messages at and above the selected level will be logged.\n#\nlogLevel =  ERROR", 
            "title": "Traefik logs"
        }, 
        {
            "location": "/configuration/commons/#traefik-logs_1", 
            "text": "By default the Traefik log is written to stdout in text format.  To write the logs into a logfile specify the  filePath .  [traefikLog]\n  filePath =  /path/to/traefik.log   To write JSON format logs, specify  json  as the format:  [traefikLog]\n  filePath =  /path/to/traefik.log \n  format   =  json", 
            "title": "Traefik Logs"
        }, 
        {
            "location": "/configuration/commons/#access-logs", 
            "text": "Access logs are written when  [accessLog]  is defined.\nBy default it will write to stdout and produce logs in the textual Common Log Format (CLF), extended with additional fields.  To enable access logs using the default settings just add the  [accessLog]  entry.  [accessLog]  To write the logs into a logfile specify the  filePath .  [accessLog]\nfilePath =  /path/to/access.log   To write JSON format logs, specify  json  as the format:  [accessLog]\nfilePath =  /path/to/access.log \nformat =  json   Deprecated way (before 1.4):  # Access logs file\n#\n# DEPRECATED - see [accessLog] lower down\n#\naccessLogsFile =  log/access.log", 
            "title": "Access Logs"
        }, 
        {
            "location": "/configuration/commons/#log-rotation", 
            "text": "Traefik will close and reopen its log files, assuming they're configured, on receipt of a USR1 signal.\nThis allows the logs to be rotated and processed by an external program, such as  logrotate .   Note  This does not work on Windows due to the lack of USR signals.", 
            "title": "Log Rotation"
        }, 
        {
            "location": "/configuration/commons/#custom-error-pages", 
            "text": "Custom error pages can be returned, in lieu of the default, according to frontend-configured ranges of HTTP Status codes.  In the example below, if a 503 status is returned from the frontend \"website\", the custom error page at http://2.3.4.5/503.html is returned with the actual status code set in the HTTP header.   Note  The  503.html  page itself is not hosted on Traefik, but some other infrastructure.   [frontends]\n  [frontends.website]\n  backend =  website \n  [frontends.website.errors]\n    [frontends.website.errors.network]\n    status = [ 500-599 ]\n    backend =  error \n    query =  /{status}.html \n  [frontends.website.routes.website]\n  rule =  Host: website.mydomain.com \n\n[backends]\n  [backends.website]\n    [backends.website.servers.website]\n    url =  https://1.2.3.4 \n  [backends.error]\n    [backends.error.servers.error]\n    url =  http://2.3.4.5   In the above example, the error page rendered was based on the status code.\nInstead, the query parameter can also be set to some generic error page like so:  query = \"/500s.html\"  Now the  500s.html  error page is returned for the configured code range.\nThe configured status code ranges are inclusive; that is, in the above example, the  500s.html  page will be returned for status codes  500  through, and including,  599 .  Custom error pages are easiest to implement using the file provider.\nFor dynamic providers, the corresponding template file needs to be customized accordingly and referenced in the Traefik configuration.", 
            "title": "Custom Error pages"
        }, 
        {
            "location": "/configuration/commons/#rate-limiting", 
            "text": "Rate limiting can be configured per frontend. \nMultiple sets of rates can be added to each frontend, but the time periods must be unique.  [frontends]\n    [frontends.frontend1]\n      # ...\n      [frontends.frontend1.ratelimit]\n        extractorfunc =  client.ip \n          [frontends.frontend1.ratelimit.rateset.rateset1]\n            period =  10s \n            average = 100\n            burst = 200\n          [frontends.frontend1.ratelimit.rateset.rateset2]\n            period =  3s \n            average = 5\n            burst = 10  In the above example, frontend1 is configured to limit requests by the client's ip address. \nAn average of 5 requests every 3 seconds is allowed and an average of 100 requests every 10 seconds. \nThese can \"burst\" up to 10 and 200 in each period respectively.", 
            "title": "Rate limiting"
        }, 
        {
            "location": "/configuration/commons/#retry-configuration", 
            "text": "# Enable retry sending request if network error\n[retry]\n\n# Number of attempts\n#\n# Optional\n# Default: (number servers in backend) -1\n#\n# attempts = 3", 
            "title": "Retry Configuration"
        }, 
        {
            "location": "/configuration/commons/#health-check-configuration", 
            "text": "# Enable custom health check options.\n[healthcheck]\n\n# Set the default health check interval.\n#\n# Optional\n# Default:  30s \n#\n# interval =  30s    interval  set the default health check interval. \nWill only be effective if health check paths are defined. \nGiven provider-specific support, the value may be overridden on a per-backend basis. \nCan be provided in a format supported by  time.ParseDuration  or as raw values (digits). \nIf no units are provided, the value is parsed assuming seconds.", 
            "title": "Health Check Configuration"
        }, 
        {
            "location": "/configuration/commons/#life-cycle", 
            "text": "Controls the behavior of Traefik during the shutdown phase.  [lifeCycle]\n\n# Duration to keep accepting requests prior to initiating the graceful\n# termination period (as defined by the `graceTimeOut` option). This\n# option is meant to give downstream load-balancers sufficient time to\n# take Traefik out of rotation.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw values (digits).\n# If no units are provided, the value is parsed assuming seconds.\n# The zero duration disables the request accepting grace period, i.e.,\n# Traefik will immediately proceed to the grace period.\n#\n# Optional\n# Default: 0\n#\n# requestAcceptGraceTimeout =  10s \n\n# Duration to give active requests a chance to finish before Traefik stops.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw values (digits).\n# If no units are provided, the value is parsed assuming seconds.\n# Note: in this time frame no new requests are accepted.\n#\n# Optional\n# Default:  10s \n#\n# graceTimeOut =  10s", 
            "title": "Life Cycle"
        }, 
        {
            "location": "/configuration/commons/#timeouts", 
            "text": "", 
            "title": "Timeouts"
        }, 
        {
            "location": "/configuration/commons/#responding-timeouts", 
            "text": "respondingTimeouts  are timeouts for incoming requests to the Traefik instance.  [respondingTimeouts]\n\n# readTimeout is the maximum duration for reading the entire request, including the body.\n#\n# Optional\n# Default:  0s \n#\n# readTimeout =  5s \n\n# writeTimeout is the maximum duration before timing out writes of the response.\n#\n# Optional\n# Default:  0s \n#\n# writeTimeout =  5s \n\n# idleTimeout is the maximum duration an idle (keep-alive) connection will remain idle before closing itself.\n#\n# Optional\n# Default:  180s \n#\n# idleTimeout =  360s     readTimeout  is the maximum duration for reading the entire request, including the body. \nIf zero, no timeout exists. \nCan be provided in a format supported by  time.ParseDuration  or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.    writeTimeout  is the maximum duration before timing out writes of the response. \nIt covers the time from the end of the request header read to the end of the response write.\nIf zero, no timeout exists. \nCan be provided in a format supported by  time.ParseDuration  or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.    idleTimeout  is the maximum duration an idle (keep-alive) connection will remain idle before closing itself. \nIf zero, no timeout exists. \nCan be provided in a format supported by  time.ParseDuration  or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.", 
            "title": "Responding Timeouts"
        }, 
        {
            "location": "/configuration/commons/#forwarding-timeouts", 
            "text": "forwardingTimeouts  are timeouts for requests forwarded to the backend servers.  [forwardingTimeouts]\n\n# dialTimeout is the amount of time to wait until a connection to a backend server can be established.\n#\n# Optional\n# Default:  30s \n#\n# dialTimeout =  30s \n\n# responseHeaderTimeout is the amount of time to wait for a server's response headers after fully writing the request (including its body, if any).\n#\n# Optional\n# Default:  0s \n#\n# responseHeaderTimeout =  0s     dialTimeout  is the amount of time to wait until a connection to a backend server can be established. \nIf zero, no timeout exists. \nCan be provided in a format supported by  time.ParseDuration  or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.    responseHeaderTimeout  is the amount of time to wait for a server's response headers after fully writing the request (including its body, if any). \nIf zero, no timeout exists. \nCan be provided in a format supported by  time.ParseDuration  or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.", 
            "title": "Forwarding Timeouts"
        }, 
        {
            "location": "/configuration/commons/#idle-timeout-deprecated", 
            "text": "Use  respondingTimeouts  instead of  IdleTimeout .\nIn the case both settings are configured, the deprecated option will be overwritten.  IdleTimeout  is the maximum amount of time an idle (keep-alive) connection will remain idle before closing itself.\nThis is set to enforce closing of stale client connections.  Can be provided in a format supported by  time.ParseDuration  or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.  # IdleTimeout\n#\n# DEPRECATED - see [respondingTimeouts] section.\n#\n# Optional\n# Default:  180s \n#\nIdleTimeout =  360s", 
            "title": "Idle Timeout (deprecated)"
        }, 
        {
            "location": "/configuration/commons/#override-default-configuration-template", 
            "text": "Warning  For advanced users only.   Supported by all backends except: File backend, Web backend and DynamoDB backend.  [backend_name]\n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n# Default:  \n#\nfilename =  custom_config_template.tpml \n\n# Enable debug logging of generated configuration template.\n#\n# Optional\n# Default: false\n#\ndebugLogGeneratedTemplate = true  Example:  [marathon]\nfilename =  my_custom_config_template.tpml   The template files can be written using functions provided by:   go template  sprig library   Example:  [backends]\n  [backends.backend1]\n  url =  http://firstserver \n  [backends.backend2]\n  url =  http://secondserver \n\n{{$frontends := dict  frontend1   backend1   frontend2   backend2 }}\n[frontends]\n{{range $frontend, $backend := $frontends}}\n  [frontends.{{$frontend}}]\n  backend =  {{$backend}} \n{{end}}", 
            "title": "Override Default Configuration Template"
        }, 
        {
            "location": "/configuration/entrypoints/", 
            "text": "Entry Points Definition\n\n\nReference\n\n\nTOML\n\n\n[entryPoints]\n  [entryPoints.http]\n    address = \n:80\n\n    whitelistSourceRange = [\n10.42.0.0/16\n, \n152.89.1.33/32\n, \nafed:be44::/16\n]\n    compress = true\n\n    [entryPoints.http.tls]\n      minVersion = \nVersionTLS12\n\n      cipherSuites = [\n        \nTLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\n,\n        \nTLS_RSA_WITH_AES_256_GCM_SHA384\n\n       ]\n      [[entryPoints.http.tls.certificates]]\n        certFile = \npath/to/my.cert\n\n        keyFile = \npath/to/my.key\n\n      [[entryPoints.http.tls.certificates]]\n        certFile = \npath/to/other.cert\n\n        keyFile = \npath/to/other.key\n\n      # ...\n      [entryPoints.http.tls.clientCA]\n        files = [\npath/to/ca1.crt\n, \npath/to/ca2.crt\n]\n        optional = false\n\n    [entryPoints.http.redirect]\n      entryPoint = \nhttps\n\n      regex = \n^http://localhost/(.*)\n\n      replacement = \nhttp://mydomain/$1\n\n\n    [entryPoints.http.auth]\n      headerField = \nX-WebAuth-User\n\n      [entryPoints.http.auth.basic]\n        users = [\n          \ntest:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/\n,\n          \ntest2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0\n,\n        ]\n        usersFile = \n/path/to/.htpasswd\n\n      [entryPoints.http.auth.digest]\n        users = [\n          \ntest:traefik:a2688e031edb4be6a3797f3882655c05\n,\n          \ntest2:traefik:518845800f9e2bfb1f1f740ec24f074e\n,\n        ]\n        usersFile = \n/path/to/.htdigest\n\n      [entryPoints.http.auth.forward]\n        address = \nhttps://authserver.com/auth\n\n        trustForwardHeader = true\n        [entryPoints.http.auth.forward.tls]\n          ca =  [ \npath/to/local.crt\n]\n          caOptional = true\n          cert = \npath/to/foo.cert\n\n          key = \npath/to/foo.key\n\n          insecureSkipVerify = true\n\n    [entryPoints.http.proxyProtocol]\n      insecure = true\n      trustedIPs = [\n10.10.10.1\n, \n10.10.10.2\n]\n\n    [entryPoints.http.forwardedHeaders]\n      trustedIPs = [\n10.10.10.1\n, \n10.10.10.2\n]\n\n  [entryPoints.https]\n    # ...\n\n\n\n\nCLI\n\n\nFor more information about the CLI, see the documentation about \nTraefik command\n.\n\n\n--entryPoints='Name:http Address::80'\n--entryPoints='Name:https Address::443 TLS'\n\n\n\n\n\n\nNote\n\n\nWhitespace is used as option separator and \n,\n is used as value separator for the list.\n\nThe names of the options are case-insensitive.\n\n\n\n\nIn compose file the entrypoint syntax is different:\n\n\ntraefik:\n    image: traefik\n    command:\n        - --defaultentrypoints=powpow\n        - \n--entryPoints=Name:powpow Address::42 Compress:true\n\n\n\n\n\nor\n\n\ntraefik:\n    image: traefik\n    command: --defaultentrypoints=powpow --entryPoints='Name:powpow Address::42 Compress:true'\n\n\n\n\nAll available options:\n\n\nName:foo\nAddress::80\nTLS:goo,gii\nTLS\nCA:car\nCA.Optional:true\nRedirect.EntryPoint:https\nRedirect.Regex:http://localhost/(.*)\nRedirect.Replacement:http://mydomain/$1\nCompress:true\nWhiteListSourceRange:10.42.0.0/16,152.89.1.33/32,afed:be44::/16\nProxyProtocol.TrustedIPs:192.168.0.1\nProxyProtocol.Insecure:tue\nForwardedHeaders.TrustedIPs:10.0.0.3/24,20.0.0.3/24\n\n\n\n\nBasic\n\n\n# Entrypoints definition\n#\n# Default:\n# [entryPoints]\n#   [entryPoints.http]\n#   address = \n:80\n\n#\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n\n\n\n\nRedirect HTTP to HTTPS\n\n\nTo redirect an http entrypoint to an https entrypoint (with SNI support).\n\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n    [entryPoints.http.redirect]\n    entryPoint = \nhttps\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile = \nintegration/fixtures/https/snitest.com.cert\n\n      keyFile = \nintegration/fixtures/https/snitest.com.key\n\n      [[entryPoints.https.tls.certificates]]\n      certFile = \nintegration/fixtures/https/snitest.org.cert\n\n      keyFile = \nintegration/fixtures/https/snitest.org.key\n\n\n\n\n\n\n\nNote\n\n\nPlease note that \nregex\n and \nreplacement\n do not have to be set in the \nredirect\n structure if an entrypoint is defined for the redirection (they will not be used in this case).\n\n\n\n\nRewriting URL\n\n\nTo redirect an entrypoint rewriting the URL.\n\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n    [entryPoints.http.redirect]\n    regex = \n^http://localhost/(.*)\n\n    replacement = \nhttp://mydomain/$1\n\n\n\n\n\n\n\nNote\n\n\nPlease note that \nregex\n and \nreplacement\n do not have to be set in the \nredirect\n structure if an \nentrypoint\n is defined for the redirection (they will not be used in this case).\n\n\n\n\nCare should be taken when defining replacement expand variables: \n$1x\n is equivalent to \n${1x}\n, not \n${1}x\n (see \nRegexp.Expand\n), so use \n${1}\n syntax.\n\n\nRegular expressions and replacements can be tested using online tools such as \nGo Playground\n or the \nRegex101\n.\n\n\nTLS\n\n\nStatic Certificates\n\n\nDefine an entrypoint with SNI support.\n\n\n[entryPoints]\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile = \nintegration/fixtures/https/snitest.com.cert\n\n      keyFile = \nintegration/fixtures/https/snitest.com.key\n\n\n\n\n\n\n\nNote\n\n\nIf an empty TLS configuration is done, default self-signed certificates are generated.\n\n\n\n\nDynamic Certificates\n\n\nIf you need to add or remove TLS certificates while Traefik is started, Dynamic TLS certificates are supported using the \nfile provider\n.\n\n\nTLS Mutual Authentication\n\n\nTLS Mutual Authentication can be \noptional\n or not.\nIf it's \noptional\n, Tr\u00e6fik will authorize connection with certificates not signed by a specified Certificate Authority (CA).\nOtherwise, Tr\u00e6fik will only accept clients that present a certificate signed by a specified Certificate Authority (CA).\n\nClientCAFiles\n can be configured with multiple \nCA:s\n in the same file or use multiple files containing one or several \nCA:s\n.\nThe \nCA:s\n has to be in PEM format.\n\n\nBy default, \nClientCAFiles\n is not optional, all clients will be required to present a valid cert.\nThe requirement will apply to all server certs in the entrypoint.\n\n\nIn the example below both \nsnitest.com\n and \nsnitest.org\n will require client certs\n\n\n[entryPoints]\n  [entryPoints.https]\n  address = \n:443\n\n  [entryPoints.https.tls]\n    [entryPoints.https.tls.ClientCA]\n    files = [\ntests/clientca1.crt\n, \ntests/clientca2.crt\n]\n    optional = false\n    [[entryPoints.https.tls.certificates]]\n    certFile = \nintegration/fixtures/https/snitest.com.cert\n\n    keyFile = \nintegration/fixtures/https/snitest.com.key\n\n    [[entryPoints.https.tls.certificates]]\n    certFile = \nintegration/fixtures/https/snitest.org.cert\n\n    keyFile = \nintegration/fixtures/https/snitest.org.key\n\n\n\n\n\n\n\nNote\n\n\nThe deprecated argument \nClientCAFiles\n allows adding Client CA files which are mandatory.\nIf this parameter exists, the new ones are not checked.\n\n\n\n\nAuthentication\n\n\nBasic Authentication\n\n\nPasswords can be encoded in MD5, SHA1 and BCrypt: you can use \nhtpasswd\n to generate them.\n\n\nUsers can be specified directly in the TOML file, or indirectly by referencing an external file;\n if both are provided, the two are merged, with external file contents having precedence.\n\n\n# To enable basic auth on an entrypoint with 2 user/pass: test:test and test2:test2\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.http.auth.basic]\n  users = [\ntest:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/\n, \ntest2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0\n]\n  usersFile = \n/path/to/.htpasswd\n\n\n\n\n\nDigest Authentication\n\n\nYou can use \nhtdigest\n to generate them.\n\n\nUsers can be specified directly in the TOML file, or indirectly by referencing an external file;\n if both are provided, the two are merged, with external file contents having precedence\n\n\n# To enable digest auth on an entrypoint with 2 user/realm/pass: test:traefik:test and test2:traefik:test2\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.http.auth.digest]\n  users = [\ntest:traefik:a2688e031edb4be6a3797f3882655c05\n, \ntest2:traefik:518845800f9e2bfb1f1f740ec24f074e\n]\n  usersFile = \n/path/to/.htdigest\n\n\n\n\n\nForward Authentication\n\n\nThis configuration will first forward the request to \nhttp://authserver.com/auth\n.\n\n\nIf the response code is 2XX, access is granted and the original request is performed.\nOtherwise, the response from the authentication server is returned.\n\n\n[entryPoints]\n  [entryPoints.http]\n    # ...\n    # To enable forward auth on an entrypoint\n    [entryPoints.http.auth.forward]\n    address = \nhttps://authserver.com/auth\n\n\n    # Trust existing X-Forwarded-* headers.\n    # Useful with another reverse proxy in front of Traefik.\n    #\n    # Optional\n    # Default: false\n    #\n    trustForwardHeader = true\n\n    # Enable forward auth TLS connection.\n    #\n    # Optional\n    #\n    [entryPoints.http.auth.forward.tls]\n    cert = \nauthserver.crt\n\n    key = \nauthserver.key\n\n\n\n\n\nSpecify Minimum TLS Version\n\n\nTo specify an https entry point with a minimum TLS version, and specifying an array of cipher suites (from \ncrypto/tls\n).\n\n\n[entryPoints]\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n    minVersion = \nVersionTLS12\n\n    cipherSuites = [\n      \nTLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\n,\n      \nTLS_RSA_WITH_AES_256_GCM_SHA384\n\n    ]\n      [[entryPoints.https.tls.certificates]]\n      certFile = \nintegration/fixtures/https/snitest.com.cert\n\n      keyFile = \nintegration/fixtures/https/snitest.com.key\n\n      [[entryPoints.https.tls.certificates]]\n      certFile = \nintegration/fixtures/https/snitest.org.cert\n\n      keyFile = \nintegration/fixtures/https/snitest.org.key\n\n\n\n\n\nCompression\n\n\nTo enable compression support using gzip format.\n\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  compress = true\n\n\n\n\nResponses are compressed when:\n\n\n\n\nThe response body is larger than \n512\n bytes\n\n\nAnd the \nAccept-Encoding\n request header contains \ngzip\n\n\nAnd the response is not already compressed, i.e. the \nContent-Encoding\n response header is not already set.\n\n\n\n\nWhitelisting\n\n\nTo enable IP whitelisting at the entrypoint level.\n\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  whiteListSourceRange = [\n127.0.0.1/32\n, \n192.168.1.7\n]\n\n\n\n\nProxyProtocol\n\n\nTo enable \nProxyProtocol\n support.\nOnly IPs in \ntrustedIPs\n will lead to remote client address replacement: you should declare your load-balancer IP or CIDR range here (in testing environment, you can trust everyone using \ninsecure = true\n).\n\n\n\n\nDanger\n\n\nWhen queuing Tr\u00e6fik behind another load-balancer, be sure to carefully configure Proxy Protocol on both sides.\nOtherwise, it could introduce a security risk in your system by forging requests.\n\n\n\n\n[entryPoints]\n  [entryPoints.http]\n    address = \n:80\n\n\n    # Enable ProxyProtocol\n    [entryPoints.http.proxyProtocol]\n      # List of trusted IPs\n      #\n      # Required\n      # Default: []\n      #\n      trustedIPs = [\n127.0.0.1/32\n, \n192.168.1.7\n]\n\n      # Insecure mode FOR TESTING ENVIRONNEMENT ONLY\n      #\n      # Optional\n      # Default: false\n      #\n      # insecure = true\n\n\n\n\nForwarded Header\n\n\nOnly IPs in \ntrustedIPs\n will be authorized to trust the client forwarded headers (\nX-Forwarded-*\n).\n\n\n[entryPoints]\n  [entryPoints.http]\n    address = \n:80\n\n\n    # Enable Forwarded Headers\n    [entryPoints.http.forwardedHeaders]\n      # List of trusted IPs\n      #\n      # Required\n      # Default: []\n      #\n      trustedIPs = [\n127.0.0.1/32\n, \n192.168.1.7\n]", 
            "title": "EntryPoints"
        }, 
        {
            "location": "/configuration/entrypoints/#entry-points-definition", 
            "text": "", 
            "title": "Entry Points Definition"
        }, 
        {
            "location": "/configuration/entrypoints/#reference", 
            "text": "", 
            "title": "Reference"
        }, 
        {
            "location": "/configuration/entrypoints/#toml", 
            "text": "[entryPoints]\n  [entryPoints.http]\n    address =  :80 \n    whitelistSourceRange = [ 10.42.0.0/16 ,  152.89.1.33/32 ,  afed:be44::/16 ]\n    compress = true\n\n    [entryPoints.http.tls]\n      minVersion =  VersionTLS12 \n      cipherSuites = [\n         TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 ,\n         TLS_RSA_WITH_AES_256_GCM_SHA384 \n       ]\n      [[entryPoints.http.tls.certificates]]\n        certFile =  path/to/my.cert \n        keyFile =  path/to/my.key \n      [[entryPoints.http.tls.certificates]]\n        certFile =  path/to/other.cert \n        keyFile =  path/to/other.key \n      # ...\n      [entryPoints.http.tls.clientCA]\n        files = [ path/to/ca1.crt ,  path/to/ca2.crt ]\n        optional = false\n\n    [entryPoints.http.redirect]\n      entryPoint =  https \n      regex =  ^http://localhost/(.*) \n      replacement =  http://mydomain/$1 \n\n    [entryPoints.http.auth]\n      headerField =  X-WebAuth-User \n      [entryPoints.http.auth.basic]\n        users = [\n           test:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/ ,\n           test2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0 ,\n        ]\n        usersFile =  /path/to/.htpasswd \n      [entryPoints.http.auth.digest]\n        users = [\n           test:traefik:a2688e031edb4be6a3797f3882655c05 ,\n           test2:traefik:518845800f9e2bfb1f1f740ec24f074e ,\n        ]\n        usersFile =  /path/to/.htdigest \n      [entryPoints.http.auth.forward]\n        address =  https://authserver.com/auth \n        trustForwardHeader = true\n        [entryPoints.http.auth.forward.tls]\n          ca =  [  path/to/local.crt ]\n          caOptional = true\n          cert =  path/to/foo.cert \n          key =  path/to/foo.key \n          insecureSkipVerify = true\n\n    [entryPoints.http.proxyProtocol]\n      insecure = true\n      trustedIPs = [ 10.10.10.1 ,  10.10.10.2 ]\n\n    [entryPoints.http.forwardedHeaders]\n      trustedIPs = [ 10.10.10.1 ,  10.10.10.2 ]\n\n  [entryPoints.https]\n    # ...", 
            "title": "TOML"
        }, 
        {
            "location": "/configuration/entrypoints/#cli", 
            "text": "For more information about the CLI, see the documentation about  Traefik command .  --entryPoints='Name:http Address::80'\n--entryPoints='Name:https Address::443 TLS'   Note  Whitespace is used as option separator and  ,  is used as value separator for the list. \nThe names of the options are case-insensitive.   In compose file the entrypoint syntax is different:  traefik:\n    image: traefik\n    command:\n        - --defaultentrypoints=powpow\n        -  --entryPoints=Name:powpow Address::42 Compress:true   or  traefik:\n    image: traefik\n    command: --defaultentrypoints=powpow --entryPoints='Name:powpow Address::42 Compress:true'", 
            "title": "CLI"
        }, 
        {
            "location": "/configuration/entrypoints/#all-available-options", 
            "text": "Name:foo\nAddress::80\nTLS:goo,gii\nTLS\nCA:car\nCA.Optional:true\nRedirect.EntryPoint:https\nRedirect.Regex:http://localhost/(.*)\nRedirect.Replacement:http://mydomain/$1\nCompress:true\nWhiteListSourceRange:10.42.0.0/16,152.89.1.33/32,afed:be44::/16\nProxyProtocol.TrustedIPs:192.168.0.1\nProxyProtocol.Insecure:tue\nForwardedHeaders.TrustedIPs:10.0.0.3/24,20.0.0.3/24", 
            "title": "All available options:"
        }, 
        {
            "location": "/configuration/entrypoints/#basic", 
            "text": "# Entrypoints definition\n#\n# Default:\n# [entryPoints]\n#   [entryPoints.http]\n#   address =  :80 \n#\n[entryPoints]\n  [entryPoints.http]\n  address =  :80", 
            "title": "Basic"
        }, 
        {
            "location": "/configuration/entrypoints/#redirect-http-to-https", 
            "text": "To redirect an http entrypoint to an https entrypoint (with SNI support).  [entryPoints]\n  [entryPoints.http]\n  address =  :80 \n    [entryPoints.http.redirect]\n    entryPoint =  https \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile =  integration/fixtures/https/snitest.com.cert \n      keyFile =  integration/fixtures/https/snitest.com.key \n      [[entryPoints.https.tls.certificates]]\n      certFile =  integration/fixtures/https/snitest.org.cert \n      keyFile =  integration/fixtures/https/snitest.org.key    Note  Please note that  regex  and  replacement  do not have to be set in the  redirect  structure if an entrypoint is defined for the redirection (they will not be used in this case).", 
            "title": "Redirect HTTP to HTTPS"
        }, 
        {
            "location": "/configuration/entrypoints/#rewriting-url", 
            "text": "To redirect an entrypoint rewriting the URL.  [entryPoints]\n  [entryPoints.http]\n  address =  :80 \n    [entryPoints.http.redirect]\n    regex =  ^http://localhost/(.*) \n    replacement =  http://mydomain/$1    Note  Please note that  regex  and  replacement  do not have to be set in the  redirect  structure if an  entrypoint  is defined for the redirection (they will not be used in this case).   Care should be taken when defining replacement expand variables:  $1x  is equivalent to  ${1x} , not  ${1}x  (see  Regexp.Expand ), so use  ${1}  syntax.  Regular expressions and replacements can be tested using online tools such as  Go Playground  or the  Regex101 .", 
            "title": "Rewriting URL"
        }, 
        {
            "location": "/configuration/entrypoints/#tls", 
            "text": "", 
            "title": "TLS"
        }, 
        {
            "location": "/configuration/entrypoints/#static-certificates", 
            "text": "Define an entrypoint with SNI support.  [entryPoints]\n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile =  integration/fixtures/https/snitest.com.cert \n      keyFile =  integration/fixtures/https/snitest.com.key    Note  If an empty TLS configuration is done, default self-signed certificates are generated.", 
            "title": "Static Certificates"
        }, 
        {
            "location": "/configuration/entrypoints/#dynamic-certificates", 
            "text": "If you need to add or remove TLS certificates while Traefik is started, Dynamic TLS certificates are supported using the  file provider .", 
            "title": "Dynamic Certificates"
        }, 
        {
            "location": "/configuration/entrypoints/#tls-mutual-authentication", 
            "text": "TLS Mutual Authentication can be  optional  or not.\nIf it's  optional , Tr\u00e6fik will authorize connection with certificates not signed by a specified Certificate Authority (CA).\nOtherwise, Tr\u00e6fik will only accept clients that present a certificate signed by a specified Certificate Authority (CA). ClientCAFiles  can be configured with multiple  CA:s  in the same file or use multiple files containing one or several  CA:s .\nThe  CA:s  has to be in PEM format.  By default,  ClientCAFiles  is not optional, all clients will be required to present a valid cert.\nThe requirement will apply to all server certs in the entrypoint.  In the example below both  snitest.com  and  snitest.org  will require client certs  [entryPoints]\n  [entryPoints.https]\n  address =  :443 \n  [entryPoints.https.tls]\n    [entryPoints.https.tls.ClientCA]\n    files = [ tests/clientca1.crt ,  tests/clientca2.crt ]\n    optional = false\n    [[entryPoints.https.tls.certificates]]\n    certFile =  integration/fixtures/https/snitest.com.cert \n    keyFile =  integration/fixtures/https/snitest.com.key \n    [[entryPoints.https.tls.certificates]]\n    certFile =  integration/fixtures/https/snitest.org.cert \n    keyFile =  integration/fixtures/https/snitest.org.key    Note  The deprecated argument  ClientCAFiles  allows adding Client CA files which are mandatory.\nIf this parameter exists, the new ones are not checked.", 
            "title": "TLS Mutual Authentication"
        }, 
        {
            "location": "/configuration/entrypoints/#authentication", 
            "text": "", 
            "title": "Authentication"
        }, 
        {
            "location": "/configuration/entrypoints/#basic-authentication", 
            "text": "Passwords can be encoded in MD5, SHA1 and BCrypt: you can use  htpasswd  to generate them.  Users can be specified directly in the TOML file, or indirectly by referencing an external file;\n if both are provided, the two are merged, with external file contents having precedence.  # To enable basic auth on an entrypoint with 2 user/pass: test:test and test2:test2\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.http.auth.basic]\n  users = [ test:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/ ,  test2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0 ]\n  usersFile =  /path/to/.htpasswd", 
            "title": "Basic Authentication"
        }, 
        {
            "location": "/configuration/entrypoints/#digest-authentication", 
            "text": "You can use  htdigest  to generate them.  Users can be specified directly in the TOML file, or indirectly by referencing an external file;\n if both are provided, the two are merged, with external file contents having precedence  # To enable digest auth on an entrypoint with 2 user/realm/pass: test:traefik:test and test2:traefik:test2\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.http.auth.digest]\n  users = [ test:traefik:a2688e031edb4be6a3797f3882655c05 ,  test2:traefik:518845800f9e2bfb1f1f740ec24f074e ]\n  usersFile =  /path/to/.htdigest", 
            "title": "Digest Authentication"
        }, 
        {
            "location": "/configuration/entrypoints/#forward-authentication", 
            "text": "This configuration will first forward the request to  http://authserver.com/auth .  If the response code is 2XX, access is granted and the original request is performed.\nOtherwise, the response from the authentication server is returned.  [entryPoints]\n  [entryPoints.http]\n    # ...\n    # To enable forward auth on an entrypoint\n    [entryPoints.http.auth.forward]\n    address =  https://authserver.com/auth \n\n    # Trust existing X-Forwarded-* headers.\n    # Useful with another reverse proxy in front of Traefik.\n    #\n    # Optional\n    # Default: false\n    #\n    trustForwardHeader = true\n\n    # Enable forward auth TLS connection.\n    #\n    # Optional\n    #\n    [entryPoints.http.auth.forward.tls]\n    cert =  authserver.crt \n    key =  authserver.key", 
            "title": "Forward Authentication"
        }, 
        {
            "location": "/configuration/entrypoints/#specify-minimum-tls-version", 
            "text": "To specify an https entry point with a minimum TLS version, and specifying an array of cipher suites (from  crypto/tls ).  [entryPoints]\n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n    minVersion =  VersionTLS12 \n    cipherSuites = [\n       TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 ,\n       TLS_RSA_WITH_AES_256_GCM_SHA384 \n    ]\n      [[entryPoints.https.tls.certificates]]\n      certFile =  integration/fixtures/https/snitest.com.cert \n      keyFile =  integration/fixtures/https/snitest.com.key \n      [[entryPoints.https.tls.certificates]]\n      certFile =  integration/fixtures/https/snitest.org.cert \n      keyFile =  integration/fixtures/https/snitest.org.key", 
            "title": "Specify Minimum TLS Version"
        }, 
        {
            "location": "/configuration/entrypoints/#compression", 
            "text": "To enable compression support using gzip format.  [entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  compress = true  Responses are compressed when:   The response body is larger than  512  bytes  And the  Accept-Encoding  request header contains  gzip  And the response is not already compressed, i.e. the  Content-Encoding  response header is not already set.", 
            "title": "Compression"
        }, 
        {
            "location": "/configuration/entrypoints/#whitelisting", 
            "text": "To enable IP whitelisting at the entrypoint level.  [entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  whiteListSourceRange = [ 127.0.0.1/32 ,  192.168.1.7 ]", 
            "title": "Whitelisting"
        }, 
        {
            "location": "/configuration/entrypoints/#proxyprotocol", 
            "text": "To enable  ProxyProtocol  support.\nOnly IPs in  trustedIPs  will lead to remote client address replacement: you should declare your load-balancer IP or CIDR range here (in testing environment, you can trust everyone using  insecure = true ).   Danger  When queuing Tr\u00e6fik behind another load-balancer, be sure to carefully configure Proxy Protocol on both sides.\nOtherwise, it could introduce a security risk in your system by forging requests.   [entryPoints]\n  [entryPoints.http]\n    address =  :80 \n\n    # Enable ProxyProtocol\n    [entryPoints.http.proxyProtocol]\n      # List of trusted IPs\n      #\n      # Required\n      # Default: []\n      #\n      trustedIPs = [ 127.0.0.1/32 ,  192.168.1.7 ]\n\n      # Insecure mode FOR TESTING ENVIRONNEMENT ONLY\n      #\n      # Optional\n      # Default: false\n      #\n      # insecure = true", 
            "title": "ProxyProtocol"
        }, 
        {
            "location": "/configuration/entrypoints/#forwarded-header", 
            "text": "Only IPs in  trustedIPs  will be authorized to trust the client forwarded headers ( X-Forwarded-* ).  [entryPoints]\n  [entryPoints.http]\n    address =  :80 \n\n    # Enable Forwarded Headers\n    [entryPoints.http.forwardedHeaders]\n      # List of trusted IPs\n      #\n      # Required\n      # Default: []\n      #\n      trustedIPs = [ 127.0.0.1/32 ,  192.168.1.7 ]", 
            "title": "Forwarded Header"
        }, 
        {
            "location": "/configuration/acme/", 
            "text": "ACME (Let's Encrypt) configuration\n\n\nSee also \nLet's Encrypt examples\n and \nDocker \n Let's Encrypt user guide\n.\n\n\nConfiguration\n\n\n# Sample entrypoint configuration when using ACME.\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n\n\n\n\n# Enable ACME (Let's Encrypt): automatic SSL.\n[acme]\n\n# Email address used for registration.\n#\n# Required\n#\nemail = \ntest@traefik.io\n\n\n# File used for certificates storage.\n#\n# Optional (Deprecated)\n#\n#storageFile = \nacme.json\n\n\n# File or key used for certificates storage.\n#\n# Required\n#\nstorage = \nacme.json\n\n# or `storage = \ntraefik/acme/account\n` if using KV store.\n\n# Entrypoint to proxy acme apply certificates to.\n# WARNING, if the TLS-SNI-01 challenge is used, it must point to an entrypoint on port 443\n#\n# Required\n#\nentryPoint = \nhttps\n\n\n# Use a DNS-01 acme challenge rather than TLS-SNI-01 challenge\n#\n# Optional (Deprecated, replaced by [acme.dnsChallenge])\n#\n# dnsProvider = \ndigitalocean\n\n\n# By default, the dnsProvider will verify the TXT DNS challenge record before letting ACME verify.\n# If delayDontCheckDNS is greater than zero, avoid this \n instead just wait so many seconds.\n# Useful if internal networks block external DNS queries.\n#\n# Optional (Deprecated, replaced by [acme.dnsChallenge])\n# Default: 0\n#\n# delayDontCheckDNS = 0\n\n# If true, display debug log messages from the acme client library.\n#\n# Optional\n# Default: false\n#\n# acmeLogging = true\n\n# Enable on demand certificate generation.\n#\n# Optional (Deprecated)\n# Default: false\n#\n# onDemand = true\n\n# Enable certificate generation on frontends Host rules.\n#\n# Optional\n# Default: false\n#\n# onHostRule = true\n\n# CA server to use.\n# - Uncomment the line to run on the staging let's encrypt server.\n# - Leave comment to go to prod.\n#\n# Optional\n# Default: \nhttps://acme-v01.api.letsencrypt.org/directory\n\n#\n# caServer = \nhttps://acme-staging.api.letsencrypt.org/directory\n\n\n# Domains list.\n#\n# [[acme.domains]]\n#   main = \nlocal1.com\n\n#   sans = [\ntest1.local1.com\n, \ntest2.local1.com\n]\n# [[acme.domains]]\n#   main = \nlocal2.com\n\n#   sans = [\ntest1.local2.com\n, \ntest2.local2.com\n]\n# [[acme.domains]]\n#   main = \nlocal3.com\n\n# [[acme.domains]]\n#   main = \nlocal4.com\n\n\n# Use a HTTP-01 acme challenge rather than TLS-SNI-01 challenge\n#\n# Optional but recommend\n#\n[acme.httpChallenge]\n\n  # EntryPoint to use for the challenges.\n  #\n  # Required\n  #\n  entryPoint = \nhttp\n\n\n# Use a DNS-01 acme challenge rather than TLS-SNI-01 challenge\n#\n# Optional\n#\n# [acme.dnsChallenge]\n\n  # Provider used.\n  #\n  # Required\n  #\n  # provider = \ndigitalocean\n\n\n  # By default, the provider will verify the TXT DNS challenge record before letting ACME verify.\n  # If delayBeforeCheck is greater than zero, avoid this \n instead just wait so many seconds.\n  # Useful if internal networks block external DNS queries.\n  #\n  # Optional\n  # Default: 0\n  #\n  # delayBeforeCheck = 0\n\n\n\n\n\n\nNote\n\n\nEven if \nTLS-SNI-01\n challenge is \ndisabled\n for the moment, it stays the \nby default\n ACME Challenge in Tr\u00e6fik.\nIf \nTLS-SNI-01\n challenge is not re-enabled in the future, it we will be removed from Tr\u00e6fik.\n\n\n\n\n\n\nNote\n\n\nIf \nTLS-SNI-01\n challenge is used, \nacme.entryPoint\n has to be reachable by Let's Encrypt through the port 443.\nIf \nHTTP-01\n challenge is used, \nacme.httpChallenge.entryPoint\n has to be defined and reachable by Let's Encrypt through the port 80.\nThese are Let's Encrypt limitations as described on the \ncommunity forum\n.\n\n\n\n\nLet's Encrypt downtime\n\n\nLet's Encrypt functionality will be limited until Tr\u00e6fik is restarted.\n\n\nIf Let's Encrypt is not reachable, these certificates will be used :\n\n\n\n\nACME certificates already generated before downtime\n\n\nExpired ACME certificates\n\n\nProvided certificates\n\n\n\n\n\n\nNote\n\n\nDefault Tr\u00e6fik certificate will be used instead of ACME certificates for new (sub)domains (which need Let's Encrypt challenge).\n\n\n\n\nstorage\n\n\n[acme]\n# ...\nstorage = \nacme.json\n\n# ...\n\n\n\n\nThe \nstorage\n option sets where are stored your ACME certificates.\n\n\nThere are two kind of \nstorage\n :\n\n\n\n\na JSON file,\n\n\na KV store entry.\n\n\n\n\n\n\nDEPRECATED\n\n\nstorage\n replaces \nstorageFile\n which is deprecated.\n\n\n\n\n\n\nNote\n\n\nDuring Tr\u00e6fik configuration migration from a configuration file to a KV store (thanks to \nstoreconfig\n subcommand as described \nhere\n), if ACME certificates have to be migrated too, use both \nstorageFile\n and \nstorage\n.\n\n\n\n\nstorageFile\n will contain the path to the \nacme.json\n file to migrate.\n\n\nstorage\n will contain the key where the certificates will be stored.\n\n\n\n\n\n\nStore data in a file\n\n\nACME certificates can be stored in a JSON file which with the \n600\n right mode.\n\n\nThere are two ways to store ACME certificates in a file from Docker:\n\n\n\n\ncreate a file on your host and mount it as a volume:\n\n\n\n\nstorage = \nacme.json\n\n\n\n\n\ndocker run -v \n/my/host/acme.json:acme.json\n traefik\n\n\n\n\n\n\nmount the folder containing the file as a volume\n\n\n\n\nstorage = \n/etc/traefik/acme/acme.json\n\n\n\n\n\ndocker run -v \n/my/host/acme:/etc/traefik/acme\n traefik\n\n\n\n\n\n\nWarning\n\n\nThis file cannot be shared per many instances of Tr\u00e6fik at the same time.\nIf you have to use Tr\u00e6fik cluster mode, please use \na KV Store entry\n.\n\n\n\n\nStore data in a KV store entry\n\n\nACME certificates can be stored in a KV Store entry.\n\n\nstorage = \ntraefik/acme/account\n\n\n\n\n\nThis kind of storage is mandatory in cluster mode.\n\n\nBecause KV stores (like Consul) have limited entries size, the certificates list is compressed before to be set in a KV store entry.\n\n\n\n\nNote\n\n\nIt's possible to store up to approximately 100 ACME certificates in Consul.\n\n\n\n\nacme.httpChallenge\n\n\nUse \nHTTP-01\n challenge to generate/renew ACME certificates.\n\n\nThe redirection is fully compatible with the HTTP-01 challenge.\nYou can use redirection with HTTP-01 challenge without problem.\n\n\n[acme]\n# ...\nentryPoint = \nhttps\n\n[acme.httpChallenge]\n  entryPoint = \nhttp\n\n\n\n\n\nentryPoint\n\n\nSpecify the entryPoint to use during the challenges.\n\n\ndefaultEntryPoints = [\nhttp\n, \nhttps\n]\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n# ...\n\n[acme]\n  # ...\n  entryPoint = \nhttps\n\n  [acme.httpChallenge]\n    entryPoint = \nhttp\n\n\n\n\n\n\n\nNote\n\n\nacme.httpChallenge.entryPoint\n has to be reachable by Let's Encrypt through the port 80.\nIt's a Let's Encrypt limitation as described on the \ncommunity forum\n.\n\n\n\n\nacme.dnsChallenge\n\n\nUse \nDNS-01\n challenge to generate/renew ACME certificates.\n\n\n[acme]\n# ...\n[acme.dnsChallenge]\n  provider = \ndigitalocean\n\n  delayBeforeCheck = 0\n# ...\n\n\n\n\nprovider\n\n\nSelect the provider that matches the DNS domain that will host the challenge TXT record, and provide environment variables to enable setting it:\n\n\n\n\n\n\n\n\nProvider Name\n\n\nProvider code\n\n\nConfiguration\n\n\n\n\n\n\n\n\n\n\nAuroradns\n\n\nauroradns\n\n\nAURORA_USER_ID\n, \nAURORA_KEY\n, \nAURORA_ENDPOINT\n\n\n\n\n\n\nAzure\n\n\nazure\n\n\nAZURE_CLIENT_ID\n, \nAZURE_CLIENT_SECRET\n, \nAZURE_SUBSCRIPTION_ID\n, \nAZURE_TENANT_ID\n, \nAZURE_RESOURCE_GROUP\n\n\n\n\n\n\nCloudflare\n\n\ncloudflare\n\n\nCLOUDFLARE_EMAIL\n, \nCLOUDFLARE_API_KEY\n - The Cloudflare \nGlobal API Key\n needs to be used and not the \nOrigin CA Key\n\n\n\n\n\n\nDigitalOcean\n\n\ndigitalocean\n\n\nDO_AUTH_TOKEN\n\n\n\n\n\n\nDNSimple\n\n\ndnsimple\n\n\nDNSIMPLE_OAUTH_TOKEN\n, \nDNSIMPLE_BASE_URL\n\n\n\n\n\n\nDNS Made Easy\n\n\ndnsmadeeasy\n\n\nDNSMADEEASY_API_KEY\n, \nDNSMADEEASY_API_SECRET\n, \nDNSMADEEASY_SANDBOX\n\n\n\n\n\n\nDNSPod\n\n\ndnspod\n\n\nDNSPOD_API_KEY\n\n\n\n\n\n\nDyn\n\n\ndyn\n\n\nDYN_CUSTOMER_NAME\n, \nDYN_USER_NAME\n, \nDYN_PASSWORD\n\n\n\n\n\n\nExoscale\n\n\nexoscale\n\n\nEXOSCALE_API_KEY\n, \nEXOSCALE_API_SECRET\n, \nEXOSCALE_ENDPOINT\n\n\n\n\n\n\nGandi\n\n\ngandi\n\n\nGANDI_API_KEY\n\n\n\n\n\n\nGoDaddy\n\n\ngodaddy\n\n\nGODADDY_API_KEY\n, \nGODADDY_API_SECRET\n\n\n\n\n\n\nGoogle Cloud DNS\n\n\ngcloud\n\n\nGCE_PROJECT\n, \nGCE_SERVICE_ACCOUNT_FILE\n\n\n\n\n\n\nLinode\n\n\nlinode\n\n\nLINODE_API_KEY\n\n\n\n\n\n\nmanual\n\n\n-\n\n\nnone, but run Tr\u00e6fik interactively \n turn on \nacmeLogging\n to see instructions \n press \nEnter\n.\n\n\n\n\n\n\nNamecheap\n\n\nnamecheap\n\n\nNAMECHEAP_API_USER\n, \nNAMECHEAP_API_KEY\n\n\n\n\n\n\nNs1\n\n\nns1\n\n\nNS1_API_KEY\n\n\n\n\n\n\nOpen Telekom Cloud\n\n\notc\n\n\nOTC_DOMAIN_NAME\n, \nOTC_USER_NAME\n, \nOTC_PASSWORD\n, \nOTC_PROJECT_NAME\n, \nOTC_IDENTITY_ENDPOINT\n\n\n\n\n\n\nOVH\n\n\novh\n\n\nOVH_ENDPOINT\n, \nOVH_APPLICATION_KEY\n, \nOVH_APPLICATION_SECRET\n, \nOVH_CONSUMER_KEY\n\n\n\n\n\n\nPowerDNS\n\n\npdns\n\n\nPDNS_API_KEY\n, \nPDNS_API_URL\n\n\n\n\n\n\nRackspace\n\n\nrackspace\n\n\nRACKSPACE_USER\n, \nRACKSPACE_API_KEY\n\n\n\n\n\n\nRFC2136\n\n\nrfc2136\n\n\nRFC2136_TSIG_KEY\n, \nRFC2136_TSIG_SECRET\n, \nRFC2136_TSIG_ALGORITHM\n, \nRFC2136_NAMESERVER\n\n\n\n\n\n\nRoute 53\n\n\nroute53\n\n\nAWS_ACCESS_KEY_ID\n, \nAWS_SECRET_ACCESS_KEY\n, \nAWS_REGION\n, \nAWS_HOSTED_ZONE_ID\n or configured user/instance IAM profile.\n\n\n\n\n\n\nVULTR\n\n\nvultr\n\n\nVULTR_API_KEY\n\n\n\n\n\n\n\n\ndelayBeforeCheck\n\n\nBy default, the \nprovider\n will verify the TXT DNS challenge record before letting ACME verify.\n\nIf \ndelayBeforeCheck\n is greater than zero, avoid this \n instead just wait so many seconds.\n\n\nUseful if internal networks block external DNS queries.\n\n\n\n\nNote\n\n\nThis field has no sense if a \nprovider\n is not defined.\n\n\n\n\nonDemand\n (Deprecated)\n\n\n\n\nDEPRECATED\n\n\nThis option is deprecated.\n\n\n\n\n[acme]\n# ...\nonDemand = true\n# ...\n\n\n\n\nEnable on demand certificate.\n\n\nThis will request a certificate from Let's Encrypt during the first TLS handshake for a host name that does not yet have a certificate.\n\n\n\n\nWarning\n\n\nTLS handshakes will be slow when requesting a host name certificate for the first time, this can lead to DoS attacks.\n\n\n\n\n\n\nWarning\n\n\nTake note that Let's Encrypt have \nrate limiting\n.\n\n\n\n\nonHostRule\n\n\n[acme]\n# ...\nonHostRule = true\n# ...\n\n\n\n\nEnable certificate generation on frontends \nHost\n rules (for frontends wired on the \nacme.entryPoint\n).\n\n\nThis will request a certificate from Let's Encrypt for each frontend with a Host rule.\n\n\nFor example, a rule \nHost:test1.traefik.io,test2.traefik.io\n will request a certificate with main domain \ntest1.traefik.io\n and SAN \ntest2.traefik.io\n.\n\n\ncaServer\n\n\n[acme]\n# ...\ncaServer = \nhttps://acme-staging.api.letsencrypt.org/directory\n\n# ...\n\n\n\n\nCA server to use.\n\n\n\n\nUncomment the line to run on the staging Let's Encrypt server.\n\n\nLeave comment to go to prod.\n\n\n\n\nacme.domains\n\n\n[acme]\n# ...\n[[acme.domains]]\n  main = \nlocal1.com\n\n  sans = [\ntest1.local1.com\n, \ntest2.local1.com\n]\n[[acme.domains]]\n  main = \nlocal2.com\n\n  sans = [\ntest1.local2.com\n, \ntest2.local2.com\n]\n[[acme.domains]]\n  main = \nlocal3.com\n\n[[acme.domains]]\n  main = \nlocal4.com\n\n# ...\n\n\n\n\nYou can provide SANs (alternative domains) to each main domain.\nAll domains must have A/AAAA records pointing to Tr\u00e6fik.\n\n\n\n\nWarning\n\n\nTake note that Let's Encrypt have \nrate limiting\n.\n\n\n\n\nEach domain \n SANs will lead to a certificate request.\n\n\ndnsProvider\n (Deprecated)\n\n\n\n\nDEPRECATED\n\n\nThis option is deprecated, use \ndnsChallenge.provider\n instead.\n\n\n\n\ndelayDontCheckDNS\n (Deprecated)\n\n\n\n\nDEPRECATED\n\n\nThis option is deprecated, use \ndnsChallenge.delayBeforeCheck\n instead.", 
            "title": "Let's Encrypt"
        }, 
        {
            "location": "/configuration/acme/#acme-lets-encrypt-configuration", 
            "text": "See also  Let's Encrypt examples  and  Docker   Let's Encrypt user guide .", 
            "title": "ACME (Let's Encrypt) configuration"
        }, 
        {
            "location": "/configuration/acme/#configuration", 
            "text": "# Sample entrypoint configuration when using ACME.\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]  # Enable ACME (Let's Encrypt): automatic SSL.\n[acme]\n\n# Email address used for registration.\n#\n# Required\n#\nemail =  test@traefik.io \n\n# File used for certificates storage.\n#\n# Optional (Deprecated)\n#\n#storageFile =  acme.json \n\n# File or key used for certificates storage.\n#\n# Required\n#\nstorage =  acme.json \n# or `storage =  traefik/acme/account ` if using KV store.\n\n# Entrypoint to proxy acme apply certificates to.\n# WARNING, if the TLS-SNI-01 challenge is used, it must point to an entrypoint on port 443\n#\n# Required\n#\nentryPoint =  https \n\n# Use a DNS-01 acme challenge rather than TLS-SNI-01 challenge\n#\n# Optional (Deprecated, replaced by [acme.dnsChallenge])\n#\n# dnsProvider =  digitalocean \n\n# By default, the dnsProvider will verify the TXT DNS challenge record before letting ACME verify.\n# If delayDontCheckDNS is greater than zero, avoid this   instead just wait so many seconds.\n# Useful if internal networks block external DNS queries.\n#\n# Optional (Deprecated, replaced by [acme.dnsChallenge])\n# Default: 0\n#\n# delayDontCheckDNS = 0\n\n# If true, display debug log messages from the acme client library.\n#\n# Optional\n# Default: false\n#\n# acmeLogging = true\n\n# Enable on demand certificate generation.\n#\n# Optional (Deprecated)\n# Default: false\n#\n# onDemand = true\n\n# Enable certificate generation on frontends Host rules.\n#\n# Optional\n# Default: false\n#\n# onHostRule = true\n\n# CA server to use.\n# - Uncomment the line to run on the staging let's encrypt server.\n# - Leave comment to go to prod.\n#\n# Optional\n# Default:  https://acme-v01.api.letsencrypt.org/directory \n#\n# caServer =  https://acme-staging.api.letsencrypt.org/directory \n\n# Domains list.\n#\n# [[acme.domains]]\n#   main =  local1.com \n#   sans = [ test1.local1.com ,  test2.local1.com ]\n# [[acme.domains]]\n#   main =  local2.com \n#   sans = [ test1.local2.com ,  test2.local2.com ]\n# [[acme.domains]]\n#   main =  local3.com \n# [[acme.domains]]\n#   main =  local4.com \n\n# Use a HTTP-01 acme challenge rather than TLS-SNI-01 challenge\n#\n# Optional but recommend\n#\n[acme.httpChallenge]\n\n  # EntryPoint to use for the challenges.\n  #\n  # Required\n  #\n  entryPoint =  http \n\n# Use a DNS-01 acme challenge rather than TLS-SNI-01 challenge\n#\n# Optional\n#\n# [acme.dnsChallenge]\n\n  # Provider used.\n  #\n  # Required\n  #\n  # provider =  digitalocean \n\n  # By default, the provider will verify the TXT DNS challenge record before letting ACME verify.\n  # If delayBeforeCheck is greater than zero, avoid this   instead just wait so many seconds.\n  # Useful if internal networks block external DNS queries.\n  #\n  # Optional\n  # Default: 0\n  #\n  # delayBeforeCheck = 0   Note  Even if  TLS-SNI-01  challenge is  disabled  for the moment, it stays the  by default  ACME Challenge in Tr\u00e6fik.\nIf  TLS-SNI-01  challenge is not re-enabled in the future, it we will be removed from Tr\u00e6fik.    Note  If  TLS-SNI-01  challenge is used,  acme.entryPoint  has to be reachable by Let's Encrypt through the port 443.\nIf  HTTP-01  challenge is used,  acme.httpChallenge.entryPoint  has to be defined and reachable by Let's Encrypt through the port 80.\nThese are Let's Encrypt limitations as described on the  community forum .", 
            "title": "Configuration"
        }, 
        {
            "location": "/configuration/acme/#lets-encrypt-downtime", 
            "text": "Let's Encrypt functionality will be limited until Tr\u00e6fik is restarted.  If Let's Encrypt is not reachable, these certificates will be used :   ACME certificates already generated before downtime  Expired ACME certificates  Provided certificates    Note  Default Tr\u00e6fik certificate will be used instead of ACME certificates for new (sub)domains (which need Let's Encrypt challenge).", 
            "title": "Let's Encrypt downtime"
        }, 
        {
            "location": "/configuration/acme/#storage", 
            "text": "[acme]\n# ...\nstorage =  acme.json \n# ...  The  storage  option sets where are stored your ACME certificates.  There are two kind of  storage  :   a JSON file,  a KV store entry.    DEPRECATED  storage  replaces  storageFile  which is deprecated.    Note  During Tr\u00e6fik configuration migration from a configuration file to a KV store (thanks to  storeconfig  subcommand as described  here ), if ACME certificates have to be migrated too, use both  storageFile  and  storage .   storageFile  will contain the path to the  acme.json  file to migrate.  storage  will contain the key where the certificates will be stored.", 
            "title": "storage"
        }, 
        {
            "location": "/configuration/acme/#store-data-in-a-file", 
            "text": "ACME certificates can be stored in a JSON file which with the  600  right mode.  There are two ways to store ACME certificates in a file from Docker:   create a file on your host and mount it as a volume:   storage =  acme.json   docker run -v  /my/host/acme.json:acme.json  traefik   mount the folder containing the file as a volume   storage =  /etc/traefik/acme/acme.json   docker run -v  /my/host/acme:/etc/traefik/acme  traefik   Warning  This file cannot be shared per many instances of Tr\u00e6fik at the same time.\nIf you have to use Tr\u00e6fik cluster mode, please use  a KV Store entry .", 
            "title": "Store data in a file"
        }, 
        {
            "location": "/configuration/acme/#store-data-in-a-kv-store-entry", 
            "text": "ACME certificates can be stored in a KV Store entry.  storage =  traefik/acme/account   This kind of storage is mandatory in cluster mode.  Because KV stores (like Consul) have limited entries size, the certificates list is compressed before to be set in a KV store entry.   Note  It's possible to store up to approximately 100 ACME certificates in Consul.", 
            "title": "Store data in a KV store entry"
        }, 
        {
            "location": "/configuration/acme/#acmehttpchallenge", 
            "text": "Use  HTTP-01  challenge to generate/renew ACME certificates.  The redirection is fully compatible with the HTTP-01 challenge.\nYou can use redirection with HTTP-01 challenge without problem.  [acme]\n# ...\nentryPoint =  https \n[acme.httpChallenge]\n  entryPoint =  http", 
            "title": "acme.httpChallenge"
        }, 
        {
            "location": "/configuration/acme/#entrypoint", 
            "text": "Specify the entryPoint to use during the challenges.  defaultEntryPoints = [ http ,  https ]\n\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n# ...\n\n[acme]\n  # ...\n  entryPoint =  https \n  [acme.httpChallenge]\n    entryPoint =  http    Note  acme.httpChallenge.entryPoint  has to be reachable by Let's Encrypt through the port 80.\nIt's a Let's Encrypt limitation as described on the  community forum .", 
            "title": "entryPoint"
        }, 
        {
            "location": "/configuration/acme/#acmednschallenge", 
            "text": "Use  DNS-01  challenge to generate/renew ACME certificates.  [acme]\n# ...\n[acme.dnsChallenge]\n  provider =  digitalocean \n  delayBeforeCheck = 0\n# ...", 
            "title": "acme.dnsChallenge"
        }, 
        {
            "location": "/configuration/acme/#provider", 
            "text": "Select the provider that matches the DNS domain that will host the challenge TXT record, and provide environment variables to enable setting it:     Provider Name  Provider code  Configuration      Auroradns  auroradns  AURORA_USER_ID ,  AURORA_KEY ,  AURORA_ENDPOINT    Azure  azure  AZURE_CLIENT_ID ,  AZURE_CLIENT_SECRET ,  AZURE_SUBSCRIPTION_ID ,  AZURE_TENANT_ID ,  AZURE_RESOURCE_GROUP    Cloudflare  cloudflare  CLOUDFLARE_EMAIL ,  CLOUDFLARE_API_KEY  - The Cloudflare  Global API Key  needs to be used and not the  Origin CA Key    DigitalOcean  digitalocean  DO_AUTH_TOKEN    DNSimple  dnsimple  DNSIMPLE_OAUTH_TOKEN ,  DNSIMPLE_BASE_URL    DNS Made Easy  dnsmadeeasy  DNSMADEEASY_API_KEY ,  DNSMADEEASY_API_SECRET ,  DNSMADEEASY_SANDBOX    DNSPod  dnspod  DNSPOD_API_KEY    Dyn  dyn  DYN_CUSTOMER_NAME ,  DYN_USER_NAME ,  DYN_PASSWORD    Exoscale  exoscale  EXOSCALE_API_KEY ,  EXOSCALE_API_SECRET ,  EXOSCALE_ENDPOINT    Gandi  gandi  GANDI_API_KEY    GoDaddy  godaddy  GODADDY_API_KEY ,  GODADDY_API_SECRET    Google Cloud DNS  gcloud  GCE_PROJECT ,  GCE_SERVICE_ACCOUNT_FILE    Linode  linode  LINODE_API_KEY    manual  -  none, but run Tr\u00e6fik interactively   turn on  acmeLogging  to see instructions   press  Enter .    Namecheap  namecheap  NAMECHEAP_API_USER ,  NAMECHEAP_API_KEY    Ns1  ns1  NS1_API_KEY    Open Telekom Cloud  otc  OTC_DOMAIN_NAME ,  OTC_USER_NAME ,  OTC_PASSWORD ,  OTC_PROJECT_NAME ,  OTC_IDENTITY_ENDPOINT    OVH  ovh  OVH_ENDPOINT ,  OVH_APPLICATION_KEY ,  OVH_APPLICATION_SECRET ,  OVH_CONSUMER_KEY    PowerDNS  pdns  PDNS_API_KEY ,  PDNS_API_URL    Rackspace  rackspace  RACKSPACE_USER ,  RACKSPACE_API_KEY    RFC2136  rfc2136  RFC2136_TSIG_KEY ,  RFC2136_TSIG_SECRET ,  RFC2136_TSIG_ALGORITHM ,  RFC2136_NAMESERVER    Route 53  route53  AWS_ACCESS_KEY_ID ,  AWS_SECRET_ACCESS_KEY ,  AWS_REGION ,  AWS_HOSTED_ZONE_ID  or configured user/instance IAM profile.    VULTR  vultr  VULTR_API_KEY", 
            "title": "provider"
        }, 
        {
            "location": "/configuration/acme/#delaybeforecheck", 
            "text": "By default, the  provider  will verify the TXT DNS challenge record before letting ACME verify. \nIf  delayBeforeCheck  is greater than zero, avoid this   instead just wait so many seconds.  Useful if internal networks block external DNS queries.   Note  This field has no sense if a  provider  is not defined.", 
            "title": "delayBeforeCheck"
        }, 
        {
            "location": "/configuration/acme/#ondemand-deprecated", 
            "text": "DEPRECATED  This option is deprecated.   [acme]\n# ...\nonDemand = true\n# ...  Enable on demand certificate.  This will request a certificate from Let's Encrypt during the first TLS handshake for a host name that does not yet have a certificate.   Warning  TLS handshakes will be slow when requesting a host name certificate for the first time, this can lead to DoS attacks.    Warning  Take note that Let's Encrypt have  rate limiting .", 
            "title": "onDemand (Deprecated)"
        }, 
        {
            "location": "/configuration/acme/#onhostrule", 
            "text": "[acme]\n# ...\nonHostRule = true\n# ...  Enable certificate generation on frontends  Host  rules (for frontends wired on the  acme.entryPoint ).  This will request a certificate from Let's Encrypt for each frontend with a Host rule.  For example, a rule  Host:test1.traefik.io,test2.traefik.io  will request a certificate with main domain  test1.traefik.io  and SAN  test2.traefik.io .", 
            "title": "onHostRule"
        }, 
        {
            "location": "/configuration/acme/#caserver", 
            "text": "[acme]\n# ...\ncaServer =  https://acme-staging.api.letsencrypt.org/directory \n# ...  CA server to use.   Uncomment the line to run on the staging Let's Encrypt server.  Leave comment to go to prod.", 
            "title": "caServer"
        }, 
        {
            "location": "/configuration/acme/#acmedomains", 
            "text": "[acme]\n# ...\n[[acme.domains]]\n  main =  local1.com \n  sans = [ test1.local1.com ,  test2.local1.com ]\n[[acme.domains]]\n  main =  local2.com \n  sans = [ test1.local2.com ,  test2.local2.com ]\n[[acme.domains]]\n  main =  local3.com \n[[acme.domains]]\n  main =  local4.com \n# ...  You can provide SANs (alternative domains) to each main domain.\nAll domains must have A/AAAA records pointing to Tr\u00e6fik.   Warning  Take note that Let's Encrypt have  rate limiting .   Each domain   SANs will lead to a certificate request.", 
            "title": "acme.domains"
        }, 
        {
            "location": "/configuration/acme/#dnsprovider-deprecated", 
            "text": "DEPRECATED  This option is deprecated, use  dnsChallenge.provider  instead.", 
            "title": "dnsProvider (Deprecated)"
        }, 
        {
            "location": "/configuration/acme/#delaydontcheckdns-deprecated", 
            "text": "DEPRECATED  This option is deprecated, use  dnsChallenge.delayBeforeCheck  instead.", 
            "title": "delayDontCheckDNS (Deprecated)"
        }, 
        {
            "location": "/configuration/backends/web/", 
            "text": "Web Backend\n\n\n\n\nDEPRECATED\n\n\nThe web provider is deprecated, please use the \napi\n, the \nping\n, the \nmetrics\n and the \nrest\n provider.\n\n\n\n\nTr\u00e6fik can be configured:\n\n\n\n\nusing a RESTful api.\n\n\nto use a monitoring system (like Prometheus, DataDog or StatD, ...).\n\n\nto expose a Web Dashboard.\n\n\n\n\nConfiguration\n\n\n# Enable web backend.\n[web]\n\n# Web administration port.\n#\n# Required\n# Default: \n:8080\n\n#\naddress = \n:8080\n\n\n# SSL certificate and key used.\n#\n# Optional\n#\n# certFile = \ntraefik.crt\n\n# keyFile = \ntraefik.key\n\n\n# Set REST API to read-only mode.\n#\n# Optional\n# Default: false\n#\nreadOnly = true\n\n# Set the root path for webui and API\n#\n# Deprecated\n# Optional\n#\n# path = \n/mypath\n\n#\n\n\n\n\nWeb UI\n\n\n\n\n\n\nAuthentication\n\n\n\n\nNote\n\n\nThe \n/ping\n path of the API is excluded from authentication (since 1.4).\n\n\n\n\nBasic Authentication\n\n\nPasswords can be encoded in MD5, SHA1 and BCrypt: you can use \nhtpasswd\n to generate those ones.\n\n\nUsers can be specified directly in the TOML file, or indirectly by referencing an external file;\n if both are provided, the two are merged, with external file contents having precedence.\n\n\n[web]\n# ...\n\n# To enable basic auth on the webui with 2 user/pass: test:test and test2:test2\n[web.auth.basic]\nusers = [\ntest:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/\n, \ntest2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0\n]\nusersFile = \n/path/to/.htpasswd\n\n\n# ...\n\n\n\n\nDigest Authentication\n\n\nYou can use \nhtdigest\n to generate those ones.\n\n\nUsers can be specified directly in the TOML file, or indirectly by referencing an external file;\n if both are provided, the two are merged, with external file contents having precedence\n\n\n[web]\n# ...\n\n# To enable digest auth on the webui with 2 user/realm/pass: test:traefik:test and test2:traefik:test2\n[web.auth.digest]\nusers = [\ntest:traefik:a2688e031edb4be6a3797f3882655c05\n, \ntest2:traefik:518845800f9e2bfb1f1f740ec24f074e\n]\nusersFile = \n/path/to/.htdigest\n\n\n# ...\n\n\n\n\nMetrics\n\n\nYou can enable Tr\u00e6fik to export internal metrics to different monitoring systems.\n\n\nPrometheus\n\n\n[web]\n# ...\n\n# To enable Traefik to export internal metrics to Prometheus\n[web.metrics.prometheus]\n\n# Buckets for latency metrics\n#\n# Optional\n# Default: [0.1, 0.3, 1.2, 5]\nbuckets=[0.1,0.3,1.2,5.0]\n\n# ...\n\n\n\n\nDataDog\n\n\n[web]\n# ...\n\n# DataDog metrics exporter type\n[web.metrics.datadog]\n\n# DataDog's address.\n#\n# Required\n# Default: \nlocalhost:8125\n\n#\naddress = \nlocalhost:8125\n\n\n# DataDog push interval\n#\n# Optional\n# Default: \n10s\n\n#\npushinterval = \n10s\n\n\n# ...\n\n\n\n\nStatsD\n\n\n[web]\n# ...\n\n# StatsD metrics exporter type\n[web.metrics.statsd]\n\n# StatD's address.\n#\n# Required\n# Default: \nlocalhost:8125\n\n#\naddress = \nlocalhost:8125\n\n\n# StatD push interval\n#\n# Optional\n# Default: \n10s\n\n#\npushinterval = \n10s\n\n\n# ...\n\n\n\n\nInfluxDB\n\n\n[web]\n# ...\n\n# InfluxDB metrics exporter type\n[web.metrics.influxdb]\n\n# InfluxDB's address.\n#\n# Required\n# Default: \nlocalhost:8089\n\n#\naddress = \nlocalhost:8089\n\n\n# InfluxDB push interval\n#\n# Optional\n# Default: \n10s\n\n#\npushinterval = \n10s\n\n\n# ...\n\n\n\n\nStatistics\n\n\n[web]\n# ...\n\n# Enable more detailed statistics.\n[web.statistics]\n\n# Number of recent errors logged.\n#\n# Default: 10\n#\nrecentErrors = 10\n\n# ...\n\n\n\n\nAPI\n\n\n\n\n\n\n\n\nPath\n\n\nMethod\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n/\n\n\nGET\n\n\nProvides a simple HTML frontend of Tr\u00e6fik\n\n\n\n\n\n\n/ping\n\n\nGET\n, \nHEAD\n\n\nA simple endpoint to check for Tr\u00e6fik process liveness. Return a code \n200\n with the content: \nOK\n\n\n\n\n\n\n/health\n\n\nGET\n\n\nJSON health metrics\n\n\n\n\n\n\n/api\n\n\nGET\n\n\nConfiguration for all providers\n\n\n\n\n\n\n/api/providers\n\n\nGET\n\n\nProviders\n\n\n\n\n\n\n/api/providers/{provider}\n\n\nGET\n, \nPUT\n\n\nGet or update provider\n\n\n\n\n\n\n/api/providers/{provider}/backends\n\n\nGET\n\n\nList backends\n\n\n\n\n\n\n/api/providers/{provider}/backends/{backend}\n\n\nGET\n\n\nGet backend\n\n\n\n\n\n\n/api/providers/{provider}/backends/{backend}/servers\n\n\nGET\n\n\nList servers in backend\n\n\n\n\n\n\n/api/providers/{provider}/backends/{backend}/servers/{server}\n\n\nGET\n\n\nGet a server in a backend\n\n\n\n\n\n\n/api/providers/{provider}/frontends\n\n\nGET\n\n\nList frontends\n\n\n\n\n\n\n/api/providers/{provider}/frontends/{frontend}\n\n\nGET\n\n\nGet a frontend\n\n\n\n\n\n\n/api/providers/{provider}/frontends/{frontend}/routes\n\n\nGET\n\n\nList routes in a frontend\n\n\n\n\n\n\n/api/providers/{provider}/frontends/{frontend}/routes/{route}\n\n\nGET\n\n\nGet a route in a frontend\n\n\n\n\n\n\n/metrics\n\n\nGET\n\n\nExport internal metrics\n\n\n\n\n\n\n\n\nExample\n\n\nPing\n\n\ncurl -sv \nhttp://localhost:8080/ping\n\n\n\n\n\n*   Trying ::1...\n* Connected to localhost (::1) port 8080 (\\#0)\n\n GET /ping HTTP/1.1\n\n Host: localhost:8080\n\n User-Agent: curl/7.43.0\n\n Accept: */*\n\n\n\n HTTP/1.1 200 OK\n\n Date: Thu, 25 Aug 2016 01:35:36 GMT\n\n Content-Length: 2\n\n Content-Type: text/plain; charset=utf-8\n\n\n* Connection \\#0 to host localhost left intact\nOK\n\n\n\n\nHealth\n\n\ncurl -s \nhttp://localhost:8080/health\n | jq .\n\n\n\n\n{\n  // Tr\u00e6fik PID\n  \npid\n: 2458,\n  // Tr\u00e6fik server uptime (formated time)\n  \nuptime\n: \n39m6.885931127s\n,\n  //  Tr\u00e6fik server uptime in seconds\n  \nuptime_sec\n: 2346.885931127,\n  // current server date\n  \ntime\n: \n2015-10-07 18:32:24.362238909 +0200 CEST\n,\n  // current server date in seconds\n  \nunixtime\n: 1444235544,\n  // count HTTP response status code in realtime\n  \nstatus_code_count\n: {\n    \n502\n: 1\n  },\n  // count HTTP response status code since Tr\u00e6fik started\n  \ntotal_status_code_count\n: {\n    \n200\n: 7,\n    \n404\n: 21,\n    \n502\n: 13\n  },\n  // count HTTP response\n  \ncount\n: 1,\n  // count HTTP response\n  \ntotal_count\n: 41,\n  // sum of all response time (formated time)\n  \ntotal_response_time\n: \n35.456865605s\n,\n  // sum of all response time in seconds\n  \ntotal_response_time_sec\n: 35.456865605,\n  // average response time (formated time)\n  \naverage_response_time\n: \n864.8016ms\n,\n  // average response time in seconds\n  \naverage_response_time_sec\n: 0.8648016000000001,\n\n  // request statistics [requires --web.statistics to be set]\n  // ten most recent requests with 4xx and 5xx status codes\n  \nrecent_errors\n: [\n    {\n      // status code\n      \nstatus_code\n: 500,\n      // description of status code\n      \nstatus\n: \nInternal Server Error\n,\n      // request HTTP method\n      \nmethod\n: \nGET\n,\n      // request host name\n      \nhost\n: \nlocalhost\n,\n      // request path\n      \npath\n: \n/path\n,\n      // RFC 3339 formatted date/time\n      \ntime\n: \n2016-10-21T16:59:15.418495872-07:00\n\n    }\n  ]\n}\n\n\n\n\nProvider configurations\n\n\ncurl -s \nhttp://localhost:8080/api\n | jq .\n\n\n\n\n{\n  \nfile\n: {\n    \nfrontends\n: {\n      \nfrontend2\n: {\n        \nroutes\n: {\n          \ntest_2\n: {\n            \nrule\n: \nPath:/test\n\n          }\n        },\n        \nbackend\n: \nbackend1\n\n      },\n      \nfrontend1\n: {\n        \nroutes\n: {\n          \ntest_1\n: {\n            \nrule\n: \nHost:test.localhost\n\n          }\n        },\n        \nbackend\n: \nbackend2\n\n      }\n    },\n    \nbackends\n: {\n      \nbackend2\n: {\n        \nloadBalancer\n: {\n          \nmethod\n: \ndrr\n\n        },\n        \nservers\n: {\n          \nserver2\n: {\n            \nweight\n: 2,\n            \nURL\n: \nhttp://172.17.0.5:80\n\n          },\n          \nserver1\n: {\n            \nweight\n: 1,\n            \nurl\n: \nhttp://172.17.0.4:80\n\n          }\n        }\n      },\n      \nbackend1\n: {\n        \nloadBalancer\n: {\n          \nmethod\n: \nwrr\n\n        },\n        \ncircuitBreaker\n: {\n          \nexpression\n: \nNetworkErrorRatio() \n 0.5\n\n        },\n        \nservers\n: {\n          \nserver2\n: {\n            \nweight\n: 1,\n            \nurl\n: \nhttp://172.17.0.3:80\n\n          },\n          \nserver1\n: {\n            \nweight\n: 10,\n            \nurl\n: \nhttp://172.17.0.2:80\n\n          }\n        }\n      }\n    }\n  }\n}\n\n\n\n\nDeprecation compatibility\n\n\nAddress\n\n\nAs the web provider is deprecated, you can handle the \nAddress\n option like this:\n\n\ndefaultEntryPoints = [\nhttp\n]\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n\n  [entryPoints.foo]\n  address = \n:8082\n\n\n  [entryPoints.bar]\n  address = \n:8083\n\n\n[ping]\nentryPoint = \nfoo\n\n\n[api]\nentryPoint = \nbar\n\n\n\n\n\nIn the above example, you would access a regular path, administration panel, and health-check as follows:\n\n\n\n\nRegular path: \nhttp://hostname:80/path\n\n\nAdmin Panel: \nhttp://hostname:8083/\n\n\nPing URL: \nhttp://hostname:8082/ping\n\n\n\n\nIn the above example, it is \nvery\n important to create a named dedicated entry point, and do \nnot\n include it in \ndefaultEntryPoints\n.\nOtherwise, you are likely to expose \nall\n services via that entry point.\n\n\nPath\n\n\nAs the web provider is deprecated, you can handle the \nPath\n option like this:\n\n\ndefaultEntryPoints = [\nhttp\n]\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n\n  [entryPoints.foo]\n  address = \n:8080\n\n\n  [entryPoints.bar]\n  address = \n:8081\n\n\n# Activate API and Dashboard\n[api]\nentryPoint = \nbar\n\ndashboard = true\n\n[file]\n  [backends]\n    [backends.backend1]\n      [backends.backend1.servers.server1]\n      url = \nhttp://127.0.0.1:8081\n\n\n  [frontends]\n    [frontends.frontend1]\n    entryPoints = [\nfoo\n]\n    backend = \nbackend1\n\n      [frontends.frontend1.routes.test_1]\n      rule = \nPathPrefixStrip:/yourprefix;PathPrefix:/yourprefix\n\n\n\n\n\nAuthentication\n\n\nAs the web provider is deprecated, you can handle the \nauth\n option like this:\n\n\ndefaultEntryPoints = [\nhttp\n]\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n\n [entryPoints.foo]\n   address=\n:8080\n\n   [entryPoints.foo.auth]\n     [entryPoints.foo.auth.basic]\n       users = [\n         \ntest:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/\n,\n         \ntest2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0\n,\n       ]\n\n[api]\nentrypoint=\nfoo\n\n\n\n\n\nFor more information, see \nentry points\n .", 
            "title": "Backend: Web"
        }, 
        {
            "location": "/configuration/backends/web/#web-backend", 
            "text": "DEPRECATED  The web provider is deprecated, please use the  api , the  ping , the  metrics  and the  rest  provider.   Tr\u00e6fik can be configured:   using a RESTful api.  to use a monitoring system (like Prometheus, DataDog or StatD, ...).  to expose a Web Dashboard.", 
            "title": "Web Backend"
        }, 
        {
            "location": "/configuration/backends/web/#configuration", 
            "text": "# Enable web backend.\n[web]\n\n# Web administration port.\n#\n# Required\n# Default:  :8080 \n#\naddress =  :8080 \n\n# SSL certificate and key used.\n#\n# Optional\n#\n# certFile =  traefik.crt \n# keyFile =  traefik.key \n\n# Set REST API to read-only mode.\n#\n# Optional\n# Default: false\n#\nreadOnly = true\n\n# Set the root path for webui and API\n#\n# Deprecated\n# Optional\n#\n# path =  /mypath \n#", 
            "title": "Configuration"
        }, 
        {
            "location": "/configuration/backends/web/#web-ui", 
            "text": "", 
            "title": "Web UI"
        }, 
        {
            "location": "/configuration/backends/web/#authentication", 
            "text": "Note  The  /ping  path of the API is excluded from authentication (since 1.4).", 
            "title": "Authentication"
        }, 
        {
            "location": "/configuration/backends/web/#basic-authentication", 
            "text": "Passwords can be encoded in MD5, SHA1 and BCrypt: you can use  htpasswd  to generate those ones.  Users can be specified directly in the TOML file, or indirectly by referencing an external file;\n if both are provided, the two are merged, with external file contents having precedence.  [web]\n# ...\n\n# To enable basic auth on the webui with 2 user/pass: test:test and test2:test2\n[web.auth.basic]\nusers = [ test:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/ ,  test2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0 ]\nusersFile =  /path/to/.htpasswd \n\n# ...", 
            "title": "Basic Authentication"
        }, 
        {
            "location": "/configuration/backends/web/#digest-authentication", 
            "text": "You can use  htdigest  to generate those ones.  Users can be specified directly in the TOML file, or indirectly by referencing an external file;\n if both are provided, the two are merged, with external file contents having precedence  [web]\n# ...\n\n# To enable digest auth on the webui with 2 user/realm/pass: test:traefik:test and test2:traefik:test2\n[web.auth.digest]\nusers = [ test:traefik:a2688e031edb4be6a3797f3882655c05 ,  test2:traefik:518845800f9e2bfb1f1f740ec24f074e ]\nusersFile =  /path/to/.htdigest \n\n# ...", 
            "title": "Digest Authentication"
        }, 
        {
            "location": "/configuration/backends/web/#metrics", 
            "text": "You can enable Tr\u00e6fik to export internal metrics to different monitoring systems.", 
            "title": "Metrics"
        }, 
        {
            "location": "/configuration/backends/web/#prometheus", 
            "text": "[web]\n# ...\n\n# To enable Traefik to export internal metrics to Prometheus\n[web.metrics.prometheus]\n\n# Buckets for latency metrics\n#\n# Optional\n# Default: [0.1, 0.3, 1.2, 5]\nbuckets=[0.1,0.3,1.2,5.0]\n\n# ...", 
            "title": "Prometheus"
        }, 
        {
            "location": "/configuration/backends/web/#datadog", 
            "text": "[web]\n# ...\n\n# DataDog metrics exporter type\n[web.metrics.datadog]\n\n# DataDog's address.\n#\n# Required\n# Default:  localhost:8125 \n#\naddress =  localhost:8125 \n\n# DataDog push interval\n#\n# Optional\n# Default:  10s \n#\npushinterval =  10s \n\n# ...", 
            "title": "DataDog"
        }, 
        {
            "location": "/configuration/backends/web/#statsd", 
            "text": "[web]\n# ...\n\n# StatsD metrics exporter type\n[web.metrics.statsd]\n\n# StatD's address.\n#\n# Required\n# Default:  localhost:8125 \n#\naddress =  localhost:8125 \n\n# StatD push interval\n#\n# Optional\n# Default:  10s \n#\npushinterval =  10s \n\n# ...", 
            "title": "StatsD"
        }, 
        {
            "location": "/configuration/backends/web/#influxdb", 
            "text": "[web]\n# ...\n\n# InfluxDB metrics exporter type\n[web.metrics.influxdb]\n\n# InfluxDB's address.\n#\n# Required\n# Default:  localhost:8089 \n#\naddress =  localhost:8089 \n\n# InfluxDB push interval\n#\n# Optional\n# Default:  10s \n#\npushinterval =  10s \n\n# ...", 
            "title": "InfluxDB"
        }, 
        {
            "location": "/configuration/backends/web/#statistics", 
            "text": "[web]\n# ...\n\n# Enable more detailed statistics.\n[web.statistics]\n\n# Number of recent errors logged.\n#\n# Default: 10\n#\nrecentErrors = 10\n\n# ...", 
            "title": "Statistics"
        }, 
        {
            "location": "/configuration/backends/web/#api", 
            "text": "Path  Method  Description      /  GET  Provides a simple HTML frontend of Tr\u00e6fik    /ping  GET ,  HEAD  A simple endpoint to check for Tr\u00e6fik process liveness. Return a code  200  with the content:  OK    /health  GET  JSON health metrics    /api  GET  Configuration for all providers    /api/providers  GET  Providers    /api/providers/{provider}  GET ,  PUT  Get or update provider    /api/providers/{provider}/backends  GET  List backends    /api/providers/{provider}/backends/{backend}  GET  Get backend    /api/providers/{provider}/backends/{backend}/servers  GET  List servers in backend    /api/providers/{provider}/backends/{backend}/servers/{server}  GET  Get a server in a backend    /api/providers/{provider}/frontends  GET  List frontends    /api/providers/{provider}/frontends/{frontend}  GET  Get a frontend    /api/providers/{provider}/frontends/{frontend}/routes  GET  List routes in a frontend    /api/providers/{provider}/frontends/{frontend}/routes/{route}  GET  Get a route in a frontend    /metrics  GET  Export internal metrics", 
            "title": "API"
        }, 
        {
            "location": "/configuration/backends/web/#example", 
            "text": "", 
            "title": "Example"
        }, 
        {
            "location": "/configuration/backends/web/#ping", 
            "text": "curl -sv  http://localhost:8080/ping   *   Trying ::1...\n* Connected to localhost (::1) port 8080 (\\#0)  GET /ping HTTP/1.1  Host: localhost:8080  User-Agent: curl/7.43.0  Accept: */*   HTTP/1.1 200 OK  Date: Thu, 25 Aug 2016 01:35:36 GMT  Content-Length: 2  Content-Type: text/plain; charset=utf-8 \n* Connection \\#0 to host localhost left intact\nOK", 
            "title": "Ping"
        }, 
        {
            "location": "/configuration/backends/web/#health", 
            "text": "curl -s  http://localhost:8080/health  | jq .  {\n  // Tr\u00e6fik PID\n   pid : 2458,\n  // Tr\u00e6fik server uptime (formated time)\n   uptime :  39m6.885931127s ,\n  //  Tr\u00e6fik server uptime in seconds\n   uptime_sec : 2346.885931127,\n  // current server date\n   time :  2015-10-07 18:32:24.362238909 +0200 CEST ,\n  // current server date in seconds\n   unixtime : 1444235544,\n  // count HTTP response status code in realtime\n   status_code_count : {\n     502 : 1\n  },\n  // count HTTP response status code since Tr\u00e6fik started\n   total_status_code_count : {\n     200 : 7,\n     404 : 21,\n     502 : 13\n  },\n  // count HTTP response\n   count : 1,\n  // count HTTP response\n   total_count : 41,\n  // sum of all response time (formated time)\n   total_response_time :  35.456865605s ,\n  // sum of all response time in seconds\n   total_response_time_sec : 35.456865605,\n  // average response time (formated time)\n   average_response_time :  864.8016ms ,\n  // average response time in seconds\n   average_response_time_sec : 0.8648016000000001,\n\n  // request statistics [requires --web.statistics to be set]\n  // ten most recent requests with 4xx and 5xx status codes\n   recent_errors : [\n    {\n      // status code\n       status_code : 500,\n      // description of status code\n       status :  Internal Server Error ,\n      // request HTTP method\n       method :  GET ,\n      // request host name\n       host :  localhost ,\n      // request path\n       path :  /path ,\n      // RFC 3339 formatted date/time\n       time :  2016-10-21T16:59:15.418495872-07:00 \n    }\n  ]\n}", 
            "title": "Health"
        }, 
        {
            "location": "/configuration/backends/web/#provider-configurations", 
            "text": "curl -s  http://localhost:8080/api  | jq .  {\n   file : {\n     frontends : {\n       frontend2 : {\n         routes : {\n           test_2 : {\n             rule :  Path:/test \n          }\n        },\n         backend :  backend1 \n      },\n       frontend1 : {\n         routes : {\n           test_1 : {\n             rule :  Host:test.localhost \n          }\n        },\n         backend :  backend2 \n      }\n    },\n     backends : {\n       backend2 : {\n         loadBalancer : {\n           method :  drr \n        },\n         servers : {\n           server2 : {\n             weight : 2,\n             URL :  http://172.17.0.5:80 \n          },\n           server1 : {\n             weight : 1,\n             url :  http://172.17.0.4:80 \n          }\n        }\n      },\n       backend1 : {\n         loadBalancer : {\n           method :  wrr \n        },\n         circuitBreaker : {\n           expression :  NetworkErrorRatio()   0.5 \n        },\n         servers : {\n           server2 : {\n             weight : 1,\n             url :  http://172.17.0.3:80 \n          },\n           server1 : {\n             weight : 10,\n             url :  http://172.17.0.2:80 \n          }\n        }\n      }\n    }\n  }\n}", 
            "title": "Provider configurations"
        }, 
        {
            "location": "/configuration/backends/web/#deprecation-compatibility", 
            "text": "", 
            "title": "Deprecation compatibility"
        }, 
        {
            "location": "/configuration/backends/web/#address", 
            "text": "As the web provider is deprecated, you can handle the  Address  option like this:  defaultEntryPoints = [ http ]\n\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n\n  [entryPoints.foo]\n  address =  :8082 \n\n  [entryPoints.bar]\n  address =  :8083 \n\n[ping]\nentryPoint =  foo \n\n[api]\nentryPoint =  bar   In the above example, you would access a regular path, administration panel, and health-check as follows:   Regular path:  http://hostname:80/path  Admin Panel:  http://hostname:8083/  Ping URL:  http://hostname:8082/ping   In the above example, it is  very  important to create a named dedicated entry point, and do  not  include it in  defaultEntryPoints .\nOtherwise, you are likely to expose  all  services via that entry point.", 
            "title": "Address"
        }, 
        {
            "location": "/configuration/backends/web/#path", 
            "text": "As the web provider is deprecated, you can handle the  Path  option like this:  defaultEntryPoints = [ http ]\n\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n\n  [entryPoints.foo]\n  address =  :8080 \n\n  [entryPoints.bar]\n  address =  :8081 \n\n# Activate API and Dashboard\n[api]\nentryPoint =  bar \ndashboard = true\n\n[file]\n  [backends]\n    [backends.backend1]\n      [backends.backend1.servers.server1]\n      url =  http://127.0.0.1:8081 \n\n  [frontends]\n    [frontends.frontend1]\n    entryPoints = [ foo ]\n    backend =  backend1 \n      [frontends.frontend1.routes.test_1]\n      rule =  PathPrefixStrip:/yourprefix;PathPrefix:/yourprefix", 
            "title": "Path"
        }, 
        {
            "location": "/configuration/backends/web/#authentication_1", 
            "text": "As the web provider is deprecated, you can handle the  auth  option like this:  defaultEntryPoints = [ http ]\n\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n\n [entryPoints.foo]\n   address= :8080 \n   [entryPoints.foo.auth]\n     [entryPoints.foo.auth.basic]\n       users = [\n          test:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/ ,\n          test2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0 ,\n       ]\n\n[api]\nentrypoint= foo   For more information, see  entry points  .", 
            "title": "Authentication"
        }, 
        {
            "location": "/configuration/backends/boltdb/", 
            "text": "BoltDB Backend\n\n\nTr\u00e6fik can be configured to use BoltDB as a backend configuration.\n\n\n################################################################\n# BoltDB configuration backend\n################################################################\n\n# Enable BoltDB configuration backend.\n[boltdb]\n\n# BoltDB file.\n#\n# Required\n# Default: \n127.0.0.1:4001\n\n#\nendpoint = \n/my.db\n\n\n# Enable watch BoltDB changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n# Default: \n/traefik\n\n#\nprefix = \n/traefik\n\n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\nfilename = \nboltdb.tmpl\n\n\n# Use BoltDB user/pass authentication.\n#\n# Optional\n#\n# username = foo\n# password = bar\n\n# Enable BoltDB TLS connection.\n#\n# Optional\n#\n#    [boltdb.tls]\n#    ca = \n/etc/ssl/ca.crt\n\n#    cert = \n/etc/ssl/boltdb.crt\n\n#    key = \n/etc/ssl/boltdb.key\n\n#    insecureskipverify = true\n\n\n\n\nTo enable constraints see \nbackend-specific constraints section\n.", 
            "title": "Backend: BoltDB"
        }, 
        {
            "location": "/configuration/backends/boltdb/#boltdb-backend", 
            "text": "Tr\u00e6fik can be configured to use BoltDB as a backend configuration.  ################################################################\n# BoltDB configuration backend\n################################################################\n\n# Enable BoltDB configuration backend.\n[boltdb]\n\n# BoltDB file.\n#\n# Required\n# Default:  127.0.0.1:4001 \n#\nendpoint =  /my.db \n\n# Enable watch BoltDB changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n# Default:  /traefik \n#\nprefix =  /traefik \n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\nfilename =  boltdb.tmpl \n\n# Use BoltDB user/pass authentication.\n#\n# Optional\n#\n# username = foo\n# password = bar\n\n# Enable BoltDB TLS connection.\n#\n# Optional\n#\n#    [boltdb.tls]\n#    ca =  /etc/ssl/ca.crt \n#    cert =  /etc/ssl/boltdb.crt \n#    key =  /etc/ssl/boltdb.key \n#    insecureskipverify = true  To enable constraints see  backend-specific constraints section .", 
            "title": "BoltDB Backend"
        }, 
        {
            "location": "/configuration/backends/consul/", 
            "text": "Consul Key-Value backend\n\n\nTr\u00e6fik can be configured to use Consul as a backend configuration.\n\n\n################################################################\n# Consul KV configuration backend\n################################################################\n\n# Enable Consul KV configuration backend.\n[consul]\n\n# Consul server endpoint.\n#\n# Required\n# Default: \n127.0.0.1:8500\n\n#\nendpoint = \n127.0.0.1:8500\n\n\n# Enable watch Consul changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n# Default: traefik\n#\nprefix = \ntraefik\n\n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename = \nconsul.tmpl\n\n\n# Use Consul user/pass authentication.\n#\n# Optional\n#\n# username = foo\n# password = bar\n\n# Enable Consul TLS connection.\n#\n# Optional\n#\n#    [consul.tls]\n#    ca = \n/etc/ssl/ca.crt\n\n#    cert = \n/etc/ssl/consul.crt\n\n#    key = \n/etc/ssl/consul.key\n\n#    insecureskipverify = true\n\n\n\n\nTo enable constraints see \nbackend-specific constraints section\n.\n\n\nPlease refer to the \nKey Value storage structure\n section to get documentation on Traefik KV structure.", 
            "title": "Backend: Consul"
        }, 
        {
            "location": "/configuration/backends/consul/#consul-key-value-backend", 
            "text": "Tr\u00e6fik can be configured to use Consul as a backend configuration.  ################################################################\n# Consul KV configuration backend\n################################################################\n\n# Enable Consul KV configuration backend.\n[consul]\n\n# Consul server endpoint.\n#\n# Required\n# Default:  127.0.0.1:8500 \n#\nendpoint =  127.0.0.1:8500 \n\n# Enable watch Consul changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n# Default: traefik\n#\nprefix =  traefik \n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename =  consul.tmpl \n\n# Use Consul user/pass authentication.\n#\n# Optional\n#\n# username = foo\n# password = bar\n\n# Enable Consul TLS connection.\n#\n# Optional\n#\n#    [consul.tls]\n#    ca =  /etc/ssl/ca.crt \n#    cert =  /etc/ssl/consul.crt \n#    key =  /etc/ssl/consul.key \n#    insecureskipverify = true  To enable constraints see  backend-specific constraints section .  Please refer to the  Key Value storage structure  section to get documentation on Traefik KV structure.", 
            "title": "Consul Key-Value backend"
        }, 
        {
            "location": "/configuration/backends/consulcatalog/", 
            "text": "Consul Catalog backend\n\n\nTr\u00e6fik can be configured to use service discovery catalog of Consul as a backend configuration.\n\n\n################################################################\n# Consul Catalog configuration backend\n################################################################\n\n# Enable Consul Catalog configuration backend.\n[consulCatalog]\n\n# Consul server endpoint.\n#\n# Required\n# Default: \n127.0.0.1:8500\n\n#\nendpoint = \n127.0.0.1:8500\n\n\n# Expose Consul catalog services by default in Traefik.\n#\n# Optional\n# Default: true\n#\nexposedByDefault = false\n\n# Default domain used.\n#\n# Optional\n#\ndomain = \nconsul.localhost\n\n\n# Prefix for Consul catalog tags.\n#\n# Optional\n# Default: \ntraefik\n\n#\nprefix = \ntraefik\n\n\n# Default frontEnd Rule for Consul services.\n#\n# The format is a Go Template with:\n# - \n.ServiceName\n, \n.Domain\n and \n.Attributes\n available\n# - \ngetTag(name, tags, defaultValue)\n, \nhasTag(name, tags)\n and \ngetAttribute(name, tags, defaultValue)\n functions are available\n# - \ngetAttribute(...)\n function uses prefixed tag names based on \nprefix\n value\n#\n# Optional\n# Default: \nHost:{{.ServiceName}}.{{.Domain}}\n\n#\n#frontEndRule = \nHost:{{.ServiceName}}.{{.Domain}}\n\n\n\n\n\nThis backend will create routes matching on hostname based on the service name used in Consul.\n\n\nTo enable constraints see \nbackend-specific constraints section\n.\n\n\nTags\n\n\nAdditional settings can be defined using Consul Catalog tags.\n\n\n\n\n\n\n\n\nTag\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntraefik.enable=false\n\n\nDisable this container in Tr\u00e6fik\n\n\n\n\n\n\ntraefik.protocol=https\n\n\nOverride the default \nhttp\n protocol\n\n\n\n\n\n\ntraefik.backend.weight=10\n\n\nAssign this weight to the container\n\n\n\n\n\n\ntraefik.backend.circuitbreaker=EXPR\n\n\nCreate a \ncircuit breaker\n to be used against the backend, ex: \nNetworkErrorRatio() \n 0.\n\n\n\n\n\n\ntraefik.backend.maxconn.amount=10\n\n\nSet a maximum number of connections to the backend. Must be used in conjunction with the below label to take effect.\n\n\n\n\n\n\ntraefik.backend.maxconn.extractorfunc=client.ip\n\n\nSet the function to be used against the request to determine what to limit maximum connections to the backend by. Must be used in conjunction with the above label to take effect.\n\n\n\n\n\n\ntraefik.frontend.rule=Host:test.traefik.io\n\n\nOverride the default frontend rule (Default: \nHost:{{.ServiceName}}.{{.Domain}}\n).\n\n\n\n\n\n\ntraefik.frontend.passHostHeader=true\n\n\nForward client \nHost\n header to the backend.\n\n\n\n\n\n\ntraefik.frontend.priority=10\n\n\nOverride default frontend priority\n\n\n\n\n\n\ntraefik.frontend.entryPoints=http,https\n\n\nAssign this frontend to entry points \nhttp\n and \nhttps\n. Overrides \ndefaultEntryPoints\n.\n\n\n\n\n\n\ntraefik.frontend.auth.basic=EXPR\n\n\nSets basic authentication for that frontend in CSV format: \nUser:Hash,User:Hash\n\n\n\n\n\n\ntraefik.backend.loadbalancer=drr\n\n\noverride the default \nwrr\n load balancer algorithm\n\n\n\n\n\n\ntraefik.backend.loadbalancer.stickiness=true\n\n\nenable backend sticky sessions\n\n\n\n\n\n\ntraefik.backend.loadbalancer.stickiness.cookieName=NAME\n\n\nManually set the cookie name for sticky sessions\n\n\n\n\n\n\ntraefik.backend.loadbalancer.sticky=true\n\n\nenable backend sticky sessions (DEPRECATED)\n\n\n\n\n\n\n\n\nExamples\n\n\nIf you want that Tr\u00e6fik uses Consul tags correctly you need to defined them like that:\n\n\ntraefik.enable=true\ntraefik.tags=api\ntraefik.tags=external\n\n\n\n\nIf the prefix defined in Tr\u00e6fik configuration is \nbla\n, tags need to be defined like that:\n\n\nbla.enable=true\nbla.tags=api\nbla.tags=external", 
            "title": "Backend: Consul Catalog"
        }, 
        {
            "location": "/configuration/backends/consulcatalog/#consul-catalog-backend", 
            "text": "Tr\u00e6fik can be configured to use service discovery catalog of Consul as a backend configuration.  ################################################################\n# Consul Catalog configuration backend\n################################################################\n\n# Enable Consul Catalog configuration backend.\n[consulCatalog]\n\n# Consul server endpoint.\n#\n# Required\n# Default:  127.0.0.1:8500 \n#\nendpoint =  127.0.0.1:8500 \n\n# Expose Consul catalog services by default in Traefik.\n#\n# Optional\n# Default: true\n#\nexposedByDefault = false\n\n# Default domain used.\n#\n# Optional\n#\ndomain =  consul.localhost \n\n# Prefix for Consul catalog tags.\n#\n# Optional\n# Default:  traefik \n#\nprefix =  traefik \n\n# Default frontEnd Rule for Consul services.\n#\n# The format is a Go Template with:\n# -  .ServiceName ,  .Domain  and  .Attributes  available\n# -  getTag(name, tags, defaultValue) ,  hasTag(name, tags)  and  getAttribute(name, tags, defaultValue)  functions are available\n# -  getAttribute(...)  function uses prefixed tag names based on  prefix  value\n#\n# Optional\n# Default:  Host:{{.ServiceName}}.{{.Domain}} \n#\n#frontEndRule =  Host:{{.ServiceName}}.{{.Domain}}   This backend will create routes matching on hostname based on the service name used in Consul.  To enable constraints see  backend-specific constraints section .", 
            "title": "Consul Catalog backend"
        }, 
        {
            "location": "/configuration/backends/consulcatalog/#tags", 
            "text": "Additional settings can be defined using Consul Catalog tags.     Tag  Description      traefik.enable=false  Disable this container in Tr\u00e6fik    traefik.protocol=https  Override the default  http  protocol    traefik.backend.weight=10  Assign this weight to the container    traefik.backend.circuitbreaker=EXPR  Create a  circuit breaker  to be used against the backend, ex:  NetworkErrorRatio()   0.    traefik.backend.maxconn.amount=10  Set a maximum number of connections to the backend. Must be used in conjunction with the below label to take effect.    traefik.backend.maxconn.extractorfunc=client.ip  Set the function to be used against the request to determine what to limit maximum connections to the backend by. Must be used in conjunction with the above label to take effect.    traefik.frontend.rule=Host:test.traefik.io  Override the default frontend rule (Default:  Host:{{.ServiceName}}.{{.Domain}} ).    traefik.frontend.passHostHeader=true  Forward client  Host  header to the backend.    traefik.frontend.priority=10  Override default frontend priority    traefik.frontend.entryPoints=http,https  Assign this frontend to entry points  http  and  https . Overrides  defaultEntryPoints .    traefik.frontend.auth.basic=EXPR  Sets basic authentication for that frontend in CSV format:  User:Hash,User:Hash    traefik.backend.loadbalancer=drr  override the default  wrr  load balancer algorithm    traefik.backend.loadbalancer.stickiness=true  enable backend sticky sessions    traefik.backend.loadbalancer.stickiness.cookieName=NAME  Manually set the cookie name for sticky sessions    traefik.backend.loadbalancer.sticky=true  enable backend sticky sessions (DEPRECATED)", 
            "title": "Tags"
        }, 
        {
            "location": "/configuration/backends/consulcatalog/#examples", 
            "text": "If you want that Tr\u00e6fik uses Consul tags correctly you need to defined them like that:  traefik.enable=true\ntraefik.tags=api\ntraefik.tags=external  If the prefix defined in Tr\u00e6fik configuration is  bla , tags need to be defined like that:  bla.enable=true\nbla.tags=api\nbla.tags=external", 
            "title": "Examples"
        }, 
        {
            "location": "/configuration/backends/docker/", 
            "text": "Docker Backend\n\n\nTr\u00e6fik can be configured to use Docker as a backend configuration.\n\n\nDocker\n\n\n################################################################\n# Docker configuration backend\n################################################################\n\n# Enable Docker configuration backend.\n[docker]\n\n# Docker server endpoint. Can be a tcp or a unix socket endpoint.\n#\n# Required\n#\nendpoint = \nunix:///var/run/docker.sock\n\n\n# Default domain used.\n# Can be overridden by setting the \ntraefik.domain\n label on a container.\n#\n# Required\n#\ndomain = \ndocker.localhost\n\n\n# Enable watch docker changes.\n#\n# Optional\n#\nwatch = true\n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename = \ndocker.tmpl\n\n\n# Expose containers by default in Traefik.\n# If set to false, containers that don't have `traefik.enable=true` will be ignored.\n#\n# Optional\n# Default: true\n#\nexposedbydefault = true\n\n# Use the IP address from the binded port instead of the inner network one.\n# For specific use-case :)\n#\n# Optional\n# Default: false\n#\nusebindportip = true\n\n# Use Swarm Mode services as data provider.\n#\n# Optional\n# Default: false\n#\nswarmmode = false\n\n# Enable docker TLS connection.\n#\n# Optional\n#\n#  [docker.tls]\n#  ca = \n/etc/ssl/ca.crt\n\n#  cert = \n/etc/ssl/docker.crt\n\n#  key = \n/etc/ssl/docker.key\n\n#  insecureskipverify = true\n\n\n\n\nTo enable constraints see \nbackend-specific constraints section\n.\n\n\nDocker Swarm Mode\n\n\n################################################################\n# Docker Swarmmode configuration backend\n################################################################\n\n# Enable Docker configuration backend.\n[docker]\n\n# Docker server endpoint.\n# Can be a tcp or a unix socket endpoint.\n#\n# Required\n# Default: \nunix:///var/run/docker.sock\n\n#\nendpoint = \ntcp://127.0.0.1:2375\n\n\n# Default domain used.\n# Can be overridden by setting the \ntraefik.domain\n label on a services.\n#\n# Optional\n# Default: \n\n#\ndomain = \ndocker.localhost\n\n\n# Enable watch docker changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Use Docker Swarm Mode as data provider.\n#\n# Optional\n# Default: false\n#\nswarmmode = true\n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename = \ndocker.tmpl\n\n\n# Expose services by default in Traefik.\n#\n# Optional\n# Default: true\n#\nexposedbydefault = false\n\n# Enable docker TLS connection.\n#\n# Optional\n#\n#  [docker.tls]\n#  ca = \n/etc/ssl/ca.crt\n\n#  cert = \n/etc/ssl/docker.crt\n\n#  key = \n/etc/ssl/docker.key\n\n#  insecureskipverify = true\n\n\n\n\nTo enable constraints see \nbackend-specific constraints section\n.\n\n\nLabels: overriding default behaviour\n\n\nUsing Docker with Swarm Mode\n\n\nIf you use a compose file with the Swarm mode, labels should be defined in the \ndeploy\n part of your service.\nThis behavior is only enabled for docker-compose version 3+ (\nCompose file reference\n).\n\n\nversion: \n3\n\nservices:\n  whoami:\n    deploy:\n      labels:\n        traefik.docker.network: traefik\n\n\n\n\nUsing Docker Compose\n\n\nIf you are intending to use only Docker Compose commands (e.g. \ndocker-compose up --scale whoami=2 -d\n), labels should be under your service, otherwise they will be ignored. \n\n\nversion: \n3\n\nservices:\n  whoami:\n    labels:\n      traefik.docker.network: traefik\n\n\n\n\nOn Containers\n\n\nLabels can be used on containers to override default behaviour.\n\n\n\n\n\n\n\n\nLabel\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntraefik.backend=foo\n\n\nGive the name \nfoo\n to the generated backend for this container.\n\n\n\n\n\n\ntraefik.backend.maxconn.amount=10\n\n\nSet a maximum number of connections to the backend. Must be used in conjunction with the below label to take effect.\n\n\n\n\n\n\ntraefik.backend.maxconn.extractorfunc=client.ip\n\n\nSet the function to be used against the request to determine what to limit maximum connections to the backend by. Must be used in conjunction with the above label to take effect.\n\n\n\n\n\n\ntraefik.backend.loadbalancer.method=drr\n\n\nOverride the default \nwrr\n load balancer algorithm\n\n\n\n\n\n\ntraefik.backend.loadbalancer.stickiness=true\n\n\nEnable backend sticky sessions\n\n\n\n\n\n\ntraefik.backend.loadbalancer.stickiness.cookieName=NAME\n\n\nManually set the cookie name for sticky sessions\n\n\n\n\n\n\ntraefik.backend.loadbalancer.sticky=true\n\n\nEnable backend sticky sessions (DEPRECATED)\n\n\n\n\n\n\ntraefik.backend.loadbalancer.swarm=true\n\n\nUse Swarm's inbuilt load balancer (only relevant under Swarm Mode).\n\n\n\n\n\n\ntraefik.backend.circuitbreaker.expression=EXPR\n\n\nCreate a \ncircuit breaker\n to be used against the backend\n\n\n\n\n\n\ntraefik.port=80\n\n\nRegister this port. Useful when the container exposes multiples ports.\n\n\n\n\n\n\ntraefik.protocol=https\n\n\nOverride the default \nhttp\n protocol\n\n\n\n\n\n\ntraefik.weight=10\n\n\nAssign this weight to the container\n\n\n\n\n\n\ntraefik.enable=false\n\n\nDisable this container in Tr\u00e6fik\n\n\n\n\n\n\ntraefik.frontend.rule=EXPR\n\n\nOverride the default frontend rule. Default: \nHost:{containerName}.{domain}\n or \nHost:{service}.{project_name}.{domain}\n if you are using \ndocker-compose\n.\n\n\n\n\n\n\ntraefik.frontend.passHostHeader=true\n\n\nForward client \nHost\n header to the backend.\n\n\n\n\n\n\ntraefik.frontend.priority=10\n\n\nOverride default frontend priority\n\n\n\n\n\n\ntraefik.frontend.entryPoints=http,https\n\n\nAssign this frontend to entry points \nhttp\n and \nhttps\n. Overrides \ndefaultEntryPoints\n\n\n\n\n\n\ntraefik.frontend.auth.basic=EXPR\n\n\nSets basic authentication for that frontend in CSV format: \nUser:Hash,User:Hash\n\n\n\n\n\n\ntraefik.frontend.whitelistSourceRange:RANGE\n\n\nList of IP-Ranges which are allowed to access. An unset or empty list allows all Source-IPs to access. If one of the Net-Specifications are invalid, the whole list is invalid and allows all Source-IPs to access.\n\n\n\n\n\n\ntraefik.docker.network\n\n\nSet the docker network to use for connections to this container. [1]\n\n\n\n\n\n\ntraefik.frontend.redirect.entryPoint=https\n\n\nEnables Redirect to another entryPoint for that frontend (e.g. HTTPS)\n\n\n\n\n\n\ntraefik.frontend.redirect.regex=^http://localhost/(.*)\n\n\nRedirect to another URL for that frontend. Must be set with \ntraefik.frontend.redirect.replacement\n.\n\n\n\n\n\n\ntraefik.frontend.redirect.replacement=http://mydomain/$1\n\n\nRedirect to another URL for that frontend. Must be set with \ntraefik.frontend.redirect.regex\n.\n\n\n\n\n\n\n\n\n[1] \ntraefik.docker.network\n:\nIf a container is linked to several networks, be sure to set the proper network name (you can check with \ndocker inspect \ncontainer_id\n) otherwise it will randomly pick one (depending on how docker is returning them).\nFor instance when deploying docker \nstack\n from compose files, the compose defined networks will be prefixed with the \nstack\n name.\nOr if your service references external network use it's name instead.\n\n\nSecurity Headers\n\n\n\n\n\n\n\n\nLabel\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntraefik.frontend.headers.allowedHosts=EXPR\n\n\nProvides a list of allowed hosts that requests will be processed. Format: \nHost1,Host2\n\n\n\n\n\n\ntraefik.frontend.headers.customRequestHeaders=EXPR\n\n\nProvides the container with custom request headers that will be appended to each request forwarded to the container. Format: \nHEADER:value\nHEADER2:value2\n\n\n\n\n\n\ntraefik.frontend.headers.customResponseHeaders=EXPR\n\n\nAppends the headers to each response returned by the container, before forwarding the response to the client. Format: \nHEADER:value\nHEADER2:value2\n\n\n\n\n\n\ntraefik.frontend.headers.hostsProxyHeaders=EXPR\n\n\nProvides a list of headers that the proxied hostname may be stored. Format:  \nHEADER1,HEADER2\n\n\n\n\n\n\ntraefik.frontend.headers.SSLRedirect=true\n\n\nForces the frontend to redirect to SSL if a non-SSL request is sent.\n\n\n\n\n\n\ntraefik.frontend.headers.SSLTemporaryRedirect=true\n\n\nForces the frontend to redirect to SSL if a non-SSL request is sent, but by sending a 302 instead of a 301.\n\n\n\n\n\n\ntraefik.frontend.headers.SSLHost=HOST\n\n\nThis setting configures the hostname that redirects will be based on. Default is \"\", which is the same host as the request.\n\n\n\n\n\n\ntraefik.frontend.headers.SSLProxyHeaders=EXPR\n\n\nHeader combinations that would signify a proper SSL Request (Such as \nX-Forwarded-For:https\n). Format:  \nHEADER:value\nHEADER2:value2\n\n\n\n\n\n\ntraefik.frontend.headers.STSSeconds=315360000\n\n\nSets the max-age of the STS header.\n\n\n\n\n\n\ntraefik.frontend.headers.STSIncludeSubdomains=true\n\n\nAdds the \nIncludeSubdomains\n section of the STS  header.\n\n\n\n\n\n\ntraefik.frontend.headers.STSPreload=true\n\n\nAdds the preload flag to the STS  header.\n\n\n\n\n\n\ntraefik.frontend.headers.forceSTSHeader=false\n\n\nAdds the STS  header to non-SSL requests.\n\n\n\n\n\n\ntraefik.frontend.headers.frameDeny=false\n\n\nAdds the \nX-Frame-Options\n header with the value of \nDENY\n.\n\n\n\n\n\n\ntraefik.frontend.headers.customFrameOptionsValue=VALUE\n\n\nOverrides the \nX-Frame-Options\n header with the custom value.\n\n\n\n\n\n\ntraefik.frontend.headers.contentTypeNosniff=true\n\n\nAdds the \nX-Content-Type-Options\n header with the value \nnosniff\n.\n\n\n\n\n\n\ntraefik.frontend.headers.browserXSSFilter=true\n\n\nAdds the X-XSS-Protection header with the value \n1; mode=block\n.\n\n\n\n\n\n\ntraefik.frontend.headers.contentSecurityPolicy=VALUE\n\n\nAdds CSP Header with the custom value.\n\n\n\n\n\n\ntraefik.frontend.headers.publicKey=VALUE\n\n\nAdds pinned HTST public key header.\n\n\n\n\n\n\ntraefik.frontend.headers.referrerPolicy=VALUE\n\n\nAdds referrer policy  header.\n\n\n\n\n\n\ntraefik.frontend.headers.isDevelopment=false\n\n\nThis will cause the \nAllowedHosts\n, \nSSLRedirect\n, and \nSTSSeconds\n/\nSTSIncludeSubdomains\n options to be ignored during development.\nWhen deploying to production, be sure to set this to false.\n\n\n\n\n\n\n\n\nOn Service\n\n\nServices labels can be used for overriding default behaviour\n\n\n\n\n\n\n\n\nLabel\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntraefik.\nservice-name\n.port=PORT\n\n\nOverrides \ntraefik.port\n. If several ports need to be exposed, the service labels could be used.\n\n\n\n\n\n\ntraefik.\nservice-name\n.protocol\n\n\nOverrides \ntraefik.protocol\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.weight\n\n\nAssign this service weight. Overrides \ntraefik.weight\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.backend=BACKEND\n\n\nAssign this service frontend to \nBACKEND\n. Default is to assign to the service backend.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.entryPoints\n\n\nOverrides \ntraefik.frontend.entrypoints\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.auth.basic\n\n\nSets a Basic Auth for that frontend\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.passHostHeader\n\n\nOverrides \ntraefik.frontend.passHostHeader\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.priority\n\n\nOverrides \ntraefik.frontend.priority\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.rule\n\n\nOverrides \ntraefik.frontend.rule\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.redirect\n\n\nOverrides \ntraefik.frontend.redirect\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.redirect.entryPoint=https\n\n\nOverrides \ntraefik.frontend.redirect.entryPoint\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.redirect.regex=^http://localhost/(.*)\n\n\nOverrides \ntraefik.frontend.redirect.regex\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.redirect.replacement=http://mydomain/$1\n\n\nOverrides \ntraefik.frontend.redirect.replacement\n.\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nIf a label is defined both as a \ncontainer label\n and a \nservice label\n (for example \ntraefik.\nservice-name\n.port=PORT\n and \ntraefik.port=PORT\n ), the \nservice label\n is used to defined the \nservice-name\n property (\nport\n in the example).\n\n\nIt's possible to mix \ncontainer labels\n and \nservice labels\n, in this case \ncontainer labels\n are used as default value for missing \nservice labels\n but no frontends are going to be created with the \ncontainer labels\n.\n\n\nMore details in this \nexample\n.\n\n\n\n\n\n\nWarning\n\n\nWhen running inside a container, Tr\u00e6fik will need network access through:\n\n\ndocker network connect \nnetwork\n \ntraefik-container", 
            "title": "Backend: Docker"
        }, 
        {
            "location": "/configuration/backends/docker/#docker-backend", 
            "text": "Tr\u00e6fik can be configured to use Docker as a backend configuration.", 
            "title": "Docker Backend"
        }, 
        {
            "location": "/configuration/backends/docker/#docker", 
            "text": "################################################################\n# Docker configuration backend\n################################################################\n\n# Enable Docker configuration backend.\n[docker]\n\n# Docker server endpoint. Can be a tcp or a unix socket endpoint.\n#\n# Required\n#\nendpoint =  unix:///var/run/docker.sock \n\n# Default domain used.\n# Can be overridden by setting the  traefik.domain  label on a container.\n#\n# Required\n#\ndomain =  docker.localhost \n\n# Enable watch docker changes.\n#\n# Optional\n#\nwatch = true\n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename =  docker.tmpl \n\n# Expose containers by default in Traefik.\n# If set to false, containers that don't have `traefik.enable=true` will be ignored.\n#\n# Optional\n# Default: true\n#\nexposedbydefault = true\n\n# Use the IP address from the binded port instead of the inner network one.\n# For specific use-case :)\n#\n# Optional\n# Default: false\n#\nusebindportip = true\n\n# Use Swarm Mode services as data provider.\n#\n# Optional\n# Default: false\n#\nswarmmode = false\n\n# Enable docker TLS connection.\n#\n# Optional\n#\n#  [docker.tls]\n#  ca =  /etc/ssl/ca.crt \n#  cert =  /etc/ssl/docker.crt \n#  key =  /etc/ssl/docker.key \n#  insecureskipverify = true  To enable constraints see  backend-specific constraints section .", 
            "title": "Docker"
        }, 
        {
            "location": "/configuration/backends/docker/#docker-swarm-mode", 
            "text": "################################################################\n# Docker Swarmmode configuration backend\n################################################################\n\n# Enable Docker configuration backend.\n[docker]\n\n# Docker server endpoint.\n# Can be a tcp or a unix socket endpoint.\n#\n# Required\n# Default:  unix:///var/run/docker.sock \n#\nendpoint =  tcp://127.0.0.1:2375 \n\n# Default domain used.\n# Can be overridden by setting the  traefik.domain  label on a services.\n#\n# Optional\n# Default:  \n#\ndomain =  docker.localhost \n\n# Enable watch docker changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Use Docker Swarm Mode as data provider.\n#\n# Optional\n# Default: false\n#\nswarmmode = true\n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename =  docker.tmpl \n\n# Expose services by default in Traefik.\n#\n# Optional\n# Default: true\n#\nexposedbydefault = false\n\n# Enable docker TLS connection.\n#\n# Optional\n#\n#  [docker.tls]\n#  ca =  /etc/ssl/ca.crt \n#  cert =  /etc/ssl/docker.crt \n#  key =  /etc/ssl/docker.key \n#  insecureskipverify = true  To enable constraints see  backend-specific constraints section .", 
            "title": "Docker Swarm Mode"
        }, 
        {
            "location": "/configuration/backends/docker/#labels-overriding-default-behaviour", 
            "text": "", 
            "title": "Labels: overriding default behaviour"
        }, 
        {
            "location": "/configuration/backends/docker/#using-docker-with-swarm-mode", 
            "text": "If you use a compose file with the Swarm mode, labels should be defined in the  deploy  part of your service.\nThis behavior is only enabled for docker-compose version 3+ ( Compose file reference ).  version:  3 \nservices:\n  whoami:\n    deploy:\n      labels:\n        traefik.docker.network: traefik", 
            "title": "Using Docker with Swarm Mode"
        }, 
        {
            "location": "/configuration/backends/docker/#using-docker-compose", 
            "text": "If you are intending to use only Docker Compose commands (e.g.  docker-compose up --scale whoami=2 -d ), labels should be under your service, otherwise they will be ignored.   version:  3 \nservices:\n  whoami:\n    labels:\n      traefik.docker.network: traefik", 
            "title": "Using Docker Compose"
        }, 
        {
            "location": "/configuration/backends/docker/#on-containers", 
            "text": "Labels can be used on containers to override default behaviour.     Label  Description      traefik.backend=foo  Give the name  foo  to the generated backend for this container.    traefik.backend.maxconn.amount=10  Set a maximum number of connections to the backend. Must be used in conjunction with the below label to take effect.    traefik.backend.maxconn.extractorfunc=client.ip  Set the function to be used against the request to determine what to limit maximum connections to the backend by. Must be used in conjunction with the above label to take effect.    traefik.backend.loadbalancer.method=drr  Override the default  wrr  load balancer algorithm    traefik.backend.loadbalancer.stickiness=true  Enable backend sticky sessions    traefik.backend.loadbalancer.stickiness.cookieName=NAME  Manually set the cookie name for sticky sessions    traefik.backend.loadbalancer.sticky=true  Enable backend sticky sessions (DEPRECATED)    traefik.backend.loadbalancer.swarm=true  Use Swarm's inbuilt load balancer (only relevant under Swarm Mode).    traefik.backend.circuitbreaker.expression=EXPR  Create a  circuit breaker  to be used against the backend    traefik.port=80  Register this port. Useful when the container exposes multiples ports.    traefik.protocol=https  Override the default  http  protocol    traefik.weight=10  Assign this weight to the container    traefik.enable=false  Disable this container in Tr\u00e6fik    traefik.frontend.rule=EXPR  Override the default frontend rule. Default:  Host:{containerName}.{domain}  or  Host:{service}.{project_name}.{domain}  if you are using  docker-compose .    traefik.frontend.passHostHeader=true  Forward client  Host  header to the backend.    traefik.frontend.priority=10  Override default frontend priority    traefik.frontend.entryPoints=http,https  Assign this frontend to entry points  http  and  https . Overrides  defaultEntryPoints    traefik.frontend.auth.basic=EXPR  Sets basic authentication for that frontend in CSV format:  User:Hash,User:Hash    traefik.frontend.whitelistSourceRange:RANGE  List of IP-Ranges which are allowed to access. An unset or empty list allows all Source-IPs to access. If one of the Net-Specifications are invalid, the whole list is invalid and allows all Source-IPs to access.    traefik.docker.network  Set the docker network to use for connections to this container. [1]    traefik.frontend.redirect.entryPoint=https  Enables Redirect to another entryPoint for that frontend (e.g. HTTPS)    traefik.frontend.redirect.regex=^http://localhost/(.*)  Redirect to another URL for that frontend. Must be set with  traefik.frontend.redirect.replacement .    traefik.frontend.redirect.replacement=http://mydomain/$1  Redirect to another URL for that frontend. Must be set with  traefik.frontend.redirect.regex .     [1]  traefik.docker.network :\nIf a container is linked to several networks, be sure to set the proper network name (you can check with  docker inspect  container_id ) otherwise it will randomly pick one (depending on how docker is returning them).\nFor instance when deploying docker  stack  from compose files, the compose defined networks will be prefixed with the  stack  name.\nOr if your service references external network use it's name instead.", 
            "title": "On Containers"
        }, 
        {
            "location": "/configuration/backends/docker/#security-headers", 
            "text": "Label  Description      traefik.frontend.headers.allowedHosts=EXPR  Provides a list of allowed hosts that requests will be processed. Format:  Host1,Host2    traefik.frontend.headers.customRequestHeaders=EXPR  Provides the container with custom request headers that will be appended to each request forwarded to the container. Format:  HEADER:value HEADER2:value2    traefik.frontend.headers.customResponseHeaders=EXPR  Appends the headers to each response returned by the container, before forwarding the response to the client. Format:  HEADER:value HEADER2:value2    traefik.frontend.headers.hostsProxyHeaders=EXPR  Provides a list of headers that the proxied hostname may be stored. Format:   HEADER1,HEADER2    traefik.frontend.headers.SSLRedirect=true  Forces the frontend to redirect to SSL if a non-SSL request is sent.    traefik.frontend.headers.SSLTemporaryRedirect=true  Forces the frontend to redirect to SSL if a non-SSL request is sent, but by sending a 302 instead of a 301.    traefik.frontend.headers.SSLHost=HOST  This setting configures the hostname that redirects will be based on. Default is \"\", which is the same host as the request.    traefik.frontend.headers.SSLProxyHeaders=EXPR  Header combinations that would signify a proper SSL Request (Such as  X-Forwarded-For:https ). Format:   HEADER:value HEADER2:value2    traefik.frontend.headers.STSSeconds=315360000  Sets the max-age of the STS header.    traefik.frontend.headers.STSIncludeSubdomains=true  Adds the  IncludeSubdomains  section of the STS  header.    traefik.frontend.headers.STSPreload=true  Adds the preload flag to the STS  header.    traefik.frontend.headers.forceSTSHeader=false  Adds the STS  header to non-SSL requests.    traefik.frontend.headers.frameDeny=false  Adds the  X-Frame-Options  header with the value of  DENY .    traefik.frontend.headers.customFrameOptionsValue=VALUE  Overrides the  X-Frame-Options  header with the custom value.    traefik.frontend.headers.contentTypeNosniff=true  Adds the  X-Content-Type-Options  header with the value  nosniff .    traefik.frontend.headers.browserXSSFilter=true  Adds the X-XSS-Protection header with the value  1; mode=block .    traefik.frontend.headers.contentSecurityPolicy=VALUE  Adds CSP Header with the custom value.    traefik.frontend.headers.publicKey=VALUE  Adds pinned HTST public key header.    traefik.frontend.headers.referrerPolicy=VALUE  Adds referrer policy  header.    traefik.frontend.headers.isDevelopment=false  This will cause the  AllowedHosts ,  SSLRedirect , and  STSSeconds / STSIncludeSubdomains  options to be ignored during development. When deploying to production, be sure to set this to false.", 
            "title": "Security Headers"
        }, 
        {
            "location": "/configuration/backends/docker/#on-service", 
            "text": "Services labels can be used for overriding default behaviour     Label  Description      traefik. service-name .port=PORT  Overrides  traefik.port . If several ports need to be exposed, the service labels could be used.    traefik. service-name .protocol  Overrides  traefik.protocol .    traefik. service-name .weight  Assign this service weight. Overrides  traefik.weight .    traefik. service-name .frontend.backend=BACKEND  Assign this service frontend to  BACKEND . Default is to assign to the service backend.    traefik. service-name .frontend.entryPoints  Overrides  traefik.frontend.entrypoints    traefik. service-name .frontend.auth.basic  Sets a Basic Auth for that frontend    traefik. service-name .frontend.passHostHeader  Overrides  traefik.frontend.passHostHeader .    traefik. service-name .frontend.priority  Overrides  traefik.frontend.priority .    traefik. service-name .frontend.rule  Overrides  traefik.frontend.rule .    traefik. service-name .frontend.redirect  Overrides  traefik.frontend.redirect .    traefik. service-name .frontend.redirect.entryPoint=https  Overrides  traefik.frontend.redirect.entryPoint .    traefik. service-name .frontend.redirect.regex=^http://localhost/(.*)  Overrides  traefik.frontend.redirect.regex .    traefik. service-name .frontend.redirect.replacement=http://mydomain/$1  Overrides  traefik.frontend.redirect.replacement .      Note  If a label is defined both as a  container label  and a  service label  (for example  traefik. service-name .port=PORT  and  traefik.port=PORT  ), the  service label  is used to defined the  service-name  property ( port  in the example).  It's possible to mix  container labels  and  service labels , in this case  container labels  are used as default value for missing  service labels  but no frontends are going to be created with the  container labels .  More details in this  example .    Warning  When running inside a container, Tr\u00e6fik will need network access through:  docker network connect  network   traefik-container", 
            "title": "On Service"
        }, 
        {
            "location": "/configuration/backends/dynamodb/", 
            "text": "DynamoDB Backend\n\n\nTr\u00e6fik can be configured to use Amazon DynamoDB as a backend configuration.\n\n\nConfiguration\n\n\n################################################################\n# DynamoDB configuration backend\n################################################################\n\n# Enable DynamoDB configuration backend.\n[dynamodb]\n\n# Region to use when connecting to AWS.\n#\n# Required\n#\nregion = \nus-west-1\n\n\n# DyanmoDB Table Name.\n#\n# Optional\n# Default: \ntraefik\n\n#\ntableName = \ntraefik\n\n\n# Enable watch DynamoDB changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Polling interval (in seconds).\n#\n# Optional\n# Default: 15\n#\nrefreshSeconds = 15\n\n# AccessKeyID to use when connecting to AWS.\n#\n# Optional\n#\naccessKeyID = \nabc\n\n\n# SecretAccessKey to use when connecting to AWS.\n#\n# Optional\n#\nsecretAccessKey = \n123\n\n\n# Endpoint of local dynamodb instance for testing?\n#\n# Optional\n#\nendpoint = \nhttp://localhost:8080\n\n\n\n\n\nTable Items\n\n\nItems in the \ndynamodb\n table must have three attributes:\n\n\n\n\nid\n (string): The id is the primary key.\n\n\nname\n(string): The name is used as the name of the frontend or backend.\n\n\nfrontend\n or \nbackend\n (map): This attribute's structure matches exactly the structure of a Frontend or Backend type in Traefik.\n\n    See \ntypes/types.go\n for details.\n\n    The presence or absence of this attribute determines its type.\n    So an item should never have both a \nfrontend\n and a \nbackend\n attribute.", 
            "title": "Backend: DynamoDB"
        }, 
        {
            "location": "/configuration/backends/dynamodb/#dynamodb-backend", 
            "text": "Tr\u00e6fik can be configured to use Amazon DynamoDB as a backend configuration.", 
            "title": "DynamoDB Backend"
        }, 
        {
            "location": "/configuration/backends/dynamodb/#configuration", 
            "text": "################################################################\n# DynamoDB configuration backend\n################################################################\n\n# Enable DynamoDB configuration backend.\n[dynamodb]\n\n# Region to use when connecting to AWS.\n#\n# Required\n#\nregion =  us-west-1 \n\n# DyanmoDB Table Name.\n#\n# Optional\n# Default:  traefik \n#\ntableName =  traefik \n\n# Enable watch DynamoDB changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Polling interval (in seconds).\n#\n# Optional\n# Default: 15\n#\nrefreshSeconds = 15\n\n# AccessKeyID to use when connecting to AWS.\n#\n# Optional\n#\naccessKeyID =  abc \n\n# SecretAccessKey to use when connecting to AWS.\n#\n# Optional\n#\nsecretAccessKey =  123 \n\n# Endpoint of local dynamodb instance for testing?\n#\n# Optional\n#\nendpoint =  http://localhost:8080", 
            "title": "Configuration"
        }, 
        {
            "location": "/configuration/backends/dynamodb/#table-items", 
            "text": "Items in the  dynamodb  table must have three attributes:   id  (string): The id is the primary key.  name (string): The name is used as the name of the frontend or backend.  frontend  or  backend  (map): This attribute's structure matches exactly the structure of a Frontend or Backend type in Traefik. \n    See  types/types.go  for details. \n    The presence or absence of this attribute determines its type.\n    So an item should never have both a  frontend  and a  backend  attribute.", 
            "title": "Table Items"
        }, 
        {
            "location": "/configuration/backends/ecs/", 
            "text": "ECS Backend\n\n\nTr\u00e6fik can be configured to use Amazon ECS as a backend configuration.\n\n\nConfiguration\n\n\n################################################################\n# ECS configuration backend\n################################################################\n\n# Enable ECS configuration backend.\n[ecs]\n\n# ECS Cluster Name.\n#\n# DEPRECATED - Please use `clusters`.\n#\ncluster = \ndefault\n\n\n# ECS Clusters Name.\n#\n# Optional\n# Default: [\ndefault\n]\n#\nclusters = [\ndefault\n]\n\n# Enable watch ECS changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Default domain used.\n#\n# Optional\n# Default: \n\n#\ndomain = \necs.localhost\n\n\n# Enable auto discover ECS clusters.\n#\n# Optional\n# Default: false\n#\nautoDiscoverClusters = false\n\n# Polling interval (in seconds).\n#\n# Optional\n# Default: 15\n#\nrefreshSeconds = 15\n\n# Expose ECS services by default in Traefik.\n#\n# Optional\n# Default: true\n#\nexposedByDefault = false\n\n# Region to use when connecting to AWS.\n#\n# Optional\n#\nregion = \nus-east-1\n\n\n# AccessKeyID to use when connecting to AWS.\n#\n# Optional\n#\naccessKeyID = \nabc\n\n\n# SecretAccessKey to use when connecting to AWS.\n#\n# Optional\n#\nsecretAccessKey = \n123\n\n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename = \necs.tmpl\n\n\n\n\n\nIf \nAccessKeyID\n/\nSecretAccessKey\n is not given credentials will be resolved in the following order:\n\n\n\n\nFrom environment variables; \nAWS_ACCESS_KEY_ID\n, \nAWS_SECRET_ACCESS_KEY\n, and \nAWS_SESSION_TOKEN\n.\n\n\nShared credentials, determined by \nAWS_PROFILE\n and \nAWS_SHARED_CREDENTIALS_FILE\n, defaults to \ndefault\n and \n~/.aws/credentials\n.\n\n\nEC2 instance role or ECS task role\n\n\n\n\nPolicy\n\n\nTr\u00e6fik needs the following policy to read ECS information:\n\n\n{\n    \nVersion\n: \n2012-10-17\n,\n    \nStatement\n: [\n        {\n            \nSid\n: \nTraefikECSReadAccess\n,\n            \nEffect\n: \nAllow\n,\n            \nAction\n: [\n                \necs:ListClusters\n,\n                \necs:DescribeClusters\n,\n                \necs:ListTasks\n,\n                \necs:DescribeTasks\n,\n                \necs:DescribeContainerInstances\n,\n                \necs:DescribeTaskDefinition\n,\n                \nec2:DescribeInstances\n\n            ],\n            \nResource\n: [\n                \n*\n\n            ]\n        }\n    ]\n}\n\n\n\n\nLabels: overriding default behaviour\n\n\nLabels can be used on task containers to override default behaviour:\n\n\n\n\n\n\n\n\nLabel\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntraefik.protocol=https\n\n\noverride the default \nhttp\n protocol\n\n\n\n\n\n\ntraefik.weight=10\n\n\nassign this weight to the container\n\n\n\n\n\n\ntraefik.enable=false\n\n\ndisable this container in Tr\u00e6fik\n\n\n\n\n\n\ntraefik.port=80\n\n\noverride the default \nport\n value. Overrides \nNetworkBindings\n from Docker Container\n\n\n\n\n\n\ntraefik.backend.loadbalancer.method=drr\n\n\noverride the default \nwrr\n load balancer algorithm\n\n\n\n\n\n\ntraefik.backend.loadbalancer.stickiness=true\n\n\nenable backend sticky sessions\n\n\n\n\n\n\ntraefik.backend.loadbalancer.stickiness.cookieName=NAME\n\n\nManually set the cookie name for sticky sessions\n\n\n\n\n\n\ntraefik.backend.loadbalancer.sticky=true\n\n\nenable backend sticky sessions (DEPRECATED)\n\n\n\n\n\n\ntraefik.backend.healthcheck.path=/health\n\n\nenable health checks for the backend, hitting the container at \npath\n\n\n\n\n\n\ntraefik.backend.healthcheck.interval=1s\n\n\nconfigure the health check interval\n\n\n\n\n\n\ntraefik.frontend.rule=Host:test.traefik.io\n\n\noverride the default frontend rule (Default: \nHost:{containerName}.{domain}\n).\n\n\n\n\n\n\ntraefik.frontend.passHostHeader=true\n\n\nforward client \nHost\n header to the backend.\n\n\n\n\n\n\ntraefik.frontend.priority=10\n\n\noverride default frontend priority\n\n\n\n\n\n\ntraefik.frontend.entryPoints=http,https\n\n\nassign this frontend to entry points \nhttp\n and \nhttps\n. Overrides \ndefaultEntryPoints\n.\n\n\n\n\n\n\ntraefik.frontend.auth.basic=EXPR\n\n\nSets basic authentication for that frontend in CSV format: \nUser:Hash,User:Hash", 
            "title": "Backend: ECS"
        }, 
        {
            "location": "/configuration/backends/ecs/#ecs-backend", 
            "text": "Tr\u00e6fik can be configured to use Amazon ECS as a backend configuration.", 
            "title": "ECS Backend"
        }, 
        {
            "location": "/configuration/backends/ecs/#configuration", 
            "text": "################################################################\n# ECS configuration backend\n################################################################\n\n# Enable ECS configuration backend.\n[ecs]\n\n# ECS Cluster Name.\n#\n# DEPRECATED - Please use `clusters`.\n#\ncluster =  default \n\n# ECS Clusters Name.\n#\n# Optional\n# Default: [ default ]\n#\nclusters = [ default ]\n\n# Enable watch ECS changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Default domain used.\n#\n# Optional\n# Default:  \n#\ndomain =  ecs.localhost \n\n# Enable auto discover ECS clusters.\n#\n# Optional\n# Default: false\n#\nautoDiscoverClusters = false\n\n# Polling interval (in seconds).\n#\n# Optional\n# Default: 15\n#\nrefreshSeconds = 15\n\n# Expose ECS services by default in Traefik.\n#\n# Optional\n# Default: true\n#\nexposedByDefault = false\n\n# Region to use when connecting to AWS.\n#\n# Optional\n#\nregion =  us-east-1 \n\n# AccessKeyID to use when connecting to AWS.\n#\n# Optional\n#\naccessKeyID =  abc \n\n# SecretAccessKey to use when connecting to AWS.\n#\n# Optional\n#\nsecretAccessKey =  123 \n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename =  ecs.tmpl   If  AccessKeyID / SecretAccessKey  is not given credentials will be resolved in the following order:   From environment variables;  AWS_ACCESS_KEY_ID ,  AWS_SECRET_ACCESS_KEY , and  AWS_SESSION_TOKEN .  Shared credentials, determined by  AWS_PROFILE  and  AWS_SHARED_CREDENTIALS_FILE , defaults to  default  and  ~/.aws/credentials .  EC2 instance role or ECS task role", 
            "title": "Configuration"
        }, 
        {
            "location": "/configuration/backends/ecs/#policy", 
            "text": "Tr\u00e6fik needs the following policy to read ECS information:  {\n     Version :  2012-10-17 ,\n     Statement : [\n        {\n             Sid :  TraefikECSReadAccess ,\n             Effect :  Allow ,\n             Action : [\n                 ecs:ListClusters ,\n                 ecs:DescribeClusters ,\n                 ecs:ListTasks ,\n                 ecs:DescribeTasks ,\n                 ecs:DescribeContainerInstances ,\n                 ecs:DescribeTaskDefinition ,\n                 ec2:DescribeInstances \n            ],\n             Resource : [\n                 * \n            ]\n        }\n    ]\n}", 
            "title": "Policy"
        }, 
        {
            "location": "/configuration/backends/ecs/#labels-overriding-default-behaviour", 
            "text": "Labels can be used on task containers to override default behaviour:     Label  Description      traefik.protocol=https  override the default  http  protocol    traefik.weight=10  assign this weight to the container    traefik.enable=false  disable this container in Tr\u00e6fik    traefik.port=80  override the default  port  value. Overrides  NetworkBindings  from Docker Container    traefik.backend.loadbalancer.method=drr  override the default  wrr  load balancer algorithm    traefik.backend.loadbalancer.stickiness=true  enable backend sticky sessions    traefik.backend.loadbalancer.stickiness.cookieName=NAME  Manually set the cookie name for sticky sessions    traefik.backend.loadbalancer.sticky=true  enable backend sticky sessions (DEPRECATED)    traefik.backend.healthcheck.path=/health  enable health checks for the backend, hitting the container at  path    traefik.backend.healthcheck.interval=1s  configure the health check interval    traefik.frontend.rule=Host:test.traefik.io  override the default frontend rule (Default:  Host:{containerName}.{domain} ).    traefik.frontend.passHostHeader=true  forward client  Host  header to the backend.    traefik.frontend.priority=10  override default frontend priority    traefik.frontend.entryPoints=http,https  assign this frontend to entry points  http  and  https . Overrides  defaultEntryPoints .    traefik.frontend.auth.basic=EXPR  Sets basic authentication for that frontend in CSV format:  User:Hash,User:Hash", 
            "title": "Labels: overriding default behaviour"
        }, 
        {
            "location": "/configuration/backends/etcd/", 
            "text": "Etcd Backend\n\n\nTr\u00e6fik can be configured to use Etcd as a backend configuration.\n\n\n################################################################\n# Etcd configuration backend\n################################################################\n\n# Enable Etcd configuration backend.\n[etcd]\n\n# Etcd server endpoint.\n#\n# Required\n# Default: \n127.0.0.1:2379\n\n#\nendpoint = \n127.0.0.1:2379\n\n\n# Enable watch Etcd changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n# Default: \n/traefik\n\n#\nprefix = \n/traefik\n\n\n# Force to use API V3 (otherwise still use API V2)\n#\n# Deprecated\n#\n# Optional\n# Default: false\n#\nuseAPIV3 = true\n\n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename = \netcd.tmpl\n\n\n# Use etcd user/pass authentication.\n#\n# Optional\n#\n# username = foo\n# password = bar\n\n# Enable etcd TLS connection.\n#\n# Optional\n#\n#    [etcd.tls]\n#    ca = \n/etc/ssl/ca.crt\n\n#    cert = \n/etc/ssl/etcd.crt\n\n#    key = \n/etc/ssl/etcd.key\n\n#    insecureskipverify = true\n\n\n\n\nTo enable constraints see \nbackend-specific constraints section\n.\n\n\nPlease refer to the \nKey Value storage structure\n section to get documentation on Traefik KV structure.\n\n\n\n\nNote\n\n\nThe option \nuseAPIV3\n allows using Etcd API V3 only if it's set to true.\nThis option is \ndeprecated\n and API V2 won't be supported in the future.", 
            "title": "Backend: Etcd"
        }, 
        {
            "location": "/configuration/backends/etcd/#etcd-backend", 
            "text": "Tr\u00e6fik can be configured to use Etcd as a backend configuration.  ################################################################\n# Etcd configuration backend\n################################################################\n\n# Enable Etcd configuration backend.\n[etcd]\n\n# Etcd server endpoint.\n#\n# Required\n# Default:  127.0.0.1:2379 \n#\nendpoint =  127.0.0.1:2379 \n\n# Enable watch Etcd changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n# Default:  /traefik \n#\nprefix =  /traefik \n\n# Force to use API V3 (otherwise still use API V2)\n#\n# Deprecated\n#\n# Optional\n# Default: false\n#\nuseAPIV3 = true\n\n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename =  etcd.tmpl \n\n# Use etcd user/pass authentication.\n#\n# Optional\n#\n# username = foo\n# password = bar\n\n# Enable etcd TLS connection.\n#\n# Optional\n#\n#    [etcd.tls]\n#    ca =  /etc/ssl/ca.crt \n#    cert =  /etc/ssl/etcd.crt \n#    key =  /etc/ssl/etcd.key \n#    insecureskipverify = true  To enable constraints see  backend-specific constraints section .  Please refer to the  Key Value storage structure  section to get documentation on Traefik KV structure.   Note  The option  useAPIV3  allows using Etcd API V3 only if it's set to true.\nThis option is  deprecated  and API V2 won't be supported in the future.", 
            "title": "Etcd Backend"
        }, 
        {
            "location": "/configuration/backends/eureka/", 
            "text": "Eureka Backend\n\n\nTr\u00e6fik can be configured to use Eureka as a backend configuration.\n\n\n################################################################\n# Eureka configuration backend\n################################################################\n\n# Enable Eureka configuration backend.\n[eureka]\n\n# Eureka server endpoint.\n#\n# Required\n#\nendpoint = \nhttp://my.eureka.server/eureka\n\n\n# Override default configuration time between refresh.\n#\n# Optional\n# Default: 30s\n#\ndelay = \n1m\n\n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename = \neureka.tmpl", 
            "title": "Backend: Eureka"
        }, 
        {
            "location": "/configuration/backends/eureka/#eureka-backend", 
            "text": "Tr\u00e6fik can be configured to use Eureka as a backend configuration.  ################################################################\n# Eureka configuration backend\n################################################################\n\n# Enable Eureka configuration backend.\n[eureka]\n\n# Eureka server endpoint.\n#\n# Required\n#\nendpoint =  http://my.eureka.server/eureka \n\n# Override default configuration time between refresh.\n#\n# Optional\n# Default: 30s\n#\ndelay =  1m \n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename =  eureka.tmpl", 
            "title": "Eureka Backend"
        }, 
        {
            "location": "/configuration/backends/file/", 
            "text": "File Backends\n\n\nTr\u00e6fik can be configured with a file.\n\n\nReference\n\n\n[file]\n\n# Backends\n[backends]\n\n  [backends.backend1]\n\n    [backends.backend1.servers]\n      [backends.backend1.servers.server0]\n        url = \nhttp://10.10.10.1:80\n\n        weight = 1\n      [backends.backend1.servers.server1]\n        url = \nhttp://10.10.10.2:80\n\n        weight = 2\n      # ...\n\n    [backends.backend1.circuitBreaker]\n      expression = \nNetworkErrorRatio() \n 0.5\n\n\n    [backends.backend1.loadBalancer]\n      method = \ndrr\n\n      [backends.backend1.loadBalancer.stickiness]\n        cookieName = \nfoobar\n\n\n    [backends.backend1.maxConn]\n      amount = 10\n      extractorfunc = \nrequest.host\n\n\n    [backends.backend1.healthCheck]\n      path = \n/health\n\n      port = 88\n      interval = \n30s\n\n\n  [backends.backend2]\n    # ...\n\n# Frontends\n[frontends]\n\n  [frontends.frontend1]\n    entryPoints = [\nhttp\n, \nhttps\n]\n    backend = \nbackend1\n\n    passHostHeader = true\n    passTLSCert = true\n    priority = 42\n    basicAuth = [\n      \ntest:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/\n,\n      \ntest2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0\n,\n    ]\n    whitelistSourceRange = [\n10.42.0.0/16\n, \n152.89.1.33/32\n, \nafed:be44::/16\n]\n\n    [frontends.frontend1.routes]\n      [frontends.frontend1.routes.route0]\n        rule = \nHost:test.localhost\n\n      [frontends.frontend1.routes.Route1]\n        rule = \nMethod:GET\n\n      # ...\n\n    [frontends.frontend1.headers]\n      allowedHosts = [\nfoobar\n, \nfoobar\n]\n      hostsProxyHeaders = [\nfoobar\n, \nfoobar\n]\n      SSLRedirect = true\n      SSLTemporaryRedirect = true\n      SSLHost = \nfoobar\n\n      STSSeconds = 42\n      STSIncludeSubdomains = true\n      STSPreload = true\n      forceSTSHeader = true\n      frameDeny = true\n      customFrameOptionsValue = \nfoobar\n\n      contentTypeNosniff = true\n      browserXSSFilter = true\n      contentSecurityPolicy = \nfoobar\n\n      publicKey = \nfoobar\n\n      referrerPolicy = \nfoobar\n\n      isDevelopment = true\n      [frontends.frontend1.headers.customRequestHeaders]\n        X-Foo-Bar-01 = \nfoobar\n\n        X-Foo-Bar-02 = \nfoobar\n\n        # ...\n      [frontends.frontend1.headers.customResponseHeaders]\n        X-Foo-Bar-03 = \nfoobar\n\n        X-Foo-Bar-04 = \nfoobar\n\n        # ...\n      [frontends.frontend1.headers.SSLProxyHeaders]\n        X-Foo-Bar-05 = \nfoobar\n\n        X-Foo-Bar-06 = \nfoobar\n\n        # ...\n\n    [frontends.frontend1.errors]\n      [frontends.frontend1.errors.errorPage0]\n        status = [\n500-599\n]\n        backend = \nerror\n\n        query = \n/{status}.html\n\n      [frontends.frontend1.errors.errorPage1]\n        status = [\n404\n, \n403\n]\n        backend = \nerror\n\n        query = \n/{status}.html\n\n      # ...\n\n    [frontends.frontend1.ratelimit]\n      extractorfunc = \nclient.ip\n\n        [frontends.frontend1.ratelimit.rateset.rateset1]\n          period = \n10s\n\n          average = 100\n          burst = 200\n        [frontends.frontend1.ratelimit.rateset.rateset2]\n          period = \n3s\n\n          average = 5\n          burst = 10\n        # ...\n\n    [frontends.frontend1.redirect]\n      entryPoint = \nhttps\n\n      regex = \n^http://localhost/(.*)\n\n      replacement = \nhttp://mydomain/$1\n\n\n  [frontends.frontend2]\n    # ...\n\n# HTTPS certificates\n[[tls]]\n  entryPoints = [\nhttps\n]\n  [tls.certificate]\n    certFile = \npath/to/my.cert\n\n    keyFile = \npath/to/my.key\n\n\n[[tls]]\n  # ...\n\n\n\n\nConfiguration mode\n\n\nYou have three choices:\n\n\n\n\nSimple\n\n\nRules in a Separate File\n\n\nMultiple \n.toml\n Files\n\n\n\n\nTo enable the file backend, you must either pass the \n--file\n option to the Tr\u00e6fik binary or put the \n[file]\n section (with or without inner settings) in the configuration file.\n\n\nThe configuration file allows managing both backends/frontends and HTTPS certificates (which are not \nLet's Encrypt\n certificates generated through Tr\u00e6fik).\n\n\nSimple\n\n\nAdd your configuration at the end of the global configuration file \ntraefik.toml\n:\n\n\ndefaultEntryPoints = [\nhttp\n, \nhttps\n]\n\n[entryPoints]\n  [entryPoints.http]\n    # ...\n  [entryPoints.https]\n    # ...\n\n[file]\n\n# rules\n[backends]\n  [backends.backend1]\n    # ...\n  [backends.backend2]\n    # ...\n\n[frontends]\n  [frontends.frontend1]\n  # ...\n  [frontends.frontend2]\n  # ...\n  [frontends.frontend3]\n  # ...\n\n# HTTPS certificate\n[[tls]]\n  # ...\n\n[[tls]]\n  # ...\n\n\n\n\n\n\nNote\n\n\nadding certificates directly to the entrypoint is still maintained but certificates declared in this way cannot be managed dynamically.\nIt's recommended to use the file provider to declare certificates.\n\n\n\n\nRules in a Separate File\n\n\nPut your rules in a separate file, for example \nrules.toml\n:\n\n\n# traefik.toml\ndefaultEntryPoints = [\nhttp\n, \nhttps\n]\n\n[entryPoints]\n  [entryPoints.http]\n    # ...\n  [entryPoints.https]\n    # ...\n\n[file]\n  filename = \nrules.toml\n\n\n\n\n\n# rules.toml\n[backends]\n  [backends.backend1]\n    # ...\n  [backends.backend2]\n    # ...\n\n[frontends]\n  [frontends.frontend1]\n  # ...\n  [frontends.frontend2]\n  # ...\n  [frontends.frontend3]\n  # ...\n\n# HTTPS certificate\n[[tls]]\n  # ...\n\n[[tls]]\n  # ...\n\n\n\n\nMultiple \n.toml\n Files\n\n\nYou could have multiple \n.toml\n files in a directory (and recursively in its sub-directories):\n\n\n[file]\n  directory = \n/path/to/config/\n\n\n\n\n\nIf you want Tr\u00e6fik to watch file changes automatically, just add:\n\n\n[file]\n  watch = true", 
            "title": "Backend: File"
        }, 
        {
            "location": "/configuration/backends/file/#file-backends", 
            "text": "Tr\u00e6fik can be configured with a file.", 
            "title": "File Backends"
        }, 
        {
            "location": "/configuration/backends/file/#reference", 
            "text": "[file]\n\n# Backends\n[backends]\n\n  [backends.backend1]\n\n    [backends.backend1.servers]\n      [backends.backend1.servers.server0]\n        url =  http://10.10.10.1:80 \n        weight = 1\n      [backends.backend1.servers.server1]\n        url =  http://10.10.10.2:80 \n        weight = 2\n      # ...\n\n    [backends.backend1.circuitBreaker]\n      expression =  NetworkErrorRatio()   0.5 \n\n    [backends.backend1.loadBalancer]\n      method =  drr \n      [backends.backend1.loadBalancer.stickiness]\n        cookieName =  foobar \n\n    [backends.backend1.maxConn]\n      amount = 10\n      extractorfunc =  request.host \n\n    [backends.backend1.healthCheck]\n      path =  /health \n      port = 88\n      interval =  30s \n\n  [backends.backend2]\n    # ...\n\n# Frontends\n[frontends]\n\n  [frontends.frontend1]\n    entryPoints = [ http ,  https ]\n    backend =  backend1 \n    passHostHeader = true\n    passTLSCert = true\n    priority = 42\n    basicAuth = [\n       test:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/ ,\n       test2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0 ,\n    ]\n    whitelistSourceRange = [ 10.42.0.0/16 ,  152.89.1.33/32 ,  afed:be44::/16 ]\n\n    [frontends.frontend1.routes]\n      [frontends.frontend1.routes.route0]\n        rule =  Host:test.localhost \n      [frontends.frontend1.routes.Route1]\n        rule =  Method:GET \n      # ...\n\n    [frontends.frontend1.headers]\n      allowedHosts = [ foobar ,  foobar ]\n      hostsProxyHeaders = [ foobar ,  foobar ]\n      SSLRedirect = true\n      SSLTemporaryRedirect = true\n      SSLHost =  foobar \n      STSSeconds = 42\n      STSIncludeSubdomains = true\n      STSPreload = true\n      forceSTSHeader = true\n      frameDeny = true\n      customFrameOptionsValue =  foobar \n      contentTypeNosniff = true\n      browserXSSFilter = true\n      contentSecurityPolicy =  foobar \n      publicKey =  foobar \n      referrerPolicy =  foobar \n      isDevelopment = true\n      [frontends.frontend1.headers.customRequestHeaders]\n        X-Foo-Bar-01 =  foobar \n        X-Foo-Bar-02 =  foobar \n        # ...\n      [frontends.frontend1.headers.customResponseHeaders]\n        X-Foo-Bar-03 =  foobar \n        X-Foo-Bar-04 =  foobar \n        # ...\n      [frontends.frontend1.headers.SSLProxyHeaders]\n        X-Foo-Bar-05 =  foobar \n        X-Foo-Bar-06 =  foobar \n        # ...\n\n    [frontends.frontend1.errors]\n      [frontends.frontend1.errors.errorPage0]\n        status = [ 500-599 ]\n        backend =  error \n        query =  /{status}.html \n      [frontends.frontend1.errors.errorPage1]\n        status = [ 404 ,  403 ]\n        backend =  error \n        query =  /{status}.html \n      # ...\n\n    [frontends.frontend1.ratelimit]\n      extractorfunc =  client.ip \n        [frontends.frontend1.ratelimit.rateset.rateset1]\n          period =  10s \n          average = 100\n          burst = 200\n        [frontends.frontend1.ratelimit.rateset.rateset2]\n          period =  3s \n          average = 5\n          burst = 10\n        # ...\n\n    [frontends.frontend1.redirect]\n      entryPoint =  https \n      regex =  ^http://localhost/(.*) \n      replacement =  http://mydomain/$1 \n\n  [frontends.frontend2]\n    # ...\n\n# HTTPS certificates\n[[tls]]\n  entryPoints = [ https ]\n  [tls.certificate]\n    certFile =  path/to/my.cert \n    keyFile =  path/to/my.key \n\n[[tls]]\n  # ...", 
            "title": "Reference"
        }, 
        {
            "location": "/configuration/backends/file/#configuration-mode", 
            "text": "You have three choices:   Simple  Rules in a Separate File  Multiple  .toml  Files   To enable the file backend, you must either pass the  --file  option to the Tr\u00e6fik binary or put the  [file]  section (with or without inner settings) in the configuration file.  The configuration file allows managing both backends/frontends and HTTPS certificates (which are not  Let's Encrypt  certificates generated through Tr\u00e6fik).", 
            "title": "Configuration mode"
        }, 
        {
            "location": "/configuration/backends/file/#simple", 
            "text": "Add your configuration at the end of the global configuration file  traefik.toml :  defaultEntryPoints = [ http ,  https ]\n\n[entryPoints]\n  [entryPoints.http]\n    # ...\n  [entryPoints.https]\n    # ...\n\n[file]\n\n# rules\n[backends]\n  [backends.backend1]\n    # ...\n  [backends.backend2]\n    # ...\n\n[frontends]\n  [frontends.frontend1]\n  # ...\n  [frontends.frontend2]\n  # ...\n  [frontends.frontend3]\n  # ...\n\n# HTTPS certificate\n[[tls]]\n  # ...\n\n[[tls]]\n  # ...   Note  adding certificates directly to the entrypoint is still maintained but certificates declared in this way cannot be managed dynamically.\nIt's recommended to use the file provider to declare certificates.", 
            "title": "Simple"
        }, 
        {
            "location": "/configuration/backends/file/#rules-in-a-separate-file", 
            "text": "Put your rules in a separate file, for example  rules.toml :  # traefik.toml\ndefaultEntryPoints = [ http ,  https ]\n\n[entryPoints]\n  [entryPoints.http]\n    # ...\n  [entryPoints.https]\n    # ...\n\n[file]\n  filename =  rules.toml   # rules.toml\n[backends]\n  [backends.backend1]\n    # ...\n  [backends.backend2]\n    # ...\n\n[frontends]\n  [frontends.frontend1]\n  # ...\n  [frontends.frontend2]\n  # ...\n  [frontends.frontend3]\n  # ...\n\n# HTTPS certificate\n[[tls]]\n  # ...\n\n[[tls]]\n  # ...", 
            "title": "Rules in a Separate File"
        }, 
        {
            "location": "/configuration/backends/file/#multiple-toml-files", 
            "text": "You could have multiple  .toml  files in a directory (and recursively in its sub-directories):  [file]\n  directory =  /path/to/config/   If you want Tr\u00e6fik to watch file changes automatically, just add:  [file]\n  watch = true", 
            "title": "Multiple .toml Files"
        }, 
        {
            "location": "/configuration/backends/kubernetes/", 
            "text": "Kubernetes Ingress Backend\n\n\nTr\u00e6fik can be configured to use Kubernetes Ingress as a backend configuration.\n\n\nSee also \nKubernetes user guide\n.\n\n\nConfiguration\n\n\n################################################################\n# Kubernetes Ingress configuration backend\n################################################################\n\n# Enable Kubernetes Ingress configuration backend.\n[kubernetes]\n\n# Kubernetes server endpoint.\n#\n# Optional for in-cluster configuration, required otherwise.\n# Default: empty\n#\n# endpoint = \nhttp://localhost:8080\n\n\n# Bearer token used for the Kubernetes client configuration.\n#\n# Optional\n# Default: empty\n#\n# token = \nmy token\n\n\n# Path to the certificate authority file.\n# Used for the Kubernetes client configuration.\n#\n# Optional\n# Default: empty\n#\n# certAuthFilePath = \n/my/ca.crt\n\n\n# Array of namespaces to watch.\n#\n# Optional\n# Default: all namespaces (empty array).\n#\n# namespaces = [\ndefault\n, \nproduction\n]\n\n# Ingress label selector to filter Ingress objects that should be processed.\n#\n# Optional\n# Default: empty (process all Ingresses)\n#\n# labelselector = \nA and not B\n\n\n# Disable PassHost Headers.\n#\n# Optional\n# Default: false\n#\n# disablePassHostHeaders = true\n\n# Enable PassTLSCert Headers.\n#\n# Optional\n# Default: false\n#\n# enablePassTLSCert = true\n\n# Override default configuration template.\n#\n# Optional\n# Default: \nbuilt-in template\n\n#\n# filename = \nkubernetes.tmpl\n\n\n\n\n\nendpoint\n\n\nThe Kubernetes server endpoint as URL.\n\n\nWhen deployed into Kubernetes, Traefik will read the environment variables \nKUBERNETES_SERVICE_HOST\n and \nKUBERNETES_SERVICE_PORT\n to construct the endpoint.\n\n\nThe access token will be looked up in \n/var/run/secrets/kubernetes.io/serviceaccount/token\n and the SSL CA certificate in \n/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n.\nBoth are provided mounted automatically when deployed inside Kubernetes.\n\n\nThe endpoint may be specified to override the environment variable values inside a cluster.\n\n\nWhen the environment variables are not found, Traefik will try to connect to the Kubernetes API server with an external-cluster client.\nIn this case, the endpoint is required.\nSpecifically, it may be set to the URL used by \nkubectl proxy\n to connect to a Kubernetes cluster using the granted autentication and authorization of the associated kubeconfig.\n\n\nlabelselector\n\n\nBy default, Traefik processes all Ingress objects in the configured namespaces.\nA label selector can be defined to filter on specific Ingress objects only.\n\n\nSee \nlabel-selectors\n for details.\n\n\nTLS communication between Traefik and backend pods\n\n\nTraefik automatically requests endpoint information based on the service provided in the ingress spec.\nAlthough traefik will connect directly to the endpoints (pods), it still checks the service port to see if TLS communication is required.\nIf the service port defined in the ingress spec is 443, then the backend communication protocol is assumed to be TLS, and will connect via TLS automatically.\n\n\n\n\nNote\n\n\nPlease note that by enabling TLS communication between traefik and your pods, you will have to have trusted certificates that have the proper trust chain and IP subject name. \nIf this is not an option, you may need to skip TLS certificate verification.\nSee the \nInsecureSkipVerify\n setting for more details.\n\n\n\n\nAnnotations\n\n\nGeneral annotations\n\n\nThe following general annotations are applicable on the Ingress object:\n\n\n\n\ntraefik.frontend.rule.type: PathPrefixStrip\n\n    Override the default frontend rule type. Default: \nPathPrefix\n.\n\n\ntraefik.frontend.priority: \"3\"\n\n    Override the default frontend rule priority.\n\n\ntraefik.frontend.redirect.entryPoint: https\n:\n    Enables Redirect to another entryPoint for that frontend (e.g. HTTPS).\n\n\ntraefik.frontend.redirect.regex: ^http://localhost/(.*)\n:\n    Redirect to another URL for that frontend. Must be set with \ntraefik.frontend.redirect.replacement\n.\n\n\ntraefik.frontend.redirect.replacement: http://mydomain/$1\n:\n    Redirect to another URL for that frontend. Must be set with \ntraefik.frontend.redirect.regex\n.\n\n\ntraefik.frontend.entryPoints: http,https\n\n    Override the default frontend endpoints.\n\n\ntraefik.frontend.passTLSCert: true\n\n    Override the default frontend PassTLSCert value. Default: \nfalse\n.\n\n\ningress.kubernetes.io/rewrite-target: /users\n\n    Replaces each matched Ingress path with the specified one, and adds the old path to the \nX-Replaced-Path\n header.\n\n\ningress.kubernetes.io/whitelist-source-range: \"1.2.3.0/24, fe80::/16\"\n\n    A comma-separated list of IP ranges permitted for access. all source IPs are permitted if the list is empty or a single range is ill-formatted.\n\n\n\n\n\n\nNote\n\n\nPlease note that \ntraefik.frontend.redirect.regex\n and \ntraefik.frontend.redirect.replacement\n do not have to be set if \ntraefik.frontend.redirect.entryPoint\n is defined for the redirection (they will not be used in this case).\n\n\n\n\nThe following annotations are applicable on the Service object associated with a particular Ingress object:\n\n\n\n\ntraefik.backend.loadbalancer.method=drr\n\n    Override the default \nwrr\n load balancer algorithm.\n\n\ntraefik.backend.loadbalancer.stickiness=true\n\n    Enable backend sticky sessions.\n\n\ntraefik.backend.loadbalancer.stickiness.cookieName=NAME\n\n    Manually set the cookie name for sticky sessions.\n\n\ntraefik.backend.loadbalancer.sticky=true\n\n    Enable backend sticky sessions (DEPRECATED).\n\n\ntraefik.backend.circuitbreaker: \nexpression\n\n    Set the circuit breaker expression for the backend.\n\n\n\n\nSecurity annotations\n\n\nThe following security annotations are applicable on the Ingress object:\n\n\n\n\n\n\n\n\nAnnotation\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ningress.kubernetes.io/allowed-hosts:EXPR\n\n\nProvides a list of allowed hosts that requests will be processed. Format: \nHost1,Host2\n\n\n\n\n\n\ningress.kubernetes.io/custom-request-headers:EXPR\n\n\nProvides the container with custom request headers that will be appended to each request forwarded to the container. Format: \nHEADER:value\nHEADER2:value2\n\n\n\n\n\n\ningress.kubernetes.io/custom-response-headers:EXPR\n\n\nAppends the headers to each response returned by the container, before forwarding the response to the client. Format: \nHEADER:value\nHEADER2:value2\n\n\n\n\n\n\ningress.kubernetes.io/proxy-headers:EXPR\n\n\nProvides a list of headers that the proxied hostname may be stored. Format:  \nHEADER1,HEADER2\n\n\n\n\n\n\ningress.kubernetes.io/ssl-redirect:true\n\n\nForces the frontend to redirect to SSL if a non-SSL request is sent.\n\n\n\n\n\n\ningress.kubernetes.io/ssl-temporary-redirect:true\n\n\nForces the frontend to redirect to SSL if a non-SSL request is sent, but by sending a 302 instead of a 301.\n\n\n\n\n\n\ningress.kubernetes.io/ssl-host:HOST\n\n\nThis setting configures the hostname that redirects will be based on. Default is \"\", which is the same host as the request.\n\n\n\n\n\n\ningress.kubernetes.io/ssl-proxy-headers:EXPR\n\n\nHeader combinations that would signify a proper SSL Request (Such as \nX-Forwarded-For:https\n). Format: \nHEADER:value\nHEADER2:value2\n\n\n\n\n\n\ningress.kubernetes.io/hsts-max-age:315360000\n\n\nSets the max-age of the HSTS header.\n\n\n\n\n\n\ningress.kubernetes.io/hsts-include-subdomains:true\n\n\nAdds the IncludeSubdomains section of the STS  header.\n\n\n\n\n\n\ningress.kubernetes.io/hsts-preload:true\n\n\nAdds the preload flag to the HSTS  header.\n\n\n\n\n\n\ningress.kubernetes.io/force-hsts:false\n\n\nAdds the STS  header to non-SSL requests.\n\n\n\n\n\n\ningress.kubernetes.io/frame-deny:false\n\n\nAdds the \nX-Frame-Options\n header with the value of \nDENY\n.\n\n\n\n\n\n\ningress.kubernetes.io/custom-frame-options-value:VALUE\n\n\nOverrides the \nX-Frame-Options\n header with the custom value.\n\n\n\n\n\n\ningress.kubernetes.io/content-type-nosniff:true\n\n\nAdds the \nX-Content-Type-Options\n header with the value \nnosniff\n.\n\n\n\n\n\n\ningress.kubernetes.io/browser-xss-filter:true\n\n\nAdds the X-XSS-Protection header with the value \n1; mode=block\n.\n\n\n\n\n\n\ningress.kubernetes.io/content-security-policy:VALUE\n\n\nAdds CSP Header with the custom value.\n\n\n\n\n\n\ningress.kubernetes.io/public-key:VALUE\n\n\nAdds pinned HTST public key header.\n\n\n\n\n\n\ningress.kubernetes.io/referrer-policy:VALUE\n\n\nAdds referrer policy  header.\n\n\n\n\n\n\ningress.kubernetes.io/is-development:false\n\n\nThis will cause the \nAllowedHosts\n, \nSSLRedirect\n, and \nSTSSeconds\n/\nSTSIncludeSubdomains\n options to be ignored during development.\nWhen deploying to production, be sure to set this to false.\n\n\n\n\n\n\n\n\nAuthentication\n\n\nIs possible to add additional authentication annotations to the Ingress object.\nThe source of the authentication is a Secret object that contains the credentials.\n\n\n\n\ningress.kubernetes.io/auth-type\n: \nbasic\n\n    Contains the authentication type. The only permitted type is \nbasic\n.\n\n\ningress.kubernetes.io/auth-secret\n: \nmysecret\n\n    Contains the username and password with access to the paths defined in the Ingress object.\n\n\n\n\nThe secret must be created in the same namespace as the Ingress object.\n\n\nThe following limitations hold:\n\n\n\n\nThe realm is not configurable; the only supported (and default) value is \ntraefik\n.\n\n\nThe Secret must contain a single file only.", 
            "title": "Backend: Kubernetes Ingress"
        }, 
        {
            "location": "/configuration/backends/kubernetes/#kubernetes-ingress-backend", 
            "text": "Tr\u00e6fik can be configured to use Kubernetes Ingress as a backend configuration.  See also  Kubernetes user guide .", 
            "title": "Kubernetes Ingress Backend"
        }, 
        {
            "location": "/configuration/backends/kubernetes/#configuration", 
            "text": "################################################################\n# Kubernetes Ingress configuration backend\n################################################################\n\n# Enable Kubernetes Ingress configuration backend.\n[kubernetes]\n\n# Kubernetes server endpoint.\n#\n# Optional for in-cluster configuration, required otherwise.\n# Default: empty\n#\n# endpoint =  http://localhost:8080 \n\n# Bearer token used for the Kubernetes client configuration.\n#\n# Optional\n# Default: empty\n#\n# token =  my token \n\n# Path to the certificate authority file.\n# Used for the Kubernetes client configuration.\n#\n# Optional\n# Default: empty\n#\n# certAuthFilePath =  /my/ca.crt \n\n# Array of namespaces to watch.\n#\n# Optional\n# Default: all namespaces (empty array).\n#\n# namespaces = [ default ,  production ]\n\n# Ingress label selector to filter Ingress objects that should be processed.\n#\n# Optional\n# Default: empty (process all Ingresses)\n#\n# labelselector =  A and not B \n\n# Disable PassHost Headers.\n#\n# Optional\n# Default: false\n#\n# disablePassHostHeaders = true\n\n# Enable PassTLSCert Headers.\n#\n# Optional\n# Default: false\n#\n# enablePassTLSCert = true\n\n# Override default configuration template.\n#\n# Optional\n# Default:  built-in template \n#\n# filename =  kubernetes.tmpl", 
            "title": "Configuration"
        }, 
        {
            "location": "/configuration/backends/kubernetes/#endpoint", 
            "text": "The Kubernetes server endpoint as URL.  When deployed into Kubernetes, Traefik will read the environment variables  KUBERNETES_SERVICE_HOST  and  KUBERNETES_SERVICE_PORT  to construct the endpoint.  The access token will be looked up in  /var/run/secrets/kubernetes.io/serviceaccount/token  and the SSL CA certificate in  /var/run/secrets/kubernetes.io/serviceaccount/ca.crt .\nBoth are provided mounted automatically when deployed inside Kubernetes.  The endpoint may be specified to override the environment variable values inside a cluster.  When the environment variables are not found, Traefik will try to connect to the Kubernetes API server with an external-cluster client.\nIn this case, the endpoint is required.\nSpecifically, it may be set to the URL used by  kubectl proxy  to connect to a Kubernetes cluster using the granted autentication and authorization of the associated kubeconfig.", 
            "title": "endpoint"
        }, 
        {
            "location": "/configuration/backends/kubernetes/#labelselector", 
            "text": "By default, Traefik processes all Ingress objects in the configured namespaces.\nA label selector can be defined to filter on specific Ingress objects only.  See  label-selectors  for details.", 
            "title": "labelselector"
        }, 
        {
            "location": "/configuration/backends/kubernetes/#tls-communication-between-traefik-and-backend-pods", 
            "text": "Traefik automatically requests endpoint information based on the service provided in the ingress spec.\nAlthough traefik will connect directly to the endpoints (pods), it still checks the service port to see if TLS communication is required.\nIf the service port defined in the ingress spec is 443, then the backend communication protocol is assumed to be TLS, and will connect via TLS automatically.   Note  Please note that by enabling TLS communication between traefik and your pods, you will have to have trusted certificates that have the proper trust chain and IP subject name. \nIf this is not an option, you may need to skip TLS certificate verification.\nSee the  InsecureSkipVerify  setting for more details.", 
            "title": "TLS communication between Traefik and backend pods"
        }, 
        {
            "location": "/configuration/backends/kubernetes/#annotations", 
            "text": "", 
            "title": "Annotations"
        }, 
        {
            "location": "/configuration/backends/kubernetes/#general-annotations", 
            "text": "The following general annotations are applicable on the Ingress object:   traefik.frontend.rule.type: PathPrefixStrip \n    Override the default frontend rule type. Default:  PathPrefix .  traefik.frontend.priority: \"3\" \n    Override the default frontend rule priority.  traefik.frontend.redirect.entryPoint: https :\n    Enables Redirect to another entryPoint for that frontend (e.g. HTTPS).  traefik.frontend.redirect.regex: ^http://localhost/(.*) :\n    Redirect to another URL for that frontend. Must be set with  traefik.frontend.redirect.replacement .  traefik.frontend.redirect.replacement: http://mydomain/$1 :\n    Redirect to another URL for that frontend. Must be set with  traefik.frontend.redirect.regex .  traefik.frontend.entryPoints: http,https \n    Override the default frontend endpoints.  traefik.frontend.passTLSCert: true \n    Override the default frontend PassTLSCert value. Default:  false .  ingress.kubernetes.io/rewrite-target: /users \n    Replaces each matched Ingress path with the specified one, and adds the old path to the  X-Replaced-Path  header.  ingress.kubernetes.io/whitelist-source-range: \"1.2.3.0/24, fe80::/16\" \n    A comma-separated list of IP ranges permitted for access. all source IPs are permitted if the list is empty or a single range is ill-formatted.    Note  Please note that  traefik.frontend.redirect.regex  and  traefik.frontend.redirect.replacement  do not have to be set if  traefik.frontend.redirect.entryPoint  is defined for the redirection (they will not be used in this case).   The following annotations are applicable on the Service object associated with a particular Ingress object:   traefik.backend.loadbalancer.method=drr \n    Override the default  wrr  load balancer algorithm.  traefik.backend.loadbalancer.stickiness=true \n    Enable backend sticky sessions.  traefik.backend.loadbalancer.stickiness.cookieName=NAME \n    Manually set the cookie name for sticky sessions.  traefik.backend.loadbalancer.sticky=true \n    Enable backend sticky sessions (DEPRECATED).  traefik.backend.circuitbreaker:  expression \n    Set the circuit breaker expression for the backend.", 
            "title": "General annotations"
        }, 
        {
            "location": "/configuration/backends/kubernetes/#security-annotations", 
            "text": "The following security annotations are applicable on the Ingress object:     Annotation  Description      ingress.kubernetes.io/allowed-hosts:EXPR  Provides a list of allowed hosts that requests will be processed. Format:  Host1,Host2    ingress.kubernetes.io/custom-request-headers:EXPR  Provides the container with custom request headers that will be appended to each request forwarded to the container. Format:  HEADER:value HEADER2:value2    ingress.kubernetes.io/custom-response-headers:EXPR  Appends the headers to each response returned by the container, before forwarding the response to the client. Format:  HEADER:value HEADER2:value2    ingress.kubernetes.io/proxy-headers:EXPR  Provides a list of headers that the proxied hostname may be stored. Format:   HEADER1,HEADER2    ingress.kubernetes.io/ssl-redirect:true  Forces the frontend to redirect to SSL if a non-SSL request is sent.    ingress.kubernetes.io/ssl-temporary-redirect:true  Forces the frontend to redirect to SSL if a non-SSL request is sent, but by sending a 302 instead of a 301.    ingress.kubernetes.io/ssl-host:HOST  This setting configures the hostname that redirects will be based on. Default is \"\", which is the same host as the request.    ingress.kubernetes.io/ssl-proxy-headers:EXPR  Header combinations that would signify a proper SSL Request (Such as  X-Forwarded-For:https ). Format:  HEADER:value HEADER2:value2    ingress.kubernetes.io/hsts-max-age:315360000  Sets the max-age of the HSTS header.    ingress.kubernetes.io/hsts-include-subdomains:true  Adds the IncludeSubdomains section of the STS  header.    ingress.kubernetes.io/hsts-preload:true  Adds the preload flag to the HSTS  header.    ingress.kubernetes.io/force-hsts:false  Adds the STS  header to non-SSL requests.    ingress.kubernetes.io/frame-deny:false  Adds the  X-Frame-Options  header with the value of  DENY .    ingress.kubernetes.io/custom-frame-options-value:VALUE  Overrides the  X-Frame-Options  header with the custom value.    ingress.kubernetes.io/content-type-nosniff:true  Adds the  X-Content-Type-Options  header with the value  nosniff .    ingress.kubernetes.io/browser-xss-filter:true  Adds the X-XSS-Protection header with the value  1; mode=block .    ingress.kubernetes.io/content-security-policy:VALUE  Adds CSP Header with the custom value.    ingress.kubernetes.io/public-key:VALUE  Adds pinned HTST public key header.    ingress.kubernetes.io/referrer-policy:VALUE  Adds referrer policy  header.    ingress.kubernetes.io/is-development:false  This will cause the  AllowedHosts ,  SSLRedirect , and  STSSeconds / STSIncludeSubdomains  options to be ignored during development. When deploying to production, be sure to set this to false.", 
            "title": "Security annotations"
        }, 
        {
            "location": "/configuration/backends/kubernetes/#authentication", 
            "text": "Is possible to add additional authentication annotations to the Ingress object.\nThe source of the authentication is a Secret object that contains the credentials.   ingress.kubernetes.io/auth-type :  basic \n    Contains the authentication type. The only permitted type is  basic .  ingress.kubernetes.io/auth-secret :  mysecret \n    Contains the username and password with access to the paths defined in the Ingress object.   The secret must be created in the same namespace as the Ingress object.  The following limitations hold:   The realm is not configurable; the only supported (and default) value is  traefik .  The Secret must contain a single file only.", 
            "title": "Authentication"
        }, 
        {
            "location": "/configuration/backends/marathon/", 
            "text": "Marathon Backend\n\n\nTr\u00e6fik can be configured to use Marathon as a backend configuration.\n\n\nSee also \nMarathon user guide\n.\n\n\nConfiguration\n\n\n################################################################\n# Mesos/Marathon configuration backend\n################################################################\n\n# Enable Marathon configuration backend.\n[marathon]\n\n# Marathon server endpoint.\n# You can also specify multiple endpoint for Marathon:\n# endpoint = \nhttp://10.241.1.71:8080,10.241.1.72:8080,10.241.1.73:8080\n\n#\n# Required\n# Default: \nhttp://127.0.0.1:8080\n\n#\nendpoint = \nhttp://127.0.0.1:8080\n\n\n# Enable watch Marathon changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Default domain used.\n# Can be overridden by setting the \ntraefik.domain\n label on an application.\n#\n# Required\n#\ndomain = \nmarathon.localhost\n\n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename = \nmarathon.tmpl\n\n\n# Expose Marathon apps by default in Traefik.\n#\n# Optional\n# Default: true\n#\n# exposedByDefault = false\n\n# Convert Marathon groups to subdomains.\n# Default behavior: /foo/bar/myapp =\n foo-bar-myapp.{defaultDomain}\n# with groupsAsSubDomains enabled: /foo/bar/myapp =\n myapp.bar.foo.{defaultDomain}\n#\n# Optional\n# Default: false\n#\n# groupsAsSubDomains = true\n\n# Enable compatibility with marathon-lb labels.\n#\n# Optional\n# Default: false\n#\n# marathonLBCompatibility = true\n\n# Enable filtering using Marathon constraints..\n# If enabled, Traefik will read Marathon constraints, as defined in https://mesosphere.github.io/marathon/docs/constraints.html\n# Each individual constraint will be treated as a verbatim compounded tag. \n# i.e. \nrack_id:CLUSTER:rack-1\n, with all constraint groups concatenated together using \n:\n\n#\n# Optional\n# Default: false\n#\n# filterMarathonConstraints = true\n\n# Enable Marathon basic authentication.\n#\n# Optional\n#\n#    [marathon.basic]\n#    httpBasicAuthUser = \nfoo\n\n#    httpBasicPassword = \nbar\n\n\n# TLS client configuration. https://golang.org/pkg/crypto/tls/#Config\n#\n# Optional\n#\n#    [marathon.TLS]\n#    CA = \n/etc/ssl/ca.crt\n\n#    Cert = \n/etc/ssl/marathon.cert\n\n#    Key = \n/etc/ssl/marathon.key\n\n#    InsecureSkipVerify = true\n\n# DCOSToken for DCOS environment.\n# This will override the Authorization header.\n#\n# Optional\n#\n# dcosToken = \nxxxxxx\n\n\n# Override DialerTimeout.\n# Amount of time to allow the Marathon provider to wait to open a TCP connection\n# to a Marathon master.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits).\n# If no units are provided, the value is parsed assuming seconds.\n#\n# Optional\n# Default: \n60s\n\n#\n# dialerTimeout = \n60s\n\n\n# Set the TCP Keep Alive interval for the Marathon HTTP Client.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits).\n# If no units are provided, the value is parsed assuming seconds.\n#\n# Optional\n# Default: \n10s\n\n#\n# keepAlive = \n10s\n\n\n# By default, a task's IP address (as returned by the Marathon API) is used as\n# backend server if an IP-per-task configuration can be found; otherwise, the\n# name of the host running the task is used.\n# The latter behavior can be enforced by enabling this switch.\n#\n# Optional\n# Default: false\n#\n# forceTaskHostname = true\n\n# Applications may define readiness checks which are probed by Marathon during\n# deployments periodically and the results exposed via the API.\n# Enabling the following parameter causes Traefik to filter out tasks\n# whose readiness checks have not succeeded.\n# Note that the checks are only valid at deployment times.\n# See the Marathon guide for details.\n#\n# Optional\n# Default: false\n#\n# respectReadinessChecks = true\n\n\n\n\nTo enable constraints see \nbackend-specific constraints section\n.\n\n\nLabels: overriding default behaviour\n\n\nMarathon labels may be used to dynamically change the routing and forwarding behaviour.\n\n\nThey may be specified on one of two levels: Application or service.\n\n\nApplication Level\n\n\nThe following labels can be defined on Marathon applications. They adjust the behaviour for the entire application.\n\n\n\n\n\n\n\n\nLabel\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntraefik.backend=foo\n\n\nassign the application to \nfoo\n backend\n\n\n\n\n\n\ntraefik.backend.maxconn.amount=10\n\n\nset a maximum number of connections to the backend. Must be used in conjunction with the below label to take effect.\n\n\n\n\n\n\ntraefik.backend.maxconn.extractorfunc=client.ip\n\n\nset the function to be used against the request to determine what to limit maximum connections to the backend by. Must be used in conjunction with the above label to take effect.\n\n\n\n\n\n\ntraefik.backend.loadbalancer.method=drr\n\n\noverride the default \nwrr\n load balancer algorithm\n\n\n\n\n\n\ntraefik.backend.loadbalancer.sticky=true\n\n\nenable backend sticky sessions (DEPRECATED)\n\n\n\n\n\n\ntraefik.backend.loadbalancer.stickiness=true\n\n\nenable backend sticky sessions\n\n\n\n\n\n\ntraefik.backend.loadbalancer.stickiness.cookieName=NAME\n\n\nManually set the cookie name for sticky sessions\n\n\n\n\n\n\ntraefik.backend.circuitbreaker.expression=NetworkErrorRatio() \n 0.5\n\n\ncreate a \ncircuit breaker\n to be used against the backend\n\n\n\n\n\n\ntraefik.backend.healthcheck.path=/health\n\n\nset the Traefik health check path [default: no health checks]\n\n\n\n\n\n\ntraefik.backend.healthcheck.interval=5s\n\n\nsets a custom health check interval in Go-parseable (\ntime.ParseDuration\n) format [default: 30s]\n\n\n\n\n\n\ntraefik.portIndex=1\n\n\nregister port by index in the application's ports array. Useful when the application exposes multiple ports.\n\n\n\n\n\n\ntraefik.port=80\n\n\nregister the explicit application port value. Cannot be used alongside \ntraefik.portIndex\n.\n\n\n\n\n\n\ntraefik.protocol=https\n\n\noverride the default \nhttp\n protocol\n\n\n\n\n\n\ntraefik.weight=10\n\n\nassign this weight to the application\n\n\n\n\n\n\ntraefik.enable=false\n\n\ndisable this application in Tr\u00e6fik\n\n\n\n\n\n\ntraefik.frontend.rule=Host:test.traefik.io\n\n\noverride the default frontend rule (Default: \nHost:{containerName}.{domain}\n).\n\n\n\n\n\n\ntraefik.frontend.passHostHeader=true\n\n\nforward client \nHost\n header to the backend.\n\n\n\n\n\n\ntraefik.frontend.priority=10\n\n\noverride default frontend priority\n\n\n\n\n\n\ntraefik.frontend.entryPoints=http,https\n\n\nassign this frontend to entry points \nhttp\n and \nhttps\n. Overrides \ndefaultEntryPoints\n.\n\n\n\n\n\n\ntraefik.frontend.auth.basic=EXPR\n\n\nSets basic authentication for that frontend in CSV format: \nUser:Hash,User:Hash\n.\n\n\n\n\n\n\n\n\nService Level\n\n\nFor applications that expose multiple ports, specific labels can be used to extract one frontend/backend configuration pair per port. Each such pair is called a \nservice\n. The (freely choosable) name of the service is an integral part of the service label name.\n\n\n\n\n\n\n\n\nLabel\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntraefik.\nservice-name\n.port=443\n\n\ncreate a service binding with frontend/backend using this port. Overrides \ntraefik.port\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.portIndex=1\n\n\ncreate a service binding with frontend/backend using this port index. Overrides \ntraefik.portIndex\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.protocol=https\n\n\nassign \nhttps\n protocol. Overrides \ntraefik.protocol\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.weight=10\n\n\nassign this service weight. Overrides \ntraefik.weight\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.backend=fooBackend\n\n\nassign this service frontend to \nfoobackend\n. Default is to assign to the service backend.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.entryPoints=http\n\n\nassign this service entrypoints. Overrides \ntraefik.frontend.entrypoints\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.auth.basic=test:EXPR\n\n\nSets basic authentication for that frontend in CSV format: \nUser:Hash,User:Hash\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.passHostHeader=true\n\n\nForward client \nHost\n header to the backend. Overrides \ntraefik.frontend.passHostHeader\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.priority=10\n\n\nassign the service frontend priority. Overrides \ntraefik.frontend.priority\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.rule=Path:/foo\n\n\nassign the service frontend rule. Overrides \ntraefik.frontend.rule\n.", 
            "title": "Backend: Marathon"
        }, 
        {
            "location": "/configuration/backends/marathon/#marathon-backend", 
            "text": "Tr\u00e6fik can be configured to use Marathon as a backend configuration.  See also  Marathon user guide .", 
            "title": "Marathon Backend"
        }, 
        {
            "location": "/configuration/backends/marathon/#configuration", 
            "text": "################################################################\n# Mesos/Marathon configuration backend\n################################################################\n\n# Enable Marathon configuration backend.\n[marathon]\n\n# Marathon server endpoint.\n# You can also specify multiple endpoint for Marathon:\n# endpoint =  http://10.241.1.71:8080,10.241.1.72:8080,10.241.1.73:8080 \n#\n# Required\n# Default:  http://127.0.0.1:8080 \n#\nendpoint =  http://127.0.0.1:8080 \n\n# Enable watch Marathon changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Default domain used.\n# Can be overridden by setting the  traefik.domain  label on an application.\n#\n# Required\n#\ndomain =  marathon.localhost \n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename =  marathon.tmpl \n\n# Expose Marathon apps by default in Traefik.\n#\n# Optional\n# Default: true\n#\n# exposedByDefault = false\n\n# Convert Marathon groups to subdomains.\n# Default behavior: /foo/bar/myapp =  foo-bar-myapp.{defaultDomain}\n# with groupsAsSubDomains enabled: /foo/bar/myapp =  myapp.bar.foo.{defaultDomain}\n#\n# Optional\n# Default: false\n#\n# groupsAsSubDomains = true\n\n# Enable compatibility with marathon-lb labels.\n#\n# Optional\n# Default: false\n#\n# marathonLBCompatibility = true\n\n# Enable filtering using Marathon constraints..\n# If enabled, Traefik will read Marathon constraints, as defined in https://mesosphere.github.io/marathon/docs/constraints.html\n# Each individual constraint will be treated as a verbatim compounded tag. \n# i.e.  rack_id:CLUSTER:rack-1 , with all constraint groups concatenated together using  : \n#\n# Optional\n# Default: false\n#\n# filterMarathonConstraints = true\n\n# Enable Marathon basic authentication.\n#\n# Optional\n#\n#    [marathon.basic]\n#    httpBasicAuthUser =  foo \n#    httpBasicPassword =  bar \n\n# TLS client configuration. https://golang.org/pkg/crypto/tls/#Config\n#\n# Optional\n#\n#    [marathon.TLS]\n#    CA =  /etc/ssl/ca.crt \n#    Cert =  /etc/ssl/marathon.cert \n#    Key =  /etc/ssl/marathon.key \n#    InsecureSkipVerify = true\n\n# DCOSToken for DCOS environment.\n# This will override the Authorization header.\n#\n# Optional\n#\n# dcosToken =  xxxxxx \n\n# Override DialerTimeout.\n# Amount of time to allow the Marathon provider to wait to open a TCP connection\n# to a Marathon master.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits).\n# If no units are provided, the value is parsed assuming seconds.\n#\n# Optional\n# Default:  60s \n#\n# dialerTimeout =  60s \n\n# Set the TCP Keep Alive interval for the Marathon HTTP Client.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits).\n# If no units are provided, the value is parsed assuming seconds.\n#\n# Optional\n# Default:  10s \n#\n# keepAlive =  10s \n\n# By default, a task's IP address (as returned by the Marathon API) is used as\n# backend server if an IP-per-task configuration can be found; otherwise, the\n# name of the host running the task is used.\n# The latter behavior can be enforced by enabling this switch.\n#\n# Optional\n# Default: false\n#\n# forceTaskHostname = true\n\n# Applications may define readiness checks which are probed by Marathon during\n# deployments periodically and the results exposed via the API.\n# Enabling the following parameter causes Traefik to filter out tasks\n# whose readiness checks have not succeeded.\n# Note that the checks are only valid at deployment times.\n# See the Marathon guide for details.\n#\n# Optional\n# Default: false\n#\n# respectReadinessChecks = true  To enable constraints see  backend-specific constraints section .", 
            "title": "Configuration"
        }, 
        {
            "location": "/configuration/backends/marathon/#labels-overriding-default-behaviour", 
            "text": "Marathon labels may be used to dynamically change the routing and forwarding behaviour.  They may be specified on one of two levels: Application or service.", 
            "title": "Labels: overriding default behaviour"
        }, 
        {
            "location": "/configuration/backends/marathon/#application-level", 
            "text": "The following labels can be defined on Marathon applications. They adjust the behaviour for the entire application.     Label  Description      traefik.backend=foo  assign the application to  foo  backend    traefik.backend.maxconn.amount=10  set a maximum number of connections to the backend. Must be used in conjunction with the below label to take effect.    traefik.backend.maxconn.extractorfunc=client.ip  set the function to be used against the request to determine what to limit maximum connections to the backend by. Must be used in conjunction with the above label to take effect.    traefik.backend.loadbalancer.method=drr  override the default  wrr  load balancer algorithm    traefik.backend.loadbalancer.sticky=true  enable backend sticky sessions (DEPRECATED)    traefik.backend.loadbalancer.stickiness=true  enable backend sticky sessions    traefik.backend.loadbalancer.stickiness.cookieName=NAME  Manually set the cookie name for sticky sessions    traefik.backend.circuitbreaker.expression=NetworkErrorRatio()   0.5  create a  circuit breaker  to be used against the backend    traefik.backend.healthcheck.path=/health  set the Traefik health check path [default: no health checks]    traefik.backend.healthcheck.interval=5s  sets a custom health check interval in Go-parseable ( time.ParseDuration ) format [default: 30s]    traefik.portIndex=1  register port by index in the application's ports array. Useful when the application exposes multiple ports.    traefik.port=80  register the explicit application port value. Cannot be used alongside  traefik.portIndex .    traefik.protocol=https  override the default  http  protocol    traefik.weight=10  assign this weight to the application    traefik.enable=false  disable this application in Tr\u00e6fik    traefik.frontend.rule=Host:test.traefik.io  override the default frontend rule (Default:  Host:{containerName}.{domain} ).    traefik.frontend.passHostHeader=true  forward client  Host  header to the backend.    traefik.frontend.priority=10  override default frontend priority    traefik.frontend.entryPoints=http,https  assign this frontend to entry points  http  and  https . Overrides  defaultEntryPoints .    traefik.frontend.auth.basic=EXPR  Sets basic authentication for that frontend in CSV format:  User:Hash,User:Hash .", 
            "title": "Application Level"
        }, 
        {
            "location": "/configuration/backends/marathon/#service-level", 
            "text": "For applications that expose multiple ports, specific labels can be used to extract one frontend/backend configuration pair per port. Each such pair is called a  service . The (freely choosable) name of the service is an integral part of the service label name.     Label  Description      traefik. service-name .port=443  create a service binding with frontend/backend using this port. Overrides  traefik.port .    traefik. service-name .portIndex=1  create a service binding with frontend/backend using this port index. Overrides  traefik.portIndex .    traefik. service-name .protocol=https  assign  https  protocol. Overrides  traefik.protocol .    traefik. service-name .weight=10  assign this service weight. Overrides  traefik.weight .    traefik. service-name .frontend.backend=fooBackend  assign this service frontend to  foobackend . Default is to assign to the service backend.    traefik. service-name .frontend.entryPoints=http  assign this service entrypoints. Overrides  traefik.frontend.entrypoints .    traefik. service-name .frontend.auth.basic=test:EXPR  Sets basic authentication for that frontend in CSV format:  User:Hash,User:Hash    traefik. service-name .frontend.passHostHeader=true  Forward client  Host  header to the backend. Overrides  traefik.frontend.passHostHeader .    traefik. service-name .frontend.priority=10  assign the service frontend priority. Overrides  traefik.frontend.priority .    traefik. service-name .frontend.rule=Path:/foo  assign the service frontend rule. Overrides  traefik.frontend.rule .", 
            "title": "Service Level"
        }, 
        {
            "location": "/configuration/backends/mesos/", 
            "text": "Mesos Generic Backend\n\n\nTr\u00e6fik can be configured to use Mesos as a backend configuration.\n\n\n################################################################\n# Mesos configuration backend\n################################################################\n\n# Enable Mesos configuration backend.\n[mesos]\n\n# Mesos server endpoint.\n# You can also specify multiple endpoint for Mesos:\n# endpoint = \n192.168.35.40:5050,192.168.35.41:5050,192.168.35.42:5050\n\n# endpoint = \nzk://192.168.35.20:2181,192.168.35.21:2181,192.168.35.22:2181/mesos\n\n#\n# Required\n# Default: \nhttp://127.0.0.1:5050\n\n#\nendpoint = \nhttp://127.0.0.1:8080\n\n\n# Enable watch Mesos changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Default domain used.\n# Can be overridden by setting the \ntraefik.domain\n label on an application.\n#\n# Required\n#\ndomain = \nmesos.localhost\n\n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename = \nmesos.tmpl\n\n\n# Expose Mesos apps by default in Traefik.\n#\n# Optional\n# Default: true\n#\n# ExposedByDefault = false\n\n# TLS client configuration. https://golang.org/pkg/crypto/tls/#Config\n#\n# Optional\n#\n# [mesos.TLS]\n# InsecureSkipVerify = true\n\n# Zookeeper timeout (in seconds).\n#\n# Optional\n# Default: 30\n#\n# ZkDetectionTimeout = 30\n\n# Polling interval (in seconds).\n#\n# Optional\n# Default: 30\n#\n# RefreshSeconds = 30\n\n# IP sources (e.g. host, docker, mesos, rkt).\n#\n# Optional\n#\n# IPSources = \nhost\n\n\n# HTTP Timeout (in seconds).\n#\n# Optional\n# Default: 30\n#\n# StateTimeoutSecond = \n30\n\n\n# Convert groups to subdomains.\n# Default behavior: /foo/bar/myapp =\n foo-bar-myapp.{defaultDomain}\n# with groupsAsSubDomains enabled: /foo/bar/myapp =\n myapp.bar.foo.{defaultDomain}\n#\n# Optional\n# Default: false\n#\n# groupsAsSubDomains = true", 
            "title": "Backend: Mesos"
        }, 
        {
            "location": "/configuration/backends/mesos/#mesos-generic-backend", 
            "text": "Tr\u00e6fik can be configured to use Mesos as a backend configuration.  ################################################################\n# Mesos configuration backend\n################################################################\n\n# Enable Mesos configuration backend.\n[mesos]\n\n# Mesos server endpoint.\n# You can also specify multiple endpoint for Mesos:\n# endpoint =  192.168.35.40:5050,192.168.35.41:5050,192.168.35.42:5050 \n# endpoint =  zk://192.168.35.20:2181,192.168.35.21:2181,192.168.35.22:2181/mesos \n#\n# Required\n# Default:  http://127.0.0.1:5050 \n#\nendpoint =  http://127.0.0.1:8080 \n\n# Enable watch Mesos changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Default domain used.\n# Can be overridden by setting the  traefik.domain  label on an application.\n#\n# Required\n#\ndomain =  mesos.localhost \n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename =  mesos.tmpl \n\n# Expose Mesos apps by default in Traefik.\n#\n# Optional\n# Default: true\n#\n# ExposedByDefault = false\n\n# TLS client configuration. https://golang.org/pkg/crypto/tls/#Config\n#\n# Optional\n#\n# [mesos.TLS]\n# InsecureSkipVerify = true\n\n# Zookeeper timeout (in seconds).\n#\n# Optional\n# Default: 30\n#\n# ZkDetectionTimeout = 30\n\n# Polling interval (in seconds).\n#\n# Optional\n# Default: 30\n#\n# RefreshSeconds = 30\n\n# IP sources (e.g. host, docker, mesos, rkt).\n#\n# Optional\n#\n# IPSources =  host \n\n# HTTP Timeout (in seconds).\n#\n# Optional\n# Default: 30\n#\n# StateTimeoutSecond =  30 \n\n# Convert groups to subdomains.\n# Default behavior: /foo/bar/myapp =  foo-bar-myapp.{defaultDomain}\n# with groupsAsSubDomains enabled: /foo/bar/myapp =  myapp.bar.foo.{defaultDomain}\n#\n# Optional\n# Default: false\n#\n# groupsAsSubDomains = true", 
            "title": "Mesos Generic Backend"
        }, 
        {
            "location": "/configuration/backends/rancher/", 
            "text": "Rancher Backend\n\n\nTr\u00e6fik can be configured to use Rancher as a backend configuration.\n\n\nGlobal Configuration\n\n\n################################################################\n# Rancher configuration backend\n################################################################\n\n# Enable Rancher configuration backend.\n[rancher]\n\n# Default domain used.\n# Can be overridden by setting the \ntraefik.domain\n label on an service.\n#\n# Required\n#\ndomain = \nrancher.localhost\n\n\n# Enable watch Rancher changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Polling interval (in seconds).\n#\n# Optional\n# Default: 15\n#\nrefreshSeconds = 15\n\n# Expose Rancher services by default in Traefik.\n#\n# Optional\n# Default: true\n#\nexposedByDefault = false\n\n# Filter services with unhealthy states and inactive states.\n#\n# Optional\n# Default: false\n#\nenableServiceHealthFilter = true\n\n\n\n\nTo enable constraints see \nbackend-specific constraints section\n.\n\n\nRancher Metadata Service\n\n\n# Enable Rancher metadata service configuration backend instead of the API\n# configuration backend.\n#\n# Optional\n# Default: false\n#\n[rancher.metadata]\n\n# Poll the Rancher metadata service for changes every `rancher.RefreshSeconds`.\n# NOTE: this is less accurate than the default long polling technique which\n# will provide near instantaneous updates to Traefik\n#\n# Optional\n# Default: false\n#\nintervalPoll = true\n\n# Prefix used for accessing the Rancher metadata service.\n#\n# Optional\n# Default: \n/latest\n\n#\nprefix = \n/2016-07-29\n\n\n\n\n\nRancher API\n\n\n# Enable Rancher API configuration backend.\n#\n# Optional\n# Default: true\n#\n[rancher.api]\n\n# Endpoint to use when connecting to the Rancher API.\n#\n# Required\nendpoint = \nhttp://rancherserver.example.com/v1\n\n\n# AccessKey to use when connecting to the Rancher API.\n#\n# Required\naccessKey = \nXXXXXXXXXXXXXXXXXXXX\n\n\n# SecretKey to use when connecting to the Rancher API.\n#\n# Required\nsecretKey = \nxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n\n\n\n\n\n\n\nNote\n\n\nIf Traefik needs access to the Rancher API, you need to set the \nendpoint\n, \naccesskey\n and \nsecretkey\n parameters.\n\n\nTo enable Traefik to fetch information about the Environment it's deployed in only, you need to create an \nEnvironment API Key\n.\nThis can be found within the API Key advanced options.\n\n\nAdd these labels to traefik docker deployment to autogenerated these values:\n\nio.rancher.container.agent.role: environment\nio.rancher.container.create_agent: true\n\n\n\n\nLabels: overriding default behaviour\n\n\nLabels can be used on task containers to override default behaviour:\n\n\n\n\n\n\n\n\nLabel\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntraefik.protocol=https\n\n\nOverride the default \nhttp\n protocol\n\n\n\n\n\n\ntraefik.weight=10\n\n\nAssign this weight to the container\n\n\n\n\n\n\ntraefik.enable=false\n\n\nDisable this container in Tr\u00e6fik\n\n\n\n\n\n\ntraefik.frontend.rule=Host:test.traefik.io\n\n\nOverride the default frontend rule (Default: \nHost:{containerName}.{domain}\n).\n\n\n\n\n\n\ntraefik.frontend.passHostHeader=true\n\n\nForward client \nHost\n header to the backend.\n\n\n\n\n\n\ntraefik.frontend.priority=10\n\n\nOverride default frontend priority\n\n\n\n\n\n\ntraefik.frontend.entryPoints=http,https\n\n\nAssign this frontend to entry points \nhttp\n and \nhttps\n. Overrides \ndefaultEntryPoints\n.\n\n\n\n\n\n\ntraefik.frontend.auth.basic=EXPR\n\n\nSets basic authentication for that frontend in CSV format: \nUser:Hash,User:Hash\n.\n\n\n\n\n\n\ntraefik.frontend.redirect.entryPoint=https\n\n\nEnables Redirect to another entryPoint for that frontend (e.g. HTTPS)\n\n\n\n\n\n\ntraefik.frontend.redirect.regex: ^http://localhost/(.*)\n\n\nRedirect to another URL for that frontend.\nMust be set with \ntraefik.frontend.redirect.replacement\n.\n\n\n\n\n\n\ntraefik.frontend.redirect.replacement: http://mydomain/$1\n\n\nRedirect to another URL for that frontend.\nMust be set with \ntraefik.frontend.redirect.regex\n.\n\n\n\n\n\n\ntraefik.backend.circuitbreaker.expression=NetworkErrorRatio() \n 0.5\n\n\nCreate a \ncircuit breaker\n to be used against the backend\n\n\n\n\n\n\ntraefik.backend.loadbalancer.method=drr\n\n\nOverride the default \nwrr\n load balancer algorithm\n\n\n\n\n\n\ntraefik.backend.loadbalancer.stickiness=true\n\n\nEnable backend sticky sessions\n\n\n\n\n\n\ntraefik.backend.loadbalancer.stickiness.cookieName=NAME\n\n\nManually set the cookie name for sticky sessions\n\n\n\n\n\n\ntraefik.backend.loadbalancer.sticky=true\n\n\nEnable backend sticky sessions (DEPRECATED)", 
            "title": "Backend: Rancher"
        }, 
        {
            "location": "/configuration/backends/rancher/#rancher-backend", 
            "text": "Tr\u00e6fik can be configured to use Rancher as a backend configuration.", 
            "title": "Rancher Backend"
        }, 
        {
            "location": "/configuration/backends/rancher/#global-configuration", 
            "text": "################################################################\n# Rancher configuration backend\n################################################################\n\n# Enable Rancher configuration backend.\n[rancher]\n\n# Default domain used.\n# Can be overridden by setting the  traefik.domain  label on an service.\n#\n# Required\n#\ndomain =  rancher.localhost \n\n# Enable watch Rancher changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Polling interval (in seconds).\n#\n# Optional\n# Default: 15\n#\nrefreshSeconds = 15\n\n# Expose Rancher services by default in Traefik.\n#\n# Optional\n# Default: true\n#\nexposedByDefault = false\n\n# Filter services with unhealthy states and inactive states.\n#\n# Optional\n# Default: false\n#\nenableServiceHealthFilter = true  To enable constraints see  backend-specific constraints section .", 
            "title": "Global Configuration"
        }, 
        {
            "location": "/configuration/backends/rancher/#rancher-metadata-service", 
            "text": "# Enable Rancher metadata service configuration backend instead of the API\n# configuration backend.\n#\n# Optional\n# Default: false\n#\n[rancher.metadata]\n\n# Poll the Rancher metadata service for changes every `rancher.RefreshSeconds`.\n# NOTE: this is less accurate than the default long polling technique which\n# will provide near instantaneous updates to Traefik\n#\n# Optional\n# Default: false\n#\nintervalPoll = true\n\n# Prefix used for accessing the Rancher metadata service.\n#\n# Optional\n# Default:  /latest \n#\nprefix =  /2016-07-29", 
            "title": "Rancher Metadata Service"
        }, 
        {
            "location": "/configuration/backends/rancher/#rancher-api", 
            "text": "# Enable Rancher API configuration backend.\n#\n# Optional\n# Default: true\n#\n[rancher.api]\n\n# Endpoint to use when connecting to the Rancher API.\n#\n# Required\nendpoint =  http://rancherserver.example.com/v1 \n\n# AccessKey to use when connecting to the Rancher API.\n#\n# Required\naccessKey =  XXXXXXXXXXXXXXXXXXXX \n\n# SecretKey to use when connecting to the Rancher API.\n#\n# Required\nsecretKey =  xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx    Note  If Traefik needs access to the Rancher API, you need to set the  endpoint ,  accesskey  and  secretkey  parameters.  To enable Traefik to fetch information about the Environment it's deployed in only, you need to create an  Environment API Key .\nThis can be found within the API Key advanced options.  Add these labels to traefik docker deployment to autogenerated these values: io.rancher.container.agent.role: environment\nio.rancher.container.create_agent: true", 
            "title": "Rancher API"
        }, 
        {
            "location": "/configuration/backends/rancher/#labels-overriding-default-behaviour", 
            "text": "Labels can be used on task containers to override default behaviour:     Label  Description      traefik.protocol=https  Override the default  http  protocol    traefik.weight=10  Assign this weight to the container    traefik.enable=false  Disable this container in Tr\u00e6fik    traefik.frontend.rule=Host:test.traefik.io  Override the default frontend rule (Default:  Host:{containerName}.{domain} ).    traefik.frontend.passHostHeader=true  Forward client  Host  header to the backend.    traefik.frontend.priority=10  Override default frontend priority    traefik.frontend.entryPoints=http,https  Assign this frontend to entry points  http  and  https . Overrides  defaultEntryPoints .    traefik.frontend.auth.basic=EXPR  Sets basic authentication for that frontend in CSV format:  User:Hash,User:Hash .    traefik.frontend.redirect.entryPoint=https  Enables Redirect to another entryPoint for that frontend (e.g. HTTPS)    traefik.frontend.redirect.regex: ^http://localhost/(.*)  Redirect to another URL for that frontend. Must be set with  traefik.frontend.redirect.replacement .    traefik.frontend.redirect.replacement: http://mydomain/$1  Redirect to another URL for that frontend. Must be set with  traefik.frontend.redirect.regex .    traefik.backend.circuitbreaker.expression=NetworkErrorRatio()   0.5  Create a  circuit breaker  to be used against the backend    traefik.backend.loadbalancer.method=drr  Override the default  wrr  load balancer algorithm    traefik.backend.loadbalancer.stickiness=true  Enable backend sticky sessions    traefik.backend.loadbalancer.stickiness.cookieName=NAME  Manually set the cookie name for sticky sessions    traefik.backend.loadbalancer.sticky=true  Enable backend sticky sessions (DEPRECATED)", 
            "title": "Labels: overriding default behaviour"
        }, 
        {
            "location": "/configuration/backends/rest/", 
            "text": "Rest Backend\n\n\nTr\u00e6fik can be configured:\n\n\n\n\nusing a RESTful api.\n\n\n\n\nConfiguration\n\n\n# Enable rest backend.\n[rest]\n  # Name of the related entry point\n  #\n  # Optional\n  # Default: \ntraefik\n\n  #\n  entryPoint = \ntraefik\n\n\n\n\n\nAPI\n\n\n\n\n\n\n\n\nPath\n\n\nMethod\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n/api/providers/web\n\n\nPUT\n\n\nupdate provider\n\n\n\n\n\n\n/api/providers/rest\n\n\nPUT\n\n\nupdate provider\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\nFor compatibility reason, when you activate the rest provider, you can use \nweb\n or \nrest\n as \nprovider\n value.\n\n\n\n\ncurl -XPUT @file \nhttp://localhost:8080/api/providers/rest\n\n\n\n\n\nwith \n@file\n:\n\n\n{\n    \nfrontends\n: {\n      \nfrontend2\n: {\n        \nroutes\n: {\n          \ntest_2\n: {\n            \nrule\n: \nPath:/test\n\n          }\n        },\n        \nbackend\n: \nbackend1\n\n      },\n      \nfrontend1\n: {\n        \nroutes\n: {\n          \ntest_1\n: {\n            \nrule\n: \nHost:test.localhost\n\n          }\n        },\n        \nbackend\n: \nbackend2\n\n      }\n    },\n    \nbackends\n: {\n      \nbackend2\n: {\n        \nloadBalancer\n: {\n          \nmethod\n: \ndrr\n\n        },\n        \nservers\n: {\n          \nserver2\n: {\n            \nweight\n: 2,\n            \nURL\n: \nhttp://172.17.0.5:80\n\n          },\n          \nserver1\n: {\n            \nweight\n: 1,\n            \nurl\n: \nhttp://172.17.0.4:80\n\n          }\n        }\n      },\n      \nbackend1\n: {\n        \nloadBalancer\n: {\n          \nmethod\n: \nwrr\n\n        },\n        \ncircuitBreaker\n: {\n          \nexpression\n: \nNetworkErrorRatio() \n 0.5\n\n        },\n        \nservers\n: {\n          \nserver2\n: {\n            \nweight\n: 1,\n            \nurl\n: \nhttp://172.17.0.3:80\n\n          },\n          \nserver1\n: {\n            \nweight\n: 10,\n            \nurl\n: \nhttp://172.17.0.2:80\n\n          }\n        }\n      }\n    }\n}", 
            "title": "Backend: Rest"
        }, 
        {
            "location": "/configuration/backends/rest/#rest-backend", 
            "text": "Tr\u00e6fik can be configured:   using a RESTful api.", 
            "title": "Rest Backend"
        }, 
        {
            "location": "/configuration/backends/rest/#configuration", 
            "text": "# Enable rest backend.\n[rest]\n  # Name of the related entry point\n  #\n  # Optional\n  # Default:  traefik \n  #\n  entryPoint =  traefik", 
            "title": "Configuration"
        }, 
        {
            "location": "/configuration/backends/rest/#api", 
            "text": "Path  Method  Description      /api/providers/web  PUT  update provider    /api/providers/rest  PUT  update provider      Warning  For compatibility reason, when you activate the rest provider, you can use  web  or  rest  as  provider  value.   curl -XPUT @file  http://localhost:8080/api/providers/rest   with  @file :  {\n     frontends : {\n       frontend2 : {\n         routes : {\n           test_2 : {\n             rule :  Path:/test \n          }\n        },\n         backend :  backend1 \n      },\n       frontend1 : {\n         routes : {\n           test_1 : {\n             rule :  Host:test.localhost \n          }\n        },\n         backend :  backend2 \n      }\n    },\n     backends : {\n       backend2 : {\n         loadBalancer : {\n           method :  drr \n        },\n         servers : {\n           server2 : {\n             weight : 2,\n             URL :  http://172.17.0.5:80 \n          },\n           server1 : {\n             weight : 1,\n             url :  http://172.17.0.4:80 \n          }\n        }\n      },\n       backend1 : {\n         loadBalancer : {\n           method :  wrr \n        },\n         circuitBreaker : {\n           expression :  NetworkErrorRatio()   0.5 \n        },\n         servers : {\n           server2 : {\n             weight : 1,\n             url :  http://172.17.0.3:80 \n          },\n           server1 : {\n             weight : 10,\n             url :  http://172.17.0.2:80 \n          }\n        }\n      }\n    }\n}", 
            "title": "API"
        }, 
        {
            "location": "/configuration/backends/servicefabric/", 
            "text": "Azure Service Fabric Backend\n\n\nTr\u00e6fik can be configured to use Azure Service Fabric as a backend configuration.\n\n\nSee \nthis repository for an example deployment package and further documentation.\n\n\nAzure Service Fabric\n\n\n################################################################\n# Azure Service Fabric provider\n################################################################\n\n# Enable Azure Service Fabric configuration backend\n[serviceFabric]\n\n# Azure Service Fabric Management Endpoint\n#\n# Required\n#\nclusterManagementUrl = \nhttps://localhost:19080\n\n\n# Azure Service Fabric Management Endpoint API Version\n#\n# Required\n# Default: \n3.0\n\n#\napiVersion = \n3.0\n\n\n# Azure Service Fabric Polling Interval (in seconds)\n#\n# Required\n# Default: 10\n#\nrefreshSeconds = 10\n\n# Enable TLS connection.\n#\n# Optional\n#\n# [serviceFabric.tls]\n#   ca = \n/etc/ssl/ca.crt\n\n#   cert = \n/etc/ssl/servicefabric.crt\n\n#   key = \n/etc/ssl/servicefabric.key\n\n#   insecureskipverify = true\n\n\n\n\nLabels\n\n\nThe provider uses labels to configure how services are exposed through Tr\u00e6fik.\nThese can be set using Extensions and the Property Manager API\n\n\nExtensions\n\n\nSet labels with extensions through the services \nServiceManifest.xml\n file.\nHere is an example of an extension setting Tr\u00e6fik labels:\n\n\nStatelessServiceType ServiceTypeName=\nWebServiceType\n\n  \nExtensions\n\n      \nExtension Name=\nTraefik\n\n        \nLabels xmlns=\nhttp://schemas.microsoft.com/2015/03/fabact-no-schema\n\n          \nLabel Key=\ntraefik.frontend.rule.example2\nPathPrefixStrip: /a/path/to/strip\n/Label\n\n          \nLabel Key=\ntraefik.expose\ntrue\n/Label\n\n          \nLabel Key=\ntraefik.frontend.passHostHeader\ntrue\n/Label\n\n        \n/Labels\n\n      \n/Extension\n\n  \n/Extensions\n\n\n/StatelessServiceType\n\n\n\n\n\nProperty Manager\n\n\nSet Labels with the property manager API to overwrite and add labels, while your service is running.\nHere is an example of adding a frontend rule using the property manager API. \n\n\ncurl -X PUT \\\n  'http://localhost:19080/Names/GettingStartedApplication2/WebService/$/GetProperty?api-version=6.0\nIncludeValues=true' \\\n  -d '{\n  \nPropertyName\n: \ntraefik.frontend.rule.default\n,\n  \nValue\n: {\n    \nKind\n: \nString\n,\n    \nData\n: \nPathPrefixStrip: /a/path/to/strip\n\n  },\n  \nCustomTypeId\n: \nLabelType\n\n}'\n\n\n\n\n\n\nNote\n\n\nThis functionality will be released in a future version of the \nsfctl\n tool.\n\n\n\n\nAvailable Labels\n\n\nLabels, set through extensions or the property manager, can be used on services to override default behaviour.\n\n\n\n\n\n\n\n\nLabel\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntraefik.backend.maxconn.amount=10\n\n\nSet a maximum number of connections to the backend.\nMust be used in conjunction with the below label to take effect.\n\n\n\n\n\n\ntraefik.backend.maxconn.extractorfunc=client.ip\n\n\nSet the function to be used against the request to determine what to limit maximum connections to the backend by.\nMust be used in conjunction with the above label to take effect.\n\n\n\n\n\n\ntraefik.backend.loadbalancer.method=drr\n\n\nOverride the default \nwrr\n load balancer algorithm\n\n\n\n\n\n\ntraefik.backend.loadbalancer.stickiness=true\n\n\nEnable backend sticky sessions\n\n\n\n\n\n\ntraefik.backend.loadbalancer.stickiness.cookieName=NAME\n\n\nManually set the cookie name for sticky sessions\n\n\n\n\n\n\ntraefik.backend.circuitbreaker.expression=EXPR\n\n\nCreate a \ncircuit breaker\n to be used against the backend\n\n\n\n\n\n\ntraefik.backend.weight=10\n\n\nAssign this weight to the container\n\n\n\n\n\n\ntraefik.expose=true\n\n\nExpose this service using tr\u00e6fik\n\n\n\n\n\n\ntraefik.frontend.rule=EXPR\n\n\nOverride the default frontend rule. Defaults to SF address.\n\n\n\n\n\n\ntraefik.frontend.passHostHeader=true\n\n\nForward client \nHost\n header to the backend.\n\n\n\n\n\n\ntraefik.frontend.priority=10\n\n\nOverride default frontend priority\n\n\n\n\n\n\ntraefik.frontend.entryPoints=http,https\n\n\nAssign this frontend to entry points \nhttp\n and \nhttps\n. Overrides \ndefaultEntryPoints\n\n\n\n\n\n\ntraefik.frontend.auth.basic=EXPR\n\n\nSet basic authentication for that frontend in CSV format: \nUser:Hash,User:Hash\n\n\n\n\n\n\ntraefik.frontend.whitelistSourceRange:RANGE\n\n\nList of IP-Ranges which are allowed to access. An unset or empty list allows all Source-IPs to access.\nIf one of the Net-Specifications are invalid, the whole list is invalid and allows all Source-IPs to access.\n\n\n\n\n\n\ntraefik.backend.group.name\n\n\nGroup all services with the same name into a single backend in Tr\u00e6fik\n\n\n\n\n\n\ntraefik.backend.group.weight\n\n\nSet the weighting of the current services nodes in the backend group", 
            "title": "Backend: Azure Service Fabric"
        }, 
        {
            "location": "/configuration/backends/servicefabric/#azure-service-fabric-backend", 
            "text": "Tr\u00e6fik can be configured to use Azure Service Fabric as a backend configuration.  See  this repository for an example deployment package and further documentation.", 
            "title": "Azure Service Fabric Backend"
        }, 
        {
            "location": "/configuration/backends/servicefabric/#azure-service-fabric", 
            "text": "################################################################\n# Azure Service Fabric provider\n################################################################\n\n# Enable Azure Service Fabric configuration backend\n[serviceFabric]\n\n# Azure Service Fabric Management Endpoint\n#\n# Required\n#\nclusterManagementUrl =  https://localhost:19080 \n\n# Azure Service Fabric Management Endpoint API Version\n#\n# Required\n# Default:  3.0 \n#\napiVersion =  3.0 \n\n# Azure Service Fabric Polling Interval (in seconds)\n#\n# Required\n# Default: 10\n#\nrefreshSeconds = 10\n\n# Enable TLS connection.\n#\n# Optional\n#\n# [serviceFabric.tls]\n#   ca =  /etc/ssl/ca.crt \n#   cert =  /etc/ssl/servicefabric.crt \n#   key =  /etc/ssl/servicefabric.key \n#   insecureskipverify = true", 
            "title": "Azure Service Fabric"
        }, 
        {
            "location": "/configuration/backends/servicefabric/#labels", 
            "text": "The provider uses labels to configure how services are exposed through Tr\u00e6fik.\nThese can be set using Extensions and the Property Manager API", 
            "title": "Labels"
        }, 
        {
            "location": "/configuration/backends/servicefabric/#extensions", 
            "text": "Set labels with extensions through the services  ServiceManifest.xml  file.\nHere is an example of an extension setting Tr\u00e6fik labels:  StatelessServiceType ServiceTypeName= WebServiceType \n   Extensions \n       Extension Name= Traefik \n         Labels xmlns= http://schemas.microsoft.com/2015/03/fabact-no-schema \n           Label Key= traefik.frontend.rule.example2 PathPrefixStrip: /a/path/to/strip /Label \n           Label Key= traefik.expose true /Label \n           Label Key= traefik.frontend.passHostHeader true /Label \n         /Labels \n       /Extension \n   /Extensions  /StatelessServiceType", 
            "title": "Extensions"
        }, 
        {
            "location": "/configuration/backends/servicefabric/#property-manager", 
            "text": "Set Labels with the property manager API to overwrite and add labels, while your service is running.\nHere is an example of adding a frontend rule using the property manager API.   curl -X PUT \\\n  'http://localhost:19080/Names/GettingStartedApplication2/WebService/$/GetProperty?api-version=6.0 IncludeValues=true' \\\n  -d '{\n   PropertyName :  traefik.frontend.rule.default ,\n   Value : {\n     Kind :  String ,\n     Data :  PathPrefixStrip: /a/path/to/strip \n  },\n   CustomTypeId :  LabelType \n}'   Note  This functionality will be released in a future version of the  sfctl  tool.", 
            "title": "Property Manager"
        }, 
        {
            "location": "/configuration/backends/servicefabric/#available-labels", 
            "text": "Labels, set through extensions or the property manager, can be used on services to override default behaviour.     Label  Description      traefik.backend.maxconn.amount=10  Set a maximum number of connections to the backend. Must be used in conjunction with the below label to take effect.    traefik.backend.maxconn.extractorfunc=client.ip  Set the function to be used against the request to determine what to limit maximum connections to the backend by. Must be used in conjunction with the above label to take effect.    traefik.backend.loadbalancer.method=drr  Override the default  wrr  load balancer algorithm    traefik.backend.loadbalancer.stickiness=true  Enable backend sticky sessions    traefik.backend.loadbalancer.stickiness.cookieName=NAME  Manually set the cookie name for sticky sessions    traefik.backend.circuitbreaker.expression=EXPR  Create a  circuit breaker  to be used against the backend    traefik.backend.weight=10  Assign this weight to the container    traefik.expose=true  Expose this service using tr\u00e6fik    traefik.frontend.rule=EXPR  Override the default frontend rule. Defaults to SF address.    traefik.frontend.passHostHeader=true  Forward client  Host  header to the backend.    traefik.frontend.priority=10  Override default frontend priority    traefik.frontend.entryPoints=http,https  Assign this frontend to entry points  http  and  https . Overrides  defaultEntryPoints    traefik.frontend.auth.basic=EXPR  Set basic authentication for that frontend in CSV format:  User:Hash,User:Hash    traefik.frontend.whitelistSourceRange:RANGE  List of IP-Ranges which are allowed to access. An unset or empty list allows all Source-IPs to access. If one of the Net-Specifications are invalid, the whole list is invalid and allows all Source-IPs to access.    traefik.backend.group.name  Group all services with the same name into a single backend in Tr\u00e6fik    traefik.backend.group.weight  Set the weighting of the current services nodes in the backend group", 
            "title": "Available Labels"
        }, 
        {
            "location": "/configuration/backends/zookeeper/", 
            "text": "Zookeeper Backend\n\n\nTr\u00e6fik can be configured to use Zookeeper as a backend configuration.\n\n\n################################################################\n# Zookeeper configuration backend\n################################################################\n\n# Enable Zookeeperconfiguration backend.\n[zookeeper]\n\n# Zookeeper server endpoint.\n#\n# Required\n# Default: \n127.0.0.1:2181\n\n#\nendpoint = \n127.0.0.1:2181\n\n\n# Enable watch Zookeeper changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n# Default: \ntraefik\n\n#\nprefix = \ntraefik\n\n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename = \nzookeeper.tmpl\n\n\n# Use Zookeeper user/pass authentication.\n#\n# Optional\n#\n# username = foo\n# password = bar\n\n# Enable Zookeeper TLS connection.\n#\n# Optional\n#\n#    [zookeeper.tls]\n#    ca = \n/etc/ssl/ca.crt\n\n#    cert = \n/etc/ssl/zookeeper.crt\n\n#    key = \n/etc/ssl/zookeeper.key\n\n#    insecureskipverify = true\n\n\n\n\nTo enable constraints see \nbackend-specific constraints section\n.\n\n\nPlease refer to the \nKey Value storage structure\n section to get documentation on Traefik KV structure.", 
            "title": "Backend: Zookeeper"
        }, 
        {
            "location": "/configuration/backends/zookeeper/#zookeeper-backend", 
            "text": "Tr\u00e6fik can be configured to use Zookeeper as a backend configuration.  ################################################################\n# Zookeeper configuration backend\n################################################################\n\n# Enable Zookeeperconfiguration backend.\n[zookeeper]\n\n# Zookeeper server endpoint.\n#\n# Required\n# Default:  127.0.0.1:2181 \n#\nendpoint =  127.0.0.1:2181 \n\n# Enable watch Zookeeper changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n# Default:  traefik \n#\nprefix =  traefik \n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename =  zookeeper.tmpl \n\n# Use Zookeeper user/pass authentication.\n#\n# Optional\n#\n# username = foo\n# password = bar\n\n# Enable Zookeeper TLS connection.\n#\n# Optional\n#\n#    [zookeeper.tls]\n#    ca =  /etc/ssl/ca.crt \n#    cert =  /etc/ssl/zookeeper.crt \n#    key =  /etc/ssl/zookeeper.key \n#    insecureskipverify = true  To enable constraints see  backend-specific constraints section .  Please refer to the  Key Value storage structure  section to get documentation on Traefik KV structure.", 
            "title": "Zookeeper Backend"
        }, 
        {
            "location": "/configuration/api/", 
            "text": "API Definition\n\n\nConfiguration\n\n\n# API definition\n[api]\n  # Name of the related entry point\n  #\n  # Optional\n  # Default: \ntraefik\n\n  #\n  entryPoint = \ntraefik\n\n\n  # Enabled Dashboard\n  #\n  # Optional\n  # Default: true\n  #\n  dashboard = true\n\n  # Enable debug mode.\n  # This will install HTTP handlers to expose Go expvars under /debug/vars and\n  # pprof profiling data under /debug/pprof.\n  # Additionally, the log level will be set to DEBUG.\n  #\n  # Optional\n  # Default: false\n  #\n  debug = true\n\n\n\n\nFor more customization, see \nentry points\n documentation and \nexamples\n.\n\n\nWeb UI\n\n\n\n\n\n\nAPI\n\n\n\n\n\n\n\n\nPath\n\n\nMethod\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n/\n\n\nGET\n\n\nProvides a simple HTML frontend of Tr\u00e6fik\n\n\n\n\n\n\n/health\n\n\nGET\n\n\nJSON health metrics\n\n\n\n\n\n\n/api\n\n\nGET\n\n\nConfiguration for all providers\n\n\n\n\n\n\n/api/providers\n\n\nGET\n\n\nProviders\n\n\n\n\n\n\n/api/providers/{provider}\n\n\nGET\n, \nPUT\n\n\nGet or update provider (1)\n\n\n\n\n\n\n/api/providers/{provider}/backends\n\n\nGET\n\n\nList backends\n\n\n\n\n\n\n/api/providers/{provider}/backends/{backend}\n\n\nGET\n\n\nGet backend\n\n\n\n\n\n\n/api/providers/{provider}/backends/{backend}/servers\n\n\nGET\n\n\nList servers in backend\n\n\n\n\n\n\n/api/providers/{provider}/backends/{backend}/servers/{server}\n\n\nGET\n\n\nGet a server in a backend\n\n\n\n\n\n\n/api/providers/{provider}/frontends\n\n\nGET\n\n\nList frontends\n\n\n\n\n\n\n/api/providers/{provider}/frontends/{frontend}\n\n\nGET\n\n\nGet a frontend\n\n\n\n\n\n\n/api/providers/{provider}/frontends/{frontend}/routes\n\n\nGET\n\n\nList routes in a frontend\n\n\n\n\n\n\n/api/providers/{provider}/frontends/{frontend}/routes/{route}\n\n\nGET\n\n\nGet a route in a frontend\n\n\n\n\n\n\n\n\n1\n See \nRest\n for more information.\n\n\n\n\nWarning\n\n\nFor compatibility reason, when you activate the rest provider, you can use \nweb\n or \nrest\n as \nprovider\n value.\nBut be careful, in the configuration for all providers the key is still \nweb\n.\n\n\n\n\nAddress / Port\n\n\nYou can define a custom address/port like this:\n\n\ndefaultEntryPoints = [\nhttp\n]\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n\n  [entryPoints.foo]\n  address = \n:8082\n\n\n  [entryPoints.bar]\n  address = \n:8083\n\n\n[ping]\nentryPoint = \nfoo\n\n\n[api]\nentryPoint = \nbar\n\n\n\n\n\nIn the above example, you would access a regular path, administration panel, and health-check as follows:\n\n\n\n\nRegular path: \nhttp://hostname:80/path\n\n\nAdmin Panel: \nhttp://hostname:8083/\n\n\nPing URL: \nhttp://hostname:8082/ping\n\n\n\n\nIn the above example, it is \nvery\n important to create a named dedicated entry point, and do \nnot\n include it in \ndefaultEntryPoints\n.\nOtherwise, you are likely to expose \nall\n services via that entry point.\n\n\nCustom Path\n\n\nYou can define a custom path like this:\n\n\ndefaultEntryPoints = [\nhttp\n]\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n\n  [entryPoints.foo]\n  address = \n:8080\n\n\n  [entryPoints.bar]\n  address = \n:8081\n\n\n# Activate API and Dashboard\n[api]\nentryPoint = \nbar\n\ndashboard = true\n\n[file]\n  [backends]\n    [backends.backend1]\n      [backends.backend1.servers.server1]\n      url = \nhttp://127.0.0.1:8081\n\n\n  [frontends]\n    [frontends.frontend1]\n    entryPoints = [\nfoo\n]\n    backend = \nbackend1\n\n      [frontends.frontend1.routes.test_1]\n      rule = \nPathPrefixStrip:/yourprefix;PathPrefix:/yourprefix\n\n\n\n\n\nAuthentication\n\n\nYou can define the authentication like this:\n\n\ndefaultEntryPoints = [\nhttp\n]\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n\n [entryPoints.foo]\n   address=\n:8080\n\n   [entryPoints.foo.auth]\n     [entryPoints.foo.auth.basic]\n       users = [\n         \ntest:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/\n,\n         \ntest2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0\n,\n       ]\n\n[api]\nentrypoint=\nfoo\n\n\n\n\n\nFor more information, see \nentry points\n .\n\n\nProvider call example\n\n\ncurl -s \nhttp://localhost:8080/api\n | jq .\n\n\n\n\n{\n  \nfile\n: {\n    \nfrontends\n: {\n      \nfrontend2\n: {\n        \nroutes\n: {\n          \ntest_2\n: {\n            \nrule\n: \nPath:/test\n\n          }\n        },\n        \nbackend\n: \nbackend1\n\n      },\n      \nfrontend1\n: {\n        \nroutes\n: {\n          \ntest_1\n: {\n            \nrule\n: \nHost:test.localhost\n\n          }\n        },\n        \nbackend\n: \nbackend2\n\n      }\n    },\n    \nbackends\n: {\n      \nbackend2\n: {\n        \nloadBalancer\n: {\n          \nmethod\n: \ndrr\n\n        },\n        \nservers\n: {\n          \nserver2\n: {\n            \nweight\n: 2,\n            \nURL\n: \nhttp://172.17.0.5:80\n\n          },\n          \nserver1\n: {\n            \nweight\n: 1,\n            \nurl\n: \nhttp://172.17.0.4:80\n\n          }\n        }\n      },\n      \nbackend1\n: {\n        \nloadBalancer\n: {\n          \nmethod\n: \nwrr\n\n        },\n        \ncircuitBreaker\n: {\n          \nexpression\n: \nNetworkErrorRatio() \n 0.5\n\n        },\n        \nservers\n: {\n          \nserver2\n: {\n            \nweight\n: 1,\n            \nurl\n: \nhttp://172.17.0.3:80\n\n          },\n          \nserver1\n: {\n            \nweight\n: 10,\n            \nurl\n: \nhttp://172.17.0.2:80\n\n          }\n        }\n      }\n    }\n  }\n}\n\n\n\n\nHealth\n\n\ncurl -s \nhttp://localhost:8080/health\n | jq .\n\n\n\n\n{\n  // Tr\u00e6fik PID\n  \npid\n: 2458,\n  // Tr\u00e6fik server uptime (formated time)\n  \nuptime\n: \n39m6.885931127s\n,\n  //  Tr\u00e6fik server uptime in seconds\n  \nuptime_sec\n: 2346.885931127,\n  // current server date\n  \ntime\n: \n2015-10-07 18:32:24.362238909 +0200 CEST\n,\n  // current server date in seconds\n  \nunixtime\n: 1444235544,\n  // count HTTP response status code in realtime\n  \nstatus_code_count\n: {\n    \n502\n: 1\n  },\n  // count HTTP response status code since Tr\u00e6fik started\n  \ntotal_status_code_count\n: {\n    \n200\n: 7,\n    \n404\n: 21,\n    \n502\n: 13\n  },\n  // count HTTP response\n  \ncount\n: 1,\n  // count HTTP response\n  \ntotal_count\n: 41,\n  // sum of all response time (formated time)\n  \ntotal_response_time\n: \n35.456865605s\n,\n  // sum of all response time in seconds\n  \ntotal_response_time_sec\n: 35.456865605,\n  // average response time (formated time)\n  \naverage_response_time\n: \n864.8016ms\n,\n  // average response time in seconds\n  \naverage_response_time_sec\n: 0.8648016000000001,\n\n  // request statistics [requires --statistics to be set]\n  // ten most recent requests with 4xx and 5xx status codes\n  \nrecent_errors\n: [\n    {\n      // status code\n      \nstatus_code\n: 500,\n      // description of status code\n      \nstatus\n: \nInternal Server Error\n,\n      // request HTTP method\n      \nmethod\n: \nGET\n,\n      // request hostname\n      \nhost\n: \nlocalhost\n,\n      // request path\n      \npath\n: \n/path\n,\n      // RFC 3339 formatted date/time\n      \ntime\n: \n2016-10-21T16:59:15.418495872-07:00\n\n    }\n  ]\n}\n\n\n\n\nMetrics\n\n\nYou can enable Traefik to export internal metrics to different monitoring systems.\n\n\n[api]\n  # ...\n\n  # Enable more detailed statistics.\n  [api.statistics]\n\n    # Number of recent errors logged.\n    #\n    # Default: 10\n    #\n    recentErrors = 10\n\n  # ...\n\n\n\n\n\n\n\n\n\n\nPath\n\n\nMethod\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n/metrics\n\n\nGET\n\n\nExport internal metrics", 
            "title": "API / Dashboard"
        }, 
        {
            "location": "/configuration/api/#api-definition", 
            "text": "", 
            "title": "API Definition"
        }, 
        {
            "location": "/configuration/api/#configuration", 
            "text": "# API definition\n[api]\n  # Name of the related entry point\n  #\n  # Optional\n  # Default:  traefik \n  #\n  entryPoint =  traefik \n\n  # Enabled Dashboard\n  #\n  # Optional\n  # Default: true\n  #\n  dashboard = true\n\n  # Enable debug mode.\n  # This will install HTTP handlers to expose Go expvars under /debug/vars and\n  # pprof profiling data under /debug/pprof.\n  # Additionally, the log level will be set to DEBUG.\n  #\n  # Optional\n  # Default: false\n  #\n  debug = true  For more customization, see  entry points  documentation and  examples .", 
            "title": "Configuration"
        }, 
        {
            "location": "/configuration/api/#web-ui", 
            "text": "", 
            "title": "Web UI"
        }, 
        {
            "location": "/configuration/api/#api", 
            "text": "Path  Method  Description      /  GET  Provides a simple HTML frontend of Tr\u00e6fik    /health  GET  JSON health metrics    /api  GET  Configuration for all providers    /api/providers  GET  Providers    /api/providers/{provider}  GET ,  PUT  Get or update provider (1)    /api/providers/{provider}/backends  GET  List backends    /api/providers/{provider}/backends/{backend}  GET  Get backend    /api/providers/{provider}/backends/{backend}/servers  GET  List servers in backend    /api/providers/{provider}/backends/{backend}/servers/{server}  GET  Get a server in a backend    /api/providers/{provider}/frontends  GET  List frontends    /api/providers/{provider}/frontends/{frontend}  GET  Get a frontend    /api/providers/{provider}/frontends/{frontend}/routes  GET  List routes in a frontend    /api/providers/{provider}/frontends/{frontend}/routes/{route}  GET  Get a route in a frontend     1  See  Rest  for more information.   Warning  For compatibility reason, when you activate the rest provider, you can use  web  or  rest  as  provider  value.\nBut be careful, in the configuration for all providers the key is still  web .", 
            "title": "API"
        }, 
        {
            "location": "/configuration/api/#address-port", 
            "text": "You can define a custom address/port like this:  defaultEntryPoints = [ http ]\n\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n\n  [entryPoints.foo]\n  address =  :8082 \n\n  [entryPoints.bar]\n  address =  :8083 \n\n[ping]\nentryPoint =  foo \n\n[api]\nentryPoint =  bar   In the above example, you would access a regular path, administration panel, and health-check as follows:   Regular path:  http://hostname:80/path  Admin Panel:  http://hostname:8083/  Ping URL:  http://hostname:8082/ping   In the above example, it is  very  important to create a named dedicated entry point, and do  not  include it in  defaultEntryPoints .\nOtherwise, you are likely to expose  all  services via that entry point.", 
            "title": "Address / Port"
        }, 
        {
            "location": "/configuration/api/#custom-path", 
            "text": "You can define a custom path like this:  defaultEntryPoints = [ http ]\n\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n\n  [entryPoints.foo]\n  address =  :8080 \n\n  [entryPoints.bar]\n  address =  :8081 \n\n# Activate API and Dashboard\n[api]\nentryPoint =  bar \ndashboard = true\n\n[file]\n  [backends]\n    [backends.backend1]\n      [backends.backend1.servers.server1]\n      url =  http://127.0.0.1:8081 \n\n  [frontends]\n    [frontends.frontend1]\n    entryPoints = [ foo ]\n    backend =  backend1 \n      [frontends.frontend1.routes.test_1]\n      rule =  PathPrefixStrip:/yourprefix;PathPrefix:/yourprefix", 
            "title": "Custom Path"
        }, 
        {
            "location": "/configuration/api/#authentication", 
            "text": "You can define the authentication like this:  defaultEntryPoints = [ http ]\n\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n\n [entryPoints.foo]\n   address= :8080 \n   [entryPoints.foo.auth]\n     [entryPoints.foo.auth.basic]\n       users = [\n          test:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/ ,\n          test2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0 ,\n       ]\n\n[api]\nentrypoint= foo   For more information, see  entry points  .", 
            "title": "Authentication"
        }, 
        {
            "location": "/configuration/api/#provider-call-example", 
            "text": "curl -s  http://localhost:8080/api  | jq .  {\n   file : {\n     frontends : {\n       frontend2 : {\n         routes : {\n           test_2 : {\n             rule :  Path:/test \n          }\n        },\n         backend :  backend1 \n      },\n       frontend1 : {\n         routes : {\n           test_1 : {\n             rule :  Host:test.localhost \n          }\n        },\n         backend :  backend2 \n      }\n    },\n     backends : {\n       backend2 : {\n         loadBalancer : {\n           method :  drr \n        },\n         servers : {\n           server2 : {\n             weight : 2,\n             URL :  http://172.17.0.5:80 \n          },\n           server1 : {\n             weight : 1,\n             url :  http://172.17.0.4:80 \n          }\n        }\n      },\n       backend1 : {\n         loadBalancer : {\n           method :  wrr \n        },\n         circuitBreaker : {\n           expression :  NetworkErrorRatio()   0.5 \n        },\n         servers : {\n           server2 : {\n             weight : 1,\n             url :  http://172.17.0.3:80 \n          },\n           server1 : {\n             weight : 10,\n             url :  http://172.17.0.2:80 \n          }\n        }\n      }\n    }\n  }\n}", 
            "title": "Provider call example"
        }, 
        {
            "location": "/configuration/api/#health", 
            "text": "curl -s  http://localhost:8080/health  | jq .  {\n  // Tr\u00e6fik PID\n   pid : 2458,\n  // Tr\u00e6fik server uptime (formated time)\n   uptime :  39m6.885931127s ,\n  //  Tr\u00e6fik server uptime in seconds\n   uptime_sec : 2346.885931127,\n  // current server date\n   time :  2015-10-07 18:32:24.362238909 +0200 CEST ,\n  // current server date in seconds\n   unixtime : 1444235544,\n  // count HTTP response status code in realtime\n   status_code_count : {\n     502 : 1\n  },\n  // count HTTP response status code since Tr\u00e6fik started\n   total_status_code_count : {\n     200 : 7,\n     404 : 21,\n     502 : 13\n  },\n  // count HTTP response\n   count : 1,\n  // count HTTP response\n   total_count : 41,\n  // sum of all response time (formated time)\n   total_response_time :  35.456865605s ,\n  // sum of all response time in seconds\n   total_response_time_sec : 35.456865605,\n  // average response time (formated time)\n   average_response_time :  864.8016ms ,\n  // average response time in seconds\n   average_response_time_sec : 0.8648016000000001,\n\n  // request statistics [requires --statistics to be set]\n  // ten most recent requests with 4xx and 5xx status codes\n   recent_errors : [\n    {\n      // status code\n       status_code : 500,\n      // description of status code\n       status :  Internal Server Error ,\n      // request HTTP method\n       method :  GET ,\n      // request hostname\n       host :  localhost ,\n      // request path\n       path :  /path ,\n      // RFC 3339 formatted date/time\n       time :  2016-10-21T16:59:15.418495872-07:00 \n    }\n  ]\n}", 
            "title": "Health"
        }, 
        {
            "location": "/configuration/api/#metrics", 
            "text": "You can enable Traefik to export internal metrics to different monitoring systems.  [api]\n  # ...\n\n  # Enable more detailed statistics.\n  [api.statistics]\n\n    # Number of recent errors logged.\n    #\n    # Default: 10\n    #\n    recentErrors = 10\n\n  # ...     Path  Method  Description      /metrics  GET  Export internal metrics", 
            "title": "Metrics"
        }, 
        {
            "location": "/configuration/ping/", 
            "text": "Ping Definition\n\n\nConfiguration\n\n\n# Ping definition\n[ping]\n  # Name of the related entry point\n  #\n  # Optional\n  # Default: \ntraefik\n\n  #\n  entryPoint = \ntraefik\n\n\n\n\n\n\n\n\n\n\n\nPath\n\n\nMethod\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n/ping\n\n\nGET\n, \nHEAD\n\n\nA simple endpoint to check for Tr\u00e6fik process liveness. Return a code \n200\n with the content: \nOK\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\nEven if you have authentication configured on entry point, the \n/ping\n path of the api is excluded from authentication.\n\n\n\n\nExamples\n\n\nThe \n/ping\n health-check URL is enabled with the command-line \n--ping\n or config file option \n[ping]\n.\nThus, if you have a regular path for \n/foo\n and an entrypoint on \n:80\n, you would access them as follows:\n\n\n\n\nRegular path: \nhttp://hostname:80/foo\n\n\nAdmin panel: \nhttp://hostname:8080/\n\n\nPing URL: \nhttp://hostname:8080/ping\n\n\n\n\nHowever, for security reasons, you may want to be able to expose the \n/ping\n health-check URL to outside health-checkers, e.g. an Internet service or cloud load-balancer, \nwithout\n exposing your administration panel's port.\nIn many environments, the security staff may not \nallow\n you to expose it.\n\n\nYou have two options:\n\n\n\n\nEnable \n/ping\n on a regular entry point\n\n\nEnable \n/ping\n on a dedicated port\n\n\n\n\nPing health check on a regular entry point\n\n\nTo proxy \n/ping\n from a regular entry point to the administration one without exposing the panel, do the following:\n\n\ndefaultEntryPoints = [\nhttp\n]\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n\n[ping]\nentryPoint = \nhttp\n\n\n\n\n\n\nThe above link \nping\n on the \nhttp\n entry point and then expose it on port \n80\n\n\nEnable ping health check on dedicated port\n\n\nIf you do not want to or cannot expose the health-check on a regular entry point - e.g. your security rules do not allow it, or you have a conflicting path - then you can enable health-check on its own entry point.\nUse the following configuration:\n\n\ndefaultEntryPoints = [\nhttp\n]\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.ping]\n  address = \n:8082\n\n\n[ping]\nentryPoint = \nping\n\n\n\n\n\nThe above is similar to the previous example, but instead of enabling \n/ping\n on the \ndefault\n entry point, we enable it on a \ndedicated\n entry point.\n\n\nIn the above example, you would access a regular path and health-check as follows:\n\n\n\n\nRegular path: \nhttp://hostname:80/foo\n\n\nPing URL: \nhttp://hostname:8082/ping\n\n\n\n\nNote the dedicated port \n:8082\n for \n/ping\n.\n\n\nIn the above example, it is \nvery\n important to create a named dedicated entry point, and do \nnot\n include it in \ndefaultEntryPoints\n.\nOtherwise, you are likely to expose \nall\n services via this entry point.", 
            "title": "Ping"
        }, 
        {
            "location": "/configuration/ping/#ping-definition", 
            "text": "", 
            "title": "Ping Definition"
        }, 
        {
            "location": "/configuration/ping/#configuration", 
            "text": "# Ping definition\n[ping]\n  # Name of the related entry point\n  #\n  # Optional\n  # Default:  traefik \n  #\n  entryPoint =  traefik      Path  Method  Description      /ping  GET ,  HEAD  A simple endpoint to check for Tr\u00e6fik process liveness. Return a code  200  with the content:  OK      Warning  Even if you have authentication configured on entry point, the  /ping  path of the api is excluded from authentication.", 
            "title": "Configuration"
        }, 
        {
            "location": "/configuration/ping/#examples", 
            "text": "The  /ping  health-check URL is enabled with the command-line  --ping  or config file option  [ping] .\nThus, if you have a regular path for  /foo  and an entrypoint on  :80 , you would access them as follows:   Regular path:  http://hostname:80/foo  Admin panel:  http://hostname:8080/  Ping URL:  http://hostname:8080/ping   However, for security reasons, you may want to be able to expose the  /ping  health-check URL to outside health-checkers, e.g. an Internet service or cloud load-balancer,  without  exposing your administration panel's port.\nIn many environments, the security staff may not  allow  you to expose it.  You have two options:   Enable  /ping  on a regular entry point  Enable  /ping  on a dedicated port", 
            "title": "Examples"
        }, 
        {
            "location": "/configuration/ping/#ping-health-check-on-a-regular-entry-point", 
            "text": "To proxy  /ping  from a regular entry point to the administration one without exposing the panel, do the following:  defaultEntryPoints = [ http ]\n\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n\n[ping]\nentryPoint =  http   The above link  ping  on the  http  entry point and then expose it on port  80", 
            "title": "Ping health check on a regular entry point"
        }, 
        {
            "location": "/configuration/ping/#enable-ping-health-check-on-dedicated-port", 
            "text": "If you do not want to or cannot expose the health-check on a regular entry point - e.g. your security rules do not allow it, or you have a conflicting path - then you can enable health-check on its own entry point.\nUse the following configuration:  defaultEntryPoints = [ http ]\n\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.ping]\n  address =  :8082 \n\n[ping]\nentryPoint =  ping   The above is similar to the previous example, but instead of enabling  /ping  on the  default  entry point, we enable it on a  dedicated  entry point.  In the above example, you would access a regular path and health-check as follows:   Regular path:  http://hostname:80/foo  Ping URL:  http://hostname:8082/ping   Note the dedicated port  :8082  for  /ping .  In the above example, it is  very  important to create a named dedicated entry point, and do  not  include it in  defaultEntryPoints .\nOtherwise, you are likely to expose  all  services via this entry point.", 
            "title": "Enable ping health check on dedicated port"
        }, 
        {
            "location": "/configuration/metrics/", 
            "text": "Metrics Definition\n\n\nPrometheus\n\n\n# Metrics definition\n[metrics]\n  #...\n\n  # To enable Traefik to export internal metrics to Prometheus\n  [metrics.prometheus]\n\n    # Name of the related entry point\n    #\n    # Optional\n    # Default: \ntraefik\n\n    #\n    entryPoint = \ntraefik\n\n\n    # Buckets for latency metrics\n    #\n    # Optional\n    # Default: [0.1, 0.3, 1.2, 5]\n    #\n    buckets = [0.1,0.3,1.2,5.0]\n\n  # ...\n\n\n\n\nDataDog\n\n\n# Metrics definition\n[metrics]\n  #...\n\n  # DataDog metrics exporter type\n  [metrics.datadog]\n\n    # DataDog's address.\n    #\n    # Required\n    # Default: \nlocalhost:8125\n\n    #\n    address = \nlocalhost:8125\n\n\n    # DataDog push interval\n    #\n    # Optional\n    # Default: \n10s\n\n    #\n    pushInterval = \n10s\n\n\n  # ...\n\n\n\n\nStatsD\n\n\n# Metrics definition\n[metrics]\n  #...\n\n  # StatsD metrics exporter type\n  [metrics.statsd]\n\n    # StatD's address.\n    #\n    # Required\n    # Default: \nlocalhost:8125\n\n    #\n    address = \nlocalhost:8125\n\n\n    # StatD push interval\n    #\n    # Optional\n    # Default: \n10s\n\n    #\n    pushInterval = \n10s\n\n\n  # ...\n\n\n\n\nInfluxDB\n\n\n[metrics]\n  # ...\n\n  # InfluxDB metrics exporter type\n  [metrics.influxdb]\n\n    # InfluxDB's address.\n    #\n    # Required\n    # Default: \nlocalhost:8089\n\n    #\n    address = \nlocalhost:8089\n\n\n    # InfluxDB push interval\n    #\n    # Optional\n    # Default: \n10s\n\n    #\n    pushinterval = \n10s\n\n\n  # ...\n\n\n\n\nStatistics\n\n\n# Metrics definition\n[metrics]\n  # ...\n\n  # Enable more detailed statistics.\n  [metrics.statistics]\n\n    # Number of recent errors logged.\n    #\n    # Default: 10\n    #\n    recentErrors = 10\n\n  # ...", 
            "title": "Metrics"
        }, 
        {
            "location": "/configuration/metrics/#metrics-definition", 
            "text": "", 
            "title": "Metrics Definition"
        }, 
        {
            "location": "/configuration/metrics/#prometheus", 
            "text": "# Metrics definition\n[metrics]\n  #...\n\n  # To enable Traefik to export internal metrics to Prometheus\n  [metrics.prometheus]\n\n    # Name of the related entry point\n    #\n    # Optional\n    # Default:  traefik \n    #\n    entryPoint =  traefik \n\n    # Buckets for latency metrics\n    #\n    # Optional\n    # Default: [0.1, 0.3, 1.2, 5]\n    #\n    buckets = [0.1,0.3,1.2,5.0]\n\n  # ...", 
            "title": "Prometheus"
        }, 
        {
            "location": "/configuration/metrics/#datadog", 
            "text": "# Metrics definition\n[metrics]\n  #...\n\n  # DataDog metrics exporter type\n  [metrics.datadog]\n\n    # DataDog's address.\n    #\n    # Required\n    # Default:  localhost:8125 \n    #\n    address =  localhost:8125 \n\n    # DataDog push interval\n    #\n    # Optional\n    # Default:  10s \n    #\n    pushInterval =  10s \n\n  # ...", 
            "title": "DataDog"
        }, 
        {
            "location": "/configuration/metrics/#statsd", 
            "text": "# Metrics definition\n[metrics]\n  #...\n\n  # StatsD metrics exporter type\n  [metrics.statsd]\n\n    # StatD's address.\n    #\n    # Required\n    # Default:  localhost:8125 \n    #\n    address =  localhost:8125 \n\n    # StatD push interval\n    #\n    # Optional\n    # Default:  10s \n    #\n    pushInterval =  10s \n\n  # ...", 
            "title": "StatsD"
        }, 
        {
            "location": "/configuration/metrics/#influxdb", 
            "text": "[metrics]\n  # ...\n\n  # InfluxDB metrics exporter type\n  [metrics.influxdb]\n\n    # InfluxDB's address.\n    #\n    # Required\n    # Default:  localhost:8089 \n    #\n    address =  localhost:8089 \n\n    # InfluxDB push interval\n    #\n    # Optional\n    # Default:  10s \n    #\n    pushinterval =  10s \n\n  # ...", 
            "title": "InfluxDB"
        }, 
        {
            "location": "/configuration/metrics/#statistics", 
            "text": "# Metrics definition\n[metrics]\n  # ...\n\n  # Enable more detailed statistics.\n  [metrics.statistics]\n\n    # Number of recent errors logged.\n    #\n    # Default: 10\n    #\n    recentErrors = 10\n\n  # ...", 
            "title": "Statistics"
        }, 
        {
            "location": "/user-guide/examples/", 
            "text": "Examples\n\n\nYou will find here some configuration examples of Tr\u00e6fik.\n\n\nHTTP only\n\n\ndefaultEntryPoints = [\nhttp\n]\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n\n\n\n\nHTTP + HTTPS (with SNI)\n\n\ndefaultEntryPoints = [\nhttp\n, \nhttps\n]\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile = \nintegration/fixtures/https/snitest.com.cert\n\n      keyFile = \nintegration/fixtures/https/snitest.com.key\n\n      [[entryPoints.https.tls.certificates]]\n      certFile = \nintegration/fixtures/https/snitest.org.cert\n\n      keyFile = \nintegration/fixtures/https/snitest.org.key\n\n\n\n\n\nNote that we can either give path to certificate file or directly the file content itself (\nlike in this TOML example\n).\n\n\nHTTP redirect on HTTPS\n\n\ndefaultEntryPoints = [\nhttp\n, \nhttps\n]\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n    [entryPoints.http.redirect]\n    entryPoint = \nhttps\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile = \nexamples/traefik.crt\n\n      keyFile = \nexamples/traefik.key\n\n\n\n\n\n\n\nNote\n\n\nPlease note that \nregex\n and \nreplacement\n do not have to be set in the \nredirect\n structure if an entrypoint is defined for the redirection (they will not be used in this case)\n\n\n\n\nLet's Encrypt support\n\n\n\n\nNote\n\n\nEven if \nTLS-SNI-01\n challenge is \ndisabled\n, for the moment, it stays the \nby default\n ACME Challenge in Tr\u00e6fik but all the examples use the \nHTTP-01\n challenge (except DNS challenge examples).\nIf \nTLS-SNI-01\n challenge is not re-enabled in the future, it we will be removed from Tr\u00e6fik.\n\n\n\n\nBasic example with HTTP challenge\n\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n\n[acme]\nemail = \ntest@traefik.io\n\nstorage = \nacme.json\n\ncaServer = \nhttp://172.18.0.1:4000/directory\n\nentryPoint = \nhttps\n\n  [acme.httpChallenge]\n  entryPoint = \nhttp\n\n\n[[acme.domains]]\n  main = \nlocal1.com\n\n  sans = [\ntest1.local1.com\n, \ntest2.local1.com\n]\n[[acme.domains]]\n  main = \nlocal2.com\n\n  sans = [\ntest1.local2.com\n, \ntest2x.local2.com\n]\n[[acme.domains]]\n  main = \nlocal3.com\n\n[[acme.domains]]\n  main = \nlocal4.com\n\n\n\n\n\nThis configuration allows generating Let's Encrypt certificates (thanks to \nHTTP-01\n challenge) for the four domains \nlocal[1-4].com\n with described SANs.\n\n\nTr\u00e6fik generates these certificates when it starts and it needs to be restart if new domains are added.\n\n\nOnHostRule option (with HTTP challenge)\n\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n\n[acme]\nemail = \ntest@traefik.io\n\nstorage = \nacme.json\n\nonHostRule = true\ncaServer = \nhttp://172.18.0.1:4000/directory\n\nentryPoint = \nhttps\n\n  [acme.httpChallenge]\n  entryPoint = \nhttp\n\n\n[[acme.domains]]\n  main = \nlocal1.com\n\n  sans = [\ntest1.local1.com\n, \ntest2.local1.com\n]\n[[acme.domains]]\n  main = \nlocal2.com\n\n  sans = [\ntest1.local2.com\n, \ntest2x.local2.com\n]\n[[acme.domains]]\n  main = \nlocal3.com\n\n[[acme.domains]]\n  main = \nlocal4.com\n\n\n\n\n\nThis configuration allows generating Let's Encrypt certificates (thanks to \nHTTP-01\n challenge) for the four domains \nlocal[1-4].com\n.\n\n\nTr\u00e6fik generates these certificates when it starts.\n\n\nIf a backend is added with a \nonHost\n rule, Tr\u00e6fik will automatically generate the Let's Encrypt certificate for the new domain (for frontends wired on the \nacme.entryPoint\n).\n\n\nOnDemand option (with HTTP challenge)\n\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n\n[acme]\nemail = \ntest@traefik.io\n\nstorage = \nacme.json\n\nonDemand = true\ncaServer = \nhttp://172.18.0.1:4000/directory\n\nentryPoint = \nhttps\n\n  [acme.httpChallenge]\n  entryPoint = \nhttp\n\n\n\n\n\nThis configuration allows generating a Let's Encrypt certificate (thanks to \nHTTP-01\n challenge) during the first HTTPS request on a new domain.\n\n\n\n\nNote\n\n\nThis option simplifies the configuration but :\n\n\n\n\nTLS handshakes will be slow when requesting a hostname certificate for the first time, which can lead to DDoS attacks.\n\n\nLet's Encrypt have rate limiting: https://letsencrypt.org/docs/rate-limits\n\n\n\n\nThat's why, it's better to use the \nonHostRule\n option if possible.\n\n\n\n\nDNS challenge\n\n\n[entryPoints]\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n\n[acme]\nemail = \ntest@traefik.io\n\nstorage = \nacme.json\n\ncaServer = \nhttp://172.18.0.1:4000/directory\n\nentryPoint = \nhttps\n\n  [acme.dnsChallenge]\n  provider = \ndigitalocean\n # DNS Provider name (cloudflare, OVH, gandi...)\n  delayBeforeCheck = 0\n\n[[acme.domains]]\n  main = \nlocal1.com\n\n  sans = [\ntest1.local1.com\n, \ntest2.local1.com\n]\n[[acme.domains]]\n  main = \nlocal2.com\n\n  sans = [\ntest1.local2.com\n, \ntest2x.local2.com\n]\n[[acme.domains]]\n  main = \nlocal3.com\n\n[[acme.domains]]\n  main = \nlocal4.com\n\n\n\n\n\nDNS challenge needs environment variables to be executed.\nThese variables have to be set on the machine/container which host Tr\u00e6fik.\n\n\nThese variables are described \nin this section\n.\n\n\nOnHostRule option and provided certificates (with HTTP challenge)\n\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile = \nexamples/traefik.crt\n\n      keyFile = \nexamples/traefik.key\n\n\n[acme]\nemail = \ntest@traefik.io\n\nstorage = \nacme.json\n\nonHostRule = true\ncaServer = \nhttp://172.18.0.1:4000/directory\n\nentryPoint = \nhttps\n\n  [acme.httpChallenge]\n  entryPoint = \nhttp\n\n\n\n\n\nTr\u00e6fik will only try to generate a Let's encrypt certificate (thanks to \nHTTP-01\n challenge) if the domain cannot be checked by the provided certificates.\n\n\nCluster mode\n\n\nPrerequisites\n\n\nBefore you use Let's Encrypt in a Traefik cluster, take a look to \nthe key-value store explanations\n and more precisely at \nthis section\n, which will describe how to migrate from a acme local storage \n(acme.json file)\n to a key-value store configuration.\n\n\nConfiguration\n\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n\n[acme]\nemail = \ntest@traefik.io\n\nstorage = \ntraefik/acme/account\n\ncaServer = \nhttp://172.18.0.1:4000/directory\n\nentryPoint = \nhttps\n\n\n[acme.httpChallenge]\n    entryPoint = \nhttp\n\n\n[[acme.domains]]\n  main = \nlocal1.com\n\n  sans = [\ntest1.local1.com\n, \ntest2.local1.com\n]\n[[acme.domains]]\n  main = \nlocal2.com\n\n  sans = [\ntest1.local2.com\n, \ntest2x.local2.com\n]\n[[acme.domains]]\n  main = \nlocal3.com\n\n[[acme.domains]]\n  main = \nlocal4.com\n\n\n[consul]\n  endpoint = \n127.0.0.1:8500\n\n  watch = true\n  prefix = \ntraefik\n\n\n\n\n\nThis configuration allows to use the key \ntraefik/acme/account\n to get/set Let's Encrypt certificates content.\nThe \nconsul\n provider contains the configuration.\n\n\n\n\nNote\n\n\nIt's possible to use others key-value store providers as described \nhere\n.\n\n\n\n\nOverride entrypoints in frontends\n\n\n[frontends]\n\n  [frontends.frontend1]\n  backend = \nbackend2\n\n    [frontends.frontend1.routes.test_1]\n    rule = \nHost:test.localhost\n\n\n  [frontends.frontend2]\n  backend = \nbackend1\n\n  passHostHeader = true\n  passTLSCert = true\n  entrypoints = [\nhttps\n] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule = \nHost:{subdomain:[a-z]+}.localhost\n\n\n  [frontends.frontend3]\n  entrypoints = [\nhttp\n, \nhttps\n] # overrides defaultEntryPoints\n  backend = \nbackend2\n\n  rule = \nPath:/test\n\n\n\n\n\nEnable Basic authentication in an entry point\n\n\nWith two user/pass:\n\n\n\n\ntest\n:\ntest\n\n\ntest2\n:\ntest2\n\n\n\n\nPasswords are encoded in MD5: you can use \nhtpasswd\n to generate them.\n\n\ndefaultEntryPoints = [\nhttp\n]\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.http.auth.basic]\n  users = [\ntest:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/\n, \ntest2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0\n]\n\n\n\n\nPass Authenticated user to application via headers\n\n\nProviding an authentication method as described above, it is possible to pass the user to the application\nvia a configurable header value.\n\n\ndefaultEntryPoints = [\nhttp\n]\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.http.auth]\n    headerField = \nX-WebAuth-User\n\n    [entryPoints.http.auth.basic]\n    users = [\ntest:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/\n, \ntest2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0\n]\n\n\n\n\nOverride the Traefik HTTP server IdleTimeout and/or throttle configurations from re-loading too quickly\n\n\nprovidersThrottleDuration = \n5s\n\n\n[respondingTimeouts]\nidleTimeout = \n360s", 
            "title": "Configuration Examples"
        }, 
        {
            "location": "/user-guide/examples/#examples", 
            "text": "You will find here some configuration examples of Tr\u00e6fik.", 
            "title": "Examples"
        }, 
        {
            "location": "/user-guide/examples/#http-only", 
            "text": "defaultEntryPoints = [ http ]\n\n[entryPoints]\n  [entryPoints.http]\n  address =  :80", 
            "title": "HTTP only"
        }, 
        {
            "location": "/user-guide/examples/#http-https-with-sni", 
            "text": "defaultEntryPoints = [ http ,  https ]\n\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile =  integration/fixtures/https/snitest.com.cert \n      keyFile =  integration/fixtures/https/snitest.com.key \n      [[entryPoints.https.tls.certificates]]\n      certFile =  integration/fixtures/https/snitest.org.cert \n      keyFile =  integration/fixtures/https/snitest.org.key   Note that we can either give path to certificate file or directly the file content itself ( like in this TOML example ).", 
            "title": "HTTP + HTTPS (with SNI)"
        }, 
        {
            "location": "/user-guide/examples/#http-redirect-on-https", 
            "text": "defaultEntryPoints = [ http ,  https ]\n\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n    [entryPoints.http.redirect]\n    entryPoint =  https \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile =  examples/traefik.crt \n      keyFile =  examples/traefik.key    Note  Please note that  regex  and  replacement  do not have to be set in the  redirect  structure if an entrypoint is defined for the redirection (they will not be used in this case)", 
            "title": "HTTP redirect on HTTPS"
        }, 
        {
            "location": "/user-guide/examples/#lets-encrypt-support", 
            "text": "Note  Even if  TLS-SNI-01  challenge is  disabled , for the moment, it stays the  by default  ACME Challenge in Tr\u00e6fik but all the examples use the  HTTP-01  challenge (except DNS challenge examples).\nIf  TLS-SNI-01  challenge is not re-enabled in the future, it we will be removed from Tr\u00e6fik.", 
            "title": "Let's Encrypt support"
        }, 
        {
            "location": "/user-guide/examples/#basic-example-with-http-challenge", 
            "text": "[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n\n[acme]\nemail =  test@traefik.io \nstorage =  acme.json \ncaServer =  http://172.18.0.1:4000/directory \nentryPoint =  https \n  [acme.httpChallenge]\n  entryPoint =  http \n\n[[acme.domains]]\n  main =  local1.com \n  sans = [ test1.local1.com ,  test2.local1.com ]\n[[acme.domains]]\n  main =  local2.com \n  sans = [ test1.local2.com ,  test2x.local2.com ]\n[[acme.domains]]\n  main =  local3.com \n[[acme.domains]]\n  main =  local4.com   This configuration allows generating Let's Encrypt certificates (thanks to  HTTP-01  challenge) for the four domains  local[1-4].com  with described SANs.  Tr\u00e6fik generates these certificates when it starts and it needs to be restart if new domains are added.", 
            "title": "Basic example with HTTP challenge"
        }, 
        {
            "location": "/user-guide/examples/#onhostrule-option-with-http-challenge", 
            "text": "[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n\n[acme]\nemail =  test@traefik.io \nstorage =  acme.json \nonHostRule = true\ncaServer =  http://172.18.0.1:4000/directory \nentryPoint =  https \n  [acme.httpChallenge]\n  entryPoint =  http \n\n[[acme.domains]]\n  main =  local1.com \n  sans = [ test1.local1.com ,  test2.local1.com ]\n[[acme.domains]]\n  main =  local2.com \n  sans = [ test1.local2.com ,  test2x.local2.com ]\n[[acme.domains]]\n  main =  local3.com \n[[acme.domains]]\n  main =  local4.com   This configuration allows generating Let's Encrypt certificates (thanks to  HTTP-01  challenge) for the four domains  local[1-4].com .  Tr\u00e6fik generates these certificates when it starts.  If a backend is added with a  onHost  rule, Tr\u00e6fik will automatically generate the Let's Encrypt certificate for the new domain (for frontends wired on the  acme.entryPoint ).", 
            "title": "OnHostRule option (with HTTP challenge)"
        }, 
        {
            "location": "/user-guide/examples/#ondemand-option-with-http-challenge", 
            "text": "[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n\n[acme]\nemail =  test@traefik.io \nstorage =  acme.json \nonDemand = true\ncaServer =  http://172.18.0.1:4000/directory \nentryPoint =  https \n  [acme.httpChallenge]\n  entryPoint =  http   This configuration allows generating a Let's Encrypt certificate (thanks to  HTTP-01  challenge) during the first HTTPS request on a new domain.   Note  This option simplifies the configuration but :   TLS handshakes will be slow when requesting a hostname certificate for the first time, which can lead to DDoS attacks.  Let's Encrypt have rate limiting: https://letsencrypt.org/docs/rate-limits   That's why, it's better to use the  onHostRule  option if possible.", 
            "title": "OnDemand option (with HTTP challenge)"
        }, 
        {
            "location": "/user-guide/examples/#dns-challenge", 
            "text": "[entryPoints]\n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n\n[acme]\nemail =  test@traefik.io \nstorage =  acme.json \ncaServer =  http://172.18.0.1:4000/directory \nentryPoint =  https \n  [acme.dnsChallenge]\n  provider =  digitalocean  # DNS Provider name (cloudflare, OVH, gandi...)\n  delayBeforeCheck = 0\n\n[[acme.domains]]\n  main =  local1.com \n  sans = [ test1.local1.com ,  test2.local1.com ]\n[[acme.domains]]\n  main =  local2.com \n  sans = [ test1.local2.com ,  test2x.local2.com ]\n[[acme.domains]]\n  main =  local3.com \n[[acme.domains]]\n  main =  local4.com   DNS challenge needs environment variables to be executed.\nThese variables have to be set on the machine/container which host Tr\u00e6fik.  These variables are described  in this section .", 
            "title": "DNS challenge"
        }, 
        {
            "location": "/user-guide/examples/#onhostrule-option-and-provided-certificates-with-http-challenge", 
            "text": "[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile =  examples/traefik.crt \n      keyFile =  examples/traefik.key \n\n[acme]\nemail =  test@traefik.io \nstorage =  acme.json \nonHostRule = true\ncaServer =  http://172.18.0.1:4000/directory \nentryPoint =  https \n  [acme.httpChallenge]\n  entryPoint =  http   Tr\u00e6fik will only try to generate a Let's encrypt certificate (thanks to  HTTP-01  challenge) if the domain cannot be checked by the provided certificates.", 
            "title": "OnHostRule option and provided certificates (with HTTP challenge)"
        }, 
        {
            "location": "/user-guide/examples/#cluster-mode", 
            "text": "", 
            "title": "Cluster mode"
        }, 
        {
            "location": "/user-guide/examples/#prerequisites", 
            "text": "Before you use Let's Encrypt in a Traefik cluster, take a look to  the key-value store explanations  and more precisely at  this section , which will describe how to migrate from a acme local storage  (acme.json file)  to a key-value store configuration.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/user-guide/examples/#configuration", 
            "text": "[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n\n[acme]\nemail =  test@traefik.io \nstorage =  traefik/acme/account \ncaServer =  http://172.18.0.1:4000/directory \nentryPoint =  https \n\n[acme.httpChallenge]\n    entryPoint =  http \n\n[[acme.domains]]\n  main =  local1.com \n  sans = [ test1.local1.com ,  test2.local1.com ]\n[[acme.domains]]\n  main =  local2.com \n  sans = [ test1.local2.com ,  test2x.local2.com ]\n[[acme.domains]]\n  main =  local3.com \n[[acme.domains]]\n  main =  local4.com \n\n[consul]\n  endpoint =  127.0.0.1:8500 \n  watch = true\n  prefix =  traefik   This configuration allows to use the key  traefik/acme/account  to get/set Let's Encrypt certificates content.\nThe  consul  provider contains the configuration.   Note  It's possible to use others key-value store providers as described  here .", 
            "title": "Configuration"
        }, 
        {
            "location": "/user-guide/examples/#override-entrypoints-in-frontends", 
            "text": "[frontends]\n\n  [frontends.frontend1]\n  backend =  backend2 \n    [frontends.frontend1.routes.test_1]\n    rule =  Host:test.localhost \n\n  [frontends.frontend2]\n  backend =  backend1 \n  passHostHeader = true\n  passTLSCert = true\n  entrypoints = [ https ] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule =  Host:{subdomain:[a-z]+}.localhost \n\n  [frontends.frontend3]\n  entrypoints = [ http ,  https ] # overrides defaultEntryPoints\n  backend =  backend2 \n  rule =  Path:/test", 
            "title": "Override entrypoints in frontends"
        }, 
        {
            "location": "/user-guide/examples/#enable-basic-authentication-in-an-entry-point", 
            "text": "With two user/pass:   test : test  test2 : test2   Passwords are encoded in MD5: you can use  htpasswd  to generate them.  defaultEntryPoints = [ http ]\n\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.http.auth.basic]\n  users = [ test:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/ ,  test2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0 ]", 
            "title": "Enable Basic authentication in an entry point"
        }, 
        {
            "location": "/user-guide/examples/#pass-authenticated-user-to-application-via-headers", 
            "text": "Providing an authentication method as described above, it is possible to pass the user to the application\nvia a configurable header value.  defaultEntryPoints = [ http ]\n\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.http.auth]\n    headerField =  X-WebAuth-User \n    [entryPoints.http.auth.basic]\n    users = [ test:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/ ,  test2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0 ]", 
            "title": "Pass Authenticated user to application via headers"
        }, 
        {
            "location": "/user-guide/examples/#override-the-traefik-http-server-idletimeout-andor-throttle-configurations-from-re-loading-too-quickly", 
            "text": "providersThrottleDuration =  5s \n\n[respondingTimeouts]\nidleTimeout =  360s", 
            "title": "Override the Traefik HTTP server IdleTimeout and/or throttle configurations from re-loading too quickly"
        }, 
        {
            "location": "/user-guide/swarm-mode/", 
            "text": "Docker Swarm (mode) cluster\n\n\nThis section explains how to create a multi-host docker cluster with swarm mode using \ndocker-machine\n and how to deploy Tr\u00e6fik on it.\n\n\nThe cluster consists of:\n\n\n\n\n3 servers\n\n\n1 manager\n\n\n2 workers\n\n\n1 \noverlay\n network (multi-host networking)\n\n\n\n\nPrerequisites\n\n\n\n\nYou will need to install \ndocker-machine\n\n\nYou will need the latest \nVirtualBox\n\n\n\n\nCluster provisioning\n\n\nFirst, let's create all the required nodes.\nIt's a shorter version of the \nswarm tutorial\n.\n\n\ndocker-machine create -d virtualbox manager\ndocker-machine create -d virtualbox worker1\ndocker-machine create -d virtualbox worker2\n\n\n\n\nThen, let's setup the cluster, in order:\n\n\n\n\ninitialize the cluster\n\n\nget the token for other host to join\n\n\non both workers, join the cluster with the token\n\n\n\n\ndocker-machine ssh manager \ndocker swarm init \\\n    --listen-addr $(docker-machine ip manager) \\\n    --advertise-addr $(docker-machine ip manager)\n\n\nexport worker_token=$(docker-machine ssh manager \ndocker swarm \\\njoin-token worker -q\n)\n\ndocker-machine ssh worker1 \ndocker swarm join \\\n    --token=${worker_token} \\\n    --listen-addr $(docker-machine ip worker1) \\\n    --advertise-addr $(docker-machine ip worker1) \\\n    $(docker-machine ip manager)\n\n\ndocker-machine ssh worker2 \ndocker swarm join \\\n    --token=${worker_token} \\\n    --listen-addr $(docker-machine ip worker2) \\\n    --advertise-addr $(docker-machine ip worker2) \\\n    $(docker-machine ip manager)\n\n\n\n\n\nLet's validate the cluster is up and running.\n\n\ndocker-machine ssh manager docker node ls\n\n\n\n\nID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS\n013v16l1sbuwjqcn7ucbu4jwt    worker1   Ready   Active\n8buzkquycd17jqjber0mo2gn8    worker2   Ready   Active\nfnpj8ozfc85zvahx2r540xfcf *  manager   Ready   Active        Leader\n\n\n\n\nFinally, let's create a network for Tr\u00e6fik to use.\n\n\ndocker-machine ssh manager \ndocker network create --driver=overlay traefik-net\n\n\n\n\n\nDeploy Tr\u00e6fik\n\n\nLet's deploy Tr\u00e6fik as a docker service in our cluster.\nThe only requirement for Tr\u00e6fik to work with swarm mode is that it needs to run on a manager node - we are going to use a \nconstraint\n for that.\n\n\ndocker-machine ssh manager \ndocker service create \\\n    --name traefik \\\n    --constraint=node.role==manager \\\n    --publish 80:80 --publish 8080:8080 \\\n    --mount type=bind,source=/var/run/docker.sock,target=/var/run/docker.sock \\\n    --network traefik-net \\\n    traefik \\\n    --docker \\\n    --docker.swarmmode \\\n    --docker.domain=traefik \\\n    --docker.watch \\\n    --api\n\n\n\n\n\nLet's explain this command:\n\n\n\n\n\n\n\n\nOption\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n--publish 80:80 --publish 8080:8080\n\n\nwe publish port \n80\n and \n8080\n on the cluster.\n\n\n\n\n\n\n--constraint=node.role==manager\n\n\nwe ask docker to schedule Tr\u00e6fik on a manager node.\n\n\n\n\n\n\n--mount type=bind,source=/var/run/docker.sock,target=/var/run/docker.sock\n\n\nwe bind mount the docker socket where Tr\u00e6fik is scheduled to be able to speak to the daemon.\n\n\n\n\n\n\n--network traefik-net\n\n\nwe attach the Tr\u00e6fik service (and thus the underlying container) to the \ntraefik-net\n network.\n\n\n\n\n\n\n--docker\n\n\nenable docker backend, and \n--docker.swarmmode\n to enable the swarm mode on Tr\u00e6fik.\n\n\n\n\n\n\n`--api\n\n\nactivate the webUI on port 8080\n\n\n\n\n\n\n\n\nDeploy your apps\n\n\nWe can now deploy our app on the cluster, here \nwhoami\n, a simple web server in Go.\nWe start 2 services, on the \ntraefik-net\n network.\n\n\ndocker-machine ssh manager \ndocker service create \\\n    --name whoami0 \\\n    --label traefik.port=80 \\\n    --network traefik-net \\\n    emilevauge/whoami\n\n\ndocker-machine ssh manager \ndocker service create \\\n    --name whoami1 \\\n    --label traefik.port=80 \\\n    --network traefik-net \\\n    --label traefik.backend.loadbalancer.sticky=true \\\n    emilevauge/whoami\n\n\n\n\n\n\n\nNote\n\n\nWe set \nwhoami1\n to use sticky sessions (\n--label traefik.backend.loadbalancer.stickiness=true\n).\nWe'll demonstrate that later.\n\n\n\n\n\n\nNote\n\n\nIf using \ndocker stack deploy\n, there is \na specific way that the labels must be defined in the docker-compose file\n.\n\n\n\n\nCheck that everything is scheduled and started:\n\n\ndocker-machine ssh manager \ndocker service ls\n\n\n\n\n\nID            NAME     MODE        REPLICAS  IMAGE                     PORTS\nmoq3dq4xqv6t  traefik  replicated  1/1       traefik:latest            *:80-\n80/tcp,*:8080-\n8080/tcp\nysil6oto1wim  whoami0  replicated  1/1       emilevauge/whoami:latest\nz9re2mnl34k4  whoami1  replicated  1/1       emilevauge/whoami:latest\n\n\n\n\nAccess to your apps through Tr\u00e6fik\n\n\ncurl -H Host:whoami0.traefik http://$(docker-machine ip manager)\n\n\n\n\nHostname: 5b0b3d148359\nIP: 127.0.0.1\nIP: 10.0.0.8\nIP: 10.0.0.4\nIP: 172.18.0.5\nGET / HTTP/1.1\nHost: whoami0.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 10.255.0.2\nX-Forwarded-Host: whoami0.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4\n\n\n\n\ncurl -H Host:whoami1.traefik http://$(docker-machine ip manager)\n\n\n\n\nHostname: 3633163970f6\nIP: 127.0.0.1\nIP: 10.0.0.14\nIP: 10.0.0.6\nIP: 172.18.0.5\nGET / HTTP/1.1\nHost: whoami1.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 10.255.0.2\nX-Forwarded-Host: whoami1.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4\n\n\n\n\n\n\nNote\n\n\nAs Tr\u00e6fik is published, you can access it from any machine and not only the manager.\n\n\n\n\ncurl -H Host:whoami0.traefik http://$(docker-machine ip worker1)\n\n\n\n\nHostname: 5b0b3d148359\nIP: 127.0.0.1\nIP: 10.0.0.8\nIP: 10.0.0.4\nIP: 172.18.0.5\nGET / HTTP/1.1\nHost: whoami0.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 10.255.0.3\nX-Forwarded-Host: whoami0.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4\n\n\n\n\ncurl -H Host:whoami1.traefik http://$(docker-machine ip worker2)\n\n\n\n\nHostname: 3633163970f6\nIP: 127.0.0.1\nIP: 10.0.0.14\nIP: 10.0.0.6\nIP: 172.18.0.5\nGET / HTTP/1.1\nHost: whoami1.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 10.255.0.4\nX-Forwarded-Host: whoami1.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4\n\n\n\n\nScale both services\n\n\ndocker-machine ssh manager \ndocker service scale whoami0=5\n\ndocker-machine ssh manager \ndocker service scale whoami1=5\n\n\n\n\n\nCheck that we now have 5 replicas of each \nwhoami\n service:\n\n\ndocker-machine ssh manager \ndocker service ls\n\n\n\n\n\nID            NAME     MODE        REPLICAS  IMAGE                     PORTS\nmoq3dq4xqv6t  traefik  replicated  1/1       traefik:latest            *:80-\n80/tcp,*:8080-\n8080/tcp\nysil6oto1wim  whoami0  replicated  5/5       emilevauge/whoami:latest\nz9re2mnl34k4  whoami1  replicated  5/5       emilevauge/whoami:latest\n\n\n\n\nAccess to your \nwhoami0\n through Tr\u00e6fik multiple times.\n\n\nRepeat the following command multiple times and note that the Hostname changes each time as Traefik load balances each request against the 5 tasks:\n\n\ncurl -H Host:whoami0.traefik http://$(docker-machine ip manager)\n\n\n\n\nHostname: f3138d15b567\nIP: 127.0.0.1\nIP: 10.0.0.5\nIP: 10.0.0.4\nIP: 172.18.0.3\nGET / HTTP/1.1\nHost: whoami0.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 10.255.0.2\nX-Forwarded-Host: whoami0.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4\n\n\n\n\nDo the same against \nwhoami1\n:\n\n\ncurl -c cookies.txt -H Host:whoami1.traefik http://$(docker-machine ip manager)\n\n\n\n\nHostname: 348e2f7bf432\nIP: 127.0.0.1\nIP: 10.0.0.15\nIP: 10.0.0.6\nIP: 172.18.0.6\nGET / HTTP/1.1\nHost: whoami1.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 10.255.0.2\nX-Forwarded-Host: whoami1.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4\n\n\n\n\nBecause the sticky sessions require cookies to work, we used the \n-c cookies.txt\n option to store the cookie into a file.\nThe cookie contains the IP of the container to which the session sticks:\n\n\ncat ./cookies.txt\n\n\n\n\n# Netscape HTTP Cookie File\n# https://curl.haxx.se/docs/http-cookies.html\n# This file was generated by libcurl! Edit at your own risk.\n\nwhoami1.traefik FALSE  /  FALSE  0  _TRAEFIK_BACKEND  http://10.0.0.15:80\n\n\n\n\nIf you load the cookies file (\n-b cookies.txt\n) for the next request, you will see that stickiness is maintained:\n\n\ncurl -b cookies.txt -H Host:whoami1.traefik http://$(docker-machine ip manager)\n\n\n\n\nHostname: 348e2f7bf432\nIP: 127.0.0.1\nIP: 10.0.0.15\nIP: 10.0.0.6\nIP: 172.18.0.6\nGET / HTTP/1.1\nHost: whoami1.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nCookie: _TRAEFIK_BACKEND=http://10.0.0.15:80\nX-Forwarded-For: 10.255.0.2\nX-Forwarded-Host: whoami1.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4", 
            "title": "Swarm Mode Cluster"
        }, 
        {
            "location": "/user-guide/swarm-mode/#docker-swarm-mode-cluster", 
            "text": "This section explains how to create a multi-host docker cluster with swarm mode using  docker-machine  and how to deploy Tr\u00e6fik on it.  The cluster consists of:   3 servers  1 manager  2 workers  1  overlay  network (multi-host networking)", 
            "title": "Docker Swarm (mode) cluster"
        }, 
        {
            "location": "/user-guide/swarm-mode/#prerequisites", 
            "text": "You will need to install  docker-machine  You will need the latest  VirtualBox", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/user-guide/swarm-mode/#cluster-provisioning", 
            "text": "First, let's create all the required nodes.\nIt's a shorter version of the  swarm tutorial .  docker-machine create -d virtualbox manager\ndocker-machine create -d virtualbox worker1\ndocker-machine create -d virtualbox worker2  Then, let's setup the cluster, in order:   initialize the cluster  get the token for other host to join  on both workers, join the cluster with the token   docker-machine ssh manager  docker swarm init \\\n    --listen-addr $(docker-machine ip manager) \\\n    --advertise-addr $(docker-machine ip manager) \n\nexport worker_token=$(docker-machine ssh manager  docker swarm \\\njoin-token worker -q )\n\ndocker-machine ssh worker1  docker swarm join \\\n    --token=${worker_token} \\\n    --listen-addr $(docker-machine ip worker1) \\\n    --advertise-addr $(docker-machine ip worker1) \\\n    $(docker-machine ip manager) \n\ndocker-machine ssh worker2  docker swarm join \\\n    --token=${worker_token} \\\n    --listen-addr $(docker-machine ip worker2) \\\n    --advertise-addr $(docker-machine ip worker2) \\\n    $(docker-machine ip manager)   Let's validate the cluster is up and running.  docker-machine ssh manager docker node ls  ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS\n013v16l1sbuwjqcn7ucbu4jwt    worker1   Ready   Active\n8buzkquycd17jqjber0mo2gn8    worker2   Ready   Active\nfnpj8ozfc85zvahx2r540xfcf *  manager   Ready   Active        Leader  Finally, let's create a network for Tr\u00e6fik to use.  docker-machine ssh manager  docker network create --driver=overlay traefik-net", 
            "title": "Cluster provisioning"
        }, 
        {
            "location": "/user-guide/swarm-mode/#deploy-trfik", 
            "text": "Let's deploy Tr\u00e6fik as a docker service in our cluster.\nThe only requirement for Tr\u00e6fik to work with swarm mode is that it needs to run on a manager node - we are going to use a  constraint  for that.  docker-machine ssh manager  docker service create \\\n    --name traefik \\\n    --constraint=node.role==manager \\\n    --publish 80:80 --publish 8080:8080 \\\n    --mount type=bind,source=/var/run/docker.sock,target=/var/run/docker.sock \\\n    --network traefik-net \\\n    traefik \\\n    --docker \\\n    --docker.swarmmode \\\n    --docker.domain=traefik \\\n    --docker.watch \\\n    --api   Let's explain this command:     Option  Description      --publish 80:80 --publish 8080:8080  we publish port  80  and  8080  on the cluster.    --constraint=node.role==manager  we ask docker to schedule Tr\u00e6fik on a manager node.    --mount type=bind,source=/var/run/docker.sock,target=/var/run/docker.sock  we bind mount the docker socket where Tr\u00e6fik is scheduled to be able to speak to the daemon.    --network traefik-net  we attach the Tr\u00e6fik service (and thus the underlying container) to the  traefik-net  network.    --docker  enable docker backend, and  --docker.swarmmode  to enable the swarm mode on Tr\u00e6fik.    `--api  activate the webUI on port 8080", 
            "title": "Deploy Tr\u00e6fik"
        }, 
        {
            "location": "/user-guide/swarm-mode/#deploy-your-apps", 
            "text": "We can now deploy our app on the cluster, here  whoami , a simple web server in Go.\nWe start 2 services, on the  traefik-net  network.  docker-machine ssh manager  docker service create \\\n    --name whoami0 \\\n    --label traefik.port=80 \\\n    --network traefik-net \\\n    emilevauge/whoami \n\ndocker-machine ssh manager  docker service create \\\n    --name whoami1 \\\n    --label traefik.port=80 \\\n    --network traefik-net \\\n    --label traefik.backend.loadbalancer.sticky=true \\\n    emilevauge/whoami    Note  We set  whoami1  to use sticky sessions ( --label traefik.backend.loadbalancer.stickiness=true ).\nWe'll demonstrate that later.    Note  If using  docker stack deploy , there is  a specific way that the labels must be defined in the docker-compose file .   Check that everything is scheduled and started:  docker-machine ssh manager  docker service ls   ID            NAME     MODE        REPLICAS  IMAGE                     PORTS\nmoq3dq4xqv6t  traefik  replicated  1/1       traefik:latest            *:80- 80/tcp,*:8080- 8080/tcp\nysil6oto1wim  whoami0  replicated  1/1       emilevauge/whoami:latest\nz9re2mnl34k4  whoami1  replicated  1/1       emilevauge/whoami:latest", 
            "title": "Deploy your apps"
        }, 
        {
            "location": "/user-guide/swarm-mode/#access-to-your-apps-through-trfik", 
            "text": "curl -H Host:whoami0.traefik http://$(docker-machine ip manager)  Hostname: 5b0b3d148359\nIP: 127.0.0.1\nIP: 10.0.0.8\nIP: 10.0.0.4\nIP: 172.18.0.5\nGET / HTTP/1.1\nHost: whoami0.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 10.255.0.2\nX-Forwarded-Host: whoami0.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4  curl -H Host:whoami1.traefik http://$(docker-machine ip manager)  Hostname: 3633163970f6\nIP: 127.0.0.1\nIP: 10.0.0.14\nIP: 10.0.0.6\nIP: 172.18.0.5\nGET / HTTP/1.1\nHost: whoami1.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 10.255.0.2\nX-Forwarded-Host: whoami1.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4   Note  As Tr\u00e6fik is published, you can access it from any machine and not only the manager.   curl -H Host:whoami0.traefik http://$(docker-machine ip worker1)  Hostname: 5b0b3d148359\nIP: 127.0.0.1\nIP: 10.0.0.8\nIP: 10.0.0.4\nIP: 172.18.0.5\nGET / HTTP/1.1\nHost: whoami0.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 10.255.0.3\nX-Forwarded-Host: whoami0.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4  curl -H Host:whoami1.traefik http://$(docker-machine ip worker2)  Hostname: 3633163970f6\nIP: 127.0.0.1\nIP: 10.0.0.14\nIP: 10.0.0.6\nIP: 172.18.0.5\nGET / HTTP/1.1\nHost: whoami1.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 10.255.0.4\nX-Forwarded-Host: whoami1.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4", 
            "title": "Access to your apps through Tr\u00e6fik"
        }, 
        {
            "location": "/user-guide/swarm-mode/#scale-both-services", 
            "text": "docker-machine ssh manager  docker service scale whoami0=5 \ndocker-machine ssh manager  docker service scale whoami1=5   Check that we now have 5 replicas of each  whoami  service:  docker-machine ssh manager  docker service ls   ID            NAME     MODE        REPLICAS  IMAGE                     PORTS\nmoq3dq4xqv6t  traefik  replicated  1/1       traefik:latest            *:80- 80/tcp,*:8080- 8080/tcp\nysil6oto1wim  whoami0  replicated  5/5       emilevauge/whoami:latest\nz9re2mnl34k4  whoami1  replicated  5/5       emilevauge/whoami:latest", 
            "title": "Scale both services"
        }, 
        {
            "location": "/user-guide/swarm-mode/#access-to-your-whoami0-through-trfik-multiple-times", 
            "text": "Repeat the following command multiple times and note that the Hostname changes each time as Traefik load balances each request against the 5 tasks:  curl -H Host:whoami0.traefik http://$(docker-machine ip manager)  Hostname: f3138d15b567\nIP: 127.0.0.1\nIP: 10.0.0.5\nIP: 10.0.0.4\nIP: 172.18.0.3\nGET / HTTP/1.1\nHost: whoami0.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 10.255.0.2\nX-Forwarded-Host: whoami0.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4  Do the same against  whoami1 :  curl -c cookies.txt -H Host:whoami1.traefik http://$(docker-machine ip manager)  Hostname: 348e2f7bf432\nIP: 127.0.0.1\nIP: 10.0.0.15\nIP: 10.0.0.6\nIP: 172.18.0.6\nGET / HTTP/1.1\nHost: whoami1.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 10.255.0.2\nX-Forwarded-Host: whoami1.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4  Because the sticky sessions require cookies to work, we used the  -c cookies.txt  option to store the cookie into a file.\nThe cookie contains the IP of the container to which the session sticks:  cat ./cookies.txt  # Netscape HTTP Cookie File\n# https://curl.haxx.se/docs/http-cookies.html\n# This file was generated by libcurl! Edit at your own risk.\n\nwhoami1.traefik FALSE  /  FALSE  0  _TRAEFIK_BACKEND  http://10.0.0.15:80  If you load the cookies file ( -b cookies.txt ) for the next request, you will see that stickiness is maintained:  curl -b cookies.txt -H Host:whoami1.traefik http://$(docker-machine ip manager)  Hostname: 348e2f7bf432\nIP: 127.0.0.1\nIP: 10.0.0.15\nIP: 10.0.0.6\nIP: 172.18.0.6\nGET / HTTP/1.1\nHost: whoami1.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nCookie: _TRAEFIK_BACKEND=http://10.0.0.15:80\nX-Forwarded-For: 10.255.0.2\nX-Forwarded-Host: whoami1.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4", 
            "title": "Access to your whoami0 through Tr\u00e6fik multiple times."
        }, 
        {
            "location": "/user-guide/swarm/", 
            "text": "Swarm cluster\n\n\nThis section explains how to create a multi-host \nswarm\n cluster using \ndocker-machine\n and how to deploy Tr\u00e6fik on it.\n\n\nThe cluster consists of:\n\n\n\n\n2 servers\n\n\n1 swarm master\n\n\n2 swarm nodes\n\n\n1 \noverlay\n network (multi-host networking)\n\n\n\n\nPrerequisites\n\n\n\n\nYou need to install \ndocker-machine\n\n\nYou need the latest \nVirtualBox\n\n\n\n\nCluster provisioning\n\n\nWe first follow \nthis guide\n to create the cluster.\n\n\nCreate machine \nmh-keystore\n\n\nThis machine is the service registry of our cluster.\n\n\ndocker-machine create -d virtualbox mh-keystore\n\n\n\n\nThen we install the service registry \nConsul\n on this machine:\n\n\neval \n$(docker-machine env mh-keystore)\n\ndocker run -d \\\n    -p \n8500:8500\n \\\n    -h \nconsul\n \\\n    progrium/consul -server -bootstrap\n\n\n\n\nCreate machine \nmhs-demo0\n\n\nThis machine is a swarm master and a swarm agent on it.\n\n\ndocker-machine create -d virtualbox \\\n    --swarm --swarm-master \\\n    --swarm-discovery=\nconsul://$(docker-machine ip mh-keystore):8500\n \\\n    --engine-opt=\ncluster-store=consul://$(docker-machine ip mh-keystore):8500\n \\\n    --engine-opt=\ncluster-advertise=eth1:2376\n \\\n    mhs-demo0\n\n\n\n\nCreate machine \nmhs-demo1\n\n\nThis machine have a swarm agent on it.\n\n\ndocker-machine create -d virtualbox \\\n    --swarm \\\n    --swarm-discovery=\nconsul://$(docker-machine ip mh-keystore):8500\n \\\n    --engine-opt=\ncluster-store=consul://$(docker-machine ip mh-keystore):8500\n \\\n    --engine-opt=\ncluster-advertise=eth1:2376\n \\\n    mhs-demo1\n\n\n\n\nCreate the overlay Network\n\n\nCreate the overlay network on the swarm master:\n\n\neval $(docker-machine env --swarm mhs-demo0)\ndocker network create --driver overlay --subnet=10.0.9.0/24 my-net\n\n\n\n\nDeploy Tr\u00e6fik\n\n\nDeploy Tr\u00e6fik:\n\n\ndocker $(docker-machine config mhs-demo0) run \\\n    -d \\\n    -p 80:80 -p 8080:8080 \\\n    --net=my-net \\\n    -v /var/lib/boot2docker/:/ssl \\\n    traefik \\\n    -l DEBUG \\\n    -c /dev/null \\\n    --docker \\\n    --docker.domain=traefik \\\n    --docker.endpoint=tcp://$(docker-machine ip mhs-demo0):2376 \\\n    --docker.tls \\\n    --docker.tls.ca=/ssl/ca.pem \\\n    --docker.tls.cert=/ssl/server.pem \\\n    --docker.tls.key=/ssl/server-key.pem \\\n    --docker.tls.insecureSkipVerify \\\n    --docker.watch \\\n    --api\n\n\n\n\nLet's explain this command:\n\n\n\n\n\n\n\n\nOption\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n-p 80:80 -p 8080:8080\n\n\nwe bind ports 80 and 8080\n\n\n\n\n\n\n--net=my-net\n\n\nrun the container on the network my-net\n\n\n\n\n\n\n-v /var/lib/boot2docker/:/ssl\n\n\nmount the ssl keys generated by docker-machine\n\n\n\n\n\n\n-c /dev/null\n\n\nempty config file\n\n\n\n\n\n\n--docker\n\n\nenable docker backend\n\n\n\n\n\n\n--docker.endpoint=tcp://172.18.0.1:2376\n\n\nconnect to the swarm master using the docker_gwbridge network\n\n\n\n\n\n\n--docker.tls\n\n\nenable TLS using the docker-machine keys\n\n\n\n\n\n\n--api\n\n\nactivate the webUI on port 8080\n\n\n\n\n\n\n\n\nDeploy your apps\n\n\nWe can now deploy our app on the cluster, here \nwhoami\n, a simple web server in GO, on the network \nmy-net\n:\n\n\neval $(docker-machine env --swarm mhs-demo0)\ndocker run -d --name=whoami0 --net=my-net --env=\nconstraint:node==mhs-demo0\n emilevauge/whoami\ndocker run -d --name=whoami1 --net=my-net --env=\nconstraint:node==mhs-demo1\n emilevauge/whoami\n\n\n\n\nCheck that everything is started:\n\n\ndocker ps\n\n\n\n\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                                      NAMES\nba2c21488299        emilevauge/whoami   \n/whoamI\n                8 seconds ago       Up 9 seconds        80/tcp                                                     mhs-demo1/whoami1\n8147a7746e7a        emilevauge/whoami   \n/whoamI\n                19 seconds ago      Up 20 seconds       80/tcp                                                     mhs-demo0/whoami0\n8fbc39271b4c        traefik             \n/traefik -l DEBUG -c\n   36 seconds ago      Up 37 seconds       192.168.99.101:80-\n80/tcp, 192.168.99.101:8080-\n8080/tcp   mhs-demo0/serene_bhabha\n\n\n\n\nAccess to your apps through Tr\u00e6fik\n\n\ncurl -H Host:whoami0.traefik http://$(docker-machine ip mhs-demo0)\n\n\n\n\nHostname: 8147a7746e7a\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.3\nIP: fe80::42:aff:fe00:903\nIP: 172.18.0.3\nIP: fe80::42:acff:fe12:3\nGET / HTTP/1.1\nHost: 10.0.9.3:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.3:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c\n\n\n\n\ncurl -H Host:whoami1.traefik http://$(docker-machine ip mhs-demo0)\n\n\n\n\nHostname: ba2c21488299\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.4\nIP: fe80::42:aff:fe00:904\nIP: 172.18.0.2\nIP: fe80::42:acff:fe12:2\nGET / HTTP/1.1\nHost: 10.0.9.4:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.4:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c", 
            "title": "Swarm Cluster"
        }, 
        {
            "location": "/user-guide/swarm/#swarm-cluster", 
            "text": "This section explains how to create a multi-host  swarm  cluster using  docker-machine  and how to deploy Tr\u00e6fik on it.  The cluster consists of:   2 servers  1 swarm master  2 swarm nodes  1  overlay  network (multi-host networking)", 
            "title": "Swarm cluster"
        }, 
        {
            "location": "/user-guide/swarm/#prerequisites", 
            "text": "You need to install  docker-machine  You need the latest  VirtualBox", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/user-guide/swarm/#cluster-provisioning", 
            "text": "We first follow  this guide  to create the cluster.", 
            "title": "Cluster provisioning"
        }, 
        {
            "location": "/user-guide/swarm/#create-machine-mh-keystore", 
            "text": "This machine is the service registry of our cluster.  docker-machine create -d virtualbox mh-keystore  Then we install the service registry  Consul  on this machine:  eval  $(docker-machine env mh-keystore) \ndocker run -d \\\n    -p  8500:8500  \\\n    -h  consul  \\\n    progrium/consul -server -bootstrap", 
            "title": "Create machine mh-keystore"
        }, 
        {
            "location": "/user-guide/swarm/#create-machine-mhs-demo0", 
            "text": "This machine is a swarm master and a swarm agent on it.  docker-machine create -d virtualbox \\\n    --swarm --swarm-master \\\n    --swarm-discovery= consul://$(docker-machine ip mh-keystore):8500  \\\n    --engine-opt= cluster-store=consul://$(docker-machine ip mh-keystore):8500  \\\n    --engine-opt= cluster-advertise=eth1:2376  \\\n    mhs-demo0", 
            "title": "Create machine mhs-demo0"
        }, 
        {
            "location": "/user-guide/swarm/#create-machine-mhs-demo1", 
            "text": "This machine have a swarm agent on it.  docker-machine create -d virtualbox \\\n    --swarm \\\n    --swarm-discovery= consul://$(docker-machine ip mh-keystore):8500  \\\n    --engine-opt= cluster-store=consul://$(docker-machine ip mh-keystore):8500  \\\n    --engine-opt= cluster-advertise=eth1:2376  \\\n    mhs-demo1", 
            "title": "Create machine mhs-demo1"
        }, 
        {
            "location": "/user-guide/swarm/#create-the-overlay-network", 
            "text": "Create the overlay network on the swarm master:  eval $(docker-machine env --swarm mhs-demo0)\ndocker network create --driver overlay --subnet=10.0.9.0/24 my-net", 
            "title": "Create the overlay Network"
        }, 
        {
            "location": "/user-guide/swarm/#deploy-trfik", 
            "text": "Deploy Tr\u00e6fik:  docker $(docker-machine config mhs-demo0) run \\\n    -d \\\n    -p 80:80 -p 8080:8080 \\\n    --net=my-net \\\n    -v /var/lib/boot2docker/:/ssl \\\n    traefik \\\n    -l DEBUG \\\n    -c /dev/null \\\n    --docker \\\n    --docker.domain=traefik \\\n    --docker.endpoint=tcp://$(docker-machine ip mhs-demo0):2376 \\\n    --docker.tls \\\n    --docker.tls.ca=/ssl/ca.pem \\\n    --docker.tls.cert=/ssl/server.pem \\\n    --docker.tls.key=/ssl/server-key.pem \\\n    --docker.tls.insecureSkipVerify \\\n    --docker.watch \\\n    --api  Let's explain this command:     Option  Description      -p 80:80 -p 8080:8080  we bind ports 80 and 8080    --net=my-net  run the container on the network my-net    -v /var/lib/boot2docker/:/ssl  mount the ssl keys generated by docker-machine    -c /dev/null  empty config file    --docker  enable docker backend    --docker.endpoint=tcp://172.18.0.1:2376  connect to the swarm master using the docker_gwbridge network    --docker.tls  enable TLS using the docker-machine keys    --api  activate the webUI on port 8080", 
            "title": "Deploy Tr\u00e6fik"
        }, 
        {
            "location": "/user-guide/swarm/#deploy-your-apps", 
            "text": "We can now deploy our app on the cluster, here  whoami , a simple web server in GO, on the network  my-net :  eval $(docker-machine env --swarm mhs-demo0)\ndocker run -d --name=whoami0 --net=my-net --env= constraint:node==mhs-demo0  emilevauge/whoami\ndocker run -d --name=whoami1 --net=my-net --env= constraint:node==mhs-demo1  emilevauge/whoami  Check that everything is started:  docker ps  CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                                      NAMES\nba2c21488299        emilevauge/whoami    /whoamI                 8 seconds ago       Up 9 seconds        80/tcp                                                     mhs-demo1/whoami1\n8147a7746e7a        emilevauge/whoami    /whoamI                 19 seconds ago      Up 20 seconds       80/tcp                                                     mhs-demo0/whoami0\n8fbc39271b4c        traefik              /traefik -l DEBUG -c    36 seconds ago      Up 37 seconds       192.168.99.101:80- 80/tcp, 192.168.99.101:8080- 8080/tcp   mhs-demo0/serene_bhabha", 
            "title": "Deploy your apps"
        }, 
        {
            "location": "/user-guide/swarm/#access-to-your-apps-through-trfik", 
            "text": "curl -H Host:whoami0.traefik http://$(docker-machine ip mhs-demo0)  Hostname: 8147a7746e7a\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.3\nIP: fe80::42:aff:fe00:903\nIP: 172.18.0.3\nIP: fe80::42:acff:fe12:3\nGET / HTTP/1.1\nHost: 10.0.9.3:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.3:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c  curl -H Host:whoami1.traefik http://$(docker-machine ip mhs-demo0)  Hostname: ba2c21488299\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.4\nIP: fe80::42:aff:fe00:904\nIP: 172.18.0.2\nIP: fe80::42:acff:fe12:2\nGET / HTTP/1.1\nHost: 10.0.9.4:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.4:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c", 
            "title": "Access to your apps through Tr\u00e6fik"
        }, 
        {
            "location": "/user-guide/docker-and-lets-encrypt/", 
            "text": "Docker \n Traefik\n\n\nIn this use case, we want to use Tr\u00e6fik as a \nlayer-7\n load balancer with SSL termination for a set of micro-services used to run a web application.\n\n\nWe also want to automatically \ndiscover any services\n on the Docker host and let Tr\u00e6fik reconfigure itself automatically when containers get created (or shut down) so HTTP traffic can be routed accordingly.\n\n\nIn addition, we want to use Let's Encrypt to automatically generate and renew SSL certificates per hostname.\n\n\nSetting Up\n\n\nIn order for this to work, you'll need a server with a public IP address, with Docker installed on it.\n\n\nIn this example, we're using the fictitious domain \nmy-awesome-app.org\n.\n\n\nIn real-life, you'll want to use your own domain and have the DNS configured accordingly so the hostname records you'll want to use point to the aforementioned public IP address.\n\n\nNetworking\n\n\nDocker containers can only communicate with each other over TCP when they share at least one network.\nThis makes sense from a topological point of view in the context of networking, since Docker under the hood creates IPTable rules so containers can't reach other containers \nunless you'd want to\n.\n\n\nIn this example, we're going to use a single network called \nweb\n where all containers that are handling HTTP traffic (including Tr\u00e6fik) will reside in.\n\n\nOn the Docker host, run the following command:\n\n\ndocker network create web\n\n\n\n\nNow, let's create a directory on the server where we will configure the rest of Tr\u00e6fik:\n\n\nmkdir -p /opt/traefik\n\n\n\n\nWithin this directory, we're going to create 3 empty files:\n\n\ntouch /opt/traefik/docker-compose.yml\ntouch /opt/traefik/acme.json \n chmod 600 /opt/traefik/acme.json\ntouch /opt/traefik/traefik.toml\n\n\n\n\nThe \ndocker-compose.yml\n file will provide us with a simple, consistent and more importantly, a deterministic way to create Tr\u00e6fik.\n\n\nThe contents of the file is as follows:\n\n\nversion: '2'\n\nservices:\n  traefik:\n    image: traefik:1.5.4\n    restart: always\n    ports:\n      - 80:80\n      - 443:443\n    networks:\n      - web\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n      - /opt/traefik/traefik.toml:/traefik.toml\n      - /opt/traefik/acme.json:/acme.json\n    container_name: traefik\n\nnetworks:\n  web:\n    external: true\n\n\n\n\nAs you can see, we're mounting the \ntraefik.toml\n file as well as the (empty) \nacme.json\n file in the container.\n\nAlso, we're mounting the \n/var/run/docker.sock\n Docker socket in the container as well, so Tr\u00e6fik can listen to Docker events and reconfigure its own internal configuration when containers are created (or shut down).\n\nAlso, we're making sure the container is automatically restarted by the Docker engine in case of problems (or: if the server is rebooted).\nWe're publishing the default HTTP ports \n80\n and \n443\n on the host, and making sure the container is placed within the \nweb\n network we've created earlier on.\n\nFinally, we're giving this container a static name called \ntraefik\n.\n\n\nLet's take a look at a simple \ntraefik.toml\n configuration as well before we'll create the Tr\u00e6fik container:\n\n\ndebug = false\n\nlogLevel = \nERROR\n\ndefaultEntryPoints = [\nhttps\n,\nhttp\n]\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n    [entryPoints.http.redirect]\n    entryPoint = \nhttps\n\n  [entryPoints.https]\n  address = \n:443\n\n  [entryPoints.https.tls]\n\n[retry]\n\n[docker]\nendpoint = \nunix:///var/run/docker.sock\n\ndomain = \nmy-awesome-app.org\n\nwatch = true\nexposedbydefault = false\n\n[acme]\nemail = \nyour-email-here@my-awesome-app.org\n\nstorage = \nacme.json\n\nentryPoint = \nhttps\n\nOnHostRule = true\n[acme.httpChallenge]\nentryPoint = \nhttp\n\n\n\n\n\nThis is the minimum configuration required to do the following:\n\n\n\n\nLog \nERROR\n-level messages (or more severe) to the console, but silence \nDEBUG\n-level messages\n\n\nCheck for new versions of Tr\u00e6fik periodically\n\n\nCreate two entry points, namely an \nHTTP\n endpoint on port \n80\n, and an \nHTTPS\n endpoint on port \n443\n where all incoming traffic on port \n80\n will immediately get redirected to \nHTTPS\n.\n\n\nEnable the Docker configuration backend and listen for container events on the Docker unix socket we've mounted earlier. However, \nnew containers will not be exposed by Tr\u00e6fik by default, we'll get into this in a bit!\n\n\nEnable automatic request and configuration of SSL certificates using Let's Encrypt.\n    These certificates will be stored in the \nacme.json\n file, which you can back-up yourself and store off-premises.\n\n\n\n\nAlright, let's boot the container. From the \n/opt/traefik\n directory, run \ndocker-compose up -d\n which will create and start the Tr\u00e6fik container.\n\n\nExposing Web Services to the Outside World\n\n\nNow that we've fully configured and started Tr\u00e6fik, it's time to get our applications running!\n\n\nLet's take a simple example of a micro-service project consisting of various services, where some will be exposed to the outside world and some will not. \n\n\nThe \ndocker-compose.yml\n of our project looks like this:\n\n\nversion: \n2.1\n\n\nservices:\n  app:\n    image: my-docker-registry.com/my-awesome-app/app:latest\n    depends_on:\n      db:\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    restart: always\n    networks:\n      - web\n      - default\n    expose:\n      - \n9000\n\n    labels:\n      - \ntraefik.backend=my-awesome-app-app\n\n      - \ntraefik.docker.network=web\n\n      - \ntraefik.frontend.rule=Host:app.my-awesome-app.org\n\n      - \ntraefik.enable=true\n\n      - \ntraefik.port=9000\n\n      - \ntraefik.default.protocol=http\n\n      - \ntraefik.admin.frontend.rule=Host:admin-app.my-awesome-app.org\n\n      - \ntraefik.admin.protocol=https\n\n      - \ntraefik.admin.port=9443\n\n\n  db:\n    image: my-docker-registry.com/back-end/5.7\n    restart: always\n\n  redis:\n    image: my-docker-registry.com/back-end/redis:4-alpine\n    restart: always\n\n  events:\n    image: my-docker-registry.com/my-awesome-app/events:latest\n    depends_on:\n      db:\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    restart: always\n    networks:\n      - web\n      - default\n    expose:\n      - \n3000\n\n    labels:\n      - \ntraefik.backend=my-awesome-app-events\n\n      - \ntraefik.docker.network=web\n\n      - \ntraefik.frontend.rule=Host:events.my-awesome-app.org\n\n      - \ntraefik.enable=true\n\n      - \ntraefik.port=3000\n\n\nnetworks:\n  web:\n    external: true\n\n\n\n\nHere, we can see a set of services with two applications that we're actually exposing to the outside world.\n\nNotice how there isn't a single container that has any published ports to the host -- everything is routed through Docker networks.\n\nAlso, only the containers that we want traffic to get routed to are attached to the \nweb\n network we created at the start of this document.\n\n\nSince the \ntraefik\n container we've created and started earlier is also attached to this network, HTTP requests can now get routed to these containers.\n\n\nLabels\n\n\nAs mentioned earlier, we don't want containers exposed automatically by Tr\u00e6fik.\n\n\nThe reason behind this is simple: we want to have control over this process ourselves.\nThanks to Docker labels, we can tell Tr\u00e6fik how to create its internal routing configuration.\n\n\nLet's take a look at the labels themselves for the \napp\n service, which is a HTTP webservice listing on port 9000:\n\n\n- \ntraefik.backend=my-awesome-app-app\n\n- \ntraefik.docker.network=web\n\n- \ntraefik.frontend.rule=Host:app.my-awesome-app.org\n\n- \ntraefik.enable=true\n\n- \ntraefik.port=9000\n\n- \ntraefik.default.protocol=http\n\n- \ntraefik.admin.frontend.rule=Host:admin-app.my-awesome-app.org\n\n- \ntraefik.admin.protocol=https\n\n- \ntraefik.admin.port=9443\n\n\n\n\n\nWe use both \ncontainer labels\n and \nservice labels\n.\n\n\nContainer labels\n\n\nFirst, we specify the \nbackend\n name which corresponds to the actual service we're routing \nto\n.\n\n\nWe also tell Tr\u00e6fik to use the \nweb\n network to route HTTP traffic to this container. \nWith the \ntraefik.enable\n label, we tell Tr\u00e6fik to include this container in its internal configuration.\n\n\nWith the \nfrontend.rule\n label, we tell Tr\u00e6fik that we want to route to this container if the incoming HTTP request contains the \nHost\n \napp.my-awesome-app.org\n.\nEssentially, this is the actual rule used for Layer-7 load balancing. \n\n\nFinally but not unimportantly, we tell Tr\u00e6fik to route \nto\n port \n9000\n, since that is the actual TCP/IP port the container actually listens on.\n\n\nService labels\n\n\nService labels\n allow managing many routes for the same container.\n\n\nWhen both \ncontainer labels\n and \nservice labels\n are defined, \ncontainer labels\n are just used as default values for missing \nservice labels\n but no frontend/backend are going to be defined only with these labels.\nObviously, labels \ntraefik.frontend.rule\n and \ntraefik.port\n described above, will only be used to complete information set in \nservice labels\n during the container frontends/bakends creation.\n\n\nIn the example, two service names are defined : \ndefault\n and \nadmin\n.\nThey allow creating two frontends and two backends.\n\n\n\n\ndefault\n has only one \nservice label\n : \ntraefik.default.protocol\n.\nTr\u00e6fik will use values set in \ntraefik.frontend.rule\n and \ntraefik.port\n to create the \ndefault\n frontend and backend.\nThe frontend listens to incoming HTTP requests which contain the \nHost\n \napp.my-awesome-app.org\n and redirect them in \nHTTP\n to the port \n9000\n of the backend.\n\n\nadmin\n has all the \nservices labels\n needed to create the \nadmin\n frontend and backend (\ntraefik.admin.frontend.rule\n, \ntraefik.admin.protocol\n, \ntraefik.admin.port\n).\nTr\u00e6fik will create a frontend to listen to incoming HTTP requests which contain the \nHost\n \nadmin-app.my-awesome-app.org\n and redirect them in \nHTTPS\n to the port \n9443\n of the backend.\n\n\n\n\nGotchas and tips\n\n\n\n\nAlways specify the correct port where the container expects HTTP traffic using \ntraefik.port\n label.\n\n    If a container exposes multiple ports, Tr\u00e6fik may forward traffic to the wrong port.\n    Even if a container only exposes one port, you should always write configuration defensively and explicitly.\n\n\nShould you choose to enable the \nexposedbydefault\n flag in the \ntraefik.toml\n configuration, be aware that all containers that are placed in the same network as Tr\u00e6fik will automatically be reachable from the outside world, for everyone and everyone to see.\n    Usually, this is a bad idea.\n\n\nWith the \ntraefik.frontend.auth.basic\n label, it's possible for Tr\u00e6fik to provide a HTTP basic-auth challenge for the endpoints you provide the label for.\n\n\nTr\u00e6fik has built-in support to automatically export \nPrometheus\n metrics\n\n\nTr\u00e6fik supports websockets out of the box. In the example above, the \nevents\n-service could be a NodeJS-based application which allows clients to connect using websocket protocol.\n    Thanks to the fact that HTTPS in our example is enforced, these websockets are automatically secure as well (WSS)\n\n\n\n\nFinal thoughts\n\n\nUsing Tr\u00e6fik as a Layer-7 load balancer in combination with both Docker and Let's Encrypt provides you with an extremely flexible, powerful and self-configuring solution for your projects.\n\n\nWith Let's Encrypt, your endpoints are automatically secured with production-ready SSL certificates that are renewed automatically as well.", 
            "title": "Let's Encrypt & Docker"
        }, 
        {
            "location": "/user-guide/docker-and-lets-encrypt/#docker-traefik", 
            "text": "In this use case, we want to use Tr\u00e6fik as a  layer-7  load balancer with SSL termination for a set of micro-services used to run a web application.  We also want to automatically  discover any services  on the Docker host and let Tr\u00e6fik reconfigure itself automatically when containers get created (or shut down) so HTTP traffic can be routed accordingly.  In addition, we want to use Let's Encrypt to automatically generate and renew SSL certificates per hostname.", 
            "title": "Docker &amp; Traefik"
        }, 
        {
            "location": "/user-guide/docker-and-lets-encrypt/#setting-up", 
            "text": "In order for this to work, you'll need a server with a public IP address, with Docker installed on it.  In this example, we're using the fictitious domain  my-awesome-app.org .  In real-life, you'll want to use your own domain and have the DNS configured accordingly so the hostname records you'll want to use point to the aforementioned public IP address.", 
            "title": "Setting Up"
        }, 
        {
            "location": "/user-guide/docker-and-lets-encrypt/#networking", 
            "text": "Docker containers can only communicate with each other over TCP when they share at least one network.\nThis makes sense from a topological point of view in the context of networking, since Docker under the hood creates IPTable rules so containers can't reach other containers  unless you'd want to .  In this example, we're going to use a single network called  web  where all containers that are handling HTTP traffic (including Tr\u00e6fik) will reside in.  On the Docker host, run the following command:  docker network create web  Now, let's create a directory on the server where we will configure the rest of Tr\u00e6fik:  mkdir -p /opt/traefik  Within this directory, we're going to create 3 empty files:  touch /opt/traefik/docker-compose.yml\ntouch /opt/traefik/acme.json   chmod 600 /opt/traefik/acme.json\ntouch /opt/traefik/traefik.toml  The  docker-compose.yml  file will provide us with a simple, consistent and more importantly, a deterministic way to create Tr\u00e6fik.  The contents of the file is as follows:  version: '2'\n\nservices:\n  traefik:\n    image: traefik:1.5.4\n    restart: always\n    ports:\n      - 80:80\n      - 443:443\n    networks:\n      - web\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n      - /opt/traefik/traefik.toml:/traefik.toml\n      - /opt/traefik/acme.json:/acme.json\n    container_name: traefik\n\nnetworks:\n  web:\n    external: true  As you can see, we're mounting the  traefik.toml  file as well as the (empty)  acme.json  file in the container. \nAlso, we're mounting the  /var/run/docker.sock  Docker socket in the container as well, so Tr\u00e6fik can listen to Docker events and reconfigure its own internal configuration when containers are created (or shut down). \nAlso, we're making sure the container is automatically restarted by the Docker engine in case of problems (or: if the server is rebooted).\nWe're publishing the default HTTP ports  80  and  443  on the host, and making sure the container is placed within the  web  network we've created earlier on. \nFinally, we're giving this container a static name called  traefik .  Let's take a look at a simple  traefik.toml  configuration as well before we'll create the Tr\u00e6fik container:  debug = false\n\nlogLevel =  ERROR \ndefaultEntryPoints = [ https , http ]\n\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n    [entryPoints.http.redirect]\n    entryPoint =  https \n  [entryPoints.https]\n  address =  :443 \n  [entryPoints.https.tls]\n\n[retry]\n\n[docker]\nendpoint =  unix:///var/run/docker.sock \ndomain =  my-awesome-app.org \nwatch = true\nexposedbydefault = false\n\n[acme]\nemail =  your-email-here@my-awesome-app.org \nstorage =  acme.json \nentryPoint =  https \nOnHostRule = true\n[acme.httpChallenge]\nentryPoint =  http   This is the minimum configuration required to do the following:   Log  ERROR -level messages (or more severe) to the console, but silence  DEBUG -level messages  Check for new versions of Tr\u00e6fik periodically  Create two entry points, namely an  HTTP  endpoint on port  80 , and an  HTTPS  endpoint on port  443  where all incoming traffic on port  80  will immediately get redirected to  HTTPS .  Enable the Docker configuration backend and listen for container events on the Docker unix socket we've mounted earlier. However,  new containers will not be exposed by Tr\u00e6fik by default, we'll get into this in a bit!  Enable automatic request and configuration of SSL certificates using Let's Encrypt.\n    These certificates will be stored in the  acme.json  file, which you can back-up yourself and store off-premises.   Alright, let's boot the container. From the  /opt/traefik  directory, run  docker-compose up -d  which will create and start the Tr\u00e6fik container.", 
            "title": "Networking"
        }, 
        {
            "location": "/user-guide/docker-and-lets-encrypt/#exposing-web-services-to-the-outside-world", 
            "text": "Now that we've fully configured and started Tr\u00e6fik, it's time to get our applications running!  Let's take a simple example of a micro-service project consisting of various services, where some will be exposed to the outside world and some will not.   The  docker-compose.yml  of our project looks like this:  version:  2.1 \n\nservices:\n  app:\n    image: my-docker-registry.com/my-awesome-app/app:latest\n    depends_on:\n      db:\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    restart: always\n    networks:\n      - web\n      - default\n    expose:\n      -  9000 \n    labels:\n      -  traefik.backend=my-awesome-app-app \n      -  traefik.docker.network=web \n      -  traefik.frontend.rule=Host:app.my-awesome-app.org \n      -  traefik.enable=true \n      -  traefik.port=9000 \n      -  traefik.default.protocol=http \n      -  traefik.admin.frontend.rule=Host:admin-app.my-awesome-app.org \n      -  traefik.admin.protocol=https \n      -  traefik.admin.port=9443 \n\n  db:\n    image: my-docker-registry.com/back-end/5.7\n    restart: always\n\n  redis:\n    image: my-docker-registry.com/back-end/redis:4-alpine\n    restart: always\n\n  events:\n    image: my-docker-registry.com/my-awesome-app/events:latest\n    depends_on:\n      db:\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    restart: always\n    networks:\n      - web\n      - default\n    expose:\n      -  3000 \n    labels:\n      -  traefik.backend=my-awesome-app-events \n      -  traefik.docker.network=web \n      -  traefik.frontend.rule=Host:events.my-awesome-app.org \n      -  traefik.enable=true \n      -  traefik.port=3000 \n\nnetworks:\n  web:\n    external: true  Here, we can see a set of services with two applications that we're actually exposing to the outside world. \nNotice how there isn't a single container that has any published ports to the host -- everything is routed through Docker networks. \nAlso, only the containers that we want traffic to get routed to are attached to the  web  network we created at the start of this document.  Since the  traefik  container we've created and started earlier is also attached to this network, HTTP requests can now get routed to these containers.", 
            "title": "Exposing Web Services to the Outside World"
        }, 
        {
            "location": "/user-guide/docker-and-lets-encrypt/#labels", 
            "text": "As mentioned earlier, we don't want containers exposed automatically by Tr\u00e6fik.  The reason behind this is simple: we want to have control over this process ourselves.\nThanks to Docker labels, we can tell Tr\u00e6fik how to create its internal routing configuration.  Let's take a look at the labels themselves for the  app  service, which is a HTTP webservice listing on port 9000:  -  traefik.backend=my-awesome-app-app \n-  traefik.docker.network=web \n-  traefik.frontend.rule=Host:app.my-awesome-app.org \n-  traefik.enable=true \n-  traefik.port=9000 \n-  traefik.default.protocol=http \n-  traefik.admin.frontend.rule=Host:admin-app.my-awesome-app.org \n-  traefik.admin.protocol=https \n-  traefik.admin.port=9443   We use both  container labels  and  service labels .", 
            "title": "Labels"
        }, 
        {
            "location": "/user-guide/docker-and-lets-encrypt/#container-labels", 
            "text": "First, we specify the  backend  name which corresponds to the actual service we're routing  to .  We also tell Tr\u00e6fik to use the  web  network to route HTTP traffic to this container. \nWith the  traefik.enable  label, we tell Tr\u00e6fik to include this container in its internal configuration.  With the  frontend.rule  label, we tell Tr\u00e6fik that we want to route to this container if the incoming HTTP request contains the  Host   app.my-awesome-app.org .\nEssentially, this is the actual rule used for Layer-7 load balancing.   Finally but not unimportantly, we tell Tr\u00e6fik to route  to  port  9000 , since that is the actual TCP/IP port the container actually listens on.", 
            "title": "Container labels"
        }, 
        {
            "location": "/user-guide/docker-and-lets-encrypt/#service-labels", 
            "text": "Service labels  allow managing many routes for the same container.  When both  container labels  and  service labels  are defined,  container labels  are just used as default values for missing  service labels  but no frontend/backend are going to be defined only with these labels.\nObviously, labels  traefik.frontend.rule  and  traefik.port  described above, will only be used to complete information set in  service labels  during the container frontends/bakends creation.  In the example, two service names are defined :  default  and  admin .\nThey allow creating two frontends and two backends.   default  has only one  service label  :  traefik.default.protocol .\nTr\u00e6fik will use values set in  traefik.frontend.rule  and  traefik.port  to create the  default  frontend and backend.\nThe frontend listens to incoming HTTP requests which contain the  Host   app.my-awesome-app.org  and redirect them in  HTTP  to the port  9000  of the backend.  admin  has all the  services labels  needed to create the  admin  frontend and backend ( traefik.admin.frontend.rule ,  traefik.admin.protocol ,  traefik.admin.port ).\nTr\u00e6fik will create a frontend to listen to incoming HTTP requests which contain the  Host   admin-app.my-awesome-app.org  and redirect them in  HTTPS  to the port  9443  of the backend.", 
            "title": "Service labels"
        }, 
        {
            "location": "/user-guide/docker-and-lets-encrypt/#gotchas-and-tips", 
            "text": "Always specify the correct port where the container expects HTTP traffic using  traefik.port  label. \n    If a container exposes multiple ports, Tr\u00e6fik may forward traffic to the wrong port.\n    Even if a container only exposes one port, you should always write configuration defensively and explicitly.  Should you choose to enable the  exposedbydefault  flag in the  traefik.toml  configuration, be aware that all containers that are placed in the same network as Tr\u00e6fik will automatically be reachable from the outside world, for everyone and everyone to see.\n    Usually, this is a bad idea.  With the  traefik.frontend.auth.basic  label, it's possible for Tr\u00e6fik to provide a HTTP basic-auth challenge for the endpoints you provide the label for.  Tr\u00e6fik has built-in support to automatically export  Prometheus  metrics  Tr\u00e6fik supports websockets out of the box. In the example above, the  events -service could be a NodeJS-based application which allows clients to connect using websocket protocol.\n    Thanks to the fact that HTTPS in our example is enforced, these websockets are automatically secure as well (WSS)", 
            "title": "Gotchas and tips"
        }, 
        {
            "location": "/user-guide/docker-and-lets-encrypt/#final-thoughts", 
            "text": "Using Tr\u00e6fik as a Layer-7 load balancer in combination with both Docker and Let's Encrypt provides you with an extremely flexible, powerful and self-configuring solution for your projects.  With Let's Encrypt, your endpoints are automatically secured with production-ready SSL certificates that are renewed automatically as well.", 
            "title": "Final thoughts"
        }, 
        {
            "location": "/user-guide/kubernetes/", 
            "text": "Kubernetes Ingress Controller\n\n\nThis guide explains how to use Tr\u00e6fik as an Ingress controller for a Kubernetes cluster.\n\n\nIf you are not familiar with Ingresses in Kubernetes you might want to read the \nKubernetes user guide\n\n\nThe config files used in this guide can be found in the \nexamples directory\n\n\nPrerequisites\n\n\n\n\nA working Kubernetes cluster. If you want to follow along with this guide, you should setup \nminikube\n on your machine, as it is the quickest way to get a local Kubernetes cluster setup for experimentation and development.\n\n\n\n\n\n\nNote\n\n\nThe guide is likely not fully adequate for a production-ready setup.\n\n\n\n\n\n\nThe \nkubectl\n binary should be \ninstalled on your workstation\n.\n\n\n\n\nRole Based Access Control configuration (Kubernetes 1.6+ only)\n\n\nKubernetes introduces \nRole Based Access Control (RBAC)\n in 1.6+ to allow fine-grained control of Kubernetes resources and API.\n\n\nIf your cluster is configured with RBAC, you will need to authorize Tr\u00e6fik to use the Kubernetes API. There are two ways to set up the proper permission: Via namespace-specific RoleBindings or a single, global ClusterRoleBinding.\n\n\nRoleBindings per namespace enable to restrict granted permissions to the very namespaces only that Tr\u00e6fik is watching over, thereby following the least-privileges principle. This is the preferred approach if Tr\u00e6fik is not supposed to watch all namespaces, and the set of namespaces does not change dynamically. Otherwise, a single ClusterRoleBinding must be employed.\n\n\n\n\nNote\n\n\nRoleBindings per namespace are available in Tr\u00e6fik 1.5 and later. Please use ClusterRoleBindings for older versions.\n\n\n\n\nFor the sake of simplicity, this guide will use a ClusterRoleBinding:\n\n\n---\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: traefik-ingress-controller\nrules:\n  - apiGroups:\n      - \n\n    resources:\n      - services\n      - endpoints\n      - secrets\n    verbs:\n      - get\n      - list\n      - watch\n  - apiGroups:\n      - extensions\n    resources:\n      - ingresses\n    verbs:\n      - get\n      - list\n      - watch\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: traefik-ingress-controller\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: traefik-ingress-controller\nsubjects:\n- kind: ServiceAccount\n  name: traefik-ingress-controller\n  namespace: kube-system\n\n\n\n\nexamples/k8s/traefik-rbac.yaml\n\n\nkubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-rbac.yaml\n\n\n\n\nFor namespaced restrictions, one RoleBinding is required per watched namespace along with a corresponding configuration of Tr\u00e6fik's \nkubernetes.namespaces\n parameter.\n\n\nDeploy Tr\u00e6fik using a Deployment or DaemonSet\n\n\nIt is possible to use Tr\u00e6fik with a \nDeployment\n or a \nDaemonSet\n object,\n whereas both options have their own pros and cons:\n\n\n\n\nThe scalability is much better when using a Deployment, because you will have a Single-Pod-per-Node model when using the DeaemonSet.\n\n\nIt is possible to exclusively run a Service on a dedicated set of machines using taints and tolerations with a DaemonSet.\n\n\nOn the other hand the DaemonSet allows you to access any Node directly on Port 80 and 443, where you have to setup a \nService\n object with a Deployment.\n\n\n\n\nThe Deployment objects looks like this:\n\n\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: traefik-ingress-controller\n  namespace: kube-system\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  name: traefik-ingress-controller\n  namespace: kube-system\n  labels:\n    k8s-app: traefik-ingress-lb\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: traefik-ingress-lb\n  template:\n    metadata:\n      labels:\n        k8s-app: traefik-ingress-lb\n        name: traefik-ingress-lb\n    spec:\n      serviceAccountName: traefik-ingress-controller\n      terminationGracePeriodSeconds: 60\n      containers:\n      - image: traefik\n        name: traefik-ingress-lb\n        args:\n        - --api\n        - --kubernetes\n---\nkind: Service\napiVersion: v1\nmetadata:\n  name: traefik-ingress-service\n  namespace: kube-system\nspec:\n  selector:\n    k8s-app: traefik-ingress-lb\n  ports:\n    - protocol: TCP\n      port: 80\n      name: web\n    - protocol: TCP\n      port: 8080\n      name: admin\n  type: NodePort\n\n\n\n\nexamples/k8s/traefik-deployment.yaml\n\n\n\n\nNote\n\n\nThe Service will expose two NodePorts which allow access to the ingress and the web interface.\n\n\n\n\nThe DaemonSet objects looks not much different:\n\n\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: traefik-ingress-controller\n  namespace: kube-system\n---\nkind: DaemonSet\napiVersion: extensions/v1beta1\nmetadata:\n  name: traefik-ingress-controller\n  namespace: kube-system\n  labels:\n    k8s-app: traefik-ingress-lb\nspec:\n  template:\n    metadata:\n      labels:\n        k8s-app: traefik-ingress-lb\n        name: traefik-ingress-lb\n    spec:\n      serviceAccountName: traefik-ingress-controller\n      terminationGracePeriodSeconds: 60\n      hostNetwork: true\n      containers:\n      - image: traefik\n        name: traefik-ingress-lb\n        ports:\n        - name: http\n          containerPort: 80\n          hostPort: 80\n        - name: admin\n          containerPort: 8080\n        securityContext:\n          privileged: true\n        args:\n        - --api\n        - --kubernetes\n        - --logLevel=INFO\n---\nkind: Service\napiVersion: v1\nmetadata:\n  name: traefik-ingress-service\n  namespace: kube-system\nspec:\n  selector:\n    k8s-app: traefik-ingress-lb\n  ports:\n    - protocol: TCP\n      port: 80\n      name: web\n    - protocol: TCP\n      port: 8080\n      name: admin\n  type: NodePort\n\n\n\n\nexamples/k8s/traefik-ds.yaml\n\n\nTo deploy Tr\u00e6fik to your cluster start by submitting one of the YAML files to the cluster with \nkubectl\n:\n\n\nkubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-deployment.yaml\n\n\n\n\nkubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-ds.yaml\n\n\n\n\nThere are some significant differences between using Deployments and DaemonSets:\n\n\n\n\nThe Deployment has easier up and down scaling possibilities.\n    It can implement full pod lifecycle and supports rolling updates from Kubernetes 1.2.\n    At least one Pod is needed to run the Deployment.\n\n\nThe DaemonSet automatically scales to all nodes that meets a specific selector and guarantees to fill nodes one at a time.\n    Rolling updates are fully supported from Kubernetes 1.7 for DaemonSets as well.\n\n\n\n\nCheck the Pods\n\n\nNow lets check if our command was successful.\n\n\nStart by listing the pods in the \nkube-system\n namespace:\n\n\nkubectl --namespace=kube-system get pods\n\n\n\n\nNAME                                         READY     STATUS    RESTARTS   AGE\nkube-addon-manager-minikubevm                1/1       Running   0          4h\nkubernetes-dashboard-s8krj                   1/1       Running   0          4h\ntraefik-ingress-controller-678226159-eqseo   1/1       Running   0          7m\n\n\n\n\nYou should see that after submitting the Deployment or DaemonSet to Kubernetes it has launched a Pod, and it is now running.\n\nIt might take a few moments for kubernetes to pull the Tr\u00e6fik image and start the container.\n\n\n\n\nNote\n\n\nYou could also check the deployment with the Kubernetes dashboard, run\n\nminikube dashboard\n to open it in your browser, then choose the \nkube-system\n\nnamespace from the menu at the top right of the screen.\n\n\n\n\nYou should now be able to access Tr\u00e6fik on port 80 of your Minikube instance when using the DaemonSet:\n\n\ncurl $(minikube ip)\n\n\n\n\n404 page not found\n\n\n\n\nIf you decided to use the deployment, then you need to target the correct NodePort, which can be seen when you execute \nkubectl get services --namespace=kube-system\n.\n\n\ncurl $(minikube ip):\nNODEPORT\n\n\n\n\n\n404 page not found\n\n\n\n\n\n\nNote\n\n\nWe expect to see a 404 response here as we haven't yet given Tr\u00e6fik any configuration.\n\n\n\n\nAll further examples below assume a DaemonSet installation. Deployment users will need to append the NodePort when constructing requests.\n\n\nDeploy Tr\u00e6fik using Helm Chart\n\n\n\n\nNote\n\n\nThe Helm Chart is maintained by the community, not the Traefik project maintainers.\n\n\n\n\nInstead of installing Tr\u00e6fik via Kubernetes object directly, you can also use the Tr\u00e6fik Helm chart.\n\n\nInstall the Tr\u00e6fik chart by:\n\n\nhelm install stable/traefik\n\n\n\n\nFor more information, check out \nthe documentation\n.\n\n\nSubmitting an Ingress to the Cluster\n\n\nLets start by creating a Service and an Ingress that will expose the \nTr\u00e6fik Web UI\n.\n\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: traefik-web-ui\n  namespace: kube-system\nspec:\n  selector:\n    k8s-app: traefik-ingress-lb\n  ports:\n  - port: 80\n    targetPort: 8080\n---\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: traefik-web-ui\n  namespace: kube-system\n  annotations:\n    kubernetes.io/ingress.class: traefik\nspec:\n  rules:\n  - host: traefik-ui.minikube\n    http:\n      paths:\n      - backend:\n          serviceName: traefik-web-ui\n          servicePort: 80\n\n\n\n\nexamples/k8s/ui.yaml\n\n\nkubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/ui.yaml\n\n\n\n\nNow lets setup an entry in our \n/etc/hosts\n file to route \ntraefik-ui.minikube\n to our cluster.\n\n\nIn production you would want to set up real DNS entries.\nYou can get the IP address of your minikube instance by running \nminikube ip\n:\n\n\necho \n$(minikube ip) traefik-ui.minikube\n | sudo tee -a /etc/hosts\n\n\n\n\nWe should now be able to visit \ntraefik-ui.minikube\n in the browser and view the Tr\u00e6fik web UI.\n\n\nBasic Authentication\n\n\nIt's possible to protect access to Traefik through basic authentication. (See the \nKubernetes Ingress\n configuration page for syntactical details and restrictions.)\n\n\nCreating the Secret\n\n\nA. Use \nhtpasswd\n to create a file containing the username and the base64-encoded password:\n\n\nhtpasswd -c ./auth myusername\n\n\n\n\nYou will be prompted for a password which you will have to enter twice.\n\nhtpasswd\n will create a file with the following:\n\n\ncat auth\n\n\n\n\nmyusername:$apr1$78Jyn/1K$ERHKVRPPlzAX8eBtLuvRZ0\n\n\n\n\nB. Now use \nkubectl\n to create a secret in the \nmonitoring\n namespace using the file created by \nhtpasswd\n.\n\n\nkubectl create secret generic mysecret --from-file auth --namespace=monitoring\n\n\n\n\n\n\nNote\n\n\nSecret must be in same namespace as the Ingress object.\n\n\n\n\nC. Attach the following annotations to the Ingress object:\n\n\n\n\ningress.kubernetes.io/auth-type: \"basic\"\n\n\ningress.kubernetes.io/auth-secret: \"mysecret\"\n\n\n\n\nThey specify basic authentication and reference the Secret \nmysecret\n containing the credentials.\n\n\nFollowing is a full Ingress example based on Prometheus:\n\n\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n name: prometheus-dashboard\n namespace: monitoring\n annotations:\n   kubernetes.io/ingress.class: traefik\n   ingress.kubernetes.io/auth-type: \nbasic\n\n   ingress.kubernetes.io/auth-secret: \nmysecret\n\nspec:\n rules:\n - host: dashboard.prometheus.example.com\n   http:\n     paths:\n     - backend:\n         serviceName: prometheus\n         servicePort: 9090\n\n\n\n\nYou can apply the example as following:\n\n\nkubectl create -f prometheus-ingress.yaml -n monitoring\n\n\n\n\nName-based Routing\n\n\nIn this example we are going to setup websites for three of the United Kingdoms best loved cheeses: Cheddar, Stilton, and Wensleydale.\n\n\nFirst lets start by launching the pods for the cheese websites.\n\n\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  name: stilton\n  labels:\n    app: cheese\n    cheese: stilton\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: cheese\n      task: stilton\n  template:\n    metadata:\n      labels:\n        app: cheese\n        task: stilton\n        version: v0.0.1\n    spec:\n      containers:\n      - name: cheese\n        image: errm/cheese:stilton\n        ports:\n        - containerPort: 80\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  name: cheddar\n  labels:\n    app: cheese\n    cheese: cheddar\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: cheese\n      task: cheddar\n  template:\n    metadata:\n      labels:\n        app: cheese\n        task: cheddar\n        version: v0.0.1\n    spec:\n      containers:\n      - name: cheese\n        image: errm/cheese:cheddar\n        ports:\n        - containerPort: 80\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  name: wensleydale\n  labels:\n    app: cheese\n    cheese: wensleydale\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: cheese\n      task: wensleydale\n  template:\n    metadata:\n      labels:\n        app: cheese\n        task: wensleydale\n        version: v0.0.1\n    spec:\n      containers:\n      - name: cheese\n        image: errm/cheese:wensleydale\n        ports:\n        - containerPort: 80\n\n\n\n\nexamples/k8s/cheese-deployments.yaml\n\n\nkubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/cheese-deployments.yaml\n\n\n\n\nNext we need to setup a Service for each of the cheese pods.\n\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: stilton\nspec:\n  ports:\n  - name: http\n    targetPort: 80\n    port: 80\n  selector:\n    app: cheese\n    task: stilton\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: cheddar\nspec:\n  ports:\n  - name: http\n    targetPort: 80\n    port: 80\n  selector:\n    app: cheese\n    task: cheddar\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: wensleydale\n  annotations:\n    traefik.backend.circuitbreaker: \nNetworkErrorRatio() \n 0.5\n\nspec:\n  ports:\n  - name: http\n    targetPort: 80\n    port: 80\n  selector:\n    app: cheese\n    task: wensleydale\n\n\n\n\n\n\nNote\n\n\nWe also set a \ncircuit breaker expression\n for one of the backends by setting the \ntraefik.backend.circuitbreaker\n annotation on the service.\n\n\n\n\nexamples/k8s/cheese-services.yaml\n\n\nkubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/cheese-services.yaml\n\n\n\n\nNow we can submit an ingress for the cheese websites.\n\n\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: cheese\n  annotations:\n    kubernetes.io/ingress.class: traefik\nspec:\n  rules:\n  - host: stilton.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: stilton\n          servicePort: http\n  - host: cheddar.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: cheddar\n          servicePort: http\n  - host: wensleydale.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: wensleydale\n          servicePort: http\n\n\n\n\nexamples/k8s/cheese-ingress.yaml\n\n\n\n\nNote\n\n\nwe list each hostname, and add a backend service.\n\n\n\n\nkubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/cheese-ingress.yaml\n\n\n\n\nNow visit the \nTr\u00e6fik dashboard\n and you should see a frontend for each host.\nAlong with a backend listing for each service with a server set up for each pod.\n\n\nIf you edit your \n/etc/hosts\n again you should be able to access the cheese websites in your browser.\n\n\necho \n$(minikube ip) stilton.minikube cheddar.minikube wensleydale.minikube\n | sudo tee -a /etc/hosts\n\n\n\n\n\n\nStilton\n\n\nCheddar\n\n\nWensleydale\n\n\n\n\nPath-based Routing\n\n\nNow lets suppose that our fictional client has decided that while they are super happy about our cheesy web design, when they asked for 3 websites they had not really bargained on having to buy 3 domain names.\n\n\nNo problem, we say, why don't we reconfigure the sites to host all 3 under one domain.\n\n\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: cheeses\n  annotations:\n    kubernetes.io/ingress.class: traefik\n    traefik.frontend.rule.type: PathPrefixStrip\nspec:\n  rules:\n  - host: cheeses.minikube\n    http:\n      paths:\n      - path: /stilton\n        backend:\n          serviceName: stilton\n          servicePort: http\n      - path: /cheddar\n        backend:\n          serviceName: cheddar\n          servicePort: http\n      - path: /wensleydale\n        backend:\n          serviceName: wensleydale\n          servicePort: http\n\n\n\n\nexamples/k8s/cheeses-ingress.yaml\n\n\n\n\nNote\n\n\nWe are configuring Tr\u00e6fik to strip the prefix from the url path with the \ntraefik.frontend.rule.type\n annotation so that we can use the containers from the previous example without modification.\n\n\n\n\nkubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/cheeses-ingress.yaml\n\n\n\n\necho \n$(minikube ip) cheeses.minikube\n | sudo tee -a /etc/hosts\n\n\n\n\nYou should now be able to visit the websites in your browser.\n\n\n\n\ncheeses.minikube/stilton\n\n\ncheeses.minikube/cheddar\n\n\ncheeses.minikube/wensleydale\n\n\n\n\nSpecifying Routing Priorities\n\n\nSometimes you need to specify priority for ingress routes, especially when handling wildcard routes.\nThis can be done by adding the \ntraefik.frontend.priority\n annotation, i.e.:\n\n\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: wildcard-cheeses\n  annotations:\n    traefik.frontend.priority: \n1\n\nspec:\n  rules:\n  - host: *.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: stilton\n          servicePort: http\n\nkind: Ingress\nmetadata:\n  name: specific-cheeses\n  annotations:\n    traefik.frontend.priority: \n2\n\nspec:\n  rules:\n  - host: specific.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: stilton\n          servicePort: http\n\n\n\n\nNote that priority values must be quoted to avoid numeric interpretation (which are illegal for annotations).\n\n\nForwarding to ExternalNames\n\n\nWhen specifying an \nExternalName\n,\nTr\u00e6fik will forward requests to the given host accordingly and use HTTPS when the Service port matches 443.\nThis still requires setting up a proper port mapping on the Service from the Ingress port to the (external) Service port.\n\n\nDisable passing the Host Header\n\n\nBy default Tr\u00e6fik will pass the incoming Host header to the upstream resource.\n\n\nHowever, there are times when you may not want this to be the case. For example, if your service is of the ExternalName type.\n\n\nDisable globally\n\n\nAdd the following to your TOML configuration file:\n\n\ndisablePassHostHeaders = true\n\n\n\n\nDisable per Ingress\n\n\nTo disable passing the Host header per ingress resource set the \ntraefik.frontend.passHostHeader\n annotation on your ingress to \n\"false\"\n.\n\n\nHere is an example definition:\n\n\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: example\n  annotations:\n    kubernetes.io/ingress.class: traefik\n    traefik.frontend.passHostHeader: \nfalse\n\nspec:\n  rules:\n  - host: example.com\n    http:\n      paths:\n      - path: /static\n        backend:\n          serviceName: static\n          servicePort: https\n\n\n\n\nAnd an example service definition:\n\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: static\nspec:\n  ports:\n  - name: https\n    port: 443\n  type: ExternalName\n  externalName: static.otherdomain.com\n\n\n\n\nIf you were to visit \nexample.com/static\n the request would then be passed on to \nstatic.otherdomain.com/static\n, and \nstatic.otherdomain.com\n would receive the request with the Host header being \nstatic.otherdomain.com\n.\n\n\n\n\nNote\n\n\nThe per-ingress annotation overrides whatever the global value is set to.\nSo you could set \ndisablePassHostHeaders\n to \ntrue\n in your TOML configuration file and then enable passing the host header per ingress if you wanted.\n\n\n\n\nPartitioning the Ingress object space\n\n\nBy default, Tr\u00e6fik processes every Ingress objects it observes. At times, however, it may be desirable to ignore certain objects. The following sub-sections describe common use cases and how they can be handled with Tr\u00e6fik.\n\n\nBetween Tr\u00e6fik and other Ingress controller implementations\n\n\nSometimes Tr\u00e6fik runs along other Ingress controller implementations. One such example is when both Tr\u00e6fik and a cloud provider Ingress controller are active.\n\n\nThe \nkubernetes.io/ingress.class\n annotation can be attached to any Ingress object in order to control whether Tr\u00e6fik should handle it.\n\n\nIf the annotation is missing, contains an empty value, or the value \ntraefik\n, then the Tr\u00e6fik controller will take responsibility and process the associated Ingress object. If the annotation contains any other value (usually the name of a different Ingress controller), Tr\u00e6fik will ignore the object.\n\n\nBetween multiple Tr\u00e6fik Deployments\n\n\nSometimes multiple Tr\u00e6fik Deployments are supposed to run concurrently. For instance, it is conceivable to have one Deployment deal with internal and another one with external traffic.\n\n\nFor such cases, it is advisable to classify Ingress objects through a label and configure the \nlabelSelector\n option per each Tr\u00e6fik Deployment accordingly. To stick with the internal/external example above, all Ingress objects meant for internal traffic could receive a \ntraffic-type: internal\n label while objects designated for external traffic receive a \ntraffic-type: external\n label. The label selectors on the Tr\u00e6fik Deployments would then be \ntraffic-type=internal\n and \ntraffic-type=external\n, respectively.\n\n\nProduction advice\n\n\nResource limitations\n\n\nThe examples shown deliberately do not specify any \nresource limitations\n as there is no one size fits all.\n\n\nIn a production environment, however, it is important to set proper bounds, especially with regards to CPU:\n\n\n\n\ntoo strict and Traefik will be throttled while serving requests (as Kubernetes imposes hard quotas)\n\n\ntoo loose and Traefik may waste resources not available for other containers\n\n\n\n\nWhen in doubt, you should measure your resource needs, and adjust requests and limits accordingly.", 
            "title": "Kubernetes"
        }, 
        {
            "location": "/user-guide/kubernetes/#kubernetes-ingress-controller", 
            "text": "This guide explains how to use Tr\u00e6fik as an Ingress controller for a Kubernetes cluster.  If you are not familiar with Ingresses in Kubernetes you might want to read the  Kubernetes user guide  The config files used in this guide can be found in the  examples directory", 
            "title": "Kubernetes Ingress Controller"
        }, 
        {
            "location": "/user-guide/kubernetes/#prerequisites", 
            "text": "A working Kubernetes cluster. If you want to follow along with this guide, you should setup  minikube  on your machine, as it is the quickest way to get a local Kubernetes cluster setup for experimentation and development.    Note  The guide is likely not fully adequate for a production-ready setup.    The  kubectl  binary should be  installed on your workstation .", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/user-guide/kubernetes/#role-based-access-control-configuration-kubernetes-16-only", 
            "text": "Kubernetes introduces  Role Based Access Control (RBAC)  in 1.6+ to allow fine-grained control of Kubernetes resources and API.  If your cluster is configured with RBAC, you will need to authorize Tr\u00e6fik to use the Kubernetes API. There are two ways to set up the proper permission: Via namespace-specific RoleBindings or a single, global ClusterRoleBinding.  RoleBindings per namespace enable to restrict granted permissions to the very namespaces only that Tr\u00e6fik is watching over, thereby following the least-privileges principle. This is the preferred approach if Tr\u00e6fik is not supposed to watch all namespaces, and the set of namespaces does not change dynamically. Otherwise, a single ClusterRoleBinding must be employed.   Note  RoleBindings per namespace are available in Tr\u00e6fik 1.5 and later. Please use ClusterRoleBindings for older versions.   For the sake of simplicity, this guide will use a ClusterRoleBinding:  ---\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: traefik-ingress-controller\nrules:\n  - apiGroups:\n      -  \n    resources:\n      - services\n      - endpoints\n      - secrets\n    verbs:\n      - get\n      - list\n      - watch\n  - apiGroups:\n      - extensions\n    resources:\n      - ingresses\n    verbs:\n      - get\n      - list\n      - watch\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: traefik-ingress-controller\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: traefik-ingress-controller\nsubjects:\n- kind: ServiceAccount\n  name: traefik-ingress-controller\n  namespace: kube-system  examples/k8s/traefik-rbac.yaml  kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-rbac.yaml  For namespaced restrictions, one RoleBinding is required per watched namespace along with a corresponding configuration of Tr\u00e6fik's  kubernetes.namespaces  parameter.", 
            "title": "Role Based Access Control configuration (Kubernetes 1.6+ only)"
        }, 
        {
            "location": "/user-guide/kubernetes/#deploy-trfik-using-a-deployment-or-daemonset", 
            "text": "It is possible to use Tr\u00e6fik with a  Deployment  or a  DaemonSet  object,\n whereas both options have their own pros and cons:   The scalability is much better when using a Deployment, because you will have a Single-Pod-per-Node model when using the DeaemonSet.  It is possible to exclusively run a Service on a dedicated set of machines using taints and tolerations with a DaemonSet.  On the other hand the DaemonSet allows you to access any Node directly on Port 80 and 443, where you have to setup a  Service  object with a Deployment.   The Deployment objects looks like this:  ---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: traefik-ingress-controller\n  namespace: kube-system\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  name: traefik-ingress-controller\n  namespace: kube-system\n  labels:\n    k8s-app: traefik-ingress-lb\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: traefik-ingress-lb\n  template:\n    metadata:\n      labels:\n        k8s-app: traefik-ingress-lb\n        name: traefik-ingress-lb\n    spec:\n      serviceAccountName: traefik-ingress-controller\n      terminationGracePeriodSeconds: 60\n      containers:\n      - image: traefik\n        name: traefik-ingress-lb\n        args:\n        - --api\n        - --kubernetes\n---\nkind: Service\napiVersion: v1\nmetadata:\n  name: traefik-ingress-service\n  namespace: kube-system\nspec:\n  selector:\n    k8s-app: traefik-ingress-lb\n  ports:\n    - protocol: TCP\n      port: 80\n      name: web\n    - protocol: TCP\n      port: 8080\n      name: admin\n  type: NodePort  examples/k8s/traefik-deployment.yaml   Note  The Service will expose two NodePorts which allow access to the ingress and the web interface.   The DaemonSet objects looks not much different:  ---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: traefik-ingress-controller\n  namespace: kube-system\n---\nkind: DaemonSet\napiVersion: extensions/v1beta1\nmetadata:\n  name: traefik-ingress-controller\n  namespace: kube-system\n  labels:\n    k8s-app: traefik-ingress-lb\nspec:\n  template:\n    metadata:\n      labels:\n        k8s-app: traefik-ingress-lb\n        name: traefik-ingress-lb\n    spec:\n      serviceAccountName: traefik-ingress-controller\n      terminationGracePeriodSeconds: 60\n      hostNetwork: true\n      containers:\n      - image: traefik\n        name: traefik-ingress-lb\n        ports:\n        - name: http\n          containerPort: 80\n          hostPort: 80\n        - name: admin\n          containerPort: 8080\n        securityContext:\n          privileged: true\n        args:\n        - --api\n        - --kubernetes\n        - --logLevel=INFO\n---\nkind: Service\napiVersion: v1\nmetadata:\n  name: traefik-ingress-service\n  namespace: kube-system\nspec:\n  selector:\n    k8s-app: traefik-ingress-lb\n  ports:\n    - protocol: TCP\n      port: 80\n      name: web\n    - protocol: TCP\n      port: 8080\n      name: admin\n  type: NodePort  examples/k8s/traefik-ds.yaml  To deploy Tr\u00e6fik to your cluster start by submitting one of the YAML files to the cluster with  kubectl :  kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-deployment.yaml  kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-ds.yaml  There are some significant differences between using Deployments and DaemonSets:   The Deployment has easier up and down scaling possibilities.\n    It can implement full pod lifecycle and supports rolling updates from Kubernetes 1.2.\n    At least one Pod is needed to run the Deployment.  The DaemonSet automatically scales to all nodes that meets a specific selector and guarantees to fill nodes one at a time.\n    Rolling updates are fully supported from Kubernetes 1.7 for DaemonSets as well.", 
            "title": "Deploy Tr\u00e6fik using a Deployment or DaemonSet"
        }, 
        {
            "location": "/user-guide/kubernetes/#check-the-pods", 
            "text": "Now lets check if our command was successful.  Start by listing the pods in the  kube-system  namespace:  kubectl --namespace=kube-system get pods  NAME                                         READY     STATUS    RESTARTS   AGE\nkube-addon-manager-minikubevm                1/1       Running   0          4h\nkubernetes-dashboard-s8krj                   1/1       Running   0          4h\ntraefik-ingress-controller-678226159-eqseo   1/1       Running   0          7m  You should see that after submitting the Deployment or DaemonSet to Kubernetes it has launched a Pod, and it is now running. It might take a few moments for kubernetes to pull the Tr\u00e6fik image and start the container.   Note  You could also check the deployment with the Kubernetes dashboard, run minikube dashboard  to open it in your browser, then choose the  kube-system \nnamespace from the menu at the top right of the screen.   You should now be able to access Tr\u00e6fik on port 80 of your Minikube instance when using the DaemonSet:  curl $(minikube ip)  404 page not found  If you decided to use the deployment, then you need to target the correct NodePort, which can be seen when you execute  kubectl get services --namespace=kube-system .  curl $(minikube ip): NODEPORT   404 page not found   Note  We expect to see a 404 response here as we haven't yet given Tr\u00e6fik any configuration.   All further examples below assume a DaemonSet installation. Deployment users will need to append the NodePort when constructing requests.", 
            "title": "Check the Pods"
        }, 
        {
            "location": "/user-guide/kubernetes/#deploy-trfik-using-helm-chart", 
            "text": "Note  The Helm Chart is maintained by the community, not the Traefik project maintainers.   Instead of installing Tr\u00e6fik via Kubernetes object directly, you can also use the Tr\u00e6fik Helm chart.  Install the Tr\u00e6fik chart by:  helm install stable/traefik  For more information, check out  the documentation .", 
            "title": "Deploy Tr\u00e6fik using Helm Chart"
        }, 
        {
            "location": "/user-guide/kubernetes/#submitting-an-ingress-to-the-cluster", 
            "text": "Lets start by creating a Service and an Ingress that will expose the  Tr\u00e6fik Web UI .  apiVersion: v1\nkind: Service\nmetadata:\n  name: traefik-web-ui\n  namespace: kube-system\nspec:\n  selector:\n    k8s-app: traefik-ingress-lb\n  ports:\n  - port: 80\n    targetPort: 8080\n---\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: traefik-web-ui\n  namespace: kube-system\n  annotations:\n    kubernetes.io/ingress.class: traefik\nspec:\n  rules:\n  - host: traefik-ui.minikube\n    http:\n      paths:\n      - backend:\n          serviceName: traefik-web-ui\n          servicePort: 80  examples/k8s/ui.yaml  kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/ui.yaml  Now lets setup an entry in our  /etc/hosts  file to route  traefik-ui.minikube  to our cluster.  In production you would want to set up real DNS entries.\nYou can get the IP address of your minikube instance by running  minikube ip :  echo  $(minikube ip) traefik-ui.minikube  | sudo tee -a /etc/hosts  We should now be able to visit  traefik-ui.minikube  in the browser and view the Tr\u00e6fik web UI.", 
            "title": "Submitting an Ingress to the Cluster"
        }, 
        {
            "location": "/user-guide/kubernetes/#basic-authentication", 
            "text": "It's possible to protect access to Traefik through basic authentication. (See the  Kubernetes Ingress  configuration page for syntactical details and restrictions.)", 
            "title": "Basic Authentication"
        }, 
        {
            "location": "/user-guide/kubernetes/#creating-the-secret", 
            "text": "A. Use  htpasswd  to create a file containing the username and the base64-encoded password:  htpasswd -c ./auth myusername  You will be prompted for a password which you will have to enter twice. htpasswd  will create a file with the following:  cat auth  myusername:$apr1$78Jyn/1K$ERHKVRPPlzAX8eBtLuvRZ0  B. Now use  kubectl  to create a secret in the  monitoring  namespace using the file created by  htpasswd .  kubectl create secret generic mysecret --from-file auth --namespace=monitoring   Note  Secret must be in same namespace as the Ingress object.   C. Attach the following annotations to the Ingress object:   ingress.kubernetes.io/auth-type: \"basic\"  ingress.kubernetes.io/auth-secret: \"mysecret\"   They specify basic authentication and reference the Secret  mysecret  containing the credentials.  Following is a full Ingress example based on Prometheus:  apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n name: prometheus-dashboard\n namespace: monitoring\n annotations:\n   kubernetes.io/ingress.class: traefik\n   ingress.kubernetes.io/auth-type:  basic \n   ingress.kubernetes.io/auth-secret:  mysecret \nspec:\n rules:\n - host: dashboard.prometheus.example.com\n   http:\n     paths:\n     - backend:\n         serviceName: prometheus\n         servicePort: 9090  You can apply the example as following:  kubectl create -f prometheus-ingress.yaml -n monitoring", 
            "title": "Creating the Secret"
        }, 
        {
            "location": "/user-guide/kubernetes/#name-based-routing", 
            "text": "In this example we are going to setup websites for three of the United Kingdoms best loved cheeses: Cheddar, Stilton, and Wensleydale.  First lets start by launching the pods for the cheese websites.  ---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  name: stilton\n  labels:\n    app: cheese\n    cheese: stilton\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: cheese\n      task: stilton\n  template:\n    metadata:\n      labels:\n        app: cheese\n        task: stilton\n        version: v0.0.1\n    spec:\n      containers:\n      - name: cheese\n        image: errm/cheese:stilton\n        ports:\n        - containerPort: 80\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  name: cheddar\n  labels:\n    app: cheese\n    cheese: cheddar\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: cheese\n      task: cheddar\n  template:\n    metadata:\n      labels:\n        app: cheese\n        task: cheddar\n        version: v0.0.1\n    spec:\n      containers:\n      - name: cheese\n        image: errm/cheese:cheddar\n        ports:\n        - containerPort: 80\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  name: wensleydale\n  labels:\n    app: cheese\n    cheese: wensleydale\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: cheese\n      task: wensleydale\n  template:\n    metadata:\n      labels:\n        app: cheese\n        task: wensleydale\n        version: v0.0.1\n    spec:\n      containers:\n      - name: cheese\n        image: errm/cheese:wensleydale\n        ports:\n        - containerPort: 80  examples/k8s/cheese-deployments.yaml  kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/cheese-deployments.yaml  Next we need to setup a Service for each of the cheese pods.  ---\napiVersion: v1\nkind: Service\nmetadata:\n  name: stilton\nspec:\n  ports:\n  - name: http\n    targetPort: 80\n    port: 80\n  selector:\n    app: cheese\n    task: stilton\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: cheddar\nspec:\n  ports:\n  - name: http\n    targetPort: 80\n    port: 80\n  selector:\n    app: cheese\n    task: cheddar\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: wensleydale\n  annotations:\n    traefik.backend.circuitbreaker:  NetworkErrorRatio()   0.5 \nspec:\n  ports:\n  - name: http\n    targetPort: 80\n    port: 80\n  selector:\n    app: cheese\n    task: wensleydale   Note  We also set a  circuit breaker expression  for one of the backends by setting the  traefik.backend.circuitbreaker  annotation on the service.   examples/k8s/cheese-services.yaml  kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/cheese-services.yaml  Now we can submit an ingress for the cheese websites.  apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: cheese\n  annotations:\n    kubernetes.io/ingress.class: traefik\nspec:\n  rules:\n  - host: stilton.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: stilton\n          servicePort: http\n  - host: cheddar.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: cheddar\n          servicePort: http\n  - host: wensleydale.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: wensleydale\n          servicePort: http  examples/k8s/cheese-ingress.yaml   Note  we list each hostname, and add a backend service.   kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/cheese-ingress.yaml  Now visit the  Tr\u00e6fik dashboard  and you should see a frontend for each host.\nAlong with a backend listing for each service with a server set up for each pod.  If you edit your  /etc/hosts  again you should be able to access the cheese websites in your browser.  echo  $(minikube ip) stilton.minikube cheddar.minikube wensleydale.minikube  | sudo tee -a /etc/hosts   Stilton  Cheddar  Wensleydale", 
            "title": "Name-based Routing"
        }, 
        {
            "location": "/user-guide/kubernetes/#path-based-routing", 
            "text": "Now lets suppose that our fictional client has decided that while they are super happy about our cheesy web design, when they asked for 3 websites they had not really bargained on having to buy 3 domain names.  No problem, we say, why don't we reconfigure the sites to host all 3 under one domain.  apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: cheeses\n  annotations:\n    kubernetes.io/ingress.class: traefik\n    traefik.frontend.rule.type: PathPrefixStrip\nspec:\n  rules:\n  - host: cheeses.minikube\n    http:\n      paths:\n      - path: /stilton\n        backend:\n          serviceName: stilton\n          servicePort: http\n      - path: /cheddar\n        backend:\n          serviceName: cheddar\n          servicePort: http\n      - path: /wensleydale\n        backend:\n          serviceName: wensleydale\n          servicePort: http  examples/k8s/cheeses-ingress.yaml   Note  We are configuring Tr\u00e6fik to strip the prefix from the url path with the  traefik.frontend.rule.type  annotation so that we can use the containers from the previous example without modification.   kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/cheeses-ingress.yaml  echo  $(minikube ip) cheeses.minikube  | sudo tee -a /etc/hosts  You should now be able to visit the websites in your browser.   cheeses.minikube/stilton  cheeses.minikube/cheddar  cheeses.minikube/wensleydale", 
            "title": "Path-based Routing"
        }, 
        {
            "location": "/user-guide/kubernetes/#specifying-routing-priorities", 
            "text": "Sometimes you need to specify priority for ingress routes, especially when handling wildcard routes.\nThis can be done by adding the  traefik.frontend.priority  annotation, i.e.:  apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: wildcard-cheeses\n  annotations:\n    traefik.frontend.priority:  1 \nspec:\n  rules:\n  - host: *.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: stilton\n          servicePort: http\n\nkind: Ingress\nmetadata:\n  name: specific-cheeses\n  annotations:\n    traefik.frontend.priority:  2 \nspec:\n  rules:\n  - host: specific.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: stilton\n          servicePort: http  Note that priority values must be quoted to avoid numeric interpretation (which are illegal for annotations).", 
            "title": "Specifying Routing Priorities"
        }, 
        {
            "location": "/user-guide/kubernetes/#forwarding-to-externalnames", 
            "text": "When specifying an  ExternalName ,\nTr\u00e6fik will forward requests to the given host accordingly and use HTTPS when the Service port matches 443.\nThis still requires setting up a proper port mapping on the Service from the Ingress port to the (external) Service port.", 
            "title": "Forwarding to ExternalNames"
        }, 
        {
            "location": "/user-guide/kubernetes/#disable-passing-the-host-header", 
            "text": "By default Tr\u00e6fik will pass the incoming Host header to the upstream resource.  However, there are times when you may not want this to be the case. For example, if your service is of the ExternalName type.", 
            "title": "Disable passing the Host Header"
        }, 
        {
            "location": "/user-guide/kubernetes/#disable-globally", 
            "text": "Add the following to your TOML configuration file:  disablePassHostHeaders = true", 
            "title": "Disable globally"
        }, 
        {
            "location": "/user-guide/kubernetes/#disable-per-ingress", 
            "text": "To disable passing the Host header per ingress resource set the  traefik.frontend.passHostHeader  annotation on your ingress to  \"false\" .  Here is an example definition:  apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: example\n  annotations:\n    kubernetes.io/ingress.class: traefik\n    traefik.frontend.passHostHeader:  false \nspec:\n  rules:\n  - host: example.com\n    http:\n      paths:\n      - path: /static\n        backend:\n          serviceName: static\n          servicePort: https  And an example service definition:  apiVersion: v1\nkind: Service\nmetadata:\n  name: static\nspec:\n  ports:\n  - name: https\n    port: 443\n  type: ExternalName\n  externalName: static.otherdomain.com  If you were to visit  example.com/static  the request would then be passed on to  static.otherdomain.com/static , and  static.otherdomain.com  would receive the request with the Host header being  static.otherdomain.com .   Note  The per-ingress annotation overrides whatever the global value is set to.\nSo you could set  disablePassHostHeaders  to  true  in your TOML configuration file and then enable passing the host header per ingress if you wanted.", 
            "title": "Disable per Ingress"
        }, 
        {
            "location": "/user-guide/kubernetes/#partitioning-the-ingress-object-space", 
            "text": "By default, Tr\u00e6fik processes every Ingress objects it observes. At times, however, it may be desirable to ignore certain objects. The following sub-sections describe common use cases and how they can be handled with Tr\u00e6fik.", 
            "title": "Partitioning the Ingress object space"
        }, 
        {
            "location": "/user-guide/kubernetes/#between-trfik-and-other-ingress-controller-implementations", 
            "text": "Sometimes Tr\u00e6fik runs along other Ingress controller implementations. One such example is when both Tr\u00e6fik and a cloud provider Ingress controller are active.  The  kubernetes.io/ingress.class  annotation can be attached to any Ingress object in order to control whether Tr\u00e6fik should handle it.  If the annotation is missing, contains an empty value, or the value  traefik , then the Tr\u00e6fik controller will take responsibility and process the associated Ingress object. If the annotation contains any other value (usually the name of a different Ingress controller), Tr\u00e6fik will ignore the object.", 
            "title": "Between Tr\u00e6fik and other Ingress controller implementations"
        }, 
        {
            "location": "/user-guide/kubernetes/#between-multiple-trfik-deployments", 
            "text": "Sometimes multiple Tr\u00e6fik Deployments are supposed to run concurrently. For instance, it is conceivable to have one Deployment deal with internal and another one with external traffic.  For such cases, it is advisable to classify Ingress objects through a label and configure the  labelSelector  option per each Tr\u00e6fik Deployment accordingly. To stick with the internal/external example above, all Ingress objects meant for internal traffic could receive a  traffic-type: internal  label while objects designated for external traffic receive a  traffic-type: external  label. The label selectors on the Tr\u00e6fik Deployments would then be  traffic-type=internal  and  traffic-type=external , respectively.", 
            "title": "Between multiple Tr\u00e6fik Deployments"
        }, 
        {
            "location": "/user-guide/kubernetes/#production-advice", 
            "text": "", 
            "title": "Production advice"
        }, 
        {
            "location": "/user-guide/kubernetes/#resource-limitations", 
            "text": "The examples shown deliberately do not specify any  resource limitations  as there is no one size fits all.  In a production environment, however, it is important to set proper bounds, especially with regards to CPU:   too strict and Traefik will be throttled while serving requests (as Kubernetes imposes hard quotas)  too loose and Traefik may waste resources not available for other containers   When in doubt, you should measure your resource needs, and adjust requests and limits accordingly.", 
            "title": "Resource limitations"
        }, 
        {
            "location": "/user-guide/marathon/", 
            "text": "Marathon\n\n\nThis guide explains how to integrate Marathon and operate the cluster in a reliable way from Traefik's standpoint.\n\n\nHost detection\n\n\nMarathon offers multiple ways to run (Docker-containerized) applications, the most popular ones being\n\n\n\n\nBRIDGE-networked containers with dynamic high ports exposed\n\n\nHOST-networked containers with host machine ports\n\n\ncontainers with dedicated IP addresses (\nIP-per-task\n).\n\n\n\n\nTraefik tries to detect the configured mode and route traffic to the right IP addresses. It is possible to force using task hosts with the \nforceTaskHostname\n option.\n\n\nGiven the complexity of the subject, it is possible that the heuristic fails.\nApart from filing an issue and waiting for the feature request / bug report to get addressed, one workaround for such situations is to customize the Marathon template file to the individual needs.\n\n\n\n\nNote\n\n\nThis does \nnot\n require rebuilding Traefik but only to point the \nfilename\n configuration parameter to a customized version of the \nmarathon.tmpl\n file on Traefik startup.\n\n\n\n\nPort detection\n\n\nTraefik also attempts to determine the right port (which is a \nnon-trivial matter in Marathon\n).\nFollowing is the order by which Traefik tries to identify the port (the first one that yields a positive result will be used):\n\n\n\n\nA arbitrary port specified through the \ntraefik.port\n label.\n\n\nThe task port (possibly indexed through the \ntraefik.portIndex\n label, otherwise the first one).\n\n\nThe port from the application's \nportDefinitions\n field (possibly indexed through the \ntraefik.portIndex\n label, otherwise the first one).\n\n\nThe port from the application's \nipAddressPerTask\n field (possibly indexed through the \ntraefik.portIndex\n label, otherwise the first one).\n\n\n\n\nApplications with multiple ports\n\n\nSome Marathon applications may expose multiple ports. Traefik supports creating one so-called \nservice\n per port using \nspecific labels\n.\n\n\nFor instance, assume that a Marathon application exposes a web API on port 80 and an admin interface on port 8080. It would then be possible to make each service available by specifying the following Marathon labels:\n\n\ntraefik.web.port=80\n\n\n\n\ntraefik.admin.port=8080\n\n\n\n\n(Note that the service names \nweb\n and \nadmin\n can be chosen arbitrarily.)\n\n\nTechnically, Traefik will create one pair of frontend and backend configurations for each service.\n\n\nAchieving high availability\n\n\nScenarios\n\n\nThere are three scenarios where the availability of a Marathon application could be impaired along with the risk of losing or failing requests:\n\n\n\n\nDuring the startup phase when Traefik already routes requests to the backend even though it has not completed its bootstrapping process yet.\n\n\nDuring the shutdown phase when Traefik still routes requests to the backend while the backend is already terminating.\n\n\nDuring a failure of the application when Traefik has not yet identified the backend as being erroneous.\n\n\n\n\nThe first two scenarios are common with every rolling upgrade of an application (i.e. a new version release or configuration update).\n\n\nThe following sub-sections describe how to resolve or mitigate each scenario.\n\n\nStartup\n\n\nIt is possible to define \nreadiness checks\n (available since Marathon version 1.1) per application and have Marathon take these into account during the startup phase.\n\n\nThe idea is that each application provides an HTTP endpoint that Marathon queries periodically during an ongoing deployment in order to mark the associated readiness check result as successful if and only if the endpoint returns a response within the configured HTTP code range.\n\nAs long as the check keeps failing, Marathon will not proceed with the deployment (within the configured upgrade strategy bounds).\n\n\nBeginning with version 1.4, Traefik respects readiness check results if the Traefik option is set and checks are configured on the applications accordingly.\n\n\n\n\nNote\n\n\nDue to the way readiness check results are currently exposed by the Marathon API, ready tasks may be taken into rotation with a small delay.\nIt is on the order of one readiness check timeout interval (as configured on the application specifiation) and guarantees that non-ready tasks do not receive traffic prematurely.\n\n\n\n\nIf readiness checks are not possible, a current mitigation strategy is to enable \nretries\n and make sure that a sufficient number of healthy application tasks exist so that one retry will likely hit one of those.\nApart from its probabilistic nature, the workaround comes at the price of increased latency.\n\n\nShutdown\n\n\nIt is possible to install a \ntermination handler\n (available since Marathon version 1.3) with each application whose responsibility it is to delay the shutdown process long enough until the backend has been taken out of load-balancing rotation with reasonable confidence (i.e., Traefik has received an update from the Marathon event bus, recomputes the available Marathon backends, and applies the new configuration).\n\nSpecifically, each termination handler should install a signal handler listening for a SIGTERM signal and implement the following steps on signal reception:\n\n\n\n\nDisable Keep-Alive HTTP connections.\n\n\nKeep accepting HTTP requests for a certain period of time.\n\n\nStop accepting new connections.\n\n\nFinish serving any in-flight requests.\n\n\nShut down.\n\n\n\n\nTraefik already ignores Marathon tasks whose state does not match \nTASK_RUNNING\n; since terminating tasks transition into the \nTASK_KILLING\n and eventually \nTASK_KILLED\n state, there is nothing further that needs to be done on Traefik's end.\n\n\nHow long HTTP requests should continue to be accepted in step 2 depends on how long Traefik needs to receive and process the Marathon configuration update.\nUnder regular operational conditions, it should be on the order of seconds, with 10 seconds possibly being a good default value.\n\n\nAgain, configuring Traefik to do retries (as discussed in the previous section) can serve as a decent workaround strategy.\n\nPaired with termination handlers, they would cover for those cases where either the termination sequence or Traefik cannot complete their part of the orchestration process in time.\n\n\nFailure\n\n\nA failing application always happens unexpectedly, and hence, it is very difficult or even impossible to rule out the adversal effects categorically.\n\n\nFailure reasons vary broadly and could stretch from unacceptable slowness, a task crash, or a network split.\n\n\nThere are two mitigaton efforts:\n\n\n\n\nConfigure \nMarathon health checks\n on each application.\n\n\nConfigure Traefik health checks (possibly via the \ntraefik.backend.healthcheck.*\n labels) and make sure they probe with proper frequency.\n\n\n\n\nThe Marathon health check makes sure that applications once deemed dysfunctional are being rescheduled to different slaves.\nHowever, they might take a while to get triggered and the follow-up processes to complete.\n\n\nFor that reason, the Treafik health check provides an additional check that responds more rapidly and does not require a configuration reload to happen.\nAdditionally, it protects from cases that the Marathon health check may not be able to cover, such as a network split.\n\n\n(Non-)Alternatives\n\n\nThere are a few alternatives of varying quality that are frequently asked for.\n\n\nThe remaining section is going to explore them along with a benefit/cost trade-off.\n\n\nReusing Marathon health checks\n\n\nIt may seem obvious to reuse the Marathon health checks as a signal to Traefik whether an application should be taken into load-balancing rotation or not.\n\n\nApart from the increased latency a failing health check may have, a major problem with this is is that Marathon does not persist the health check results.\nConsequently, if a master re-election occurs in the Marathon clusters, all health check results will revert to the \nunknown\n state, effectively causing all applications inside the cluster to become unavailable and leading to a complete cluster failure.\n\nRe-elections do not only happen during regular maintenance work (often requiring rolling upgrades of the Marathon nodes) but also when the Marathon leader fails spontaneously.\nAs such, there is no way to handle this situation deterministically.\n\n\nFinally, Marathon health checks are not mandatory (the default is to use the task state as reported by Mesos), so requiring them for Traefik would raise the entry barrier for Marathon users.\n\n\nTraefik used to use the health check results as a strict requirement but moved away from it as \nusers reported the dramatic consequences\n.\nIf health check results are known to exist, however, they will be used to signal task availability.\n\n\nDraining\n\n\nAnother common approach is to let a proxy drain backends that are supposed to shut down.\nThat is, once a backend is supposed to shut down, Traefik would stop forwarding requests.\n\n\nOn the plus side, this would not require any modifications to the application in question.\nHowever, implementing this fully within Traefik seems like a non-trivial undertaking.\n\n\nAdditionally, the approach is less flexible compared to a custom termination handler since only the latter allows for the implementation of custom termination sequences that go beyond simple request draining (e.g., persisting a snapshot state to disk prior to terminating).\n\n\nThe feature is currently not implemented; a request for draining in general is at \nissue 41\n.", 
            "title": "Marathon"
        }, 
        {
            "location": "/user-guide/marathon/#marathon", 
            "text": "This guide explains how to integrate Marathon and operate the cluster in a reliable way from Traefik's standpoint.", 
            "title": "Marathon"
        }, 
        {
            "location": "/user-guide/marathon/#host-detection", 
            "text": "Marathon offers multiple ways to run (Docker-containerized) applications, the most popular ones being   BRIDGE-networked containers with dynamic high ports exposed  HOST-networked containers with host machine ports  containers with dedicated IP addresses ( IP-per-task ).   Traefik tries to detect the configured mode and route traffic to the right IP addresses. It is possible to force using task hosts with the  forceTaskHostname  option.  Given the complexity of the subject, it is possible that the heuristic fails.\nApart from filing an issue and waiting for the feature request / bug report to get addressed, one workaround for such situations is to customize the Marathon template file to the individual needs.   Note  This does  not  require rebuilding Traefik but only to point the  filename  configuration parameter to a customized version of the  marathon.tmpl  file on Traefik startup.", 
            "title": "Host detection"
        }, 
        {
            "location": "/user-guide/marathon/#port-detection", 
            "text": "Traefik also attempts to determine the right port (which is a  non-trivial matter in Marathon ).\nFollowing is the order by which Traefik tries to identify the port (the first one that yields a positive result will be used):   A arbitrary port specified through the  traefik.port  label.  The task port (possibly indexed through the  traefik.portIndex  label, otherwise the first one).  The port from the application's  portDefinitions  field (possibly indexed through the  traefik.portIndex  label, otherwise the first one).  The port from the application's  ipAddressPerTask  field (possibly indexed through the  traefik.portIndex  label, otherwise the first one).", 
            "title": "Port detection"
        }, 
        {
            "location": "/user-guide/marathon/#applications-with-multiple-ports", 
            "text": "Some Marathon applications may expose multiple ports. Traefik supports creating one so-called  service  per port using  specific labels .  For instance, assume that a Marathon application exposes a web API on port 80 and an admin interface on port 8080. It would then be possible to make each service available by specifying the following Marathon labels:  traefik.web.port=80  traefik.admin.port=8080  (Note that the service names  web  and  admin  can be chosen arbitrarily.)  Technically, Traefik will create one pair of frontend and backend configurations for each service.", 
            "title": "Applications with multiple ports"
        }, 
        {
            "location": "/user-guide/marathon/#achieving-high-availability", 
            "text": "", 
            "title": "Achieving high availability"
        }, 
        {
            "location": "/user-guide/marathon/#scenarios", 
            "text": "There are three scenarios where the availability of a Marathon application could be impaired along with the risk of losing or failing requests:   During the startup phase when Traefik already routes requests to the backend even though it has not completed its bootstrapping process yet.  During the shutdown phase when Traefik still routes requests to the backend while the backend is already terminating.  During a failure of the application when Traefik has not yet identified the backend as being erroneous.   The first two scenarios are common with every rolling upgrade of an application (i.e. a new version release or configuration update).  The following sub-sections describe how to resolve or mitigate each scenario.", 
            "title": "Scenarios"
        }, 
        {
            "location": "/user-guide/marathon/#startup", 
            "text": "It is possible to define  readiness checks  (available since Marathon version 1.1) per application and have Marathon take these into account during the startup phase.  The idea is that each application provides an HTTP endpoint that Marathon queries periodically during an ongoing deployment in order to mark the associated readiness check result as successful if and only if the endpoint returns a response within the configured HTTP code range. \nAs long as the check keeps failing, Marathon will not proceed with the deployment (within the configured upgrade strategy bounds).  Beginning with version 1.4, Traefik respects readiness check results if the Traefik option is set and checks are configured on the applications accordingly.   Note  Due to the way readiness check results are currently exposed by the Marathon API, ready tasks may be taken into rotation with a small delay.\nIt is on the order of one readiness check timeout interval (as configured on the application specifiation) and guarantees that non-ready tasks do not receive traffic prematurely.   If readiness checks are not possible, a current mitigation strategy is to enable  retries  and make sure that a sufficient number of healthy application tasks exist so that one retry will likely hit one of those.\nApart from its probabilistic nature, the workaround comes at the price of increased latency.", 
            "title": "Startup"
        }, 
        {
            "location": "/user-guide/marathon/#shutdown", 
            "text": "It is possible to install a  termination handler  (available since Marathon version 1.3) with each application whose responsibility it is to delay the shutdown process long enough until the backend has been taken out of load-balancing rotation with reasonable confidence (i.e., Traefik has received an update from the Marathon event bus, recomputes the available Marathon backends, and applies the new configuration). \nSpecifically, each termination handler should install a signal handler listening for a SIGTERM signal and implement the following steps on signal reception:   Disable Keep-Alive HTTP connections.  Keep accepting HTTP requests for a certain period of time.  Stop accepting new connections.  Finish serving any in-flight requests.  Shut down.   Traefik already ignores Marathon tasks whose state does not match  TASK_RUNNING ; since terminating tasks transition into the  TASK_KILLING  and eventually  TASK_KILLED  state, there is nothing further that needs to be done on Traefik's end.  How long HTTP requests should continue to be accepted in step 2 depends on how long Traefik needs to receive and process the Marathon configuration update.\nUnder regular operational conditions, it should be on the order of seconds, with 10 seconds possibly being a good default value.  Again, configuring Traefik to do retries (as discussed in the previous section) can serve as a decent workaround strategy. \nPaired with termination handlers, they would cover for those cases where either the termination sequence or Traefik cannot complete their part of the orchestration process in time.", 
            "title": "Shutdown"
        }, 
        {
            "location": "/user-guide/marathon/#failure", 
            "text": "A failing application always happens unexpectedly, and hence, it is very difficult or even impossible to rule out the adversal effects categorically.  Failure reasons vary broadly and could stretch from unacceptable slowness, a task crash, or a network split.  There are two mitigaton efforts:   Configure  Marathon health checks  on each application.  Configure Traefik health checks (possibly via the  traefik.backend.healthcheck.*  labels) and make sure they probe with proper frequency.   The Marathon health check makes sure that applications once deemed dysfunctional are being rescheduled to different slaves.\nHowever, they might take a while to get triggered and the follow-up processes to complete.  For that reason, the Treafik health check provides an additional check that responds more rapidly and does not require a configuration reload to happen.\nAdditionally, it protects from cases that the Marathon health check may not be able to cover, such as a network split.", 
            "title": "Failure"
        }, 
        {
            "location": "/user-guide/marathon/#non-alternatives", 
            "text": "There are a few alternatives of varying quality that are frequently asked for.  The remaining section is going to explore them along with a benefit/cost trade-off.", 
            "title": "(Non-)Alternatives"
        }, 
        {
            "location": "/user-guide/marathon/#reusing-marathon-health-checks", 
            "text": "It may seem obvious to reuse the Marathon health checks as a signal to Traefik whether an application should be taken into load-balancing rotation or not.  Apart from the increased latency a failing health check may have, a major problem with this is is that Marathon does not persist the health check results.\nConsequently, if a master re-election occurs in the Marathon clusters, all health check results will revert to the  unknown  state, effectively causing all applications inside the cluster to become unavailable and leading to a complete cluster failure. \nRe-elections do not only happen during regular maintenance work (often requiring rolling upgrades of the Marathon nodes) but also when the Marathon leader fails spontaneously.\nAs such, there is no way to handle this situation deterministically.  Finally, Marathon health checks are not mandatory (the default is to use the task state as reported by Mesos), so requiring them for Traefik would raise the entry barrier for Marathon users.  Traefik used to use the health check results as a strict requirement but moved away from it as  users reported the dramatic consequences .\nIf health check results are known to exist, however, they will be used to signal task availability.", 
            "title": "Reusing Marathon health checks"
        }, 
        {
            "location": "/user-guide/marathon/#draining", 
            "text": "Another common approach is to let a proxy drain backends that are supposed to shut down.\nThat is, once a backend is supposed to shut down, Traefik would stop forwarding requests.  On the plus side, this would not require any modifications to the application in question.\nHowever, implementing this fully within Traefik seems like a non-trivial undertaking.  Additionally, the approach is less flexible compared to a custom termination handler since only the latter allows for the implementation of custom termination sequences that go beyond simple request draining (e.g., persisting a snapshot state to disk prior to terminating).  The feature is currently not implemented; a request for draining in general is at  issue 41 .", 
            "title": "Draining"
        }, 
        {
            "location": "/user-guide/kv-config/", 
            "text": "Key-value store configuration\n\n\nBoth \nstatic global configuration\n and \ndynamic\n configuration can be stored in a Key-value store.\n\n\nThis section explains how to launch Tr\u00e6fik using a configuration loaded from a Key-value store.\n\n\nTr\u00e6fik supports several Key-value stores:\n\n\n\n\nConsul\n\n\netcd\n\n\nZooKeeper\n\n\nboltdb\n\n\n\n\nStatic configuration in Key-value store\n\n\nWe will see the steps to set it up with an easy example.\n\n\n\n\nNote\n\n\nWe could do the same with any other Key-value Store.\n\n\n\n\ndocker-compose file for Consul\n\n\nThe Tr\u00e6fik global configuration will be retrieved from a \nConsul\n store.\n\n\nFirst we have to launch Consul in a container.\n\n\nThe \ndocker-compose file\n allows us to launch Consul and four instances of the trivial app \nemilevauge/whoamI\n :\n\n\nconsul:\n  image: progrium/consul\n  command: -server -bootstrap -log-level debug -ui-dir /ui\n  ports:\n    - \n8400:8400\n\n    - \n8500:8500\n\n    - \n8600:53/udp\n\n  expose:\n    - \n8300\n\n    - \n8301\n\n    - \n8301/udp\n\n    - \n8302\n\n    - \n8302/udp\n\n\nwhoami1:\n  image: emilevauge/whoami\n\nwhoami2:\n  image: emilevauge/whoami\n\nwhoami3:\n  image: emilevauge/whoami\n\nwhoami4:\n  image: emilevauge/whoami\n\n\n\n\nUpload the configuration in the Key-value store\n\n\nWe should now fill the store with the Tr\u00e6fik global configuration, as we do with a \nTOML file configuration\n.\n\nTo do that, we can send the Key-value pairs via \ncurl commands\n or via the \nWeb UI\n.\n\n\nFortunately, Tr\u00e6fik allows automation of this process using the \nstoreconfig\n subcommand.\n\nPlease refer to the \nstore Tr\u00e6fik configuration\n section to get documentation on it.\n\n\nHere is the toml configuration we would like to store in the Key-value Store  :\n\n\nlogLevel = \nDEBUG\n\n\ndefaultEntryPoints = [\nhttp\n, \nhttps\n]\n\n[entryPoints]\n  [entryPoints.api]\n    address = \n:8081\n\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.https]\n  address = \n:443\n\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile = \nintegration/fixtures/https/snitest.com.cert\n\n      keyFile = \nintegration/fixtures/https/snitest.com.key\n\n      [[entryPoints.https.tls.certificates]]\n      certFile = \n-----BEGIN CERTIFICATE-----\n                      \ncert file content\n\n                      -----END CERTIFICATE-----\n\n      keyFile = \n-----BEGIN CERTIFICATE-----\n                      \nkey file content\n\n                      -----END CERTIFICATE-----\n\n    [entryPoints.other-https]\n    address = \n:4443\n\n      [entryPoints.other-https.tls]\n\n[consul]\n  endpoint = \n127.0.0.1:8500\n\n  watch = true\n  prefix = \ntraefik\n\n\n[api]\n  entrypoint = \napi\n\n\n\n\n\nAnd there, the same global configuration in the Key-value Store (using \nprefix = \"traefik\"\n):\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/loglevel\n\n\nDEBUG\n\n\n\n\n\n\n/traefik/defaultentrypoints/0\n\n\nhttp\n\n\n\n\n\n\n/traefik/defaultentrypoints/1\n\n\nhttps\n\n\n\n\n\n\n/traefik/entrypoints/api/address\n\n\n:8081\n\n\n\n\n\n\n/traefik/entrypoints/http/address\n\n\n:80\n\n\n\n\n\n\n/traefik/entrypoints/https/address\n\n\n:443\n\n\n\n\n\n\n/traefik/entrypoints/https/tls/certificates/0/certfile\n\n\nintegration/fixtures/https/snitest.com.cert\n\n\n\n\n\n\n/traefik/entrypoints/https/tls/certificates/0/keyfile\n\n\nintegration/fixtures/https/snitest.com.key\n\n\n\n\n\n\n/traefik/entrypoints/https/tls/certificates/1/certfile\n\n\n--BEGIN CERTIFICATE--\ncert file content\n--END CERTIFICATE--\n\n\n\n\n\n\n/traefik/entrypoints/https/tls/certificates/1/keyfile\n\n\n--BEGIN CERTIFICATE--\nkey file content\n--END CERTIFICATE--\n\n\n\n\n\n\n/traefik/entrypoints/other-https/address\n\n\n:4443\n\n\n\n\n\n\n/traefik/consul/endpoint\n\n\n127.0.0.1:8500\n\n\n\n\n\n\n/traefik/consul/watch\n\n\ntrue\n\n\n\n\n\n\n/traefik/consul/prefix\n\n\ntraefik\n\n\n\n\n\n\n/traefik/api/entrypoint\n\n\napi\n\n\n\n\n\n\n\n\nIn case you are setting key values manually:\n\n\n\n\nRemember to specify the indexes (\n0\n,\n1\n, \n2\n, ... ) under prefixes \n/traefik/defaultentrypoints/\n and \n/traefik/entrypoints/https/tls/certificates/\n in order to match the global configuration structure.\n\n\nBe careful to give the correct IP address and port on the key \n/traefik/consul/endpoint\n.\n\n\n\n\nNote that we can either give path to certificate file or directly the file content itself.\n\n\nLaunch Tr\u00e6fik\n\n\nWe will now launch Tr\u00e6fik in a container.\n\n\nWe use CLI flags to setup the connection between Tr\u00e6fik and Consul.\nAll the rest of the global configuration is stored in Consul.\n\n\nHere is the \ndocker-compose file\n :\n\n\ntraefik:\n  image: traefik\n  command: --consul --consul.endpoint=127.0.0.1:8500\n  ports:\n    - \n80:80\n\n    - \n8080:8080\n\n\n\n\n\n\n\nWarning\n\n\nBe careful to give the correct IP address and port in the flag \n--consul.endpoint\n.\n\n\n\n\nConsul ACL Token support\n\n\nTo specify a Consul ACL token for Traefik, we have to set a System Environment variable named \nCONSUL_HTTP_TOKEN\n prior to starting Traefik.\nThis variable must be initialized with the ACL token value.\n\n\nIf Traefik is launched into a Docker container, the variable \nCONSUL_HTTP_TOKEN\n can be initialized with the \n-e\n Docker option : \n-e \"CONSUL_HTTP_TOKEN=[consul-acl-token-value]\"\n\n\nIf a Consul ACL is used to restrict Tr\u00e6fik read/write access, one of the following configurations is needed.\n\n\n\n\nHCL format :\n\n\n\n\n    key \ntraefik\n {\n        policy = \nwrite\n\n    },\n\n    session \n {\n        policy = \nwrite\n\n    }\n\n\n\n\n\n\nJSON format :\n\n\n\n\n{\n    \nkey\n: {\n        \ntraefik\n: {\n          \npolicy\n: \nwrite\n\n        }\n    },\n    \nsession\n: {\n        \n: {\n        \npolicy\n: \nwrite\n\n        }\n    }\n}\n\n\n\n\nTLS support\n\n\nTo connect to a Consul endpoint using SSL, simply specify \nhttps://\n in the \nconsul.endpoint\n property\n\n\n\n\n--consul.endpoint=https://[consul-host]:[consul-ssl-port]\n\n\n\n\nTLS support with client certificates\n\n\nSo far, only \nConsul\n and \netcd\n support TLS connections with client certificates.\n\n\nTo set it up, we should enable \nconsul security\n (or \netcd security\n).\n\n\nThen, we have to provide CA, Cert and Key to Tr\u00e6fik using \nconsul\n flags :\n\n\n\n\n--consul.tls\n\n\n--consul.tls.ca=path/to/the/file\n\n\n--consul.tls.cert=path/to/the/file\n\n\n--consul.tls.key=path/to/the/file\n\n\n\n\nOr etcd flags :\n\n\n\n\n--etcd.tls\n\n\n--etcd.tls.ca=path/to/the/file\n\n\n--etcd.tls.cert=path/to/the/file\n\n\n--etcd.tls.key=path/to/the/file\n\n\n\n\n!! note\n    We can either give directly directly the file content itself (instead of the path to certificate) in a TOML file configuration.\n\n\nRemember the command \ntraefik --help\n to display the updated list of flags.\n\n\nDynamic configuration in Key-value store\n\n\nFollowing our example, we will provide backends/frontends  rules and HTTPS certificates to Tr\u00e6fik.\n\n\n\n\nNote\n\n\nThis section is independent of the way Tr\u00e6fik got its static configuration.\nIt means that the static configuration can either come from the same Key-value store or from any other sources.\n\n\n\n\nKey-value storage structure\n\n\nHere is the toml configuration we would like to store in the store :\n\n\n[file]\n\n# rules\n[backends]\n  [backends.backend1]\n    [backends.backend1.circuitbreaker]\n    expression = \nNetworkErrorRatio() \n 0.5\n\n    [backends.backend1.servers.server1]\n    url = \nhttp://172.17.0.2:80\n\n    weight = 10\n    [backends.backend1.servers.server2]\n    url = \nhttp://172.17.0.3:80\n\n    weight = 1\n  [backends.backend2]\n    [backends.backend1.maxconn]\n    amount = 10\n    extractorfunc = \nrequest.host\n\n    [backends.backend2.LoadBalancer]\n    method = \ndrr\n\n    [backends.backend2.servers.server1]\n    url = \nhttp://172.17.0.4:80\n\n    weight = 1\n    [backends.backend2.servers.server2]\n    url = \nhttp://172.17.0.5:80\n\n    weight = 2\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend2\n\n    [frontends.frontend1.routes.test_1]\n    rule = \nHost:test.localhost\n\n  [frontends.frontend2]\n  backend = \nbackend1\n\n  passHostHeader = true\n  priority = 10\n  entrypoints = [\nhttps\n] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule = \nHost:{subdomain:[a-z]+}.localhost\n\n  [frontends.frontend3]\n  entrypoints = [\nhttp\n, \nhttps\n] # overrides defaultEntryPoints\n  backend = \nbackend2\n\n  rule = \nPath:/test\n\n\n[[tls]]\nentryPoints = [\nhttps\n]\n  [tls.certificate]\n    certFile = \npath/to/your.cert\n\n    keyFile = \npath/to/your.key\n\n[[tls]]\nentryPoints = [\nhttps\n,\nother-https\n]\n  [tls.certificate]\n    certFile = \n-----BEGIN CERTIFICATE-----\n                      \ncert file content\n\n                      -----END CERTIFICATE-----\n\n    keyFile = \n-----BEGIN CERTIFICATE-----\n                      \nkey file content\n\n                      -----END CERTIFICATE-----\n\n\n\n\n\nAnd there, the same dynamic configuration in a KV Store (using \nprefix = \"traefik\"\n):\n\n\n\n\nbackend 1\n\n\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/backends/backend1/circuitbreaker/expression\n\n\nNetworkErrorRatio() \n 0.5\n\n\n\n\n\n\n/traefik/backends/backend1/servers/server1/url\n\n\nhttp://172.17.0.2:80\n\n\n\n\n\n\n/traefik/backends/backend1/servers/server1/weight\n\n\n10\n\n\n\n\n\n\n/traefik/backends/backend1/servers/server2/url\n\n\nhttp://172.17.0.3:80\n\n\n\n\n\n\n/traefik/backends/backend1/servers/server2/weight\n\n\n1\n\n\n\n\n\n\n/traefik/backends/backend1/servers/server2/tags\n\n\napi,helloworld\n\n\n\n\n\n\n\n\n\n\nbackend 2\n\n\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/backends/backend2/maxconn/amount\n\n\n10\n\n\n\n\n\n\n/traefik/backends/backend2/maxconn/extractorfunc\n\n\nrequest.host\n\n\n\n\n\n\n/traefik/backends/backend2/loadbalancer/method\n\n\ndrr\n\n\n\n\n\n\n/traefik/backends/backend2/servers/server1/url\n\n\nhttp://172.17.0.4:80\n\n\n\n\n\n\n/traefik/backends/backend2/servers/server1/weight\n\n\n1\n\n\n\n\n\n\n/traefik/backends/backend2/servers/server2/url\n\n\nhttp://172.17.0.5:80\n\n\n\n\n\n\n/traefik/backends/backend2/servers/server2/weight\n\n\n2\n\n\n\n\n\n\n/traefik/backends/backend2/servers/server2/tags\n\n\nweb\n\n\n\n\n\n\n\n\n\n\nfrontend 1\n\n\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/frontends/frontend1/backend\n\n\nbackend2\n\n\n\n\n\n\n/traefik/frontends/frontend1/routes/test_1/rule\n\n\nHost:test.localhost\n\n\n\n\n\n\n\n\n\n\nfrontend 2\n\n\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/frontends/frontend2/backend\n\n\nbackend1\n\n\n\n\n\n\n/traefik/frontends/frontend2/passhostheader\n\n\ntrue\n\n\n\n\n\n\n/traefik/frontends/frontend2/priority\n\n\n10\n\n\n\n\n\n\n/traefik/frontends/frontend2/entrypoints\n\n\nhttp,https\n\n\n\n\n\n\n/traefik/frontends/frontend2/routes/test_2/rule\n\n\nPathPrefix:/test\n\n\n\n\n\n\n\n\n\n\ncertificate 1\n\n\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/tls/1/entrypoints\n\n\nhttps\n\n\n\n\n\n\n/traefik/tls/1/certificate/certfile\n\n\npath/to/your.cert\n\n\n\n\n\n\n/traefik/tls/1/certificate/keyfile\n\n\npath/to/your.key\n\n\n\n\n\n\n\n\n\n\ncertificate 2\n\n\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/tls/2/entrypoints\n\n\nhttps,other-https\n\n\n\n\n\n\n/traefik/tls/2/certificate/certfile\n\n\ncert file content\n\n\n\n\n\n\n/traefik/tls/2/certificate/certfile\n\n\nkey file content\n\n\n\n\n\n\n\n\nAtomic configuration changes\n\n\nTr\u00e6fik can watch the backends/frontends configuration changes and generate its configuration automatically.\n\n\n\n\nNote\n\n\nOnly backends/frontends rules are dynamic, the rest of the Tr\u00e6fik configuration stay static.\n\n\n\n\nThe \nEtcd\n and \nConsul\n backends do not support updating multiple keys atomically.\n\nAs a result, it may be possible for Tr\u00e6fik to read an intermediate configuration state despite judicious use of the \n--providersThrottleDuration\n flag.\n\nTo solve this problem, Tr\u00e6fik supports a special key called \n/traefik/alias\n.\nIf set, Tr\u00e6fik use the value as an alternative key prefix.\n\n\n\n\nNote\n\n\nThe field \nuseAPIV3\n allows using Etcd V3 API which should support updating multiple keys atomically with Etcd.\nEtcd API V2 is deprecated and, in the future, Tr\u00e6fik will support API V3 by default.\n\n\n\n\nGiven the key structure below, Tr\u00e6fik will use the \nhttp://172.17.0.2:80\n as its only backend (frontend keys have been omitted for brevity).\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/alias\n\n\n/traefik_configurations/1\n\n\n\n\n\n\n/traefik_configurations/1/backends/backend1/servers/server1/url\n\n\nhttp://172.17.0.2:80\n\n\n\n\n\n\n/traefik_configurations/1/backends/backend1/servers/server1/weight\n\n\n10\n\n\n\n\n\n\n\n\nWhen an atomic configuration change is required, you may write a new configuration at an alternative prefix.\n\n\nHere, although the \n/traefik_configurations/2/...\n keys have been set, the old configuration is still active because the \n/traefik/alias\n key still points to \n/traefik_configurations/1\n:\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/alias\n\n\n/traefik_configurations/1\n\n\n\n\n\n\n/traefik_configurations/1/backends/backend1/servers/server1/url\n\n\nhttp://172.17.0.2:80\n\n\n\n\n\n\n/traefik_configurations/1/backends/backend1/servers/server1/weight\n\n\n10\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server1/url\n\n\nhttp://172.17.0.2:80\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server1/weight\n\n\n5\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server2/url\n\n\nhttp://172.17.0.3:80\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server2/weight\n\n\n5\n\n\n\n\n\n\n\n\nOnce the \n/traefik/alias\n key is updated, the new \n/traefik_configurations/2\n configuration becomes active atomically.\n\n\nHere, we have a 50% balance between the \nhttp://172.17.0.3:80\n and the \nhttp://172.17.0.4:80\n hosts while no traffic is sent to the \n172.17.0.2:80\n host:\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/alias\n\n\n/traefik_configurations/2\n\n\n\n\n\n\n/traefik_configurations/1/backends/backend1/servers/server1/url\n\n\nhttp://172.17.0.2:80\n\n\n\n\n\n\n/traefik_configurations/1/backends/backend1/servers/server1/weight\n\n\n10\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server1/url\n\n\nhttp://172.17.0.3:80\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server1/weight\n\n\n5\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server2/url\n\n\nhttp://172.17.0.4:80\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server2/weight\n\n\n5\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nTr\u00e6fik \nwill not watch for key changes in the \n/traefik_configurations\n prefix\n. It will only watch for changes in the \n/traefik/alias\n.\n\nFurther, if the \n/traefik/alias\n key is set, all other configuration with \n/traefik/backends\n or \n/traefik/frontends\n prefix are ignored.\n\n\n\n\nStore configuration in Key-value store\n\n\n\n\nNote\n\n\nDon't forget to \nsetup the connection between Tr\u00e6fik and Key-value store\n.\n\n\n\n\nThe static Tr\u00e6fik configuration in a key-value store can be automatically created and updated, using the \nstoreconfig\n subcommand\n.\n\n\ntraefik storeconfig [flags] ...\n\n\n\n\nThis command is here only to automate the \nprocess which upload the configuration into the Key-value store\n.\nTr\u00e6fik will not start but the \nstatic configuration\n will be uploaded into the Key-value store.  \n\n\nIf you configured ACME (Let's Encrypt), your registration account and your certificates will also be uploaded.\n\n\nIf you configured a file backend \n[file]\n, all your dynamic configuration (backends, frontends...) will be uploaded to the Key-value store.\n\n\nTo upload your ACME certificates to the KV store, get your Traefik TOML file and add the new \nstorage\n option in the \nacme\n section:\n\n\n[acme]\nemail = \ntest@traefik.io\n\nstorage = \ntraefik/acme/account\n # the key where to store your certificates in the KV store\nstorageFile = \nacme.json\n # your old certificates store\n\n\n\n\nCall \ntraefik\u00a0storeconfig\n to upload your config in the KV store.\nThen remove the line \nstorageFile = \"acme.json\"\n from your TOML config file.\n\n\nThat's it!", 
            "title": "Key-value Store Configuration"
        }, 
        {
            "location": "/user-guide/kv-config/#key-value-store-configuration", 
            "text": "Both  static global configuration  and  dynamic  configuration can be stored in a Key-value store.  This section explains how to launch Tr\u00e6fik using a configuration loaded from a Key-value store.  Tr\u00e6fik supports several Key-value stores:   Consul  etcd  ZooKeeper  boltdb", 
            "title": "Key-value store configuration"
        }, 
        {
            "location": "/user-guide/kv-config/#static-configuration-in-key-value-store", 
            "text": "We will see the steps to set it up with an easy example.   Note  We could do the same with any other Key-value Store.", 
            "title": "Static configuration in Key-value store"
        }, 
        {
            "location": "/user-guide/kv-config/#docker-compose-file-for-consul", 
            "text": "The Tr\u00e6fik global configuration will be retrieved from a  Consul  store.  First we have to launch Consul in a container.  The  docker-compose file  allows us to launch Consul and four instances of the trivial app  emilevauge/whoamI  :  consul:\n  image: progrium/consul\n  command: -server -bootstrap -log-level debug -ui-dir /ui\n  ports:\n    -  8400:8400 \n    -  8500:8500 \n    -  8600:53/udp \n  expose:\n    -  8300 \n    -  8301 \n    -  8301/udp \n    -  8302 \n    -  8302/udp \n\nwhoami1:\n  image: emilevauge/whoami\n\nwhoami2:\n  image: emilevauge/whoami\n\nwhoami3:\n  image: emilevauge/whoami\n\nwhoami4:\n  image: emilevauge/whoami", 
            "title": "docker-compose file for Consul"
        }, 
        {
            "location": "/user-guide/kv-config/#upload-the-configuration-in-the-key-value-store", 
            "text": "We should now fill the store with the Tr\u00e6fik global configuration, as we do with a  TOML file configuration . \nTo do that, we can send the Key-value pairs via  curl commands  or via the  Web UI .  Fortunately, Tr\u00e6fik allows automation of this process using the  storeconfig  subcommand. \nPlease refer to the  store Tr\u00e6fik configuration  section to get documentation on it.  Here is the toml configuration we would like to store in the Key-value Store  :  logLevel =  DEBUG \n\ndefaultEntryPoints = [ http ,  https ]\n\n[entryPoints]\n  [entryPoints.api]\n    address =  :8081 \n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.https]\n  address =  :443 \n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile =  integration/fixtures/https/snitest.com.cert \n      keyFile =  integration/fixtures/https/snitest.com.key \n      [[entryPoints.https.tls.certificates]]\n      certFile =  -----BEGIN CERTIFICATE-----\n                       cert file content \n                      -----END CERTIFICATE----- \n      keyFile =  -----BEGIN CERTIFICATE-----\n                       key file content \n                      -----END CERTIFICATE----- \n    [entryPoints.other-https]\n    address =  :4443 \n      [entryPoints.other-https.tls]\n\n[consul]\n  endpoint =  127.0.0.1:8500 \n  watch = true\n  prefix =  traefik \n\n[api]\n  entrypoint =  api   And there, the same global configuration in the Key-value Store (using  prefix = \"traefik\" ):     Key  Value      /traefik/loglevel  DEBUG    /traefik/defaultentrypoints/0  http    /traefik/defaultentrypoints/1  https    /traefik/entrypoints/api/address  :8081    /traefik/entrypoints/http/address  :80    /traefik/entrypoints/https/address  :443    /traefik/entrypoints/https/tls/certificates/0/certfile  integration/fixtures/https/snitest.com.cert    /traefik/entrypoints/https/tls/certificates/0/keyfile  integration/fixtures/https/snitest.com.key    /traefik/entrypoints/https/tls/certificates/1/certfile  --BEGIN CERTIFICATE-- cert file content --END CERTIFICATE--    /traefik/entrypoints/https/tls/certificates/1/keyfile  --BEGIN CERTIFICATE-- key file content --END CERTIFICATE--    /traefik/entrypoints/other-https/address  :4443    /traefik/consul/endpoint  127.0.0.1:8500    /traefik/consul/watch  true    /traefik/consul/prefix  traefik    /traefik/api/entrypoint  api     In case you are setting key values manually:   Remember to specify the indexes ( 0 , 1 ,  2 , ... ) under prefixes  /traefik/defaultentrypoints/  and  /traefik/entrypoints/https/tls/certificates/  in order to match the global configuration structure.  Be careful to give the correct IP address and port on the key  /traefik/consul/endpoint .   Note that we can either give path to certificate file or directly the file content itself.", 
            "title": "Upload the configuration in the Key-value store"
        }, 
        {
            "location": "/user-guide/kv-config/#launch-trfik", 
            "text": "We will now launch Tr\u00e6fik in a container.  We use CLI flags to setup the connection between Tr\u00e6fik and Consul.\nAll the rest of the global configuration is stored in Consul.  Here is the  docker-compose file  :  traefik:\n  image: traefik\n  command: --consul --consul.endpoint=127.0.0.1:8500\n  ports:\n    -  80:80 \n    -  8080:8080    Warning  Be careful to give the correct IP address and port in the flag  --consul.endpoint .", 
            "title": "Launch Tr\u00e6fik"
        }, 
        {
            "location": "/user-guide/kv-config/#consul-acl-token-support", 
            "text": "To specify a Consul ACL token for Traefik, we have to set a System Environment variable named  CONSUL_HTTP_TOKEN  prior to starting Traefik.\nThis variable must be initialized with the ACL token value.  If Traefik is launched into a Docker container, the variable  CONSUL_HTTP_TOKEN  can be initialized with the  -e  Docker option :  -e \"CONSUL_HTTP_TOKEN=[consul-acl-token-value]\"  If a Consul ACL is used to restrict Tr\u00e6fik read/write access, one of the following configurations is needed.   HCL format :       key  traefik  {\n        policy =  write \n    },\n\n    session   {\n        policy =  write \n    }   JSON format :   {\n     key : {\n         traefik : {\n           policy :  write \n        }\n    },\n     session : {\n         : {\n         policy :  write \n        }\n    }\n}", 
            "title": "Consul ACL Token support"
        }, 
        {
            "location": "/user-guide/kv-config/#tls-support", 
            "text": "To connect to a Consul endpoint using SSL, simply specify  https://  in the  consul.endpoint  property   --consul.endpoint=https://[consul-host]:[consul-ssl-port]", 
            "title": "TLS support"
        }, 
        {
            "location": "/user-guide/kv-config/#tls-support-with-client-certificates", 
            "text": "So far, only  Consul  and  etcd  support TLS connections with client certificates.  To set it up, we should enable  consul security  (or  etcd security ).  Then, we have to provide CA, Cert and Key to Tr\u00e6fik using  consul  flags :   --consul.tls  --consul.tls.ca=path/to/the/file  --consul.tls.cert=path/to/the/file  --consul.tls.key=path/to/the/file   Or etcd flags :   --etcd.tls  --etcd.tls.ca=path/to/the/file  --etcd.tls.cert=path/to/the/file  --etcd.tls.key=path/to/the/file   !! note\n    We can either give directly directly the file content itself (instead of the path to certificate) in a TOML file configuration.  Remember the command  traefik --help  to display the updated list of flags.", 
            "title": "TLS support with client certificates"
        }, 
        {
            "location": "/user-guide/kv-config/#dynamic-configuration-in-key-value-store", 
            "text": "Following our example, we will provide backends/frontends  rules and HTTPS certificates to Tr\u00e6fik.   Note  This section is independent of the way Tr\u00e6fik got its static configuration.\nIt means that the static configuration can either come from the same Key-value store or from any other sources.", 
            "title": "Dynamic configuration in Key-value store"
        }, 
        {
            "location": "/user-guide/kv-config/#key-value-storage-structure", 
            "text": "Here is the toml configuration we would like to store in the store :  [file]\n\n# rules\n[backends]\n  [backends.backend1]\n    [backends.backend1.circuitbreaker]\n    expression =  NetworkErrorRatio()   0.5 \n    [backends.backend1.servers.server1]\n    url =  http://172.17.0.2:80 \n    weight = 10\n    [backends.backend1.servers.server2]\n    url =  http://172.17.0.3:80 \n    weight = 1\n  [backends.backend2]\n    [backends.backend1.maxconn]\n    amount = 10\n    extractorfunc =  request.host \n    [backends.backend2.LoadBalancer]\n    method =  drr \n    [backends.backend2.servers.server1]\n    url =  http://172.17.0.4:80 \n    weight = 1\n    [backends.backend2.servers.server2]\n    url =  http://172.17.0.5:80 \n    weight = 2\n\n[frontends]\n  [frontends.frontend1]\n  backend =  backend2 \n    [frontends.frontend1.routes.test_1]\n    rule =  Host:test.localhost \n  [frontends.frontend2]\n  backend =  backend1 \n  passHostHeader = true\n  priority = 10\n  entrypoints = [ https ] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule =  Host:{subdomain:[a-z]+}.localhost \n  [frontends.frontend3]\n  entrypoints = [ http ,  https ] # overrides defaultEntryPoints\n  backend =  backend2 \n  rule =  Path:/test \n\n[[tls]]\nentryPoints = [ https ]\n  [tls.certificate]\n    certFile =  path/to/your.cert \n    keyFile =  path/to/your.key \n[[tls]]\nentryPoints = [ https , other-https ]\n  [tls.certificate]\n    certFile =  -----BEGIN CERTIFICATE-----\n                       cert file content \n                      -----END CERTIFICATE----- \n    keyFile =  -----BEGIN CERTIFICATE-----\n                       key file content \n                      -----END CERTIFICATE-----   And there, the same dynamic configuration in a KV Store (using  prefix = \"traefik\" ):   backend 1      Key  Value      /traefik/backends/backend1/circuitbreaker/expression  NetworkErrorRatio()   0.5    /traefik/backends/backend1/servers/server1/url  http://172.17.0.2:80    /traefik/backends/backend1/servers/server1/weight  10    /traefik/backends/backend1/servers/server2/url  http://172.17.0.3:80    /traefik/backends/backend1/servers/server2/weight  1    /traefik/backends/backend1/servers/server2/tags  api,helloworld      backend 2      Key  Value      /traefik/backends/backend2/maxconn/amount  10    /traefik/backends/backend2/maxconn/extractorfunc  request.host    /traefik/backends/backend2/loadbalancer/method  drr    /traefik/backends/backend2/servers/server1/url  http://172.17.0.4:80    /traefik/backends/backend2/servers/server1/weight  1    /traefik/backends/backend2/servers/server2/url  http://172.17.0.5:80    /traefik/backends/backend2/servers/server2/weight  2    /traefik/backends/backend2/servers/server2/tags  web      frontend 1      Key  Value      /traefik/frontends/frontend1/backend  backend2    /traefik/frontends/frontend1/routes/test_1/rule  Host:test.localhost      frontend 2      Key  Value      /traefik/frontends/frontend2/backend  backend1    /traefik/frontends/frontend2/passhostheader  true    /traefik/frontends/frontend2/priority  10    /traefik/frontends/frontend2/entrypoints  http,https    /traefik/frontends/frontend2/routes/test_2/rule  PathPrefix:/test      certificate 1      Key  Value      /traefik/tls/1/entrypoints  https    /traefik/tls/1/certificate/certfile  path/to/your.cert    /traefik/tls/1/certificate/keyfile  path/to/your.key      certificate 2      Key  Value      /traefik/tls/2/entrypoints  https,other-https    /traefik/tls/2/certificate/certfile  cert file content    /traefik/tls/2/certificate/certfile  key file content", 
            "title": "Key-value storage structure"
        }, 
        {
            "location": "/user-guide/kv-config/#atomic-configuration-changes", 
            "text": "Tr\u00e6fik can watch the backends/frontends configuration changes and generate its configuration automatically.   Note  Only backends/frontends rules are dynamic, the rest of the Tr\u00e6fik configuration stay static.   The  Etcd  and  Consul  backends do not support updating multiple keys atomically. \nAs a result, it may be possible for Tr\u00e6fik to read an intermediate configuration state despite judicious use of the  --providersThrottleDuration  flag. \nTo solve this problem, Tr\u00e6fik supports a special key called  /traefik/alias .\nIf set, Tr\u00e6fik use the value as an alternative key prefix.   Note  The field  useAPIV3  allows using Etcd V3 API which should support updating multiple keys atomically with Etcd.\nEtcd API V2 is deprecated and, in the future, Tr\u00e6fik will support API V3 by default.   Given the key structure below, Tr\u00e6fik will use the  http://172.17.0.2:80  as its only backend (frontend keys have been omitted for brevity).     Key  Value      /traefik/alias  /traefik_configurations/1    /traefik_configurations/1/backends/backend1/servers/server1/url  http://172.17.0.2:80    /traefik_configurations/1/backends/backend1/servers/server1/weight  10     When an atomic configuration change is required, you may write a new configuration at an alternative prefix.  Here, although the  /traefik_configurations/2/...  keys have been set, the old configuration is still active because the  /traefik/alias  key still points to  /traefik_configurations/1 :     Key  Value      /traefik/alias  /traefik_configurations/1    /traefik_configurations/1/backends/backend1/servers/server1/url  http://172.17.0.2:80    /traefik_configurations/1/backends/backend1/servers/server1/weight  10    /traefik_configurations/2/backends/backend1/servers/server1/url  http://172.17.0.2:80    /traefik_configurations/2/backends/backend1/servers/server1/weight  5    /traefik_configurations/2/backends/backend1/servers/server2/url  http://172.17.0.3:80    /traefik_configurations/2/backends/backend1/servers/server2/weight  5     Once the  /traefik/alias  key is updated, the new  /traefik_configurations/2  configuration becomes active atomically.  Here, we have a 50% balance between the  http://172.17.0.3:80  and the  http://172.17.0.4:80  hosts while no traffic is sent to the  172.17.0.2:80  host:     Key  Value      /traefik/alias  /traefik_configurations/2    /traefik_configurations/1/backends/backend1/servers/server1/url  http://172.17.0.2:80    /traefik_configurations/1/backends/backend1/servers/server1/weight  10    /traefik_configurations/2/backends/backend1/servers/server1/url  http://172.17.0.3:80    /traefik_configurations/2/backends/backend1/servers/server1/weight  5    /traefik_configurations/2/backends/backend1/servers/server2/url  http://172.17.0.4:80    /traefik_configurations/2/backends/backend1/servers/server2/weight  5      Note  Tr\u00e6fik  will not watch for key changes in the  /traefik_configurations  prefix . It will only watch for changes in the  /traefik/alias . \nFurther, if the  /traefik/alias  key is set, all other configuration with  /traefik/backends  or  /traefik/frontends  prefix are ignored.", 
            "title": "Atomic configuration changes"
        }, 
        {
            "location": "/user-guide/kv-config/#store-configuration-in-key-value-store", 
            "text": "Note  Don't forget to  setup the connection between Tr\u00e6fik and Key-value store .   The static Tr\u00e6fik configuration in a key-value store can be automatically created and updated, using the  storeconfig  subcommand .  traefik storeconfig [flags] ...  This command is here only to automate the  process which upload the configuration into the Key-value store .\nTr\u00e6fik will not start but the  static configuration  will be uploaded into the Key-value store.    If you configured ACME (Let's Encrypt), your registration account and your certificates will also be uploaded.  If you configured a file backend  [file] , all your dynamic configuration (backends, frontends...) will be uploaded to the Key-value store.  To upload your ACME certificates to the KV store, get your Traefik TOML file and add the new  storage  option in the  acme  section:  [acme]\nemail =  test@traefik.io \nstorage =  traefik/acme/account  # the key where to store your certificates in the KV store\nstorageFile =  acme.json  # your old certificates store  Call  traefik\u00a0storeconfig  to upload your config in the KV store.\nThen remove the line  storageFile = \"acme.json\"  from your TOML config file.  That's it!", 
            "title": "Store configuration in Key-value store"
        }, 
        {
            "location": "/user-guide/cluster/", 
            "text": "Clustering / High Availability (beta)\n\n\nThis guide explains how to use Tr\u00e6fik in high availability mode.\n\n\nIn order to deploy and configure multiple Tr\u00e6fik instances, without copying the same configuration file on each instance, we will use a distributed Key-Value store.\n\n\nPrerequisites\n\n\nYou will need a working KV store cluster.\n\n(Currently, we recommend \nConsul\n .)\n\n\nFile configuration to KV store migration\n\n\nWe created a special Tr\u00e6fik command to help configuring your Key Value store from a Tr\u00e6fik TOML configuration file.\n\n\nPlease refer to \nthis section\n to get more details.\n\n\nDeploy a Tr\u00e6fik cluster\n\n\nOnce your Tr\u00e6fik configuration is uploaded on your KV store, you can start each Tr\u00e6fik instance.\n\n\nA Tr\u00e6fik cluster is based on a manager/worker model.\n\n\nWhen starting, Tr\u00e6fik will elect a manager.\nIf this instance fails, another manager will be automatically elected.\n\n\nTr\u00e6fik cluster and Let's Encrypt\n\n\nIn cluster mode, ACME certificates have to be stored in \na KV Store entry\n.\n\n\nThanks to the Tr\u00e6fik cluster mode algorithm (based on \nthe Raft Consensus Algorithm\n), only one instance will contact Let's encrypt to solve the challenges.\n\n\nThe others instances will get ACME certificate from the KV Store entry.", 
            "title": "Clustering/HA"
        }, 
        {
            "location": "/user-guide/cluster/#clustering-high-availability-beta", 
            "text": "This guide explains how to use Tr\u00e6fik in high availability mode.  In order to deploy and configure multiple Tr\u00e6fik instances, without copying the same configuration file on each instance, we will use a distributed Key-Value store.", 
            "title": "Clustering / High Availability (beta)"
        }, 
        {
            "location": "/user-guide/cluster/#prerequisites", 
            "text": "You will need a working KV store cluster. (Currently, we recommend  Consul  .)", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/user-guide/cluster/#file-configuration-to-kv-store-migration", 
            "text": "We created a special Tr\u00e6fik command to help configuring your Key Value store from a Tr\u00e6fik TOML configuration file.  Please refer to  this section  to get more details.", 
            "title": "File configuration to KV store migration"
        }, 
        {
            "location": "/user-guide/cluster/#deploy-a-trfik-cluster", 
            "text": "Once your Tr\u00e6fik configuration is uploaded on your KV store, you can start each Tr\u00e6fik instance.  A Tr\u00e6fik cluster is based on a manager/worker model.  When starting, Tr\u00e6fik will elect a manager.\nIf this instance fails, another manager will be automatically elected.", 
            "title": "Deploy a Tr\u00e6fik cluster"
        }, 
        {
            "location": "/user-guide/cluster/#trfik-cluster-and-lets-encrypt", 
            "text": "In cluster mode, ACME certificates have to be stored in  a KV Store entry .  Thanks to the Tr\u00e6fik cluster mode algorithm (based on  the Raft Consensus Algorithm ), only one instance will contact Let's encrypt to solve the challenges.  The others instances will get ACME certificate from the KV Store entry.", 
            "title": "Tr\u00e6fik cluster and Let's Encrypt"
        }, 
        {
            "location": "/user-guide/grpc/", 
            "text": "gRPC example\n\n\nThis section explains how to use Traefik as reverse proxy for gRPC application with self-signed certificates.\n\n\n\n\nWarning\n\n\nAs gRPC needs HTTP2, we need HTTPS certificates on both gRPC Server and Tr\u00e6fik.\n\n\n\n\n\n\n\n\n\n\n\ngRPC Server certificate\n\n\nIn order to secure the gRPC server, we generate a self-signed certificate for backend url:\n\n\nopenssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout ./backend.key -out ./backend.cert\n\n\n\n\nThat will prompt for information, the important answer is:\n\n\nCommon Name (e.g. server FQDN or YOUR name) []: backend.local\n\n\n\n\ngRPC Client certificate\n\n\nGenerate your self-signed certificate for frontend url:\n\n\nopenssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout ./frontend.key -out ./frontend.cert\n\n\n\n\nwith\n\n\nCommon Name (e.g. server FQDN or YOUR name) []: frontend.local\n\n\n\n\nTr\u00e6fik configuration\n\n\nAt last, we configure our Tr\u00e6fik instance to use both self-signed certificates.\n\n\ndefaultEntryPoints = [\nhttps\n]\n\n# For secure connection on backend.local\nRootCAs = [ \n./backend.cert\n ]\n\n[entryPoints]\n  [entryPoints.https]\n  address = \n:4443\n\n    [entryPoints.https.tls]\n     # For secure connection on frontend.local\n     [[entryPoints.https.tls.certificates]]\n     certFile = \n./frontend.cert\n\n     keyFile  = \n./frontend.key\n\n\n\n[api]\n\n[file]\n\n[backends]\n  [backends.backend1]\n    [backends.backend1.servers.server1]\n    # Access on backend with HTTPS\n    url = \nhttps://backend.local:8080\n\n\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend1\n\n    [frontends.frontend1.routes.test_1]\n    rule = \nHost:frontend.local\n\n\n\n\n\n\n\nWarning\n\n\nWith some backends, the server URLs use the IP, so you may need to configure \nInsecureSkipVerify\n instead of the \nRootCAS\n to activate HTTPS without hostname verification.\n\n\n\n\nConclusion\n\n\nWe don't need specific configuration to use gRPC in Tr\u00e6fik, we just need to be careful that all the exchanges (between client and Tr\u00e6fik, and between Tr\u00e6fik and backend) are HTTPS communications because gRPC uses HTTP2.\n\n\nA gRPC example in go\n\n\nWe will use the gRPC greeter example in \ngrpc-go\n\n\n\n\nWarning\n\n\nIn order to use this gRPC example, we need to modify it to use HTTPS\n\n\n\n\nSo we modify the \"gRPC server example\" to use our own self-signed certificate:\n\n\n// ...\n\n// Read cert and key file\nBackendCert, _ := ioutil.ReadFile(\n./backend.cert\n)\nBackendKey, _ := ioutil.ReadFile(\n./backend.key\n)\n\n// Generate Certificate struct\ncert, err := tls.X509KeyPair(BackendCert, BackendKey)\nif err != nil {\n  log.Fatalf(\nfailed to parse certificate: %v\n, err)\n}\n\n// Create credentials\ncreds := credentials.NewServerTLSFromCert(\ncert)\n\n// Use Credentials in gRPC server options\nserverOption := grpc.Creds(creds)\nvar s *grpc.Server = grpc.NewServer(serverOption)\ndefer s.Stop()\n\npb.RegisterGreeterServer(s, \nserver{})\nerr := s.Serve(lis)\n\n// ...\n\n\n\n\nNext we will modify gRPC Client to use our Tr\u00e6fik self-signed certificate:\n\n\n// ...\n\n// Read cert file\nFrontendCert, _ := ioutil.ReadFile(\n./frontend.cert\n)\n\n// Create CertPool\nroots := x509.NewCertPool()\nroots.AppendCertsFromPEM(FrontendCert)\n\n// Create credentials\ncredsClient := credentials.NewClientTLSFromCert(roots, \n)\n\n// Dial with specific Transport (with credentials)\nconn, err := grpc.Dial(\nfrontend.local:4443\n, grpc.WithTransportCredentials(credsClient))\nif err != nil {\n    log.Fatalf(\ndid not connect: %v\n, err)\n}\n\ndefer conn.Close()\nclient := pb.NewGreeterClient(conn)\n\nname := \nWorld\n\nr, err := client.SayHello(context.Background(), \npb.HelloRequest{Name: name})\n\n// ...", 
            "title": "gRPC Example"
        }, 
        {
            "location": "/user-guide/grpc/#grpc-example", 
            "text": "This section explains how to use Traefik as reverse proxy for gRPC application with self-signed certificates.   Warning  As gRPC needs HTTP2, we need HTTPS certificates on both gRPC Server and Tr\u00e6fik.", 
            "title": "gRPC example"
        }, 
        {
            "location": "/user-guide/grpc/#grpc-server-certificate", 
            "text": "In order to secure the gRPC server, we generate a self-signed certificate for backend url:  openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout ./backend.key -out ./backend.cert  That will prompt for information, the important answer is:  Common Name (e.g. server FQDN or YOUR name) []: backend.local", 
            "title": "gRPC Server certificate"
        }, 
        {
            "location": "/user-guide/grpc/#grpc-client-certificate", 
            "text": "Generate your self-signed certificate for frontend url:  openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout ./frontend.key -out ./frontend.cert  with  Common Name (e.g. server FQDN or YOUR name) []: frontend.local", 
            "title": "gRPC Client certificate"
        }, 
        {
            "location": "/user-guide/grpc/#trfik-configuration", 
            "text": "At last, we configure our Tr\u00e6fik instance to use both self-signed certificates.  defaultEntryPoints = [ https ]\n\n# For secure connection on backend.local\nRootCAs = [  ./backend.cert  ]\n\n[entryPoints]\n  [entryPoints.https]\n  address =  :4443 \n    [entryPoints.https.tls]\n     # For secure connection on frontend.local\n     [[entryPoints.https.tls.certificates]]\n     certFile =  ./frontend.cert \n     keyFile  =  ./frontend.key \n\n\n[api]\n\n[file]\n\n[backends]\n  [backends.backend1]\n    [backends.backend1.servers.server1]\n    # Access on backend with HTTPS\n    url =  https://backend.local:8080 \n\n\n[frontends]\n  [frontends.frontend1]\n  backend =  backend1 \n    [frontends.frontend1.routes.test_1]\n    rule =  Host:frontend.local    Warning  With some backends, the server URLs use the IP, so you may need to configure  InsecureSkipVerify  instead of the  RootCAS  to activate HTTPS without hostname verification.", 
            "title": "Tr\u00e6fik configuration"
        }, 
        {
            "location": "/user-guide/grpc/#conclusion", 
            "text": "We don't need specific configuration to use gRPC in Tr\u00e6fik, we just need to be careful that all the exchanges (between client and Tr\u00e6fik, and between Tr\u00e6fik and backend) are HTTPS communications because gRPC uses HTTP2.", 
            "title": "Conclusion"
        }, 
        {
            "location": "/user-guide/grpc/#a-grpc-example-in-go", 
            "text": "We will use the gRPC greeter example in  grpc-go   Warning  In order to use this gRPC example, we need to modify it to use HTTPS   So we modify the \"gRPC server example\" to use our own self-signed certificate:  // ...\n\n// Read cert and key file\nBackendCert, _ := ioutil.ReadFile( ./backend.cert )\nBackendKey, _ := ioutil.ReadFile( ./backend.key )\n\n// Generate Certificate struct\ncert, err := tls.X509KeyPair(BackendCert, BackendKey)\nif err != nil {\n  log.Fatalf( failed to parse certificate: %v , err)\n}\n\n// Create credentials\ncreds := credentials.NewServerTLSFromCert( cert)\n\n// Use Credentials in gRPC server options\nserverOption := grpc.Creds(creds)\nvar s *grpc.Server = grpc.NewServer(serverOption)\ndefer s.Stop()\n\npb.RegisterGreeterServer(s,  server{})\nerr := s.Serve(lis)\n\n// ...  Next we will modify gRPC Client to use our Tr\u00e6fik self-signed certificate:  // ...\n\n// Read cert file\nFrontendCert, _ := ioutil.ReadFile( ./frontend.cert )\n\n// Create CertPool\nroots := x509.NewCertPool()\nroots.AppendCertsFromPEM(FrontendCert)\n\n// Create credentials\ncredsClient := credentials.NewClientTLSFromCert(roots,  )\n\n// Dial with specific Transport (with credentials)\nconn, err := grpc.Dial( frontend.local:4443 , grpc.WithTransportCredentials(credsClient))\nif err != nil {\n    log.Fatalf( did not connect: %v , err)\n}\n\ndefer conn.Close()\nclient := pb.NewGreeterClient(conn)\n\nname :=  World \nr, err := client.SayHello(context.Background(),  pb.HelloRequest{Name: name})\n\n// ...", 
            "title": "A gRPC example in go"
        }, 
        {
            "location": "/user-guide/cluster-docker-consul/", 
            "text": "Clustering / High Availability on Docker Swarm with Consul\n\n\nThis guide explains how to use Tr\u00e6fik in high availability mode in a Docker Swarm and with Let's Encrypt.\n\n\nWhy do we need Tr\u00e6fik in cluster mode? Running multiple instances should work out of the box?\n\n\nIf you want to use Let's Encrypt with Tr\u00e6fik, sharing configuration or TLS certificates between many Tr\u00e6fik instances, you need Tr\u00e6fik cluster/HA.\n\n\nOk, could we mount a shared volume used by all my instances? Yes, you can, but it will not work.\nWhen you use Let's Encrypt, you need to store certificates, but not only.\nWhen Tr\u00e6fik generates a new certificate, it configures a challenge and once Let's Encrypt will verify the ownership of the domain, it will ping back the challenge.\nIf the challenge is not knowing by other Tr\u00e6fik instances, the validation will fail.\n\n\nFor more information about challenge: \nAutomatic Certificate Management Environment (ACME)\n\n\nPrerequisites\n\n\nYou will need a working Docker Swarm cluster.\n\n\nTr\u00e6fik configuration\n\n\nIn this guide, we will not use a TOML configuration file, but only command line flag.\nWith that, we can use the base image without mounting configuration file or building custom image.\n\n\nWhat Tr\u00e6fik should do:\n\n\n\n\nListen to 80 and 443\n\n\nRedirect HTTP traffic to HTTPS\n\n\nGenerate SSL certificate when a domain is added\n\n\nListen to Docker Swarm event\n\n\n\n\nEntryPoints configuration\n\n\nTL;DR:\n\n\n$ traefik \\\n    --entrypoints='Name:http Address::80 Redirect.EntryPoint:https' \\\n    --entrypoints='Name:https Address::443 TLS' \\\n    --defaultentrypoints=http,https\n\n\n\n\nTo listen to different ports, we need to create an entry point for each.\n\n\nThe CLI syntax is \n--entrypoints='Name:a_name Address:an_ip_or_empty:a_port options'\n.\nIf you want to redirect traffic from one entry point to another, it's the option \nRedirect.EntryPoint:entrypoint_name\n.\n\n\nBy default, we don't want to configure all our services to listen on http and https, we add a default entry point configuration: \n--defaultentrypoints=http,https\n.\n\n\nLet's Encrypt configuration\n\n\nTL;DR:\n\n\n$ traefik \\\n    --acme \\\n    --acme.storage=/etc/traefik/acme/acme.json \\\n    --acme.entryPoint=https \\\n    --acme.httpChallenge.entryPoint=http \\\n    --acme.email=contact@mydomain.ca\n\n\n\n\nLet's Encrypt needs 4 parameters: an TLS entry point to listen to, a non-TLS entry point to allow HTTP challenges, a storage for certificates, and an email for the registration.\n\n\nTo enable Let's Encrypt support, you need to add \n--acme\n flag.\n\n\nNow, Tr\u00e6fik needs to know where to store the certificates, we can choose between a key in a Key-Value store, or a file path: \n--acme.storage=my/key\n or \n--acme.storage=/path/to/acme.json\n.\n\n\nThe \nacme.httpChallenge.entryPoint\n flag enables the \nHTTP-01\n challenge and specifies the entryPoint to use during the challenges.\n\n\nFor your email and the entry point, it's \n--acme.entryPoint\n and \n--acme.email\n flags.\n\n\nDocker configuration\n\n\nTL;DR:\n\n\n$ traefik \\\n    --docker \\\n    --docker.swarmmode \\\n    --docker.domain=mydomain.ca \\\n    --docker.watch\n\n\n\n\nTo enable docker and swarm-mode support, you need to add \n--docker\n and \n--docker.swarmmode\n flags.\nTo watch docker events, add \n--docker.watch\n.\n\n\nFull docker-compose file\n\n\nversion: \n3\n\nservices:\n  traefik:\n    image: traefik:1.5\n    command:\n      - \n--api\n\n      - \n--entrypoints=Name:http Address::80 Redirect.EntryPoint:https\n\n      - \n--entrypoints=Name:https Address::443 TLS\n\n      - \n--defaultentrypoints=http,https\n\n      - \n--acme\n\n      - \n--acme.storage=/etc/traefik/acme/acme.json\n\n      - \n--acme.entryPoint=https\n\n      - \n--acme.httpChallenge.entryPoint=http\n\n      - \n--acme.OnHostRule=true\n\n      - \n--acme.onDemand=false\n\n      - \n--acme.email=contact@mydomain.ca\n\n      - \n--docker\n\n      - \n--docker.swarmmode\n\n      - \n--docker.domain=mydomain.ca\n\n      - \n--docker.watch\n\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n    networks:\n      - webgateway\n      - traefik\n    ports:\n      - target: 80\n        published: 80\n        mode: host\n      - target: 443\n        published: 443\n        mode: host\n      - target: 8080\n        published: 8080\n        mode: host\n    deploy:\n      mode: global\n      placement:\n        constraints:\n          - node.role == manager\n      update_config:\n        parallelism: 1\n        delay: 10s\n      restart_policy:\n        condition: on-failure\nnetworks:\n  webgateway:\n    driver: overlay\n    external: true\n  traefik:\n    driver: overlay\n\n\n\n\nMigrate configuration to Consul\n\n\nWe created a special Tr\u00e6fik command to help configuring your Key Value store from a Tr\u00e6fik TOML configuration file and/or CLI flags.\n\n\nDeploy a Tr\u00e6fik cluster\n\n\nThe best way we found is to have an initializer service.\nThis service will push the config to Consul via the \nstoreconfig\n sub-command.\n\n\nThis service will retry until finishing without error because Consul may not be ready when the service tries to push the configuration.\n\n\nThe initializer in a docker-compose file will be:\n\n\n  traefik_init:\n    image: traefik:1.5\n    command:\n      - \nstoreconfig\n\n      - \n--api\n\n      [...]\n      - \n--consul\n\n      - \n--consul.endpoint=consul:8500\n\n      - \n--consul.prefix=traefik\n\n    networks:\n      - traefik\n    deploy:\n      restart_policy:\n        condition: on-failure\n    depends_on:\n      - consul\n\n\n\n\nAnd now, the Tr\u00e6fik part will only have the Consul configuration.\n\n\n  traefik:\n    image: traefik:1.5\n    depends_on:\n      - traefik_init\n      - consul\n    command:\n      - \n--consul\n\n      - \n--consul.endpoint=consul:8500\n\n      - \n--consul.prefix=traefik\n\n    [...]\n\n\n\n\n\n\nNote\n\n\nFor Tr\u00e6fik \n1.5.0 add \nacme.storage=traefik/acme/account\n because Tr\u00e6fik is not reading it from Consul.\n\n\n\n\nIf you have some update to do, update the initializer service and re-deploy it.\nThe new configuration will be stored in Consul, and you need to restart the Tr\u00e6fik node: \ndocker service update --force traefik_traefik\n.\n\n\nFull docker-compose file\n\n\nversion: \n3.4\n\nservices:\n  traefik_init:\n    image: traefik:1.5\n    command:\n      - \nstoreconfig\n\n      - \n--api\n\n      - \n--entrypoints=Name:http Address::80 Redirect.EntryPoint:https\n\n      - \n--entrypoints=Name:https Address::443 TLS\n\n      - \n--defaultentrypoints=http,https\n\n      - \n--acme\n\n      - \n--acme.storage=traefik/acme/account\n\n      - \n--acme.entryPoint=https\n\n      - \n--acme.httpChallenge.entryPoint=http\n\n      - \n--acme.OnHostRule=true\n\n      - \n--acme.onDemand=false\n\n      - \n--acme.email=foobar@example.com\n\n      - \n--docker\n\n      - \n--docker.swarmmode\n\n      - \n--docker.domain=example.com\n\n      - \n--docker.watch\n\n      - \n--consul\n\n      - \n--consul.endpoint=consul:8500\n\n      - \n--consul.prefix=traefik\n\n    networks:\n      - traefik\n    deploy:\n      restart_policy:\n        condition: on-failure\n    depends_on:\n      - consul\n  traefik:\n    image: traefik:1.5\n    depends_on:\n      - traefik_init\n      - consul\n    command:\n      - \n--consul\n\n      - \n--consul.endpoint=consul:8500\n\n      - \n--consul.prefix=traefik\n\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n    networks:\n      - webgateway\n      - traefik\n    ports:\n      - target: 80\n        published: 80\n        mode: host\n      - target: 443\n        published: 443\n        mode: host\n      - target: 8080\n        published: 8080\n        mode: host\n    deploy:\n      mode: global\n      placement:\n        constraints:\n          - node.role == manager\n      update_config:\n        parallelism: 1\n        delay: 10s\n      restart_policy:\n        condition: on-failure\n  consul:\n    image: consul\n    command: agent -server -bootstrap-expect=1\n    volumes:\n      - consul-data:/consul/data\n    environment:\n      - CONSUL_LOCAL_CONFIG={\ndatacenter\n:\nus_east2\n,\nserver\n:true}\n      - CONSUL_BIND_INTERFACE=eth0\n      - CONSUL_CLIENT_INTERFACE=eth0\n    deploy:\n      replicas: 1\n      placement:\n        constraints:\n          - node.role == manager\n      restart_policy:\n        condition: on-failure\n    networks:\n      - traefik\n\nnetworks:\n  webgateway:\n    driver: overlay\n    external: true\n  traefik:\n    driver: overlay\n\nvolumes:\n  consul-data:\n      driver: [not local]", 
            "title": "Traefik cluster example with Swarm"
        }, 
        {
            "location": "/user-guide/cluster-docker-consul/#clustering-high-availability-on-docker-swarm-with-consul", 
            "text": "This guide explains how to use Tr\u00e6fik in high availability mode in a Docker Swarm and with Let's Encrypt.  Why do we need Tr\u00e6fik in cluster mode? Running multiple instances should work out of the box?  If you want to use Let's Encrypt with Tr\u00e6fik, sharing configuration or TLS certificates between many Tr\u00e6fik instances, you need Tr\u00e6fik cluster/HA.  Ok, could we mount a shared volume used by all my instances? Yes, you can, but it will not work.\nWhen you use Let's Encrypt, you need to store certificates, but not only.\nWhen Tr\u00e6fik generates a new certificate, it configures a challenge and once Let's Encrypt will verify the ownership of the domain, it will ping back the challenge.\nIf the challenge is not knowing by other Tr\u00e6fik instances, the validation will fail.  For more information about challenge:  Automatic Certificate Management Environment (ACME)", 
            "title": "Clustering / High Availability on Docker Swarm with Consul"
        }, 
        {
            "location": "/user-guide/cluster-docker-consul/#prerequisites", 
            "text": "You will need a working Docker Swarm cluster.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/user-guide/cluster-docker-consul/#trfik-configuration", 
            "text": "In this guide, we will not use a TOML configuration file, but only command line flag.\nWith that, we can use the base image without mounting configuration file or building custom image.  What Tr\u00e6fik should do:   Listen to 80 and 443  Redirect HTTP traffic to HTTPS  Generate SSL certificate when a domain is added  Listen to Docker Swarm event", 
            "title": "Tr\u00e6fik configuration"
        }, 
        {
            "location": "/user-guide/cluster-docker-consul/#entrypoints-configuration", 
            "text": "TL;DR:  $ traefik \\\n    --entrypoints='Name:http Address::80 Redirect.EntryPoint:https' \\\n    --entrypoints='Name:https Address::443 TLS' \\\n    --defaultentrypoints=http,https  To listen to different ports, we need to create an entry point for each.  The CLI syntax is  --entrypoints='Name:a_name Address:an_ip_or_empty:a_port options' .\nIf you want to redirect traffic from one entry point to another, it's the option  Redirect.EntryPoint:entrypoint_name .  By default, we don't want to configure all our services to listen on http and https, we add a default entry point configuration:  --defaultentrypoints=http,https .", 
            "title": "EntryPoints configuration"
        }, 
        {
            "location": "/user-guide/cluster-docker-consul/#lets-encrypt-configuration", 
            "text": "TL;DR:  $ traefik \\\n    --acme \\\n    --acme.storage=/etc/traefik/acme/acme.json \\\n    --acme.entryPoint=https \\\n    --acme.httpChallenge.entryPoint=http \\\n    --acme.email=contact@mydomain.ca  Let's Encrypt needs 4 parameters: an TLS entry point to listen to, a non-TLS entry point to allow HTTP challenges, a storage for certificates, and an email for the registration.  To enable Let's Encrypt support, you need to add  --acme  flag.  Now, Tr\u00e6fik needs to know where to store the certificates, we can choose between a key in a Key-Value store, or a file path:  --acme.storage=my/key  or  --acme.storage=/path/to/acme.json .  The  acme.httpChallenge.entryPoint  flag enables the  HTTP-01  challenge and specifies the entryPoint to use during the challenges.  For your email and the entry point, it's  --acme.entryPoint  and  --acme.email  flags.", 
            "title": "Let's Encrypt configuration"
        }, 
        {
            "location": "/user-guide/cluster-docker-consul/#docker-configuration", 
            "text": "TL;DR:  $ traefik \\\n    --docker \\\n    --docker.swarmmode \\\n    --docker.domain=mydomain.ca \\\n    --docker.watch  To enable docker and swarm-mode support, you need to add  --docker  and  --docker.swarmmode  flags.\nTo watch docker events, add  --docker.watch .", 
            "title": "Docker configuration"
        }, 
        {
            "location": "/user-guide/cluster-docker-consul/#full-docker-compose-file", 
            "text": "version:  3 \nservices:\n  traefik:\n    image: traefik:1.5\n    command:\n      -  --api \n      -  --entrypoints=Name:http Address::80 Redirect.EntryPoint:https \n      -  --entrypoints=Name:https Address::443 TLS \n      -  --defaultentrypoints=http,https \n      -  --acme \n      -  --acme.storage=/etc/traefik/acme/acme.json \n      -  --acme.entryPoint=https \n      -  --acme.httpChallenge.entryPoint=http \n      -  --acme.OnHostRule=true \n      -  --acme.onDemand=false \n      -  --acme.email=contact@mydomain.ca \n      -  --docker \n      -  --docker.swarmmode \n      -  --docker.domain=mydomain.ca \n      -  --docker.watch \n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n    networks:\n      - webgateway\n      - traefik\n    ports:\n      - target: 80\n        published: 80\n        mode: host\n      - target: 443\n        published: 443\n        mode: host\n      - target: 8080\n        published: 8080\n        mode: host\n    deploy:\n      mode: global\n      placement:\n        constraints:\n          - node.role == manager\n      update_config:\n        parallelism: 1\n        delay: 10s\n      restart_policy:\n        condition: on-failure\nnetworks:\n  webgateway:\n    driver: overlay\n    external: true\n  traefik:\n    driver: overlay", 
            "title": "Full docker-compose file"
        }, 
        {
            "location": "/user-guide/cluster-docker-consul/#migrate-configuration-to-consul", 
            "text": "We created a special Tr\u00e6fik command to help configuring your Key Value store from a Tr\u00e6fik TOML configuration file and/or CLI flags.", 
            "title": "Migrate configuration to Consul"
        }, 
        {
            "location": "/user-guide/cluster-docker-consul/#deploy-a-trfik-cluster", 
            "text": "The best way we found is to have an initializer service.\nThis service will push the config to Consul via the  storeconfig  sub-command.  This service will retry until finishing without error because Consul may not be ready when the service tries to push the configuration.  The initializer in a docker-compose file will be:    traefik_init:\n    image: traefik:1.5\n    command:\n      -  storeconfig \n      -  --api \n      [...]\n      -  --consul \n      -  --consul.endpoint=consul:8500 \n      -  --consul.prefix=traefik \n    networks:\n      - traefik\n    deploy:\n      restart_policy:\n        condition: on-failure\n    depends_on:\n      - consul  And now, the Tr\u00e6fik part will only have the Consul configuration.    traefik:\n    image: traefik:1.5\n    depends_on:\n      - traefik_init\n      - consul\n    command:\n      -  --consul \n      -  --consul.endpoint=consul:8500 \n      -  --consul.prefix=traefik \n    [...]   Note  For Tr\u00e6fik  1.5.0 add  acme.storage=traefik/acme/account  because Tr\u00e6fik is not reading it from Consul.   If you have some update to do, update the initializer service and re-deploy it.\nThe new configuration will be stored in Consul, and you need to restart the Tr\u00e6fik node:  docker service update --force traefik_traefik .", 
            "title": "Deploy a Tr\u00e6fik cluster"
        }, 
        {
            "location": "/user-guide/cluster-docker-consul/#full-docker-compose-file_1", 
            "text": "version:  3.4 \nservices:\n  traefik_init:\n    image: traefik:1.5\n    command:\n      -  storeconfig \n      -  --api \n      -  --entrypoints=Name:http Address::80 Redirect.EntryPoint:https \n      -  --entrypoints=Name:https Address::443 TLS \n      -  --defaultentrypoints=http,https \n      -  --acme \n      -  --acme.storage=traefik/acme/account \n      -  --acme.entryPoint=https \n      -  --acme.httpChallenge.entryPoint=http \n      -  --acme.OnHostRule=true \n      -  --acme.onDemand=false \n      -  --acme.email=foobar@example.com \n      -  --docker \n      -  --docker.swarmmode \n      -  --docker.domain=example.com \n      -  --docker.watch \n      -  --consul \n      -  --consul.endpoint=consul:8500 \n      -  --consul.prefix=traefik \n    networks:\n      - traefik\n    deploy:\n      restart_policy:\n        condition: on-failure\n    depends_on:\n      - consul\n  traefik:\n    image: traefik:1.5\n    depends_on:\n      - traefik_init\n      - consul\n    command:\n      -  --consul \n      -  --consul.endpoint=consul:8500 \n      -  --consul.prefix=traefik \n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n    networks:\n      - webgateway\n      - traefik\n    ports:\n      - target: 80\n        published: 80\n        mode: host\n      - target: 443\n        published: 443\n        mode: host\n      - target: 8080\n        published: 8080\n        mode: host\n    deploy:\n      mode: global\n      placement:\n        constraints:\n          - node.role == manager\n      update_config:\n        parallelism: 1\n        delay: 10s\n      restart_policy:\n        condition: on-failure\n  consul:\n    image: consul\n    command: agent -server -bootstrap-expect=1\n    volumes:\n      - consul-data:/consul/data\n    environment:\n      - CONSUL_LOCAL_CONFIG={ datacenter : us_east2 , server :true}\n      - CONSUL_BIND_INTERFACE=eth0\n      - CONSUL_CLIENT_INTERFACE=eth0\n    deploy:\n      replicas: 1\n      placement:\n        constraints:\n          - node.role == manager\n      restart_policy:\n        condition: on-failure\n    networks:\n      - traefik\n\nnetworks:\n  webgateway:\n    driver: overlay\n    external: true\n  traefik:\n    driver: overlay\n\nvolumes:\n  consul-data:\n      driver: [not local]", 
            "title": "Full docker-compose file"
        }, 
        {
            "location": "/benchmarks/", 
            "text": "Benchmarks\n\n\nConfiguration\n\n\nI would like to thanks \nvincentbernat\n from \nexoscale.ch\n who kindly provided the infrastructure needed for the benchmarks.\n\n\nI used 4 VMs for the tests with the following configuration:\n\n\n\n\n32 GB RAM\n\n\n8 CPU Cores\n\n\n10 GB SSD\n\n\nUbuntu 14.04 LTS 64-bit\n\n\n\n\nSetup\n\n\n\n\nOne VM used to launch the benchmarking tool \nwrk\n\n\nOne VM for Traefik (v1.0.0-beta.416) / nginx (v1.4.6)\n\n\nTwo VMs for 2 backend servers in go \nwhoami\n\n\n\n\nEach VM has been tuned using the following limits:\n\n\nsysctl -w fs.file-max=\n9999999\n\nsysctl -w fs.nr_open=\n9999999\n\nsysctl -w net.core.netdev_max_backlog=\n4096\n\nsysctl -w net.core.rmem_max=\n16777216\n\nsysctl -w net.core.somaxconn=\n65535\n\nsysctl -w net.core.wmem_max=\n16777216\n\nsysctl -w net.ipv4.ip_local_port_range=\n1025       65535\n\nsysctl -w net.ipv4.tcp_fin_timeout=\n30\n\nsysctl -w net.ipv4.tcp_keepalive_time=\n30\n\nsysctl -w net.ipv4.tcp_max_syn_backlog=\n20480\n\nsysctl -w net.ipv4.tcp_max_tw_buckets=\n400000\n\nsysctl -w net.ipv4.tcp_no_metrics_save=\n1\n\nsysctl -w net.ipv4.tcp_syn_retries=\n2\n\nsysctl -w net.ipv4.tcp_synack_retries=\n2\n\nsysctl -w net.ipv4.tcp_tw_recycle=\n1\n\nsysctl -w net.ipv4.tcp_tw_reuse=\n1\n\nsysctl -w vm.min_free_kbytes=\n65536\n\nsysctl -w vm.overcommit_memory=\n1\n\nulimit -n 9999999\n\n\n\n\nNginx\n\n\nHere is the config Nginx file use \n/etc/nginx/nginx.conf\n:\n\n\nuser www-data;\nworker_processes auto;\nworker_rlimit_nofile 200000;\npid /var/run/nginx.pid;\n\nevents {\n    worker_connections 10000;\n    use epoll;\n    multi_accept on;\n}\n\nhttp {\n    sendfile on;\n    tcp_nopush on;\n    tcp_nodelay on;\n    keepalive_timeout 300;\n    keepalive_requests 10000;\n    types_hash_max_size 2048;\n\n    open_file_cache max=200000 inactive=300s;\n    open_file_cache_valid 300s;\n    open_file_cache_min_uses 2;\n    open_file_cache_errors on;\n\n    server_tokens off;\n    dav_methods off;\n\n    include /etc/nginx/mime.types;\n    default_type application/octet-stream;\n\n    access_log /var/log/nginx/access.log combined;\n    error_log /var/log/nginx/error.log warn;\n\n    gzip off;\n    gzip_vary off;\n\n    include /etc/nginx/conf.d/*.conf;\n    include /etc/nginx/sites-enabled/*.conf;\n}\n\n\n\n\nHere is the Nginx vhost file used:\n\n\nupstream whoami {\n    server IP-whoami1:80;\n    server IP-whoami2:80;\n    keepalive 300;\n}\n\nserver {\n    listen 8001;\n    server_name test.traefik;\n    access_log off;\n    error_log /dev/null crit;\n    if ($host != \ntest.traefik\n) {\n        return 404;\n    }\n    location / {\n        proxy_pass http://whoami;\n        proxy_http_version 1.1;\n        proxy_set_header Connection \n;\n    proxy_set_header  X-Forwarded-Host $host;\n    }\n}\n\n\n\n\nTraefik\n\n\nHere is the \ntraefik.toml\n file used:\n\n\nMaxIdleConnsPerHost = 100000\ndefaultEntryPoints = [\nhttp\n]\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:8000\n\n\n[file]\n[backends]\n  [backends.backend1]\n    [backends.backend1.servers.server1]\n    url = \nhttp://IP-whoami1:80\n\n    weight = 1\n    [backends.backend1.servers.server2]\n    url = \nhttp://IP-whoami2:80\n\n    weight = 1\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend1\n\n    [frontends.frontend1.routes.test_1]\n    rule = \nHost: test.traefik\n\n\n\n\n\nResults\n\n\nwhoami:\n\n\nwrk -t20 -c1000 -d60s -H \nHost: test.traefik\n --latency  http://IP-whoami:80/bench\nRunning 1m test @ http://IP-whoami:80/bench\n  20 threads and 1000 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency    70.28ms  134.72ms   1.91s    89.94%\n    Req/Sec     2.92k   742.42     8.78k    68.80%\n  Latency Distribution\n     50%   10.63ms\n     75%   75.64ms\n     90%  205.65ms\n     99%  668.28ms\n  3476705 requests in 1.00m, 384.61MB read\n  Socket errors: connect 0, read 0, write 0, timeout 103\nRequests/sec:  57894.35\nTransfer/sec:      6.40MB\n\n\n\n\nnginx:\n\n\nwrk -t20 -c1000 -d60s -H \nHost: test.traefik\n --latency  http://IP-nginx:8001/bench\nRunning 1m test @ http://IP-nginx:8001/bench\n  20 threads and 1000 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency   101.25ms  180.09ms   1.99s    89.34%\n    Req/Sec     1.69k   567.69     9.39k    72.62%\n  Latency Distribution\n     50%   15.46ms\n     75%  129.11ms\n     90%  302.44ms\n     99%  846.59ms\n  2018427 requests in 1.00m, 298.36MB read\n  Socket errors: connect 0, read 0, write 0, timeout 90\nRequests/sec:  33591.67\nTransfer/sec:      4.97MB\n\n\n\n\nTraefik:\n\n\nwrk -t20 -c1000 -d60s -H \nHost: test.traefik\n --latency  http://IP-traefik:8000/bench\nRunning 1m test @ http://IP-traefik:8000/bench\n  20 threads and 1000 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency    91.72ms  150.43ms   2.00s    90.50%\n    Req/Sec     1.43k   266.37     2.97k    69.77%\n  Latency Distribution\n     50%   19.74ms\n     75%  121.98ms\n     90%  237.39ms\n     99%  687.49ms\n  1705073 requests in 1.00m, 188.63MB read\n  Socket errors: connect 0, read 0, write 0, timeout 7\nRequests/sec:  28392.44\nTransfer/sec:      3.14MB\n\n\n\n\nConclusion\n\n\nTraefik is obviously slower than Nginx, but not so much: Traefik can serve 28392 requests/sec and Nginx 33591 requests/sec which gives a ratio of 85%.\nNot bad for young project :) !\n\n\nSome areas of possible improvements:\n\n\n\n\nUse \nGO_REUSEPORT\n listener\n\n\nRun a separate server instance per CPU core with \nGOMAXPROCS=1\n (it appears during benchmarks that there is a lot more context switches with Traefik than with nginx)", 
            "title": "Benchmarks"
        }, 
        {
            "location": "/benchmarks/#benchmarks", 
            "text": "", 
            "title": "Benchmarks"
        }, 
        {
            "location": "/benchmarks/#configuration", 
            "text": "I would like to thanks  vincentbernat  from  exoscale.ch  who kindly provided the infrastructure needed for the benchmarks.  I used 4 VMs for the tests with the following configuration:   32 GB RAM  8 CPU Cores  10 GB SSD  Ubuntu 14.04 LTS 64-bit", 
            "title": "Configuration"
        }, 
        {
            "location": "/benchmarks/#setup", 
            "text": "One VM used to launch the benchmarking tool  wrk  One VM for Traefik (v1.0.0-beta.416) / nginx (v1.4.6)  Two VMs for 2 backend servers in go  whoami   Each VM has been tuned using the following limits:  sysctl -w fs.file-max= 9999999 \nsysctl -w fs.nr_open= 9999999 \nsysctl -w net.core.netdev_max_backlog= 4096 \nsysctl -w net.core.rmem_max= 16777216 \nsysctl -w net.core.somaxconn= 65535 \nsysctl -w net.core.wmem_max= 16777216 \nsysctl -w net.ipv4.ip_local_port_range= 1025       65535 \nsysctl -w net.ipv4.tcp_fin_timeout= 30 \nsysctl -w net.ipv4.tcp_keepalive_time= 30 \nsysctl -w net.ipv4.tcp_max_syn_backlog= 20480 \nsysctl -w net.ipv4.tcp_max_tw_buckets= 400000 \nsysctl -w net.ipv4.tcp_no_metrics_save= 1 \nsysctl -w net.ipv4.tcp_syn_retries= 2 \nsysctl -w net.ipv4.tcp_synack_retries= 2 \nsysctl -w net.ipv4.tcp_tw_recycle= 1 \nsysctl -w net.ipv4.tcp_tw_reuse= 1 \nsysctl -w vm.min_free_kbytes= 65536 \nsysctl -w vm.overcommit_memory= 1 \nulimit -n 9999999", 
            "title": "Setup"
        }, 
        {
            "location": "/benchmarks/#nginx", 
            "text": "Here is the config Nginx file use  /etc/nginx/nginx.conf :  user www-data;\nworker_processes auto;\nworker_rlimit_nofile 200000;\npid /var/run/nginx.pid;\n\nevents {\n    worker_connections 10000;\n    use epoll;\n    multi_accept on;\n}\n\nhttp {\n    sendfile on;\n    tcp_nopush on;\n    tcp_nodelay on;\n    keepalive_timeout 300;\n    keepalive_requests 10000;\n    types_hash_max_size 2048;\n\n    open_file_cache max=200000 inactive=300s;\n    open_file_cache_valid 300s;\n    open_file_cache_min_uses 2;\n    open_file_cache_errors on;\n\n    server_tokens off;\n    dav_methods off;\n\n    include /etc/nginx/mime.types;\n    default_type application/octet-stream;\n\n    access_log /var/log/nginx/access.log combined;\n    error_log /var/log/nginx/error.log warn;\n\n    gzip off;\n    gzip_vary off;\n\n    include /etc/nginx/conf.d/*.conf;\n    include /etc/nginx/sites-enabled/*.conf;\n}  Here is the Nginx vhost file used:  upstream whoami {\n    server IP-whoami1:80;\n    server IP-whoami2:80;\n    keepalive 300;\n}\n\nserver {\n    listen 8001;\n    server_name test.traefik;\n    access_log off;\n    error_log /dev/null crit;\n    if ($host !=  test.traefik ) {\n        return 404;\n    }\n    location / {\n        proxy_pass http://whoami;\n        proxy_http_version 1.1;\n        proxy_set_header Connection  ;\n    proxy_set_header  X-Forwarded-Host $host;\n    }\n}", 
            "title": "Nginx"
        }, 
        {
            "location": "/benchmarks/#traefik", 
            "text": "Here is the  traefik.toml  file used:  MaxIdleConnsPerHost = 100000\ndefaultEntryPoints = [ http ]\n\n[entryPoints]\n  [entryPoints.http]\n  address =  :8000 \n\n[file]\n[backends]\n  [backends.backend1]\n    [backends.backend1.servers.server1]\n    url =  http://IP-whoami1:80 \n    weight = 1\n    [backends.backend1.servers.server2]\n    url =  http://IP-whoami2:80 \n    weight = 1\n\n[frontends]\n  [frontends.frontend1]\n  backend =  backend1 \n    [frontends.frontend1.routes.test_1]\n    rule =  Host: test.traefik", 
            "title": "Traefik"
        }, 
        {
            "location": "/benchmarks/#results", 
            "text": "", 
            "title": "Results"
        }, 
        {
            "location": "/benchmarks/#whoami", 
            "text": "wrk -t20 -c1000 -d60s -H  Host: test.traefik  --latency  http://IP-whoami:80/bench\nRunning 1m test @ http://IP-whoami:80/bench\n  20 threads and 1000 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency    70.28ms  134.72ms   1.91s    89.94%\n    Req/Sec     2.92k   742.42     8.78k    68.80%\n  Latency Distribution\n     50%   10.63ms\n     75%   75.64ms\n     90%  205.65ms\n     99%  668.28ms\n  3476705 requests in 1.00m, 384.61MB read\n  Socket errors: connect 0, read 0, write 0, timeout 103\nRequests/sec:  57894.35\nTransfer/sec:      6.40MB", 
            "title": "whoami:"
        }, 
        {
            "location": "/benchmarks/#nginx_1", 
            "text": "wrk -t20 -c1000 -d60s -H  Host: test.traefik  --latency  http://IP-nginx:8001/bench\nRunning 1m test @ http://IP-nginx:8001/bench\n  20 threads and 1000 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency   101.25ms  180.09ms   1.99s    89.34%\n    Req/Sec     1.69k   567.69     9.39k    72.62%\n  Latency Distribution\n     50%   15.46ms\n     75%  129.11ms\n     90%  302.44ms\n     99%  846.59ms\n  2018427 requests in 1.00m, 298.36MB read\n  Socket errors: connect 0, read 0, write 0, timeout 90\nRequests/sec:  33591.67\nTransfer/sec:      4.97MB", 
            "title": "nginx:"
        }, 
        {
            "location": "/benchmarks/#traefik_1", 
            "text": "wrk -t20 -c1000 -d60s -H  Host: test.traefik  --latency  http://IP-traefik:8000/bench\nRunning 1m test @ http://IP-traefik:8000/bench\n  20 threads and 1000 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency    91.72ms  150.43ms   2.00s    90.50%\n    Req/Sec     1.43k   266.37     2.97k    69.77%\n  Latency Distribution\n     50%   19.74ms\n     75%  121.98ms\n     90%  237.39ms\n     99%  687.49ms\n  1705073 requests in 1.00m, 188.63MB read\n  Socket errors: connect 0, read 0, write 0, timeout 7\nRequests/sec:  28392.44\nTransfer/sec:      3.14MB", 
            "title": "Traefik:"
        }, 
        {
            "location": "/benchmarks/#conclusion", 
            "text": "Traefik is obviously slower than Nginx, but not so much: Traefik can serve 28392 requests/sec and Nginx 33591 requests/sec which gives a ratio of 85%.\nNot bad for young project :) !  Some areas of possible improvements:   Use  GO_REUSEPORT  listener  Run a separate server instance per CPU core with  GOMAXPROCS=1  (it appears during benchmarks that there is a lot more context switches with Traefik than with nginx)", 
            "title": "Conclusion"
        }
    ]
}