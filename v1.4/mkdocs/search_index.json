{
    "docs": [
        {
            "location": "/", 
            "text": "Tr\u00e6fik (pronounced like \ntraffic\n) is a modern HTTP reverse proxy and load balancer made to deploy microservices with ease.\nIt supports several backends (\nDocker\n, \nSwarm mode\n, \nKubernetes\n, \nMarathon\n, \nConsul\n, \nEtcd\n, \nRancher\n, \nAmazon ECS\n, and a lot more) to manage its configuration automatically and dynamically.\n\n\nOverview\n\n\nImagine that you have deployed a bunch of microservices on your infrastructure. You probably used a service registry (like etcd or consul) and/or an orchestrator (swarm, Mesos/Marathon) to manage all these services.\nIf you want your users to access some of your microservices from the Internet, you will have to use a reverse proxy and configure it using virtual hosts or prefix paths:\n\n\n\n\ndomain \napi.domain.com\n will point the microservice \napi\n in your private network\n\n\npath \ndomain.com/web\n will point the microservice \nweb\n in your private network\n\n\ndomain \nbackoffice.domain.com\n will point the microservices \nbackoffice\n in your private network, load-balancing between your multiple instances\n\n\n\n\nBut a microservices architecture is dynamic... Services are added, removed, killed or upgraded often, eventually several times a day.\n\n\nTraditional reverse-proxies are not natively dynamic. You can't change their configuration and hot-reload easily.\n\n\nHere enters Tr\u00e6fik.\n\n\n\n\nTr\u00e6fik can listen to your service registry/orchestrator API, and knows each time a microservice is added, removed, killed or upgraded, and can generate its configuration automatically.\nRoutes to your services will be created instantly.\n\n\nRun it and forget it!\n\n\nFeatures\n\n\n\n\nIt's fast\n\n\nNo dependency hell, single binary made with go\n\n\nTiny\n \nofficial\n docker image\n\n\nRest API\n\n\nHot-reloading of configuration. No need to restart the process\n\n\nCircuit breakers, retry\n\n\nRound Robin, rebalancer load-balancers\n\n\nMetrics (Rest, Prometheus, Datadog, Statd)\n\n\nClean AngularJS Web UI\n\n\nWebsocket, HTTP/2, GRPC ready\n\n\nAccess Logs (JSON, CLF)\n\n\nLet's Encrypt\n support (Automatic HTTPS with renewal)\n\n\nHigh Availability with cluster mode\n\n\n\n\nSupported backends\n\n\n\n\nDocker\n / \nSwarm mode\n\n\nKubernetes\n\n\nMesos\n / \nMarathon\n\n\nRancher\n (API, Metadata)\n\n\nConsul\n / \nEtcd\n / \nZookeeper\n / \nBoltDB\n\n\nEureka\n\n\nAmazon ECS\n\n\nAmazon DynamoDB\n\n\nFile\n\n\nRest API\n\n\n\n\nQuickstart\n\n\nYou can have a quick look at Tr\u00e6fik in this \nKatacoda tutorial\n that shows how to load balance requests between multiple Docker containers.\n\n\nHere is a talk given by \nEmile Vauge\n at \nGopherCon 2017\n.\nYou will learn Tr\u00e6fik basics in less than 10 minutes.\n\n\n\n\nHere is a talk given by \nEd Robinson\n at \nContainerCamp UK\n conference.\nYou will learn fundamental Tr\u00e6fik features and see some demos with Kubernetes.\n\n\n\n\nGet it\n\n\nBinary\n\n\nYou can grab the latest binary from the \nreleases\n page and just run it with the \nsample configuration file\n:\n\n\n./traefik -c traefik.toml\n\n\n\n\nDocker\n\n\nUsing the tiny Docker image:\n\n\ndocker run -d -p 8080:8080 -p 80:80 -v $PWD/traefik.toml:/etc/traefik/traefik.toml traefik\n\n\n\n\nTest it\n\n\nYou can test Tr\u00e6fik easily using \nDocker compose\n, with this \ndocker-compose.yml\n file in a folder named \ntraefik\n:\n\n\nversion: '2'\n\nservices:\n  proxy:\n    image: traefik\n    command: --web --docker --docker.domain=docker.localhost --logLevel=DEBUG\n    networks:\n      - webgateway\n    ports:\n      - \n80:80\n\n      - \n8080:8080\n\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n      - /dev/null:/traefik.toml\n\nnetworks:\n  webgateway:\n    driver: bridge\n\n\n\n\nStart it from within the \ntraefik\n folder:\n\n\ndocker-compose up -d\n\n\n\n\nIn a browser you may open \nhttp://localhost:8080\n to access Tr\u00e6fik's dashboard and observe the following magic.\n\n\nNow, create a folder named \ntest\n and create a \ndocker-compose.yml\n in it with this content:\n\n\nversion: '2'\n\nservices:\n  whoami:\n    image: emilevauge/whoami\n    networks:\n      - web\n    labels:\n      - \ntraefik.backend=whoami\n\n      - \ntraefik.frontend.rule=Host:whoami.docker.localhost\n\n\nnetworks:\n  web:\n    external:\n      name: traefik_webgateway\n\n\n\n\nThen, start and scale it in the \ntest\n folder:\n\n\ndocker-compose up -d\ndocker-compose scale whoami=2\n\n\n\n\nFinally, test load-balancing between the two services \ntest_whoami_1\n and \ntest_whoami_2\n:\n\n\ncurl -H Host:whoami.docker.localhost http://127.0.0.1\n\n\n\n\nHostname: ef194d07634a\nIP: 127.0.0.1\nIP: ::1\nIP: 172.17.0.4\nIP: fe80::42:acff:fe11:4\nGET / HTTP/1.1\nHost: 172.17.0.4:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 172.17.0.1\nX-Forwarded-Host: 172.17.0.4:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: dbb60406010d\n\n\n\n\ncurl -H Host:whoami.docker.localhost http://127.0.0.1\n\n\n\n\nHostname: 6c3c5df0c79a\nIP: 127.0.0.1\nIP: ::1\nIP: 172.17.0.3\nIP: fe80::42:acff:fe11:3\nGET / HTTP/1.1\nHost: 172.17.0.3:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 172.17.0.1\nX-Forwarded-Host: 172.17.0.3:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: dbb60406010d", 
            "title": "Getting Started"
        }, 
        {
            "location": "/#overview", 
            "text": "Imagine that you have deployed a bunch of microservices on your infrastructure. You probably used a service registry (like etcd or consul) and/or an orchestrator (swarm, Mesos/Marathon) to manage all these services.\nIf you want your users to access some of your microservices from the Internet, you will have to use a reverse proxy and configure it using virtual hosts or prefix paths:   domain  api.domain.com  will point the microservice  api  in your private network  path  domain.com/web  will point the microservice  web  in your private network  domain  backoffice.domain.com  will point the microservices  backoffice  in your private network, load-balancing between your multiple instances   But a microservices architecture is dynamic... Services are added, removed, killed or upgraded often, eventually several times a day.  Traditional reverse-proxies are not natively dynamic. You can't change their configuration and hot-reload easily.  Here enters Tr\u00e6fik.   Tr\u00e6fik can listen to your service registry/orchestrator API, and knows each time a microservice is added, removed, killed or upgraded, and can generate its configuration automatically.\nRoutes to your services will be created instantly.  Run it and forget it!", 
            "title": "Overview"
        }, 
        {
            "location": "/#features", 
            "text": "It's fast  No dependency hell, single binary made with go  Tiny   official  docker image  Rest API  Hot-reloading of configuration. No need to restart the process  Circuit breakers, retry  Round Robin, rebalancer load-balancers  Metrics (Rest, Prometheus, Datadog, Statd)  Clean AngularJS Web UI  Websocket, HTTP/2, GRPC ready  Access Logs (JSON, CLF)  Let's Encrypt  support (Automatic HTTPS with renewal)  High Availability with cluster mode", 
            "title": "Features"
        }, 
        {
            "location": "/#supported-backends", 
            "text": "Docker  /  Swarm mode  Kubernetes  Mesos  /  Marathon  Rancher  (API, Metadata)  Consul  /  Etcd  /  Zookeeper  /  BoltDB  Eureka  Amazon ECS  Amazon DynamoDB  File  Rest API", 
            "title": "Supported backends"
        }, 
        {
            "location": "/#quickstart", 
            "text": "You can have a quick look at Tr\u00e6fik in this  Katacoda tutorial  that shows how to load balance requests between multiple Docker containers.  Here is a talk given by  Emile Vauge  at  GopherCon 2017 .\nYou will learn Tr\u00e6fik basics in less than 10 minutes.   Here is a talk given by  Ed Robinson  at  ContainerCamp UK  conference.\nYou will learn fundamental Tr\u00e6fik features and see some demos with Kubernetes.", 
            "title": "Quickstart"
        }, 
        {
            "location": "/#get-it", 
            "text": "", 
            "title": "Get it"
        }, 
        {
            "location": "/#binary", 
            "text": "You can grab the latest binary from the  releases  page and just run it with the  sample configuration file :  ./traefik -c traefik.toml", 
            "title": "Binary"
        }, 
        {
            "location": "/#docker", 
            "text": "Using the tiny Docker image:  docker run -d -p 8080:8080 -p 80:80 -v $PWD/traefik.toml:/etc/traefik/traefik.toml traefik", 
            "title": "Docker"
        }, 
        {
            "location": "/#test-it", 
            "text": "You can test Tr\u00e6fik easily using  Docker compose , with this  docker-compose.yml  file in a folder named  traefik :  version: '2'\n\nservices:\n  proxy:\n    image: traefik\n    command: --web --docker --docker.domain=docker.localhost --logLevel=DEBUG\n    networks:\n      - webgateway\n    ports:\n      -  80:80 \n      -  8080:8080 \n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n      - /dev/null:/traefik.toml\n\nnetworks:\n  webgateway:\n    driver: bridge  Start it from within the  traefik  folder:  docker-compose up -d  In a browser you may open  http://localhost:8080  to access Tr\u00e6fik's dashboard and observe the following magic.  Now, create a folder named  test  and create a  docker-compose.yml  in it with this content:  version: '2'\n\nservices:\n  whoami:\n    image: emilevauge/whoami\n    networks:\n      - web\n    labels:\n      -  traefik.backend=whoami \n      -  traefik.frontend.rule=Host:whoami.docker.localhost \n\nnetworks:\n  web:\n    external:\n      name: traefik_webgateway  Then, start and scale it in the  test  folder:  docker-compose up -d\ndocker-compose scale whoami=2  Finally, test load-balancing between the two services  test_whoami_1  and  test_whoami_2 :  curl -H Host:whoami.docker.localhost http://127.0.0.1  Hostname: ef194d07634a\nIP: 127.0.0.1\nIP: ::1\nIP: 172.17.0.4\nIP: fe80::42:acff:fe11:4\nGET / HTTP/1.1\nHost: 172.17.0.4:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 172.17.0.1\nX-Forwarded-Host: 172.17.0.4:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: dbb60406010d  curl -H Host:whoami.docker.localhost http://127.0.0.1  Hostname: 6c3c5df0c79a\nIP: 127.0.0.1\nIP: ::1\nIP: 172.17.0.3\nIP: fe80::42:acff:fe11:3\nGET / HTTP/1.1\nHost: 172.17.0.3:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 172.17.0.1\nX-Forwarded-Host: 172.17.0.3:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: dbb60406010d", 
            "title": "Test it"
        }, 
        {
            "location": "/basics/", 
            "text": "Basics\n\n\nConcepts\n\n\nLet's take our example from the \noverview\n again:\n\n\n\n\nImagine that you have deployed a bunch of microservices on your infrastructure. You probably used a service registry (like etcd or consul) and/or an orchestrator (swarm, Mesos/Marathon) to manage all these services.\nIf you want your users to access some of your microservices from the Internet, you will have to use a reverse proxy and configure it using virtual hosts or prefix paths:\n\n\n\n\ndomain \napi.domain.com\n will point the microservice \napi\n in your private network\n\n\npath \ndomain.com/web\n will point the microservice \nweb\n in your private network\n\n\ndomain \nbackoffice.domain.com\n will point the microservices \nbackoffice\n in your private network, load-balancing between your multiple instances\n\n\n\n\n\n\n\n\nLet's zoom on Tr\u00e6fik and have an overview of its internal architecture:\n\n\n\n\n\n\nIncoming requests end on \nentrypoints\n, as the name suggests, they are the network entry points into Tr\u00e6fik (listening port, SSL, traffic redirection...).\n\n\nTraffic is then forwarded to a matching \nfrontend\n. A frontend defines routes from \nentrypoints\n to \nbackends\n.\nRoutes are created using requests fields (\nHost\n, \nPath\n, \nHeaders\n...) and can match or not a request.\n\n\nThe \nfrontend\n will then send the request to a \nbackend\n. A backend can be composed by one or more \nservers\n, and by a load-balancing strategy.\n\n\nFinally, the \nserver\n will forward the request to the corresponding microservice in the private network.\n\n\n\n\nEntrypoints\n\n\nEntrypoints are the network entry points into Tr\u00e6fik.\nThey can be defined using:\n\n\n\n\na port (80, 443...)\n\n\nSSL (Certificates, Keys, authentication with a client certificate signed by a trusted CA...)\n\n\nredirection to another entrypoint (redirect \nHTTP\n to \nHTTPS\n)\n\n\n\n\nHere is an example of entrypoints definition:\n\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n    [entryPoints.http.redirect]\n    entryPoint = \nhttps\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile = \ntests/traefik.crt\n\n      keyFile = \ntests/traefik.key\n\n\n\n\n\n\n\nTwo entrypoints are defined \nhttp\n and \nhttps\n.\n\n\nhttp\n listens on port \n80\n and \nhttps\n on port \n443\n.\n\n\nWe enable SSL on \nhttps\n by giving a certificate and a key.\n\n\nWe also redirect all the traffic from entrypoint \nhttp\n to \nhttps\n.\n\n\n\n\nAnd here is another example with client certificate authentication:\n\n\n[entryPoints]\n  [entryPoints.https]\n  address = \n:443\n\n  [entryPoints.https.tls]\n  clientCAFiles = [\ntests/clientca1.crt\n, \ntests/clientca2.crt\n]\n    [[entryPoints.https.tls.certificates]]\n    certFile = \ntests/traefik.crt\n\n    keyFile = \ntests/traefik.key\n\n\n\n\n\n\n\nWe enable SSL on \nhttps\n by giving a certificate and a key.\n\n\nOne or several files containing Certificate Authorities in PEM format are added.\n\n\nIt is possible to have multiple CA:s in the same file or keep them in separate files.\n\n\n\n\nFrontends\n\n\nA frontend consists of a set of rules that determine how incoming requests are forwarded from an entrypoint to a backend.\n\n\nRules may be classified in one of two groups: Modifiers and matchers.\n\n\nModifiers\n\n\nModifier rules only modify the request. They do not have any impact on routing decisions being made.\n\n\nFollowing is the list of existing modifier rules:\n\n\n\n\nAddPrefix: /products\n: Add path prefix to the existing request path prior to forwarding the request to the backend.\n\n\nReplacePath: /serverless-path\n: Replaces the path and adds the old path to the \nX-Replaced-Path\n header. Useful for mapping to AWS Lambda or Google Cloud Functions.\n\n\n\n\nMatchers\n\n\nMatcher rules determine if a particular request should be forwarded to a backend.\n\n\nSeparate multiple rule values by \n,\n (comma) in order to enable ANY semantics (i.e., forward a request if any rule matches).\nDoes not work for \nHeaders\n and \nHeadersRegexp\n.\n\n\nSeparate multiple rule values by \n;\n (semicolon) in order to enable ALL semantics (i.e., forward a request if all rules match).\n\n\nFollowing is the list of existing matcher rules along with examples:\n\n\n\n\n\n\n\n\nMatcher\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nHeaders: Content-Type, application/json\n\n\nMatch HTTP header. It accepts a comma-separated key/value pair where both key and value must be literals.\n\n\n\n\n\n\nHeadersRegexp: Content-Type, application/(text/json)\n\n\nMatch HTTP header. It accepts a comma-separated key/value pair where the key must be a literal and the value may be a literal or a regular expression.\n\n\n\n\n\n\nHost: traefik.io, www.traefik.io\n\n\nMatch request host. It accepts a sequence of literal hosts.\n\n\n\n\n\n\nHostRegexp: traefik.io, {subdomain:[a-z]+}.traefik.io\n\n\nMatch request host. It accepts a sequence of literal and regular expression hosts.\n\n\n\n\n\n\nMethod: GET, POST, PUT\n\n\nMatch request HTTP method. It accepts a sequence of HTTP methods.\n\n\n\n\n\n\nPath: /products/, /articles/{category}/{id:[0-9]+}\n\n\nMatch exact request path. It accepts a sequence of literal and regular expression paths.\n\n\n\n\n\n\nPathStrip: /products/\n\n\nMatch exact path and strip off the path prior to forwarding the request to the backend. It accepts a sequence of literal paths.\n\n\n\n\n\n\nPathStripRegex: /articles/{category}/{id:[0-9]+}\n\n\nMatch exact path and strip off the path prior to forwarding the request to the backend. It accepts a sequence of literal and regular expression paths.\n\n\n\n\n\n\nPathPrefix: /products/, /articles/{category}/{id:[0-9]+}\n\n\nMatch request prefix path. It accepts a sequence of literal and regular expression prefix paths.\n\n\n\n\n\n\nPathPrefixStrip: /products/\n\n\nMatch request prefix path and strip off the path prefix prior to forwarding the request to the backend. It accepts a sequence of literal prefix paths. Starting with Traefik 1.3, the stripped prefix path will be available in the \nX-Forwarded-Prefix\n header.\n\n\n\n\n\n\nPathPrefixStripRegex: /articles/{category}/{id:[0-9]+}\n\n\nMatch request prefix path and strip off the path prefix prior to forwarding the request to the backend. It accepts a sequence of literal and regular expression prefix paths. Starting with Traefik 1.3, the stripped prefix path will be available in the \nX-Forwarded-Prefix\n header.\n\n\n\n\n\n\nQuery: foo=bar, bar=baz\n\n\nMatch Query String parameters. It accepts a sequence of key=value pairs.\n\n\n\n\n\n\n\n\nIn order to use regular expressions with Host and Path matchers, you must declare an arbitrarily named variable followed by the colon-separated regular expression, all enclosed in curly braces. Any pattern supported by \nGo's regexp package\n may be used (example: \n/posts/{id:[0-9]+}\n).\n\n\n\n\nNote\n\n\nThe variable has no special meaning; however, it is required by the \ngorilla/mux\n dependency which embeds the regular expression and defines the syntax.\n\n\n\n\nYou can optionally enable \npassHostHeader\n to forward client \nHost\n header to the backend.\nYou can also optionally enable \npassTLSCert\n to forward TLS Client certificates to the backend.\n\n\nPath Matcher Usage Guidelines\n\n\nThis section explains when to use the various path matchers.\n\n\nUse \nPath\n if your backend listens on the exact path only. For instance, \nPath: /products\n would match \n/products\n but not \n/products/shoes\n.\n\n\nUse a \n*Prefix*\n matcher if your backend listens on a particular base path but also serves requests on sub-paths.\nFor instance, \nPathPrefix: /products\n would match \n/products\n but also \n/products/shoes\n and \n/products/shirts\n.\nSince the path is forwarded as-is, your backend is expected to listen on \n/products\n.\n\n\nUse a \n*Strip\n matcher if your backend listens on the root path (\n/\n) but should be routeable on a specific prefix.\nFor instance, \nPathPrefixStrip: /products\n would match \n/products\n but also \n/products/shoes\n and \n/products/shirts\n.\n\nSince the path is stripped prior to forwarding, your backend is expected to listen on \n/\n.\n\nIf your backend is serving assets (e.g., images or Javascript files), chances are it must return properly constructed relative URLs.\n\nContinuing on the example, the backend should return \n/products/shoes/image.png\n (and not \n/images.png\n which Traefik would likely not be able to associate with the same backend).\n\nThe \nX-Forwarded-Prefix\n header (available since Traefik 1.3) can be queried to build such URLs dynamically.\n\n\nInstead of distinguishing your backends by path only, you can add a Host matcher to the mix.\nThat way, namespacing of your backends happens on the basis of hosts in addition to paths.\n\n\nExamples\n\n\nHere is an example of frontends definition:\n\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend2\n\n    [frontends.frontend1.routes.test_1]\n    rule = \nHost:test.localhost,test2.localhost\n\n  [frontends.frontend2]\n  backend = \nbackend1\n\n  passHostHeader = true\n  passTLSCert = true\n  priority = 10\n  entrypoints = [\nhttps\n] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule = \nHostRegexp:localhost,{subdomain:[a-z]+}.localhost\n\n  [frontends.frontend3]\n  backend = \nbackend2\n\n    [frontends.frontend3.routes.test_1]\n    rule = \nHost:test3.localhost;Path:/test\n\n\n\n\n\n\n\nThree frontends are defined: \nfrontend1\n, \nfrontend2\n and \nfrontend3\n\n\nfrontend1\n will forward the traffic to the \nbackend2\n if the rule \nHost:test.localhost,test2.localhost\n is matched\n\n\nfrontend2\n will forward the traffic to the \nbackend1\n if the rule \nHost:localhost,{subdomain:[a-z]+}.localhost\n is matched (forwarding client \nHost\n header to the backend)\n\n\nfrontend3\n will forward the traffic to the \nbackend2\n if the rules \nHost:test3.localhost\n \nAND\n \nPath:/test\n are matched\n\n\n\n\nCombining multiple rules\n\n\nAs seen in the previous example, you can combine multiple rules.\nIn TOML file, you can use multiple routes:\n\n\n  [frontends.frontend3]\n  backend = \nbackend2\n\n    [frontends.frontend3.routes.test_1]\n    rule = \nHost:test3.localhost\n\n    [frontends.frontend3.routes.test_2]\n    rule = \nPath:/test\n\n\n\n\n\nHere \nfrontend3\n will forward the traffic to the \nbackend2\n if the rules \nHost:test3.localhost\n \nAND\n \nPath:/test\n are matched.\n\n\nYou can also use the notation using a \n;\n separator, same result:\n\n\n  [frontends.frontend3]\n  backend = \nbackend2\n\n    [frontends.frontend3.routes.test_1]\n    rule = \nHost:test3.localhost;Path:/test\n\n\n\n\n\nFinally, you can create a rule to bind multiple domains or Path to a frontend, using the \n,\n separator:\n\n\n [frontends.frontend2]\n    [frontends.frontend2.routes.test_1]\n    rule = \nHost:test1.localhost,test2.localhost\n\n  [frontends.frontend3]\n  backend = \nbackend2\n\n    [frontends.frontend3.routes.test_1]\n    rule = \nPath:/test1,/test2\n\n\n\n\n\nRules Order\n\n\nWhen combining \nModifier\n rules with \nMatcher\n rules, it is important to remember that \nModifier\n rules \nALWAYS\n apply after the \nMatcher\n rules.\n\n\nThe following rules are both \nMatchers\n and \nModifiers\n, so the \nMatcher\n portion of the rule will apply first, and the \nModifier\n will apply later.\n\n\n\n\nPathStrip\n\n\nPathStripRegex\n\n\nPathPrefixStrip\n\n\nPathPrefixStripRegex\n\n\n\n\nModifiers\n will be applied in a pre-determined order regardless of their order in the \nrule\n configuration section.\n\n\n\n\nPathStrip\n\n\nPathPrefixStrip\n\n\nPathStripRegex\n\n\nPathPrefixStripRegex\n\n\nAddPrefix\n\n\nReplacePath\n\n\n\n\nPriorities\n\n\nBy default, routes will be sorted (in descending order) using rules length (to avoid path overlap):\n\nPathPrefix:/12345\n will be matched before \nPathPrefix:/1234\n that will be matched before \nPathPrefix:/1\n.\n\n\nYou can customize priority by frontend:\n\n\n  [frontends]\n    [frontends.frontend1]\n    backend = \nbackend1\n\n    priority = 10\n    passHostHeader = true\n      [frontends.frontend1.routes.test_1]\n      rule = \nPathPrefix:/to\n\n    [frontends.frontend2]\n    priority = 5\n    backend = \nbackend2\n\n    passHostHeader = true\n      [frontends.frontend2.routes.test_1]\n      rule = \nPathPrefix:/toto\n\n\n\n\n\nHere, \nfrontend1\n will be matched before \nfrontend2\n (\n10 \n 5\n).\n\n\nCustom headers\n\n\nCustom headers can be configured through the frontends, to add headers to either requests or responses that match the frontend's rules.\nThis allows for setting headers such as \nX-Script-Name\n to be added to the request, or custom headers to be added to the response.\n\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend1\n\n    [frontends.frontend1.headers.customresponseheaders]\n    X-Custom-Response-Header = \nTrue\n\n    [frontends.frontend1.headers.customrequestheaders]\n    X-Script-Name = \ntest\n\n    [frontends.frontend1.routes.test_1]\n    rule = \nPathPrefixStrip:/cheese\n\n\n\n\n\nIn this example, all matches to the path \n/cheese\n will have the \nX-Script-Name\n header added to the proxied request, and the \nX-Custom-Response-Header\n added to the response.\n\n\nSecurity headers\n\n\nSecurity related headers (HSTS headers, SSL redirection, Browser XSS filter, etc) can be added and configured per frontend in a similar manner to the custom headers above.\nThis functionality allows for some easy security features to quickly be set.\n\n\nAn example of some of the security headers:\n\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend1\n\n    [frontends.frontend1.headers]\n    FrameDeny = true\n    [frontends.frontend1.routes.test_1]\n    rule = \nPathPrefixStrip:/cheddar\n\n  [frontends.frontend2]\n  backend = \nbackend2\n\n    [frontends.frontend2.headers]\n    SSLRedirect = true\n    [frontends.frontend2.routes.test_1]\n    rule = \nPathPrefixStrip:/stilton\n\n\n\n\n\nIn this example, traffic routed through the first frontend will have the \nX-Frame-Options\n header set to \nDENY\n, and the second will only allow HTTPS request through, otherwise will return a 301 HTTPS redirect.\n\n\n\n\nNote\n\n\nThe detailed documentation for those security headers can be found in \nunrolled/secure\n.\n\n\n\n\nBackends\n\n\nA backend is responsible to load-balance the traffic coming from one or more frontends to a set of http servers.\n\n\nVarious methods of load-balancing are supported:\n\n\n\n\nwrr\n: Weighted Round Robin\n\n\ndrr\n: Dynamic Round Robin: increases weights on servers that perform better than others.\n    It also rolls back to original weights if the servers have changed.\n\n\n\n\nA circuit breaker can also be applied to a backend, preventing high loads on failing servers.\nInitial state is Standby. CB observes the statistics and does not modify the request.\nIn case the condition matches, CB enters Tripped state, where it responds with predefined code or redirects to another frontend.\nOnce Tripped timer expires, CB enters Recovering state and resets all stats.\nIn case the condition does not match and recovery timer expires, CB enters Standby state.\n\n\nIt can be configured using:\n\n\n\n\nMethods: \nLatencyAtQuantileMS\n, \nNetworkErrorRatio\n, \nResponseCodeRatio\n\n\nOperators:  \nAND\n, \nOR\n, \nEQ\n, \nNEQ\n, \nLT\n, \nLE\n, \nGT\n, \nGE\n\n\n\n\nFor example:\n\n\n\n\nNetworkErrorRatio() \n 0.5\n: watch error ratio over 10 second sliding window for a frontend\n\n\nLatencyAtQuantileMS(50.0) \n 50\n:  watch latency at quantile in milliseconds.\n\n\nResponseCodeRatio(500, 600, 0, 600) \n 0.5\n: ratio of response codes in range [500-600) to  [0-600)\n\n\n\n\nTo proactively prevent backends from being overwhelmed with high load, a maximum connection limit can\nalso be applied to each backend.\n\n\nMaximum connections can be configured by specifying an integer value for \nmaxconn.amount\n and\n\nmaxconn.extractorfunc\n which is a strategy used to determine how to categorize requests in order to\nevaluate the maximum connections.\n\n\nFor example:\n\n\n[backends]\n  [backends.backend1]\n    [backends.backend1.maxconn]\n       amount = 10\n       extractorfunc = \nrequest.host\n\n\n\n\n\n\n\nbackend1\n will return \nHTTP code 429 Too Many Requests\n if there are already 10 requests in progress for the same Host header.\n\n\nAnother possible value for \nextractorfunc\n is \nclient.ip\n which will categorize requests based on client source ip.\n\n\nLastly \nextractorfunc\n can take the value of \nrequest.header.ANY_HEADER\n which will categorize requests based on \nANY_HEADER\n that you provide.\n\n\n\n\nSticky sessions\n\n\nSticky sessions are supported with both load balancers.\n\nWhen sticky sessions are enabled, a cookie is set on the initial request.\nThe default cookie name is an abbreviation of a sha1 (ex: \n_1d52e\n).\nOn subsequent requests, the client will be directed to the backend stored in the cookie if it is still healthy.\nIf not, a new backend will be assigned.\n\n\n[backends]\n  [backends.backend1]\n    # Enable sticky session\n    [backends.backend1.loadbalancer.stickiness]\n\n    # Customize the cookie name\n    #\n    # Optional\n    # Default: a sha1 (6 chars)\n    #\n    #  cookieName = \nmy_cookie\n\n\n\n\n\nThe deprecated way:\n\n\n[backends]\n  [backends.backend1]\n    [backends.backend1.loadbalancer]\n      sticky = true\n\n\n\n\nHealth Check\n\n\nA health check can be configured in order to remove a backend from LB rotation as long as it keeps returning HTTP status codes other than \n200 OK\n to HTTP GET requests periodically carried out by Traefik.\n\nThe check is defined by a pathappended to the backend URL and an interval (given in a format understood by \ntime.ParseDuration\n) specifying how often the health check should be executed (the default being 30 seconds).\nEach backend must respond to the health check within 5 seconds.\n\nBy default, the port of the backend server is used, however, this may be overridden.\n\n\nA recovering backend returning 200 OK responses again is being returned to the\nLB rotation pool.\n\n\nFor example:\n\n\n[backends]\n  [backends.backend1]\n    [backends.backend1.healthcheck]\n    path = \n/health\n\n    interval = \n10s\n\n\n\n\n\nTo use a different port for the healthcheck:\n\n\n[backends]\n  [backends.backend1]\n    [backends.backend1.healthcheck]\n    path = \n/health\n\n    interval = \n10s\n\n    port = 8080\n\n\n\n\nServers\n\n\nServers are simply defined using a \nurl\n. You can also apply a custom \nweight\n to each server (this will be used by load-balancing).\n\n\n\n\nNote\n\n\nPaths in \nurl\n are ignored. Use \nModifier\n to specify paths instead.\n\n\n\n\nHere is an example of backends and servers definition:\n\n\n[backends]\n  [backends.backend1]\n    [backends.backend1.circuitbreaker]\n    expression = \nNetworkErrorRatio() \n 0.5\n\n    [backends.backend1.servers.server1]\n    url = \nhttp://172.17.0.2:80\n\n    weight = 10\n    [backends.backend1.servers.server2]\n    url = \nhttp://172.17.0.3:80\n\n    weight = 1\n  [backends.backend2]\n    [backends.backend2.LoadBalancer]\n    method = \ndrr\n\n    [backends.backend2.servers.server1]\n    url = \nhttp://172.17.0.4:80\n\n    weight = 1\n    [backends.backend2.servers.server2]\n    url = \nhttp://172.17.0.5:80\n\n    weight = 2\n\n\n\n\n\n\nTwo backends are defined: \nbackend1\n and \nbackend2\n\n\nbackend1\n will forward the traffic to two servers: \nhttp://172.17.0.2:80\"\n with weight \n10\n and \nhttp://172.17.0.3:80\n with weight \n1\n using default \nwrr\n load-balancing strategy.\n\n\nbackend2\n will forward the traffic to two servers: \nhttp://172.17.0.4:80\"\n with weight \n1\n and \nhttp://172.17.0.5:80\n with weight \n2\n using \ndrr\n load-balancing strategy.\n\n\na circuit breaker is added on \nbackend1\n using the expression \nNetworkErrorRatio() \n 0.5\n: watch error ratio over 10 second sliding window\n\n\n\n\nConfiguration\n\n\nTr\u00e6fik's configuration has two parts:\n\n\n\n\nThe \nstatic Tr\u00e6fik configuration\n which is loaded only at the beginning.\n\n\nThe \ndynamic Tr\u00e6fik configuration\n which can be hot-reloaded (no need to restart the process).\n\n\n\n\nStatic Tr\u00e6fik configuration\n\n\nThe static configuration is the global configuration which is setting up connections to configuration backends and entrypoints.\n\n\nTr\u00e6fik can be configured using many configuration sources with the following precedence order.\nEach item takes precedence over the item below it:\n\n\n\n\nKey-value store\n\n\nArguments\n\n\nConfiguration file\n\n\nDefault\n\n\n\n\nIt means that arguments override configuration file, and key-value store overrides arguments.\n\n\n\n\nNote\n\n\nthe provider-enabling argument parameters (e.g., \n--docker\n) set all default values for the specific provider.\n\nIt must not be used if a configuration source with less precedence wants to set a non-default provider value.\n\n\n\n\nConfiguration file\n\n\nBy default, Tr\u00e6fik will try to find a \ntraefik.toml\n in the following places:\n\n\n\n\n/etc/traefik/\n\n\n$HOME/.traefik/\n\n\n.\n \nthe working directory\n\n\n\n\nYou can override this by setting a \nconfigFile\n argument:\n\n\ntraefik --configFile=foo/bar/myconfigfile.toml\n\n\n\n\nPlease refer to the \nglobal configuration\n section to get documentation on it.\n\n\nArguments\n\n\nEach argument (and command) is described in the help section:\n\n\ntraefik --help\n\n\n\n\nNote that all default values will be displayed as well.\n\n\nKey-value stores\n\n\nTr\u00e6fik supports several Key-value stores:\n\n\n\n\nConsul\n\n\netcd\n\n\nZooKeeper\n\n\nboltdb\n\n\n\n\nPlease refer to the \nUser Guide Key-value store configuration\n section to get documentation on it.\n\n\nDynamic Tr\u00e6fik configuration\n\n\nThe dynamic configuration concerns :\n\n\n\n\nFrontends\n\n\nBackends\n\n\nServers\n\n\n\n\nTr\u00e6fik can hot-reload those rules which could be provided by \nmultiple configuration backends\n.\n\n\nWe only need to enable \nwatch\n option to make Tr\u00e6fik watch configuration backend changes and generate its configuration automatically.\nRoutes to services will be created and updated instantly at any changes.\n\n\nPlease refer to the \nconfiguration backends\n section to get documentation on it.\n\n\nCommands\n\n\ntraefik\n\n\nUsage:\n\n\ntraefik [command] [--flag=flag_argument]\n\n\n\n\nList of Tr\u00e6fik available\u00a0commands with description :\n\n\n\n\nversion\n : Print\u00a0version\n\n\nstoreconfig\n : Store the static Traefik configuration into a Key-value stores.\u00a0Please refer to the \nStore Tr\u00e6fik configuration\n section to get documentation on it.\n\n\nbug\n: The easiest way to submit a pre-filled issue.\n\n\nhealthcheck\n: Calls Traefik \n/ping\n to check health.\n\n\n\n\nEach command may have related flags.\n\n\nAll those related flags will be displayed with :\n\n\ntraefik [command] --help\n\n\n\n\nEach command is described at the beginning of the help section:\n\n\ntraefik --help\n\n\n\n\nCommand: bug\n\n\nHere is the easiest way to submit a pre-filled issue on \nTr\u00e6fik GitHub\n.\n\n\ntraefik bug\n\n\n\n\nWatch \nthis demo\n.\n\n\nCommand: healthcheck\n\n\nThis command allows to check the health of Traefik. Its exit status is \n0\n if Traefik is healthy and \n1\n if it is unhealthy.\n\n\nThis can be used with Docker \nHEALTHCHECK\n instruction or any other health check orchestration mechanism.\n\n\n\n\nNote\n\n\nThe \nweb\n provider\n must be enabled to allow \n/ping\n calls by the \nhealthcheck\n command.\n\n\n\n\ntraefik healthcheck\n\n\n\n\nOK: http://:8082/ping", 
            "title": "Basics"
        }, 
        {
            "location": "/basics/#basics", 
            "text": "", 
            "title": "Basics"
        }, 
        {
            "location": "/basics/#concepts", 
            "text": "Let's take our example from the  overview  again:   Imagine that you have deployed a bunch of microservices on your infrastructure. You probably used a service registry (like etcd or consul) and/or an orchestrator (swarm, Mesos/Marathon) to manage all these services.\nIf you want your users to access some of your microservices from the Internet, you will have to use a reverse proxy and configure it using virtual hosts or prefix paths:   domain  api.domain.com  will point the microservice  api  in your private network  path  domain.com/web  will point the microservice  web  in your private network  domain  backoffice.domain.com  will point the microservices  backoffice  in your private network, load-balancing between your multiple instances     Let's zoom on Tr\u00e6fik and have an overview of its internal architecture:    Incoming requests end on  entrypoints , as the name suggests, they are the network entry points into Tr\u00e6fik (listening port, SSL, traffic redirection...).  Traffic is then forwarded to a matching  frontend . A frontend defines routes from  entrypoints  to  backends .\nRoutes are created using requests fields ( Host ,  Path ,  Headers ...) and can match or not a request.  The  frontend  will then send the request to a  backend . A backend can be composed by one or more  servers , and by a load-balancing strategy.  Finally, the  server  will forward the request to the corresponding microservice in the private network.", 
            "title": "Concepts"
        }, 
        {
            "location": "/basics/#entrypoints", 
            "text": "Entrypoints are the network entry points into Tr\u00e6fik.\nThey can be defined using:   a port (80, 443...)  SSL (Certificates, Keys, authentication with a client certificate signed by a trusted CA...)  redirection to another entrypoint (redirect  HTTP  to  HTTPS )   Here is an example of entrypoints definition:  [entryPoints]\n  [entryPoints.http]\n  address =  :80 \n    [entryPoints.http.redirect]\n    entryPoint =  https \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile =  tests/traefik.crt \n      keyFile =  tests/traefik.key    Two entrypoints are defined  http  and  https .  http  listens on port  80  and  https  on port  443 .  We enable SSL on  https  by giving a certificate and a key.  We also redirect all the traffic from entrypoint  http  to  https .   And here is another example with client certificate authentication:  [entryPoints]\n  [entryPoints.https]\n  address =  :443 \n  [entryPoints.https.tls]\n  clientCAFiles = [ tests/clientca1.crt ,  tests/clientca2.crt ]\n    [[entryPoints.https.tls.certificates]]\n    certFile =  tests/traefik.crt \n    keyFile =  tests/traefik.key    We enable SSL on  https  by giving a certificate and a key.  One or several files containing Certificate Authorities in PEM format are added.  It is possible to have multiple CA:s in the same file or keep them in separate files.", 
            "title": "Entrypoints"
        }, 
        {
            "location": "/basics/#frontends", 
            "text": "A frontend consists of a set of rules that determine how incoming requests are forwarded from an entrypoint to a backend.  Rules may be classified in one of two groups: Modifiers and matchers.", 
            "title": "Frontends"
        }, 
        {
            "location": "/basics/#modifiers", 
            "text": "Modifier rules only modify the request. They do not have any impact on routing decisions being made.  Following is the list of existing modifier rules:   AddPrefix: /products : Add path prefix to the existing request path prior to forwarding the request to the backend.  ReplacePath: /serverless-path : Replaces the path and adds the old path to the  X-Replaced-Path  header. Useful for mapping to AWS Lambda or Google Cloud Functions.", 
            "title": "Modifiers"
        }, 
        {
            "location": "/basics/#matchers", 
            "text": "Matcher rules determine if a particular request should be forwarded to a backend.  Separate multiple rule values by  ,  (comma) in order to enable ANY semantics (i.e., forward a request if any rule matches).\nDoes not work for  Headers  and  HeadersRegexp .  Separate multiple rule values by  ;  (semicolon) in order to enable ALL semantics (i.e., forward a request if all rules match).  Following is the list of existing matcher rules along with examples:     Matcher  Description      Headers: Content-Type, application/json  Match HTTP header. It accepts a comma-separated key/value pair where both key and value must be literals.    HeadersRegexp: Content-Type, application/(text/json)  Match HTTP header. It accepts a comma-separated key/value pair where the key must be a literal and the value may be a literal or a regular expression.    Host: traefik.io, www.traefik.io  Match request host. It accepts a sequence of literal hosts.    HostRegexp: traefik.io, {subdomain:[a-z]+}.traefik.io  Match request host. It accepts a sequence of literal and regular expression hosts.    Method: GET, POST, PUT  Match request HTTP method. It accepts a sequence of HTTP methods.    Path: /products/, /articles/{category}/{id:[0-9]+}  Match exact request path. It accepts a sequence of literal and regular expression paths.    PathStrip: /products/  Match exact path and strip off the path prior to forwarding the request to the backend. It accepts a sequence of literal paths.    PathStripRegex: /articles/{category}/{id:[0-9]+}  Match exact path and strip off the path prior to forwarding the request to the backend. It accepts a sequence of literal and regular expression paths.    PathPrefix: /products/, /articles/{category}/{id:[0-9]+}  Match request prefix path. It accepts a sequence of literal and regular expression prefix paths.    PathPrefixStrip: /products/  Match request prefix path and strip off the path prefix prior to forwarding the request to the backend. It accepts a sequence of literal prefix paths. Starting with Traefik 1.3, the stripped prefix path will be available in the  X-Forwarded-Prefix  header.    PathPrefixStripRegex: /articles/{category}/{id:[0-9]+}  Match request prefix path and strip off the path prefix prior to forwarding the request to the backend. It accepts a sequence of literal and regular expression prefix paths. Starting with Traefik 1.3, the stripped prefix path will be available in the  X-Forwarded-Prefix  header.    Query: foo=bar, bar=baz  Match Query String parameters. It accepts a sequence of key=value pairs.     In order to use regular expressions with Host and Path matchers, you must declare an arbitrarily named variable followed by the colon-separated regular expression, all enclosed in curly braces. Any pattern supported by  Go's regexp package  may be used (example:  /posts/{id:[0-9]+} ).   Note  The variable has no special meaning; however, it is required by the  gorilla/mux  dependency which embeds the regular expression and defines the syntax.   You can optionally enable  passHostHeader  to forward client  Host  header to the backend.\nYou can also optionally enable  passTLSCert  to forward TLS Client certificates to the backend.", 
            "title": "Matchers"
        }, 
        {
            "location": "/basics/#path-matcher-usage-guidelines", 
            "text": "This section explains when to use the various path matchers.  Use  Path  if your backend listens on the exact path only. For instance,  Path: /products  would match  /products  but not  /products/shoes .  Use a  *Prefix*  matcher if your backend listens on a particular base path but also serves requests on sub-paths.\nFor instance,  PathPrefix: /products  would match  /products  but also  /products/shoes  and  /products/shirts .\nSince the path is forwarded as-is, your backend is expected to listen on  /products .  Use a  *Strip  matcher if your backend listens on the root path ( / ) but should be routeable on a specific prefix.\nFor instance,  PathPrefixStrip: /products  would match  /products  but also  /products/shoes  and  /products/shirts . \nSince the path is stripped prior to forwarding, your backend is expected to listen on  / . \nIf your backend is serving assets (e.g., images or Javascript files), chances are it must return properly constructed relative URLs. \nContinuing on the example, the backend should return  /products/shoes/image.png  (and not  /images.png  which Traefik would likely not be able to associate with the same backend). \nThe  X-Forwarded-Prefix  header (available since Traefik 1.3) can be queried to build such URLs dynamically.  Instead of distinguishing your backends by path only, you can add a Host matcher to the mix.\nThat way, namespacing of your backends happens on the basis of hosts in addition to paths.", 
            "title": "Path Matcher Usage Guidelines"
        }, 
        {
            "location": "/basics/#examples", 
            "text": "Here is an example of frontends definition:  [frontends]\n  [frontends.frontend1]\n  backend =  backend2 \n    [frontends.frontend1.routes.test_1]\n    rule =  Host:test.localhost,test2.localhost \n  [frontends.frontend2]\n  backend =  backend1 \n  passHostHeader = true\n  passTLSCert = true\n  priority = 10\n  entrypoints = [ https ] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule =  HostRegexp:localhost,{subdomain:[a-z]+}.localhost \n  [frontends.frontend3]\n  backend =  backend2 \n    [frontends.frontend3.routes.test_1]\n    rule =  Host:test3.localhost;Path:/test    Three frontends are defined:  frontend1 ,  frontend2  and  frontend3  frontend1  will forward the traffic to the  backend2  if the rule  Host:test.localhost,test2.localhost  is matched  frontend2  will forward the traffic to the  backend1  if the rule  Host:localhost,{subdomain:[a-z]+}.localhost  is matched (forwarding client  Host  header to the backend)  frontend3  will forward the traffic to the  backend2  if the rules  Host:test3.localhost   AND   Path:/test  are matched", 
            "title": "Examples"
        }, 
        {
            "location": "/basics/#combining-multiple-rules", 
            "text": "As seen in the previous example, you can combine multiple rules.\nIn TOML file, you can use multiple routes:    [frontends.frontend3]\n  backend =  backend2 \n    [frontends.frontend3.routes.test_1]\n    rule =  Host:test3.localhost \n    [frontends.frontend3.routes.test_2]\n    rule =  Path:/test   Here  frontend3  will forward the traffic to the  backend2  if the rules  Host:test3.localhost   AND   Path:/test  are matched.  You can also use the notation using a  ;  separator, same result:    [frontends.frontend3]\n  backend =  backend2 \n    [frontends.frontend3.routes.test_1]\n    rule =  Host:test3.localhost;Path:/test   Finally, you can create a rule to bind multiple domains or Path to a frontend, using the  ,  separator:   [frontends.frontend2]\n    [frontends.frontend2.routes.test_1]\n    rule =  Host:test1.localhost,test2.localhost \n  [frontends.frontend3]\n  backend =  backend2 \n    [frontends.frontend3.routes.test_1]\n    rule =  Path:/test1,/test2", 
            "title": "Combining multiple rules"
        }, 
        {
            "location": "/basics/#rules-order", 
            "text": "When combining  Modifier  rules with  Matcher  rules, it is important to remember that  Modifier  rules  ALWAYS  apply after the  Matcher  rules.  The following rules are both  Matchers  and  Modifiers , so the  Matcher  portion of the rule will apply first, and the  Modifier  will apply later.   PathStrip  PathStripRegex  PathPrefixStrip  PathPrefixStripRegex   Modifiers  will be applied in a pre-determined order regardless of their order in the  rule  configuration section.   PathStrip  PathPrefixStrip  PathStripRegex  PathPrefixStripRegex  AddPrefix  ReplacePath", 
            "title": "Rules Order"
        }, 
        {
            "location": "/basics/#priorities", 
            "text": "By default, routes will be sorted (in descending order) using rules length (to avoid path overlap): PathPrefix:/12345  will be matched before  PathPrefix:/1234  that will be matched before  PathPrefix:/1 .  You can customize priority by frontend:    [frontends]\n    [frontends.frontend1]\n    backend =  backend1 \n    priority = 10\n    passHostHeader = true\n      [frontends.frontend1.routes.test_1]\n      rule =  PathPrefix:/to \n    [frontends.frontend2]\n    priority = 5\n    backend =  backend2 \n    passHostHeader = true\n      [frontends.frontend2.routes.test_1]\n      rule =  PathPrefix:/toto   Here,  frontend1  will be matched before  frontend2  ( 10   5 ).", 
            "title": "Priorities"
        }, 
        {
            "location": "/basics/#custom-headers", 
            "text": "Custom headers can be configured through the frontends, to add headers to either requests or responses that match the frontend's rules.\nThis allows for setting headers such as  X-Script-Name  to be added to the request, or custom headers to be added to the response.  [frontends]\n  [frontends.frontend1]\n  backend =  backend1 \n    [frontends.frontend1.headers.customresponseheaders]\n    X-Custom-Response-Header =  True \n    [frontends.frontend1.headers.customrequestheaders]\n    X-Script-Name =  test \n    [frontends.frontend1.routes.test_1]\n    rule =  PathPrefixStrip:/cheese   In this example, all matches to the path  /cheese  will have the  X-Script-Name  header added to the proxied request, and the  X-Custom-Response-Header  added to the response.", 
            "title": "Custom headers"
        }, 
        {
            "location": "/basics/#security-headers", 
            "text": "Security related headers (HSTS headers, SSL redirection, Browser XSS filter, etc) can be added and configured per frontend in a similar manner to the custom headers above.\nThis functionality allows for some easy security features to quickly be set.  An example of some of the security headers:  [frontends]\n  [frontends.frontend1]\n  backend =  backend1 \n    [frontends.frontend1.headers]\n    FrameDeny = true\n    [frontends.frontend1.routes.test_1]\n    rule =  PathPrefixStrip:/cheddar \n  [frontends.frontend2]\n  backend =  backend2 \n    [frontends.frontend2.headers]\n    SSLRedirect = true\n    [frontends.frontend2.routes.test_1]\n    rule =  PathPrefixStrip:/stilton   In this example, traffic routed through the first frontend will have the  X-Frame-Options  header set to  DENY , and the second will only allow HTTPS request through, otherwise will return a 301 HTTPS redirect.   Note  The detailed documentation for those security headers can be found in  unrolled/secure .", 
            "title": "Security headers"
        }, 
        {
            "location": "/basics/#backends", 
            "text": "A backend is responsible to load-balance the traffic coming from one or more frontends to a set of http servers.  Various methods of load-balancing are supported:   wrr : Weighted Round Robin  drr : Dynamic Round Robin: increases weights on servers that perform better than others.\n    It also rolls back to original weights if the servers have changed.   A circuit breaker can also be applied to a backend, preventing high loads on failing servers.\nInitial state is Standby. CB observes the statistics and does not modify the request.\nIn case the condition matches, CB enters Tripped state, where it responds with predefined code or redirects to another frontend.\nOnce Tripped timer expires, CB enters Recovering state and resets all stats.\nIn case the condition does not match and recovery timer expires, CB enters Standby state.  It can be configured using:   Methods:  LatencyAtQuantileMS ,  NetworkErrorRatio ,  ResponseCodeRatio  Operators:   AND ,  OR ,  EQ ,  NEQ ,  LT ,  LE ,  GT ,  GE   For example:   NetworkErrorRatio()   0.5 : watch error ratio over 10 second sliding window for a frontend  LatencyAtQuantileMS(50.0)   50 :  watch latency at quantile in milliseconds.  ResponseCodeRatio(500, 600, 0, 600)   0.5 : ratio of response codes in range [500-600) to  [0-600)   To proactively prevent backends from being overwhelmed with high load, a maximum connection limit can\nalso be applied to each backend.  Maximum connections can be configured by specifying an integer value for  maxconn.amount  and maxconn.extractorfunc  which is a strategy used to determine how to categorize requests in order to\nevaluate the maximum connections.  For example:  [backends]\n  [backends.backend1]\n    [backends.backend1.maxconn]\n       amount = 10\n       extractorfunc =  request.host    backend1  will return  HTTP code 429 Too Many Requests  if there are already 10 requests in progress for the same Host header.  Another possible value for  extractorfunc  is  client.ip  which will categorize requests based on client source ip.  Lastly  extractorfunc  can take the value of  request.header.ANY_HEADER  which will categorize requests based on  ANY_HEADER  that you provide.", 
            "title": "Backends"
        }, 
        {
            "location": "/basics/#sticky-sessions", 
            "text": "Sticky sessions are supported with both load balancers. \nWhen sticky sessions are enabled, a cookie is set on the initial request.\nThe default cookie name is an abbreviation of a sha1 (ex:  _1d52e ).\nOn subsequent requests, the client will be directed to the backend stored in the cookie if it is still healthy.\nIf not, a new backend will be assigned.  [backends]\n  [backends.backend1]\n    # Enable sticky session\n    [backends.backend1.loadbalancer.stickiness]\n\n    # Customize the cookie name\n    #\n    # Optional\n    # Default: a sha1 (6 chars)\n    #\n    #  cookieName =  my_cookie   The deprecated way:  [backends]\n  [backends.backend1]\n    [backends.backend1.loadbalancer]\n      sticky = true", 
            "title": "Sticky sessions"
        }, 
        {
            "location": "/basics/#health-check", 
            "text": "A health check can be configured in order to remove a backend from LB rotation as long as it keeps returning HTTP status codes other than  200 OK  to HTTP GET requests periodically carried out by Traefik. \nThe check is defined by a pathappended to the backend URL and an interval (given in a format understood by  time.ParseDuration ) specifying how often the health check should be executed (the default being 30 seconds).\nEach backend must respond to the health check within 5 seconds. \nBy default, the port of the backend server is used, however, this may be overridden.  A recovering backend returning 200 OK responses again is being returned to the\nLB rotation pool.  For example:  [backends]\n  [backends.backend1]\n    [backends.backend1.healthcheck]\n    path =  /health \n    interval =  10s   To use a different port for the healthcheck:  [backends]\n  [backends.backend1]\n    [backends.backend1.healthcheck]\n    path =  /health \n    interval =  10s \n    port = 8080", 
            "title": "Health Check"
        }, 
        {
            "location": "/basics/#servers", 
            "text": "Servers are simply defined using a  url . You can also apply a custom  weight  to each server (this will be used by load-balancing).   Note  Paths in  url  are ignored. Use  Modifier  to specify paths instead.   Here is an example of backends and servers definition:  [backends]\n  [backends.backend1]\n    [backends.backend1.circuitbreaker]\n    expression =  NetworkErrorRatio()   0.5 \n    [backends.backend1.servers.server1]\n    url =  http://172.17.0.2:80 \n    weight = 10\n    [backends.backend1.servers.server2]\n    url =  http://172.17.0.3:80 \n    weight = 1\n  [backends.backend2]\n    [backends.backend2.LoadBalancer]\n    method =  drr \n    [backends.backend2.servers.server1]\n    url =  http://172.17.0.4:80 \n    weight = 1\n    [backends.backend2.servers.server2]\n    url =  http://172.17.0.5:80 \n    weight = 2   Two backends are defined:  backend1  and  backend2  backend1  will forward the traffic to two servers:  http://172.17.0.2:80\"  with weight  10  and  http://172.17.0.3:80  with weight  1  using default  wrr  load-balancing strategy.  backend2  will forward the traffic to two servers:  http://172.17.0.4:80\"  with weight  1  and  http://172.17.0.5:80  with weight  2  using  drr  load-balancing strategy.  a circuit breaker is added on  backend1  using the expression  NetworkErrorRatio()   0.5 : watch error ratio over 10 second sliding window", 
            "title": "Servers"
        }, 
        {
            "location": "/basics/#configuration", 
            "text": "Tr\u00e6fik's configuration has two parts:   The  static Tr\u00e6fik configuration  which is loaded only at the beginning.  The  dynamic Tr\u00e6fik configuration  which can be hot-reloaded (no need to restart the process).", 
            "title": "Configuration"
        }, 
        {
            "location": "/basics/#static-trfik-configuration", 
            "text": "The static configuration is the global configuration which is setting up connections to configuration backends and entrypoints.  Tr\u00e6fik can be configured using many configuration sources with the following precedence order.\nEach item takes precedence over the item below it:   Key-value store  Arguments  Configuration file  Default   It means that arguments override configuration file, and key-value store overrides arguments.   Note  the provider-enabling argument parameters (e.g.,  --docker ) set all default values for the specific provider. \nIt must not be used if a configuration source with less precedence wants to set a non-default provider value.", 
            "title": "Static Tr\u00e6fik configuration"
        }, 
        {
            "location": "/basics/#configuration-file", 
            "text": "By default, Tr\u00e6fik will try to find a  traefik.toml  in the following places:   /etc/traefik/  $HOME/.traefik/  .   the working directory   You can override this by setting a  configFile  argument:  traefik --configFile=foo/bar/myconfigfile.toml  Please refer to the  global configuration  section to get documentation on it.", 
            "title": "Configuration file"
        }, 
        {
            "location": "/basics/#arguments", 
            "text": "Each argument (and command) is described in the help section:  traefik --help  Note that all default values will be displayed as well.", 
            "title": "Arguments"
        }, 
        {
            "location": "/basics/#key-value-stores", 
            "text": "Tr\u00e6fik supports several Key-value stores:   Consul  etcd  ZooKeeper  boltdb   Please refer to the  User Guide Key-value store configuration  section to get documentation on it.", 
            "title": "Key-value stores"
        }, 
        {
            "location": "/basics/#dynamic-trfik-configuration", 
            "text": "The dynamic configuration concerns :   Frontends  Backends  Servers   Tr\u00e6fik can hot-reload those rules which could be provided by  multiple configuration backends .  We only need to enable  watch  option to make Tr\u00e6fik watch configuration backend changes and generate its configuration automatically.\nRoutes to services will be created and updated instantly at any changes.  Please refer to the  configuration backends  section to get documentation on it.", 
            "title": "Dynamic Tr\u00e6fik configuration"
        }, 
        {
            "location": "/basics/#commands", 
            "text": "", 
            "title": "Commands"
        }, 
        {
            "location": "/basics/#traefik", 
            "text": "Usage:  traefik [command] [--flag=flag_argument]  List of Tr\u00e6fik available\u00a0commands with description :   version  : Print\u00a0version  storeconfig  : Store the static Traefik configuration into a Key-value stores.\u00a0Please refer to the  Store Tr\u00e6fik configuration  section to get documentation on it.  bug : The easiest way to submit a pre-filled issue.  healthcheck : Calls Traefik  /ping  to check health.   Each command may have related flags.  All those related flags will be displayed with :  traefik [command] --help  Each command is described at the beginning of the help section:  traefik --help", 
            "title": "traefik"
        }, 
        {
            "location": "/basics/#command-bug", 
            "text": "Here is the easiest way to submit a pre-filled issue on  Tr\u00e6fik GitHub .  traefik bug  Watch  this demo .", 
            "title": "Command: bug"
        }, 
        {
            "location": "/basics/#command-healthcheck", 
            "text": "This command allows to check the health of Traefik. Its exit status is  0  if Traefik is healthy and  1  if it is unhealthy.  This can be used with Docker  HEALTHCHECK  instruction or any other health check orchestration mechanism.   Note  The  web  provider  must be enabled to allow  /ping  calls by the  healthcheck  command.   traefik healthcheck  OK: http://:8082/ping", 
            "title": "Command: healthcheck"
        }, 
        {
            "location": "/configuration/commons/", 
            "text": "Global Configuration\n\n\nMain Section\n\n\n# Duration to give active requests a chance to finish before Traefik stops.\n#\n# Optional\n# Default: \n10s\n\n#\n# graceTimeOut = \n10s\n\n\n# Enable debug mode.\n#\n# Optional\n# Default: false\n#\n# debug = true\n\n# Periodically check if a new version has been released.\n#\n# Optional\n# Default: true\n#\n# checkNewVersion = false\n\n# Backends throttle duration.\n#\n# Optional\n# Default: \n2s\n\n#\n# ProvidersThrottleDuration = \n2s\n\n\n# Controls the maximum idle (keep-alive) connections to keep per-host.\n#\n# Optional\n# Default: 200\n#\n# MaxIdleConnsPerHost = 200\n\n# If set to true invalid SSL certificates are accepted for backends.\n# This disables detection of man-in-the-middle attacks so should only be used on secure backend networks.\n#\n# Optional\n# Default: false\n#\n# InsecureSkipVerify = true\n\n# Register Certificates in the RootCA.\n#\n# Optional\n# Default: []\n#\n# RootCAs = [ \n/mycert.cert\n ]\n\n# Entrypoints to be used by frontends that do not specify any entrypoint.\n# Each frontend can specify its own entrypoints.\n#\n# Optional\n# Default: [\nhttp\n]\n#\n# defaultEntryPoints = [\nhttp\n, \nhttps\n]\n\n\n\n\n\n\n\n\ngraceTimeOut\n: Duration to give active requests a chance to finish before Traefik stops.\n\nCan be provided in a format supported by \ntime.ParseDuration\n or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.\n\n\nNote:\n in this time frame no new requests are accepted.\n\n\n\n\n\n\nProvidersThrottleDuration\n: Backends throttle duration: minimum duration in seconds between 2 events from providers before applying a new configuration.\nIt avoids unnecessary reloads if multiples events are sent in a short amount of time.\n\nCan be provided in a format supported by \ntime.ParseDuration\n or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.\n\n\n\n\n\n\nMaxIdleConnsPerHost\n: Controls the maximum idle (keep-alive) connections to keep per-host.\n\nIf zero, \nDefaultMaxIdleConnsPerHost\n from the Go standard library net/http module is used.\nIf you encounter 'too many open files' errors, you can either increase this value or change the \nulimit\n.\n\n\n\n\n\n\nInsecureSkipVerify\n : If set to true invalid SSL certificates are accepted for backends.\n\n\nNote:\n This disables detection of man-in-the-middle attacks so should only be used on secure backend networks.\n\n\n\n\n\n\nRootCAs\n: Register Certificates in the RootCA. This certificates will be use for backends calls.\n\n\nNote\n You can use file path or cert content directly\n\n\n\n\n\n\ndefaultEntryPoints\n: Entrypoints to be used by frontends that do not specify any entrypoint.\n\nEach frontend can specify its own entrypoints.\n\n\n\n\n\n\nConstraints\n\n\nIn a micro-service architecture, with a central service discovery, setting constraints limits Tr\u00e6fik scope to a smaller number of routes.\n\n\nTr\u00e6fik filters services according to service attributes/tags set in your configuration backends.\n\n\nSupported filters:\n\n\n\n\ntag\n\n\n\n\nSimple\n\n\n# Simple matching constraint\nconstraints = [\ntag==api\n]\n\n# Simple mismatching constraint\nconstraints = [\ntag!=api\n]\n\n# Globbing\nconstraints = [\ntag==us-*\n]\n\n\n\n\nMultiple\n\n\n# Multiple constraints\n#   - \ntag==\n must match with at least one tag\n#   - \ntag!=\n must match with none of tags\nconstraints = [\ntag!=us-*\n, \ntag!=asia-*\n]\n\n\n\n\nBackend-specific\n\n\nSupported backends:\n\n\n\n\nDocker\n\n\nConsul K/V\n\n\nBoltDB\n\n\nZookeeper\n\n\nEtcd\n\n\nConsul Catalog\n\n\nRancher\n\n\nMarathon\n\n\nKubernetes (using a provider-specific mechanism based on label selectors)\n\n\n\n\n# Backend-specific constraint\n[consulCatalog]\n# ...\nconstraints = [\ntag==api\n]\n\n# Backend-specific constraint\n[marathon]\n# ...\nconstraints = [\ntag==api\n, \ntag!=v*-beta\n]\n\n\n\n\nLogs Definition\n\n\nTraefik logs\n\n\n# Traefik logs file\n# If not defined, logs to stdout\ntraefikLogsFile = \nlog/traefik.log\n\n\n# Log level\n#\n# Optional\n# Default: \nERROR\n\n#\n# Accepted values, in order of severity: \nDEBUG\n, \nINFO\n, \nWARN\n, \nERROR\n, \nFATAL\n, \nPANIC\n\n# Messages at and above the selected level will be logged.\n#\nlogLevel = \nERROR\n\n\n\n\n\nAccess Logs\n\n\nAccess logs are written when \n[accessLog]\n is defined.\nBy default it will write to stdout and produce logs in the textual Common Log Format (CLF), extended with additional fields.\n\n\nTo enable access logs using the default settings just add the \n[accessLog]\n entry.\n\n\n[accessLog]\n\n\n\n\nTo write the logs into a logfile specify the \nfilePath\n.\n\n\n[accessLog]\nfilePath = \n/path/to/access.log\n\n\n\n\n\nTo write JSON format logs, specify \njson\n as the format:\n\n\n[accessLog]\nfilePath = \n/path/to/access.log\n\nformat = \njson\n\n\n\n\n\nDeprecated way (before 1.4):\n\n\n# Access logs file\n#\n# DEPRECATED - see [accessLog] lower down\n#\naccessLogsFile = \nlog/access.log\n\n\n\n\n\nLog Rotation\n\n\nTraefik will close and reopen its log files, assuming they're configured, on receipt of a USR1 signal.\nThis allows the logs to be rotated and processed by an external program, such as \nlogrotate\n.\n\n\n\n\nNote\n\n\nThis does not work on Windows due to the lack of USR signals.\n\n\n\n\nCustom Error pages\n\n\nCustom error pages can be returned, in lieu of the default, according to frontend-configured ranges of HTTP Status codes.\n\n\nIn the example below, if a 503 status is returned from the frontend \"website\", the custom error page at http://2.3.4.5/503.html is returned with the actual status code set in the HTTP header.\n\n\n\n\nNote\n\n\nThe \n503.html\n page itself is not hosted on Traefik, but some other infrastructure.\n\n\n\n\n[frontends]\n  [frontends.website]\n  backend = \nwebsite\n\n  [frontends.website.errors]\n    [frontends.website.errors.network]\n    status = [\n500-599\n]\n    backend = \nerror\n\n    query = \n/{status}.html\n\n  [frontends.website.routes.website]\n  rule = \nHost: website.mydomain.com\n\n\n[backends]\n  [backends.website]\n    [backends.website.servers.website]\n    url = \nhttps://1.2.3.4\n\n  [backends.error]\n    [backends.error.servers.error]\n    url = \nhttp://2.3.4.5\n\n\n\n\n\nIn the above example, the error page rendered was based on the status code.\nInstead, the query parameter can also be set to some generic error page like so: \nquery = \"/500s.html\"\n\n\nNow the \n500s.html\n error page is returned for the configured code range.\nThe configured status code ranges are inclusive; that is, in the above example, the \n500s.html\n page will be returned for status codes \n500\n through, and including, \n599\n.\n\n\nCustom error pages are easiest to implement using the file provider.\nFor dynamic providers, the corresponding template file needs to be customized accordingly and referenced in the Traefik configuration.\n\n\nRetry Configuration\n\n\n# Enable retry sending request if network error\n[retry]\n\n# Number of attempts\n#\n# Optional\n# Default: (number servers in backend) -1\n#\n# attempts = 3\n\n\n\n\nHealth Check Configuration\n\n\n# Enable custom health check options.\n[healthcheck]\n\n# Set the default health check interval.\n#\n# Optional\n# Default: \n30s\n\n#\n# interval = \n30s\n\n\n\n\n\n\n\ninterval\n set the default health check interval.\n\nWill only be effective if health check paths are defined.\n\nGiven provider-specific support, the value may be overridden on a per-backend basis.\n\nCan be provided in a format supported by \ntime.ParseDuration\n or as raw values (digits).\n\nIf no units are provided, the value is parsed assuming seconds.\n\n\n\n\nTimeouts\n\n\nResponding Timeouts\n\n\nrespondingTimeouts\n are timeouts for incoming requests to the Traefik instance.\n\n\n[respondingTimeouts]\n\n# readTimeout is the maximum duration for reading the entire request, including the body.\n#\n# Optional\n# Default: \n0s\n\n#\n# readTimeout = \n5s\n\n\n# writeTimeout is the maximum duration before timing out writes of the response.\n#\n# Optional\n# Default: \n0s\n\n#\n# writeTimeout = \n5s\n\n\n# idleTimeout is the maximum duration an idle (keep-alive) connection will remain idle before closing itself.\n#\n# Optional\n# Default: \n180s\n\n#\n# idleTimeout = \n360s\n\n\n\n\n\n\n\n\n\nreadTimeout\n is the maximum duration for reading the entire request, including the body.\n\nIf zero, no timeout exists.\n\nCan be provided in a format supported by \ntime.ParseDuration\n or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.\n\n\n\n\n\n\nwriteTimeout\n is the maximum duration before timing out writes of the response.\n\nIt covers the time from the end of the request header read to the end of the response write.\nIf zero, no timeout exists.\n\nCan be provided in a format supported by \ntime.ParseDuration\n or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.\n\n\n\n\n\n\nidleTimeout\n is the maximum duration an idle (keep-alive) connection will remain idle before closing itself.\n\nIf zero, no timeout exists.\n\nCan be provided in a format supported by \ntime.ParseDuration\n or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.\n\n\n\n\n\n\nForwarding Timeouts\n\n\nforwardingTimeouts\n are timeouts for requests forwarded to the backend servers.\n\n\n[forwardingTimeouts]\n\n# dialTimeout is the amount of time to wait until a connection to a backend server can be established.\n#\n# Optional\n# Default: \n30s\n\n#\n# dialTimeout = \n30s\n\n\n# responseHeaderTimeout is the amount of time to wait for a server's response headers after fully writing the request (including its body, if any).\n#\n# Optional\n# Default: \n0s\n\n#\n# responseHeaderTimeout = \n0s\n\n\n\n\n\n\n\n\n\ndialTimeout\n is the amount of time to wait until a connection to a backend server can be established.\n\nIf zero, no timeout exists.\n\nCan be provided in a format supported by \ntime.ParseDuration\n or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.\n\n\n\n\n\n\nresponseHeaderTimeout\n is the amount of time to wait for a server's response headers after fully writing the request (including its body, if any).\n\nIf zero, no timeout exists.\n\nCan be provided in a format supported by \ntime.ParseDuration\n or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.\n\n\n\n\n\n\nIdle Timeout (deprecated)\n\n\nUse \nrespondingTimeouts\n instead of \nIdleTimeout\n.\nIn the case both settings are configured, the deprecated option will be overwritten.\n\n\nIdleTimeout\n is the maximum amount of time an idle (keep-alive) connection will remain idle before closing itself.\nThis is set to enforce closing of stale client connections.\n\n\nCan be provided in a format supported by \ntime.ParseDuration\n or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.\n\n\n# IdleTimeout\n#\n# DEPRECATED - see [respondingTimeouts] section.\n#\n# Optional\n# Default: \n180s\n\n#\nIdleTimeout = \n360s\n\n\n\n\n\nOverride Default Configuration Template\n\n\n\n\nWarning\n\n\nFor advanced users only.\n\n\n\n\nSupported by all backends except: File backend, Web backend and DynamoDB backend.\n\n\n[backend_name]\n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n# Default: \n\n#\nfilename = \ncustom_config_template.tpml\n\n\n# Enable debug logging of generated configuration template.\n#\n# Optional\n# Default: false\n#\ndebugLogGeneratedTemplate = true\n\n\n\n\nExample:\n\n\n[marathon]\nfilename = \nmy_custom_config_template.tpml\n\n\n\n\n\nThe template files can be written using functions provided by:\n\n\n\n\ngo template\n\n\nsprig library\n\n\n\n\nExample:\n\n\n[backends]\n  [backends.backend1]\n  url = \nhttp://firstserver\n\n  [backends.backend2]\n  url = \nhttp://secondserver\n\n\n{{$frontends := dict \nfrontend1\n \nbackend1\n \nfrontend2\n \nbackend2\n}}\n[frontends]\n{{range $frontend, $backend := $frontends}}\n  [frontends.{{$frontend}}]\n  backend = \n{{$backend}}\n\n{{end}}", 
            "title": "Commons"
        }, 
        {
            "location": "/configuration/commons/#global-configuration", 
            "text": "", 
            "title": "Global Configuration"
        }, 
        {
            "location": "/configuration/commons/#main-section", 
            "text": "# Duration to give active requests a chance to finish before Traefik stops.\n#\n# Optional\n# Default:  10s \n#\n# graceTimeOut =  10s \n\n# Enable debug mode.\n#\n# Optional\n# Default: false\n#\n# debug = true\n\n# Periodically check if a new version has been released.\n#\n# Optional\n# Default: true\n#\n# checkNewVersion = false\n\n# Backends throttle duration.\n#\n# Optional\n# Default:  2s \n#\n# ProvidersThrottleDuration =  2s \n\n# Controls the maximum idle (keep-alive) connections to keep per-host.\n#\n# Optional\n# Default: 200\n#\n# MaxIdleConnsPerHost = 200\n\n# If set to true invalid SSL certificates are accepted for backends.\n# This disables detection of man-in-the-middle attacks so should only be used on secure backend networks.\n#\n# Optional\n# Default: false\n#\n# InsecureSkipVerify = true\n\n# Register Certificates in the RootCA.\n#\n# Optional\n# Default: []\n#\n# RootCAs = [  /mycert.cert  ]\n\n# Entrypoints to be used by frontends that do not specify any entrypoint.\n# Each frontend can specify its own entrypoints.\n#\n# Optional\n# Default: [ http ]\n#\n# defaultEntryPoints = [ http ,  https ]    graceTimeOut : Duration to give active requests a chance to finish before Traefik stops. \nCan be provided in a format supported by  time.ParseDuration  or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.  Note:  in this time frame no new requests are accepted.    ProvidersThrottleDuration : Backends throttle duration: minimum duration in seconds between 2 events from providers before applying a new configuration.\nIt avoids unnecessary reloads if multiples events are sent in a short amount of time. \nCan be provided in a format supported by  time.ParseDuration  or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.    MaxIdleConnsPerHost : Controls the maximum idle (keep-alive) connections to keep per-host. \nIf zero,  DefaultMaxIdleConnsPerHost  from the Go standard library net/http module is used.\nIf you encounter 'too many open files' errors, you can either increase this value or change the  ulimit .    InsecureSkipVerify  : If set to true invalid SSL certificates are accepted for backends.  Note:  This disables detection of man-in-the-middle attacks so should only be used on secure backend networks.    RootCAs : Register Certificates in the RootCA. This certificates will be use for backends calls.  Note  You can use file path or cert content directly    defaultEntryPoints : Entrypoints to be used by frontends that do not specify any entrypoint. \nEach frontend can specify its own entrypoints.", 
            "title": "Main Section"
        }, 
        {
            "location": "/configuration/commons/#constraints", 
            "text": "In a micro-service architecture, with a central service discovery, setting constraints limits Tr\u00e6fik scope to a smaller number of routes.  Tr\u00e6fik filters services according to service attributes/tags set in your configuration backends.  Supported filters:   tag", 
            "title": "Constraints"
        }, 
        {
            "location": "/configuration/commons/#simple", 
            "text": "# Simple matching constraint\nconstraints = [ tag==api ]\n\n# Simple mismatching constraint\nconstraints = [ tag!=api ]\n\n# Globbing\nconstraints = [ tag==us-* ]", 
            "title": "Simple"
        }, 
        {
            "location": "/configuration/commons/#multiple", 
            "text": "# Multiple constraints\n#   -  tag==  must match with at least one tag\n#   -  tag!=  must match with none of tags\nconstraints = [ tag!=us-* ,  tag!=asia-* ]", 
            "title": "Multiple"
        }, 
        {
            "location": "/configuration/commons/#backend-specific", 
            "text": "Supported backends:   Docker  Consul K/V  BoltDB  Zookeeper  Etcd  Consul Catalog  Rancher  Marathon  Kubernetes (using a provider-specific mechanism based on label selectors)   # Backend-specific constraint\n[consulCatalog]\n# ...\nconstraints = [ tag==api ]\n\n# Backend-specific constraint\n[marathon]\n# ...\nconstraints = [ tag==api ,  tag!=v*-beta ]", 
            "title": "Backend-specific"
        }, 
        {
            "location": "/configuration/commons/#logs-definition", 
            "text": "", 
            "title": "Logs Definition"
        }, 
        {
            "location": "/configuration/commons/#traefik-logs", 
            "text": "# Traefik logs file\n# If not defined, logs to stdout\ntraefikLogsFile =  log/traefik.log \n\n# Log level\n#\n# Optional\n# Default:  ERROR \n#\n# Accepted values, in order of severity:  DEBUG ,  INFO ,  WARN ,  ERROR ,  FATAL ,  PANIC \n# Messages at and above the selected level will be logged.\n#\nlogLevel =  ERROR", 
            "title": "Traefik logs"
        }, 
        {
            "location": "/configuration/commons/#access-logs", 
            "text": "Access logs are written when  [accessLog]  is defined.\nBy default it will write to stdout and produce logs in the textual Common Log Format (CLF), extended with additional fields.  To enable access logs using the default settings just add the  [accessLog]  entry.  [accessLog]  To write the logs into a logfile specify the  filePath .  [accessLog]\nfilePath =  /path/to/access.log   To write JSON format logs, specify  json  as the format:  [accessLog]\nfilePath =  /path/to/access.log \nformat =  json   Deprecated way (before 1.4):  # Access logs file\n#\n# DEPRECATED - see [accessLog] lower down\n#\naccessLogsFile =  log/access.log", 
            "title": "Access Logs"
        }, 
        {
            "location": "/configuration/commons/#log-rotation", 
            "text": "Traefik will close and reopen its log files, assuming they're configured, on receipt of a USR1 signal.\nThis allows the logs to be rotated and processed by an external program, such as  logrotate .   Note  This does not work on Windows due to the lack of USR signals.", 
            "title": "Log Rotation"
        }, 
        {
            "location": "/configuration/commons/#custom-error-pages", 
            "text": "Custom error pages can be returned, in lieu of the default, according to frontend-configured ranges of HTTP Status codes.  In the example below, if a 503 status is returned from the frontend \"website\", the custom error page at http://2.3.4.5/503.html is returned with the actual status code set in the HTTP header.   Note  The  503.html  page itself is not hosted on Traefik, but some other infrastructure.   [frontends]\n  [frontends.website]\n  backend =  website \n  [frontends.website.errors]\n    [frontends.website.errors.network]\n    status = [ 500-599 ]\n    backend =  error \n    query =  /{status}.html \n  [frontends.website.routes.website]\n  rule =  Host: website.mydomain.com \n\n[backends]\n  [backends.website]\n    [backends.website.servers.website]\n    url =  https://1.2.3.4 \n  [backends.error]\n    [backends.error.servers.error]\n    url =  http://2.3.4.5   In the above example, the error page rendered was based on the status code.\nInstead, the query parameter can also be set to some generic error page like so:  query = \"/500s.html\"  Now the  500s.html  error page is returned for the configured code range.\nThe configured status code ranges are inclusive; that is, in the above example, the  500s.html  page will be returned for status codes  500  through, and including,  599 .  Custom error pages are easiest to implement using the file provider.\nFor dynamic providers, the corresponding template file needs to be customized accordingly and referenced in the Traefik configuration.", 
            "title": "Custom Error pages"
        }, 
        {
            "location": "/configuration/commons/#retry-configuration", 
            "text": "# Enable retry sending request if network error\n[retry]\n\n# Number of attempts\n#\n# Optional\n# Default: (number servers in backend) -1\n#\n# attempts = 3", 
            "title": "Retry Configuration"
        }, 
        {
            "location": "/configuration/commons/#health-check-configuration", 
            "text": "# Enable custom health check options.\n[healthcheck]\n\n# Set the default health check interval.\n#\n# Optional\n# Default:  30s \n#\n# interval =  30s    interval  set the default health check interval. \nWill only be effective if health check paths are defined. \nGiven provider-specific support, the value may be overridden on a per-backend basis. \nCan be provided in a format supported by  time.ParseDuration  or as raw values (digits). \nIf no units are provided, the value is parsed assuming seconds.", 
            "title": "Health Check Configuration"
        }, 
        {
            "location": "/configuration/commons/#timeouts", 
            "text": "", 
            "title": "Timeouts"
        }, 
        {
            "location": "/configuration/commons/#responding-timeouts", 
            "text": "respondingTimeouts  are timeouts for incoming requests to the Traefik instance.  [respondingTimeouts]\n\n# readTimeout is the maximum duration for reading the entire request, including the body.\n#\n# Optional\n# Default:  0s \n#\n# readTimeout =  5s \n\n# writeTimeout is the maximum duration before timing out writes of the response.\n#\n# Optional\n# Default:  0s \n#\n# writeTimeout =  5s \n\n# idleTimeout is the maximum duration an idle (keep-alive) connection will remain idle before closing itself.\n#\n# Optional\n# Default:  180s \n#\n# idleTimeout =  360s     readTimeout  is the maximum duration for reading the entire request, including the body. \nIf zero, no timeout exists. \nCan be provided in a format supported by  time.ParseDuration  or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.    writeTimeout  is the maximum duration before timing out writes of the response. \nIt covers the time from the end of the request header read to the end of the response write.\nIf zero, no timeout exists. \nCan be provided in a format supported by  time.ParseDuration  or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.    idleTimeout  is the maximum duration an idle (keep-alive) connection will remain idle before closing itself. \nIf zero, no timeout exists. \nCan be provided in a format supported by  time.ParseDuration  or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.", 
            "title": "Responding Timeouts"
        }, 
        {
            "location": "/configuration/commons/#forwarding-timeouts", 
            "text": "forwardingTimeouts  are timeouts for requests forwarded to the backend servers.  [forwardingTimeouts]\n\n# dialTimeout is the amount of time to wait until a connection to a backend server can be established.\n#\n# Optional\n# Default:  30s \n#\n# dialTimeout =  30s \n\n# responseHeaderTimeout is the amount of time to wait for a server's response headers after fully writing the request (including its body, if any).\n#\n# Optional\n# Default:  0s \n#\n# responseHeaderTimeout =  0s     dialTimeout  is the amount of time to wait until a connection to a backend server can be established. \nIf zero, no timeout exists. \nCan be provided in a format supported by  time.ParseDuration  or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.    responseHeaderTimeout  is the amount of time to wait for a server's response headers after fully writing the request (including its body, if any). \nIf zero, no timeout exists. \nCan be provided in a format supported by  time.ParseDuration  or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.", 
            "title": "Forwarding Timeouts"
        }, 
        {
            "location": "/configuration/commons/#idle-timeout-deprecated", 
            "text": "Use  respondingTimeouts  instead of  IdleTimeout .\nIn the case both settings are configured, the deprecated option will be overwritten.  IdleTimeout  is the maximum amount of time an idle (keep-alive) connection will remain idle before closing itself.\nThis is set to enforce closing of stale client connections.  Can be provided in a format supported by  time.ParseDuration  or as raw values (digits).\nIf no units are provided, the value is parsed assuming seconds.  # IdleTimeout\n#\n# DEPRECATED - see [respondingTimeouts] section.\n#\n# Optional\n# Default:  180s \n#\nIdleTimeout =  360s", 
            "title": "Idle Timeout (deprecated)"
        }, 
        {
            "location": "/configuration/commons/#override-default-configuration-template", 
            "text": "Warning  For advanced users only.   Supported by all backends except: File backend, Web backend and DynamoDB backend.  [backend_name]\n\n# Override default configuration template. For advanced users :)\n#\n# Optional\n# Default:  \n#\nfilename =  custom_config_template.tpml \n\n# Enable debug logging of generated configuration template.\n#\n# Optional\n# Default: false\n#\ndebugLogGeneratedTemplate = true  Example:  [marathon]\nfilename =  my_custom_config_template.tpml   The template files can be written using functions provided by:   go template  sprig library   Example:  [backends]\n  [backends.backend1]\n  url =  http://firstserver \n  [backends.backend2]\n  url =  http://secondserver \n\n{{$frontends := dict  frontend1   backend1   frontend2   backend2 }}\n[frontends]\n{{range $frontend, $backend := $frontends}}\n  [frontends.{{$frontend}}]\n  backend =  {{$backend}} \n{{end}}", 
            "title": "Override Default Configuration Template"
        }, 
        {
            "location": "/configuration/entrypoints/", 
            "text": "Entry Points Definition\n\n\n# Entrypoints definition\n#\n# Default:\n# [entryPoints]\n#   [entryPoints.http]\n#   address = \n:80\n\n#\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n\n\n\n\nRedirect HTTP to HTTPS\n\n\nTo redirect an http entrypoint to an https entrypoint (with SNI support).\n\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n    [entryPoints.http.redirect]\n    entryPoint = \nhttps\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \nintegration/fixtures/https/snitest.com.cert\n\n      KeyFile = \nintegration/fixtures/https/snitest.com.key\n\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \nintegration/fixtures/https/snitest.org.cert\n\n      KeyFile = \nintegration/fixtures/https/snitest.org.key\n\n\n\n\n\nRewriting URL\n\n\nTo redirect an entrypoint rewriting the URL.\n\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n    [entryPoints.http.redirect]\n    regex = \n^http://localhost/(.*)\n\n    replacement = \nhttp://mydomain/$1\n\n\n\n\n\nTLS Mutual Authentication\n\n\nOnly accept clients that present a certificate signed by a specified Certificate Authority (CA).\n\nClientCAFiles\n can be configured with multiple \nCA:s\n in the same file or use multiple files containing one or several \nCA:s\n.\nThe \nCA:s\n has to be in PEM format.\n\n\nAll clients will be required to present a valid cert.\nThe requirement will apply to all server certs in the entrypoint.\n\n\nIn the example below both \nsnitest.com\n and \nsnitest.org\n will require client certs\n\n\n[entryPoints]\n  [entryPoints.https]\n  address = \n:443\n\n  [entryPoints.https.tls]\n  ClientCAFiles = [\ntests/clientca1.crt\n, \ntests/clientca2.crt\n]\n    [[entryPoints.https.tls.certificates]]\n    CertFile = \nintegration/fixtures/https/snitest.com.cert\n\n    KeyFile = \nintegration/fixtures/https/snitest.com.key\n\n    [[entryPoints.https.tls.certificates]]\n    CertFile = \nintegration/fixtures/https/snitest.org.cert\n\n    KeyFile = \nintegration/fixtures/https/snitest.org.key\n\n\n\n\n\nAuthentication\n\n\nBasic Authentication\n\n\nPasswords can be encoded in MD5, SHA1 and BCrypt: you can use \nhtpasswd\n to generate those ones.\n\n\nUsers can be specified directly in the toml file, or indirectly by referencing an external file;\n if both are provided, the two are merged, with external file contents having precedence.\n\n\n# To enable basic auth on an entrypoint with 2 user/pass: test:test and test2:test2\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.http.auth.basic]\n  users = [\ntest:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/\n, \ntest2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0\n]\n  usersFile = \n/path/to/.htpasswd\n\n\n\n\n\nDigest Authentication\n\n\nYou can use \nhtdigest\n to generate those ones.\n\n\nUsers can be specified directly in the toml file, or indirectly by referencing an external file;\n if both are provided, the two are merged, with external file contents having precedence\n\n\n# To enable digest auth on an entrypoint with 2 user/realm/pass: test:traefik:test and test2:traefik:test2\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.http.auth.basic]\n  users = [\ntest:traefik:a2688e031edb4be6a3797f3882655c05 \n, \ntest2:traefik:518845800f9e2bfb1f1f740ec24f074e\n]\n  usersFile = \n/path/to/.htdigest\n\n\n\n\n\nForward Authentication\n\n\nThis configuration will first forward the request to \nhttp://authserver.com/auth\n.\n\n\nIf the response code is 2XX, access is granted and the original request is performed.\nOtherwise, the response from the auth server is returned.\n\n\n[entryPoints]\n  [entryPoints.http]\n    # ...\n    # To enable forward auth on an entrypoint\n    [entryPoints.http.auth.forward]\n    address = \nhttps://authserver.com/auth\n\n\n    # Trust existing X-Forwarded-* headers.\n    # Useful with another reverse proxy in front of Traefik.\n    #\n    # Optional\n    # Default: false\n    #\n    trustForwardHeader = true\n\n    # Enable forward auth TLS connection.\n    #\n    # Optional\n    #\n    [entryPoints.http.auth.forward.tls]\n    cert = \nauthserver.crt\n\n    key = \nauthserver.key\n\n\n\n\n\nSpecify Minimum TLS Version\n\n\nTo specify an https entry point with a minimum TLS version, and specifying an array of cipher suites (from crypto/tls).\n\n\n[entryPoints]\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n    minVersion = \nVersionTLS12\n\n    cipherSuites = [\nTLS_RSA_WITH_AES_256_GCM_SHA384\n]\n      [[entryPoints.https.tls.certificates]]\n      certFile = \nintegration/fixtures/https/snitest.com.cert\n\n      keyFile = \nintegration/fixtures/https/snitest.com.key\n\n      [[entryPoints.https.tls.certificates]]\n      certFile = \nintegration/fixtures/https/snitest.org.cert\n\n      keyFile = \nintegration/fixtures/https/snitest.org.key\n\n\n\n\n\nCompression\n\n\nTo enable compression support using gzip format.\n\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  compress = true\n\n\n\n\nResponses are compressed when:\n\n\n\n\nThe response body is larger than \n512\n bytes\n\n\nAnd the \nAccept-Encoding\n request header contains \ngzip\n\n\nAnd the response is not already compressed, i.e. the \nContent-Encoding\n response header is not already set.\n\n\n\n\nWhitelisting\n\n\nTo enable IP whitelisting at the entrypoint level.\n\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  whiteListSourceRange = [\n127.0.0.1/32\n, \n192.168.1.7\n]\n\n\n\n\nProxyProtocol\n\n\nTo enable \nProxyProtocol\n support.\nOnly IPs in \ntrustedIPs\n will lead to remote client address replacement: you should declare your load-balancer IP or CIDR range here (in testing environment, you can trust everyone using \ninsecure = true\n).\n\n\n\n\nDanger\n\n\nWhen queuing Tr\u00e6fik behind another load-balancer, be sure to carefully configure Proxy Protocol on both sides.\nOtherwise, it could introduce a security risk in your system by forging requests. \n\n\n\n\n[entryPoints]\n  [entryPoints.http]\n    address = \n:80\n\n\n    # Enable ProxyProtocol\n    [entryPoints.http.proxyProtocol]\n      # List of trusted IPs\n      #\n      # Required\n      # Default: []\n      #\n      trustedIPs = [\n127.0.0.1/32\n, \n192.168.1.7\n]\n\n      # Insecure mode FOR TESTING ENVIRONNEMENT ONLY\n      #\n      # Optional\n      # Default: false\n      #\n      # insecure = true\n\n\n\n\nForwarded Header\n\n\nOnly IPs in \ntrustedIPs\n will be authorized to trust the client forwarded headers (\nX-Forwarded-*\n).\n\n\n[entryPoints]\n  [entryPoints.http]\n    address = \n:80\n\n\n    # Enable Forwarded Headers\n    [entryPoints.http.forwardedHeaders]\n      # List of trusted IPs\n      #\n      # Required\n      # Default: []\n      #\n      trustedIPs = [\n127.0.0.1/32\n, \n192.168.1.7\n]", 
            "title": "EntryPoints"
        }, 
        {
            "location": "/configuration/entrypoints/#entry-points-definition", 
            "text": "# Entrypoints definition\n#\n# Default:\n# [entryPoints]\n#   [entryPoints.http]\n#   address =  :80 \n#\n[entryPoints]\n  [entryPoints.http]\n  address =  :80", 
            "title": "Entry Points Definition"
        }, 
        {
            "location": "/configuration/entrypoints/#redirect-http-to-https", 
            "text": "To redirect an http entrypoint to an https entrypoint (with SNI support).  [entryPoints]\n  [entryPoints.http]\n  address =  :80 \n    [entryPoints.http.redirect]\n    entryPoint =  https \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile =  integration/fixtures/https/snitest.com.cert \n      KeyFile =  integration/fixtures/https/snitest.com.key \n      [[entryPoints.https.tls.certificates]]\n      CertFile =  integration/fixtures/https/snitest.org.cert \n      KeyFile =  integration/fixtures/https/snitest.org.key", 
            "title": "Redirect HTTP to HTTPS"
        }, 
        {
            "location": "/configuration/entrypoints/#rewriting-url", 
            "text": "To redirect an entrypoint rewriting the URL.  [entryPoints]\n  [entryPoints.http]\n  address =  :80 \n    [entryPoints.http.redirect]\n    regex =  ^http://localhost/(.*) \n    replacement =  http://mydomain/$1", 
            "title": "Rewriting URL"
        }, 
        {
            "location": "/configuration/entrypoints/#tls-mutual-authentication", 
            "text": "Only accept clients that present a certificate signed by a specified Certificate Authority (CA). ClientCAFiles  can be configured with multiple  CA:s  in the same file or use multiple files containing one or several  CA:s .\nThe  CA:s  has to be in PEM format.  All clients will be required to present a valid cert.\nThe requirement will apply to all server certs in the entrypoint.  In the example below both  snitest.com  and  snitest.org  will require client certs  [entryPoints]\n  [entryPoints.https]\n  address =  :443 \n  [entryPoints.https.tls]\n  ClientCAFiles = [ tests/clientca1.crt ,  tests/clientca2.crt ]\n    [[entryPoints.https.tls.certificates]]\n    CertFile =  integration/fixtures/https/snitest.com.cert \n    KeyFile =  integration/fixtures/https/snitest.com.key \n    [[entryPoints.https.tls.certificates]]\n    CertFile =  integration/fixtures/https/snitest.org.cert \n    KeyFile =  integration/fixtures/https/snitest.org.key", 
            "title": "TLS Mutual Authentication"
        }, 
        {
            "location": "/configuration/entrypoints/#authentication", 
            "text": "", 
            "title": "Authentication"
        }, 
        {
            "location": "/configuration/entrypoints/#basic-authentication", 
            "text": "Passwords can be encoded in MD5, SHA1 and BCrypt: you can use  htpasswd  to generate those ones.  Users can be specified directly in the toml file, or indirectly by referencing an external file;\n if both are provided, the two are merged, with external file contents having precedence.  # To enable basic auth on an entrypoint with 2 user/pass: test:test and test2:test2\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.http.auth.basic]\n  users = [ test:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/ ,  test2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0 ]\n  usersFile =  /path/to/.htpasswd", 
            "title": "Basic Authentication"
        }, 
        {
            "location": "/configuration/entrypoints/#digest-authentication", 
            "text": "You can use  htdigest  to generate those ones.  Users can be specified directly in the toml file, or indirectly by referencing an external file;\n if both are provided, the two are merged, with external file contents having precedence  # To enable digest auth on an entrypoint with 2 user/realm/pass: test:traefik:test and test2:traefik:test2\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.http.auth.basic]\n  users = [ test:traefik:a2688e031edb4be6a3797f3882655c05  ,  test2:traefik:518845800f9e2bfb1f1f740ec24f074e ]\n  usersFile =  /path/to/.htdigest", 
            "title": "Digest Authentication"
        }, 
        {
            "location": "/configuration/entrypoints/#forward-authentication", 
            "text": "This configuration will first forward the request to  http://authserver.com/auth .  If the response code is 2XX, access is granted and the original request is performed.\nOtherwise, the response from the auth server is returned.  [entryPoints]\n  [entryPoints.http]\n    # ...\n    # To enable forward auth on an entrypoint\n    [entryPoints.http.auth.forward]\n    address =  https://authserver.com/auth \n\n    # Trust existing X-Forwarded-* headers.\n    # Useful with another reverse proxy in front of Traefik.\n    #\n    # Optional\n    # Default: false\n    #\n    trustForwardHeader = true\n\n    # Enable forward auth TLS connection.\n    #\n    # Optional\n    #\n    [entryPoints.http.auth.forward.tls]\n    cert =  authserver.crt \n    key =  authserver.key", 
            "title": "Forward Authentication"
        }, 
        {
            "location": "/configuration/entrypoints/#specify-minimum-tls-version", 
            "text": "To specify an https entry point with a minimum TLS version, and specifying an array of cipher suites (from crypto/tls).  [entryPoints]\n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n    minVersion =  VersionTLS12 \n    cipherSuites = [ TLS_RSA_WITH_AES_256_GCM_SHA384 ]\n      [[entryPoints.https.tls.certificates]]\n      certFile =  integration/fixtures/https/snitest.com.cert \n      keyFile =  integration/fixtures/https/snitest.com.key \n      [[entryPoints.https.tls.certificates]]\n      certFile =  integration/fixtures/https/snitest.org.cert \n      keyFile =  integration/fixtures/https/snitest.org.key", 
            "title": "Specify Minimum TLS Version"
        }, 
        {
            "location": "/configuration/entrypoints/#compression", 
            "text": "To enable compression support using gzip format.  [entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  compress = true  Responses are compressed when:   The response body is larger than  512  bytes  And the  Accept-Encoding  request header contains  gzip  And the response is not already compressed, i.e. the  Content-Encoding  response header is not already set.", 
            "title": "Compression"
        }, 
        {
            "location": "/configuration/entrypoints/#whitelisting", 
            "text": "To enable IP whitelisting at the entrypoint level.  [entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  whiteListSourceRange = [ 127.0.0.1/32 ,  192.168.1.7 ]", 
            "title": "Whitelisting"
        }, 
        {
            "location": "/configuration/entrypoints/#proxyprotocol", 
            "text": "To enable  ProxyProtocol  support.\nOnly IPs in  trustedIPs  will lead to remote client address replacement: you should declare your load-balancer IP or CIDR range here (in testing environment, you can trust everyone using  insecure = true ).   Danger  When queuing Tr\u00e6fik behind another load-balancer, be sure to carefully configure Proxy Protocol on both sides.\nOtherwise, it could introduce a security risk in your system by forging requests.    [entryPoints]\n  [entryPoints.http]\n    address =  :80 \n\n    # Enable ProxyProtocol\n    [entryPoints.http.proxyProtocol]\n      # List of trusted IPs\n      #\n      # Required\n      # Default: []\n      #\n      trustedIPs = [ 127.0.0.1/32 ,  192.168.1.7 ]\n\n      # Insecure mode FOR TESTING ENVIRONNEMENT ONLY\n      #\n      # Optional\n      # Default: false\n      #\n      # insecure = true", 
            "title": "ProxyProtocol"
        }, 
        {
            "location": "/configuration/entrypoints/#forwarded-header", 
            "text": "Only IPs in  trustedIPs  will be authorized to trust the client forwarded headers ( X-Forwarded-* ).  [entryPoints]\n  [entryPoints.http]\n    address =  :80 \n\n    # Enable Forwarded Headers\n    [entryPoints.http.forwardedHeaders]\n      # List of trusted IPs\n      #\n      # Required\n      # Default: []\n      #\n      trustedIPs = [ 127.0.0.1/32 ,  192.168.1.7 ]", 
            "title": "Forwarded Header"
        }, 
        {
            "location": "/configuration/acme/", 
            "text": "ACME (Let's Encrypt) configuration\n\n\nSee also \nLet's Encrypt examples\n and \nDocker \n Let's Encrypt user guide\n.\n\n\nConfiguration\n\n\n# Sample entrypoint configuration when using ACME.\n[entryPoints]\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n\n# Enable ACME (Let's Encrypt): automatic SSL.\n[acme]\n\n# Email address used for registration.\n#\n# Required\n#\nemail = \ntest@traefik.io\n\n\n# File or key used for certificates storage.\n#\n# Required\n#\nstorage = \nacme.json\n\n# or `storage = \ntraefik/acme/account\n` if using KV store.\n\n# Entrypoint to proxy acme challenge/apply certificates to.\n# WARNING, must point to an entrypoint on port 443\n#\n# Required\n#\nentryPoint = \nhttps\n\n\n# Use a DNS based acme challenge rather than external HTTPS access\n#\n#\n# Optional\n#\n# dnsProvider = \ndigitalocean\n\n\n# By default, the dnsProvider will verify the TXT DNS challenge record before letting ACME verify.\n# If delayDontCheckDNS is greater than zero, avoid this \n instead just wait so many seconds.\n# Useful if internal networks block external DNS queries.\n#\n# Optional\n#\n# delayDontCheckDNS = 0\n\n# If true, display debug log messages from the acme client library.\n#\n# Optional\n#\n# acmeLogging = true\n\n# Enable on demand certificate.\n#\n# Optional\n#\n# onDemand = true\n\n# Enable certificate generation on frontends Host rules.\n#\n# Optional\n#\n# onHostRule = true\n\n# CA server to use.\n# - Uncomment the line to run on the staging let's encrypt server.\n# - Leave comment to go to prod.\n#\n# Optional\n#\n# caServer = \nhttps://acme-staging.api.letsencrypt.org/directory\n\n\n# Domains list.\n#\n# [[acme.domains]]\n# main = \nlocal1.com\n\n# sans = [\ntest1.local1.com\n, \ntest2.local1.com\n]\n# [[acme.domains]]\n# main = \nlocal2.com\n\n# sans = [\ntest1.local2.com\n, \ntest2.local2.com\n]\n# [[acme.domains]]\n# main = \nlocal3.com\n\n# [[acme.domains]]\n# main = \nlocal4.com\n\n\n\n\n\nstorage\n\n\n[acme]\n# ...\nstorage = \nacme.json\n\n# ...\n\n\n\n\nFile or key used for certificates storage.\n\n\nWARNING\n If you use Traefik in Docker, you have 2 options:\n\n\n\n\ncreate a file on your host and mount it as a volume:\n\n\n\n\nstorage = \nacme.json\n\n\n\n\n\ndocker run -v \n/my/host/acme.json:acme.json\n traefik\n\n\n\n\n\n\nmount the folder containing the file as a volume\n\n\n\n\nstorage = \n/etc/traefik/acme/acme.json\n\n\n\n\n\ndocker run -v \n/my/host/acme:/etc/traefik/acme\n traefik\n\n\n\n\ndnsProvider\n\n\n[acme]\n# ...\ndnsProvider = \ndigitalocean\n\n# ...\n\n\n\n\nUse a DNS based acme challenge rather than external HTTPS access, e.g. for a firewalled server.\n\n\nSelect the provider that matches the DNS domain that will host the challenge TXT record, and provide environment variables with access keys to enable setting it:\n\n\n\n\n\n\n\n\nProvider\n\n\nConfiguration\n\n\n\n\n\n\n\n\n\n\nCloudflare\n\n\nCLOUDFLARE_EMAIL\n, \nCLOUDFLARE_API_KEY\n\n\n\n\n\n\nDigitalOcean\n\n\nDO_AUTH_TOKEN\n\n\n\n\n\n\nDNSimple\n\n\nDNSIMPLE_EMAIL\n, \nDNSIMPLE_OAUTH_TOKEN\n\n\n\n\n\n\nDNS Made Easy\n\n\nDNSMADEEASY_API_KEY\n, \nDNSMADEEASY_API_SECRET\n\n\n\n\n\n\nExoscale\n\n\nEXOSCALE_API_KEY\n, \nEXOSCALE_API_SECRET\n\n\n\n\n\n\nGandi\n\n\nGANDI_API_KEY\n\n\n\n\n\n\nLinode\n\n\nLINODE_API_KEY\n\n\n\n\n\n\nmanual\n\n\nnone, but run Traefik interactively \n turn on \nacmeLogging\n to see instructions \n press \nEnter\n.\n\n\n\n\n\n\nNamecheap\n\n\nNAMECHEAP_API_USER\n, \nNAMECHEAP_API_KEY\n\n\n\n\n\n\nRFC2136\n\n\nRFC2136_TSIG_KEY\n, \nRFC2136_TSIG_SECRET\n, \nRFC2136_TSIG_ALGORITHM\n, \nRFC2136_NAMESERVER\n\n\n\n\n\n\nRoute 53\n\n\nAWS_ACCESS_KEY_ID\n, \nAWS_SECRET_ACCESS_KEY\n, \nAWS_REGION\n, or configured user/instance IAM profile.\n\n\n\n\n\n\ndyn\n\n\nDYN_CUSTOMER_NAME\n, \nDYN_USER_NAME\n, \nDYN_PASSWORD\n\n\n\n\n\n\nVULTR\n\n\nVULTR_API_KEY\n\n\n\n\n\n\nOVH\n\n\nOVH_ENDPOINT\n, \nOVH_APPLICATION_KEY\n, \nOVH_APPLICATION_SECRET\n, \nOVH_CONSUMER_KEY\n\n\n\n\n\n\npdns\n\n\nPDNS_API_KEY\n, \nPDNS_API_URL\n\n\n\n\n\n\n\n\ndelayDontCheckDNS\n\n\n[acme]\n# ...\ndelayDontCheckDNS = 0\n# ...\n\n\n\n\nBy default, the dnsProvider will verify the TXT DNS challenge record before letting ACME verify.\n\nIf \ndelayDontCheckDNS\n is greater than zero, avoid this \n instead just wait so many seconds.\n\n\nUseful if internal networks block external DNS queries.\n\n\nonDemand\n\n\n[acme]\n# ...\nonDemand = true\n# ...\n\n\n\n\nEnable on demand certificate.\n\n\nThis will request a certificate from Let's Encrypt during the first TLS handshake for a hostname that does not yet have a certificate.\n\n\n\n\nWarning\n\n\nTLS handshakes will be slow when requesting a hostname certificate for the first time, this can lead to DoS attacks.\n\n\n\n\n\n\nWarning\n\n\nTake note that Let's Encrypt have \nrate limiting\n\n\n\n\nonHostRule\n\n\n[acme]\n# ...\nonHostRule = true\n# ...\n\n\n\n\nEnable certificate generation on frontends Host rules.\n\n\nThis will request a certificate from Let's Encrypt for each frontend with a Host rule.\n\n\nFor example, a rule \nHost:test1.traefik.io,test2.traefik.io\n will request a certificate with main domain \ntest1.traefik.io\n and SAN \ntest2.traefik.io\n.\n\n\ncaServer\n\n\n[acme]\n# ...\ncaServer = \nhttps://acme-staging.api.letsencrypt.org/directory\n\n# ...\n\n\n\n\nCA server to use.\n\n\n\n\nUncomment the line to run on the staging Let's Encrypt server.\n\n\nLeave comment to go to prod.\n\n\n\n\ndomains\n\n\n[acme]\n# ...\n[[acme.domains]]\nmain = \nlocal1.com\n\nsans = [\ntest1.local1.com\n, \ntest2.local1.com\n]\n[[acme.domains]]\nmain = \nlocal2.com\n\nsans = [\ntest1.local2.com\n, \ntest2.local2.com\n]\n[[acme.domains]]\nmain = \nlocal3.com\n\n[[acme.domains]]\nmain = \nlocal4.com\n\n# ...\n\n\n\n\nYou can provide SANs (alternative domains) to each main domain.\nAll domains must have A/AAAA records pointing to Traefik.\n\n\n\n\nWarning\n\n\nTake note that Let's Encrypt have \nrate limiting\n.\n\n\n\n\nEach domain \n SANs will lead to a certificate request.", 
            "title": "Let's Encrypt"
        }, 
        {
            "location": "/configuration/acme/#acme-lets-encrypt-configuration", 
            "text": "See also  Let's Encrypt examples  and  Docker   Let's Encrypt user guide .", 
            "title": "ACME (Let's Encrypt) configuration"
        }, 
        {
            "location": "/configuration/acme/#configuration", 
            "text": "# Sample entrypoint configuration when using ACME.\n[entryPoints]\n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n\n# Enable ACME (Let's Encrypt): automatic SSL.\n[acme]\n\n# Email address used for registration.\n#\n# Required\n#\nemail =  test@traefik.io \n\n# File or key used for certificates storage.\n#\n# Required\n#\nstorage =  acme.json \n# or `storage =  traefik/acme/account ` if using KV store.\n\n# Entrypoint to proxy acme challenge/apply certificates to.\n# WARNING, must point to an entrypoint on port 443\n#\n# Required\n#\nentryPoint =  https \n\n# Use a DNS based acme challenge rather than external HTTPS access\n#\n#\n# Optional\n#\n# dnsProvider =  digitalocean \n\n# By default, the dnsProvider will verify the TXT DNS challenge record before letting ACME verify.\n# If delayDontCheckDNS is greater than zero, avoid this   instead just wait so many seconds.\n# Useful if internal networks block external DNS queries.\n#\n# Optional\n#\n# delayDontCheckDNS = 0\n\n# If true, display debug log messages from the acme client library.\n#\n# Optional\n#\n# acmeLogging = true\n\n# Enable on demand certificate.\n#\n# Optional\n#\n# onDemand = true\n\n# Enable certificate generation on frontends Host rules.\n#\n# Optional\n#\n# onHostRule = true\n\n# CA server to use.\n# - Uncomment the line to run on the staging let's encrypt server.\n# - Leave comment to go to prod.\n#\n# Optional\n#\n# caServer =  https://acme-staging.api.letsencrypt.org/directory \n\n# Domains list.\n#\n# [[acme.domains]]\n# main =  local1.com \n# sans = [ test1.local1.com ,  test2.local1.com ]\n# [[acme.domains]]\n# main =  local2.com \n# sans = [ test1.local2.com ,  test2.local2.com ]\n# [[acme.domains]]\n# main =  local3.com \n# [[acme.domains]]\n# main =  local4.com", 
            "title": "Configuration"
        }, 
        {
            "location": "/configuration/acme/#storage", 
            "text": "[acme]\n# ...\nstorage =  acme.json \n# ...  File or key used for certificates storage.  WARNING  If you use Traefik in Docker, you have 2 options:   create a file on your host and mount it as a volume:   storage =  acme.json   docker run -v  /my/host/acme.json:acme.json  traefik   mount the folder containing the file as a volume   storage =  /etc/traefik/acme/acme.json   docker run -v  /my/host/acme:/etc/traefik/acme  traefik", 
            "title": "storage"
        }, 
        {
            "location": "/configuration/acme/#dnsprovider", 
            "text": "[acme]\n# ...\ndnsProvider =  digitalocean \n# ...  Use a DNS based acme challenge rather than external HTTPS access, e.g. for a firewalled server.  Select the provider that matches the DNS domain that will host the challenge TXT record, and provide environment variables with access keys to enable setting it:     Provider  Configuration      Cloudflare  CLOUDFLARE_EMAIL ,  CLOUDFLARE_API_KEY    DigitalOcean  DO_AUTH_TOKEN    DNSimple  DNSIMPLE_EMAIL ,  DNSIMPLE_OAUTH_TOKEN    DNS Made Easy  DNSMADEEASY_API_KEY ,  DNSMADEEASY_API_SECRET    Exoscale  EXOSCALE_API_KEY ,  EXOSCALE_API_SECRET    Gandi  GANDI_API_KEY    Linode  LINODE_API_KEY    manual  none, but run Traefik interactively   turn on  acmeLogging  to see instructions   press  Enter .    Namecheap  NAMECHEAP_API_USER ,  NAMECHEAP_API_KEY    RFC2136  RFC2136_TSIG_KEY ,  RFC2136_TSIG_SECRET ,  RFC2136_TSIG_ALGORITHM ,  RFC2136_NAMESERVER    Route 53  AWS_ACCESS_KEY_ID ,  AWS_SECRET_ACCESS_KEY ,  AWS_REGION , or configured user/instance IAM profile.    dyn  DYN_CUSTOMER_NAME ,  DYN_USER_NAME ,  DYN_PASSWORD    VULTR  VULTR_API_KEY    OVH  OVH_ENDPOINT ,  OVH_APPLICATION_KEY ,  OVH_APPLICATION_SECRET ,  OVH_CONSUMER_KEY    pdns  PDNS_API_KEY ,  PDNS_API_URL", 
            "title": "dnsProvider"
        }, 
        {
            "location": "/configuration/acme/#delaydontcheckdns", 
            "text": "[acme]\n# ...\ndelayDontCheckDNS = 0\n# ...  By default, the dnsProvider will verify the TXT DNS challenge record before letting ACME verify. \nIf  delayDontCheckDNS  is greater than zero, avoid this   instead just wait so many seconds.  Useful if internal networks block external DNS queries.", 
            "title": "delayDontCheckDNS"
        }, 
        {
            "location": "/configuration/acme/#ondemand", 
            "text": "[acme]\n# ...\nonDemand = true\n# ...  Enable on demand certificate.  This will request a certificate from Let's Encrypt during the first TLS handshake for a hostname that does not yet have a certificate.   Warning  TLS handshakes will be slow when requesting a hostname certificate for the first time, this can lead to DoS attacks.    Warning  Take note that Let's Encrypt have  rate limiting", 
            "title": "onDemand"
        }, 
        {
            "location": "/configuration/acme/#onhostrule", 
            "text": "[acme]\n# ...\nonHostRule = true\n# ...  Enable certificate generation on frontends Host rules.  This will request a certificate from Let's Encrypt for each frontend with a Host rule.  For example, a rule  Host:test1.traefik.io,test2.traefik.io  will request a certificate with main domain  test1.traefik.io  and SAN  test2.traefik.io .", 
            "title": "onHostRule"
        }, 
        {
            "location": "/configuration/acme/#caserver", 
            "text": "[acme]\n# ...\ncaServer =  https://acme-staging.api.letsencrypt.org/directory \n# ...  CA server to use.   Uncomment the line to run on the staging Let's Encrypt server.  Leave comment to go to prod.", 
            "title": "caServer"
        }, 
        {
            "location": "/configuration/acme/#domains", 
            "text": "[acme]\n# ...\n[[acme.domains]]\nmain =  local1.com \nsans = [ test1.local1.com ,  test2.local1.com ]\n[[acme.domains]]\nmain =  local2.com \nsans = [ test1.local2.com ,  test2.local2.com ]\n[[acme.domains]]\nmain =  local3.com \n[[acme.domains]]\nmain =  local4.com \n# ...  You can provide SANs (alternative domains) to each main domain.\nAll domains must have A/AAAA records pointing to Traefik.   Warning  Take note that Let's Encrypt have  rate limiting .   Each domain   SANs will lead to a certificate request.", 
            "title": "domains"
        }, 
        {
            "location": "/configuration/backends/web/", 
            "text": "Web Backend\n\n\nTr\u00e6fik can be configured:\n\n\n\n\nusing a RESTful api.\n\n\nto use a monitoring system (like Prometheus, DataDog or StatD, ...).\n\n\nto expose a Web Dashboard.\n\n\n\n\nConfiguration\n\n\n# Enable web backend.\n[web]\n\n# Web administration port.\n#\n# Required\n# Default: \n:8080\n\n#\naddress = \n:8080\n\n\n# SSL certificate and key used.\n#\n# Optional\n#\n# certFile = \ntraefik.crt\n\n# keyFile = \ntraefik.key\n\n\n# Set REST API to read-only mode.\n#\n# Optional\n# Default: false\n#\nreadOnly = true\n\n\n\n\nWeb UI\n\n\n\n\n\n\nAuthentication\n\n\n\n\nNote\n\n\nThe \n/ping\n path of the api is excluded from authentication (since 1.4).\n\n\n\n\nBasic Authentication\n\n\nPasswords can be encoded in MD5, SHA1 and BCrypt: you can use \nhtpasswd\n to generate those ones.\n\n\nUsers can be specified directly in the toml file, or indirectly by referencing an external file;\n if both are provided, the two are merged, with external file contents having precedence.\n\n\n[web]\n# ...\n\n# To enable basic auth on the webui with 2 user/pass: test:test and test2:test2\n[web.auth.basic]\nusers = [\ntest:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/\n, \ntest2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0\n]\nusersFile = \n/path/to/.htpasswd\n\n\n# ...\n\n\n\n\nDigest Authentication\n\n\nYou can use \nhtdigest\n to generate those ones.\n\n\nUsers can be specified directly in the toml file, or indirectly by referencing an external file;\n if both are provided, the two are merged, with external file contents having precedence\n\n\n[web]\n# ...\n\n# To enable digest auth on the webui with 2 user/realm/pass: test:traefik:test and test2:traefik:test2\n[web.auth.digest]\nusers = [\ntest:traefik:a2688e031edb4be6a3797f3882655c05 \n, \ntest2:traefik:518845800f9e2bfb1f1f740ec24f074e\n]\nusersFile = \n/path/to/.htdigest\n\n\n# ...\n\n\n\n\nMetrics\n\n\nYou can enable Traefik to export internal metrics to different monitoring systems.\n\n\nPrometheus\n\n\n[web]\n# ...\n\n# To enable Traefik to export internal metrics to Prometheus\n[web.metrics.prometheus]\n\n# Buckets for latency metrics\n#\n# Optional\n# Default: [0.1, 0.3, 1.2, 5]\nbuckets=[0.1,0.3,1.2,5.0]\n\n# ...\n\n\n\n\nDataDog\n\n\n[web]\n# ...\n\n# DataDog metrics exporter type\n[web.metrics.datadog]\n\n# DataDog's address.\n#\n# Required\n# Default: \nlocalhost:8125\n\n#\naddress = \nlocalhost:8125\n\n\n# DataDog push interval\n#\n# Optional\n# Default: \n10s\n\n#\npushinterval = \n10s\n\n\n# ...\n\n\n\n\nStatsD\n\n\n[web]\n# ...\n\n# StatsD metrics exporter type\n[web.metrics.statsd]\n\n# StatD's address.\n#\n# Required\n# Default: \nlocalhost:8125\n\n#\naddress = \nlocalhost:8125\n\n\n# StatD push interval\n#\n# Optional\n# Default: \n10s\n\n#\npushinterval = \n10s\n\n\n# ...\n\n\n\n\nStatistics\n\n\n[web]\n# ...\n\n# Enable more detailed statistics.\n[web.statistics]\n\n# Number of recent errors logged.\n#\n# Default: 10\n#\nrecentErrors = 10\n\n# ...\n\n\n\n\nAPI\n\n\n\n\n\n\n\n\nPath\n\n\nMethod\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n/\n\n\nGET\n\n\nProvides a simple HTML frontend of Tr\u00e6fik\n\n\n\n\n\n\n/ping\n\n\nGET\n, \nHEAD\n\n\nA simple endpoint to check for Tr\u00e6fik process liveness. Return a code \n200\n with the content: \nOK\n\n\n\n\n\n\n/health\n\n\nGET\n\n\njson health metrics\n\n\n\n\n\n\n/api\n\n\nGET\n\n\nConfiguration for all providers\n\n\n\n\n\n\n/api/providers\n\n\nGET\n\n\nProviders\n\n\n\n\n\n\n/api/providers/{provider}\n\n\nGET\n, \nPUT\n\n\nGet or update provider\n\n\n\n\n\n\n/api/providers/{provider}/backends\n\n\nGET\n\n\nList backends\n\n\n\n\n\n\n/api/providers/{provider}/backends/{backend}\n\n\nGET\n\n\nGet backend\n\n\n\n\n\n\n/api/providers/{provider}/backends/{backend}/servers\n\n\nGET\n\n\nList servers in backend\n\n\n\n\n\n\n/api/providers/{provider}/backends/{backend}/servers/{server}\n\n\nGET\n\n\nGet a server in a backend\n\n\n\n\n\n\n/api/providers/{provider}/frontends\n\n\nGET\n\n\nList frontends\n\n\n\n\n\n\n/api/providers/{provider}/frontends/{frontend}\n\n\nGET\n\n\nGet a frontend\n\n\n\n\n\n\n/api/providers/{provider}/frontends/{frontend}/routes\n\n\nGET\n\n\nList routes in a frontend\n\n\n\n\n\n\n/api/providers/{provider}/frontends/{frontend}/routes/{route}\n\n\nGET\n\n\nGet a route in a frontend\n\n\n\n\n\n\n/metrics\n\n\nGET\n\n\nExport internal metrics\n\n\n\n\n\n\n\n\nExample\n\n\nPing\n\n\ncurl -sv \nhttp://localhost:8080/ping\n\n\n\n\n\n*   Trying ::1...\n* Connected to localhost (::1) port 8080 (#0)\n\n GET /ping HTTP/1.1\n\n Host: localhost:8080\n\n User-Agent: curl/7.43.0\n\n Accept: */*\n\n\n\n HTTP/1.1 200 OK\n\n Date: Thu, 25 Aug 2016 01:35:36 GMT\n\n Content-Length: 2\n\n Content-Type: text/plain; charset=utf-8\n\n\n* Connection #0 to host localhost left intact\nOK\n\n\n\n\nHealth\n\n\ncurl -s \nhttp://localhost:8080/health\n | jq .\n\n\n\n\n{\n  // Tr\u00e6fik PID\n  \npid\n: 2458,\n  // Tr\u00e6fik server uptime (formated time)\n  \nuptime\n: \n39m6.885931127s\n,\n  //  Tr\u00e6fik server uptime in seconds\n  \nuptime_sec\n: 2346.885931127,\n  // current server date\n  \ntime\n: \n2015-10-07 18:32:24.362238909 +0200 CEST\n,\n  // current server date in seconds\n  \nunixtime\n: 1444235544,\n  // count HTTP response status code in realtime\n  \nstatus_code_count\n: {\n    \n502\n: 1\n  },\n  // count HTTP response status code since Tr\u00e6fik started\n  \ntotal_status_code_count\n: {\n    \n200\n: 7,\n    \n404\n: 21,\n    \n502\n: 13\n  },\n  // count HTTP response\n  \ncount\n: 1,\n  // count HTTP response\n  \ntotal_count\n: 41,\n  // sum of all response time (formated time)\n  \ntotal_response_time\n: \n35.456865605s\n,\n  // sum of all response time in seconds\n  \ntotal_response_time_sec\n: 35.456865605,\n  // average response time (formated time)\n  \naverage_response_time\n: \n864.8016ms\n,\n  // average response time in seconds\n  \naverage_response_time_sec\n: 0.8648016000000001,\n\n  // request statistics [requires --web.statistics to be set]\n  // ten most recent requests with 4xx and 5xx status codes\n  \nrecent_errors\n: [\n    {\n      // status code\n      \nstatus_code\n: 500,\n      // description of status code\n      \nstatus\n: \nInternal Server Error\n,\n      // request HTTP method\n      \nmethod\n: \nGET\n,\n      // request hostname\n      \nhost\n: \nlocalhost\n,\n      // request path\n      \npath\n: \n/path\n,\n      // RFC 3339 formatted date/time\n      \ntime\n: \n2016-10-21T16:59:15.418495872-07:00\n\n    }\n  ]\n}\n\n\n\n\nProvider configurations\n\n\ncurl -s \nhttp://localhost:8080/api\n | jq .\n\n\n\n\n{\n  \nfile\n: {\n    \nfrontends\n: {\n      \nfrontend2\n: {\n        \nroutes\n: {\n          \ntest_2\n: {\n            \nrule\n: \nPath:/test\n\n          }\n        },\n        \nbackend\n: \nbackend1\n\n      },\n      \nfrontend1\n: {\n        \nroutes\n: {\n          \ntest_1\n: {\n            \nrule\n: \nHost:test.localhost\n\n          }\n        },\n        \nbackend\n: \nbackend2\n\n      }\n    },\n    \nbackends\n: {\n      \nbackend2\n: {\n        \nloadBalancer\n: {\n          \nmethod\n: \ndrr\n\n        },\n        \nservers\n: {\n          \nserver2\n: {\n            \nweight\n: 2,\n            \nURL\n: \nhttp://172.17.0.5:80\n\n          },\n          \nserver1\n: {\n            \nweight\n: 1,\n            \nurl\n: \nhttp://172.17.0.4:80\n\n          }\n        }\n      },\n      \nbackend1\n: {\n        \nloadBalancer\n: {\n          \nmethod\n: \nwrr\n\n        },\n        \ncircuitBreaker\n: {\n          \nexpression\n: \nNetworkErrorRatio() \n 0.5\n\n        },\n        \nservers\n: {\n          \nserver2\n: {\n            \nweight\n: 1,\n            \nurl\n: \nhttp://172.17.0.3:80\n\n          },\n          \nserver1\n: {\n            \nweight\n: 10,\n            \nurl\n: \nhttp://172.17.0.2:80\n\n          }\n        }\n      }\n    }\n  }\n}", 
            "title": "Backend: Web"
        }, 
        {
            "location": "/configuration/backends/web/#web-backend", 
            "text": "Tr\u00e6fik can be configured:   using a RESTful api.  to use a monitoring system (like Prometheus, DataDog or StatD, ...).  to expose a Web Dashboard.", 
            "title": "Web Backend"
        }, 
        {
            "location": "/configuration/backends/web/#configuration", 
            "text": "# Enable web backend.\n[web]\n\n# Web administration port.\n#\n# Required\n# Default:  :8080 \n#\naddress =  :8080 \n\n# SSL certificate and key used.\n#\n# Optional\n#\n# certFile =  traefik.crt \n# keyFile =  traefik.key \n\n# Set REST API to read-only mode.\n#\n# Optional\n# Default: false\n#\nreadOnly = true", 
            "title": "Configuration"
        }, 
        {
            "location": "/configuration/backends/web/#web-ui", 
            "text": "", 
            "title": "Web UI"
        }, 
        {
            "location": "/configuration/backends/web/#authentication", 
            "text": "Note  The  /ping  path of the api is excluded from authentication (since 1.4).", 
            "title": "Authentication"
        }, 
        {
            "location": "/configuration/backends/web/#basic-authentication", 
            "text": "Passwords can be encoded in MD5, SHA1 and BCrypt: you can use  htpasswd  to generate those ones.  Users can be specified directly in the toml file, or indirectly by referencing an external file;\n if both are provided, the two are merged, with external file contents having precedence.  [web]\n# ...\n\n# To enable basic auth on the webui with 2 user/pass: test:test and test2:test2\n[web.auth.basic]\nusers = [ test:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/ ,  test2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0 ]\nusersFile =  /path/to/.htpasswd \n\n# ...", 
            "title": "Basic Authentication"
        }, 
        {
            "location": "/configuration/backends/web/#digest-authentication", 
            "text": "You can use  htdigest  to generate those ones.  Users can be specified directly in the toml file, or indirectly by referencing an external file;\n if both are provided, the two are merged, with external file contents having precedence  [web]\n# ...\n\n# To enable digest auth on the webui with 2 user/realm/pass: test:traefik:test and test2:traefik:test2\n[web.auth.digest]\nusers = [ test:traefik:a2688e031edb4be6a3797f3882655c05  ,  test2:traefik:518845800f9e2bfb1f1f740ec24f074e ]\nusersFile =  /path/to/.htdigest \n\n# ...", 
            "title": "Digest Authentication"
        }, 
        {
            "location": "/configuration/backends/web/#metrics", 
            "text": "You can enable Traefik to export internal metrics to different monitoring systems.", 
            "title": "Metrics"
        }, 
        {
            "location": "/configuration/backends/web/#prometheus", 
            "text": "[web]\n# ...\n\n# To enable Traefik to export internal metrics to Prometheus\n[web.metrics.prometheus]\n\n# Buckets for latency metrics\n#\n# Optional\n# Default: [0.1, 0.3, 1.2, 5]\nbuckets=[0.1,0.3,1.2,5.0]\n\n# ...", 
            "title": "Prometheus"
        }, 
        {
            "location": "/configuration/backends/web/#datadog", 
            "text": "[web]\n# ...\n\n# DataDog metrics exporter type\n[web.metrics.datadog]\n\n# DataDog's address.\n#\n# Required\n# Default:  localhost:8125 \n#\naddress =  localhost:8125 \n\n# DataDog push interval\n#\n# Optional\n# Default:  10s \n#\npushinterval =  10s \n\n# ...", 
            "title": "DataDog"
        }, 
        {
            "location": "/configuration/backends/web/#statsd", 
            "text": "[web]\n# ...\n\n# StatsD metrics exporter type\n[web.metrics.statsd]\n\n# StatD's address.\n#\n# Required\n# Default:  localhost:8125 \n#\naddress =  localhost:8125 \n\n# StatD push interval\n#\n# Optional\n# Default:  10s \n#\npushinterval =  10s \n\n# ...", 
            "title": "StatsD"
        }, 
        {
            "location": "/configuration/backends/web/#statistics", 
            "text": "[web]\n# ...\n\n# Enable more detailed statistics.\n[web.statistics]\n\n# Number of recent errors logged.\n#\n# Default: 10\n#\nrecentErrors = 10\n\n# ...", 
            "title": "Statistics"
        }, 
        {
            "location": "/configuration/backends/web/#api", 
            "text": "Path  Method  Description      /  GET  Provides a simple HTML frontend of Tr\u00e6fik    /ping  GET ,  HEAD  A simple endpoint to check for Tr\u00e6fik process liveness. Return a code  200  with the content:  OK    /health  GET  json health metrics    /api  GET  Configuration for all providers    /api/providers  GET  Providers    /api/providers/{provider}  GET ,  PUT  Get or update provider    /api/providers/{provider}/backends  GET  List backends    /api/providers/{provider}/backends/{backend}  GET  Get backend    /api/providers/{provider}/backends/{backend}/servers  GET  List servers in backend    /api/providers/{provider}/backends/{backend}/servers/{server}  GET  Get a server in a backend    /api/providers/{provider}/frontends  GET  List frontends    /api/providers/{provider}/frontends/{frontend}  GET  Get a frontend    /api/providers/{provider}/frontends/{frontend}/routes  GET  List routes in a frontend    /api/providers/{provider}/frontends/{frontend}/routes/{route}  GET  Get a route in a frontend    /metrics  GET  Export internal metrics", 
            "title": "API"
        }, 
        {
            "location": "/configuration/backends/web/#example", 
            "text": "", 
            "title": "Example"
        }, 
        {
            "location": "/configuration/backends/web/#ping", 
            "text": "curl -sv  http://localhost:8080/ping   *   Trying ::1...\n* Connected to localhost (::1) port 8080 (#0)  GET /ping HTTP/1.1  Host: localhost:8080  User-Agent: curl/7.43.0  Accept: */*   HTTP/1.1 200 OK  Date: Thu, 25 Aug 2016 01:35:36 GMT  Content-Length: 2  Content-Type: text/plain; charset=utf-8 \n* Connection #0 to host localhost left intact\nOK", 
            "title": "Ping"
        }, 
        {
            "location": "/configuration/backends/web/#health", 
            "text": "curl -s  http://localhost:8080/health  | jq .  {\n  // Tr\u00e6fik PID\n   pid : 2458,\n  // Tr\u00e6fik server uptime (formated time)\n   uptime :  39m6.885931127s ,\n  //  Tr\u00e6fik server uptime in seconds\n   uptime_sec : 2346.885931127,\n  // current server date\n   time :  2015-10-07 18:32:24.362238909 +0200 CEST ,\n  // current server date in seconds\n   unixtime : 1444235544,\n  // count HTTP response status code in realtime\n   status_code_count : {\n     502 : 1\n  },\n  // count HTTP response status code since Tr\u00e6fik started\n   total_status_code_count : {\n     200 : 7,\n     404 : 21,\n     502 : 13\n  },\n  // count HTTP response\n   count : 1,\n  // count HTTP response\n   total_count : 41,\n  // sum of all response time (formated time)\n   total_response_time :  35.456865605s ,\n  // sum of all response time in seconds\n   total_response_time_sec : 35.456865605,\n  // average response time (formated time)\n   average_response_time :  864.8016ms ,\n  // average response time in seconds\n   average_response_time_sec : 0.8648016000000001,\n\n  // request statistics [requires --web.statistics to be set]\n  // ten most recent requests with 4xx and 5xx status codes\n   recent_errors : [\n    {\n      // status code\n       status_code : 500,\n      // description of status code\n       status :  Internal Server Error ,\n      // request HTTP method\n       method :  GET ,\n      // request hostname\n       host :  localhost ,\n      // request path\n       path :  /path ,\n      // RFC 3339 formatted date/time\n       time :  2016-10-21T16:59:15.418495872-07:00 \n    }\n  ]\n}", 
            "title": "Health"
        }, 
        {
            "location": "/configuration/backends/web/#provider-configurations", 
            "text": "curl -s  http://localhost:8080/api  | jq .  {\n   file : {\n     frontends : {\n       frontend2 : {\n         routes : {\n           test_2 : {\n             rule :  Path:/test \n          }\n        },\n         backend :  backend1 \n      },\n       frontend1 : {\n         routes : {\n           test_1 : {\n             rule :  Host:test.localhost \n          }\n        },\n         backend :  backend2 \n      }\n    },\n     backends : {\n       backend2 : {\n         loadBalancer : {\n           method :  drr \n        },\n         servers : {\n           server2 : {\n             weight : 2,\n             URL :  http://172.17.0.5:80 \n          },\n           server1 : {\n             weight : 1,\n             url :  http://172.17.0.4:80 \n          }\n        }\n      },\n       backend1 : {\n         loadBalancer : {\n           method :  wrr \n        },\n         circuitBreaker : {\n           expression :  NetworkErrorRatio()   0.5 \n        },\n         servers : {\n           server2 : {\n             weight : 1,\n             url :  http://172.17.0.3:80 \n          },\n           server1 : {\n             weight : 10,\n             url :  http://172.17.0.2:80 \n          }\n        }\n      }\n    }\n  }\n}", 
            "title": "Provider configurations"
        }, 
        {
            "location": "/configuration/backends/boltdb/", 
            "text": "BoltDB Backend\n\n\nTr\u00e6fik can be configured to use BoltDB as a backend configuration.\n\n\n################################################################\n# BoltDB configuration backend\n################################################################\n\n# Enable BoltDB configuration backend.\n[boltdb]\n\n# BoltDB file.\n#\n# Required\n# Default: \n127.0.0.1:4001\n\n#\nendpoint = \n/my.db\n\n\n# Enable watch BoltDB changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n# Default: \n/traefik\n\n#\nprefix = \n/traefik\n\n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\nfilename = \nboltdb.tmpl\n\n\n# Use BoltDB user/pass authentication.\n#\n# Optional\n#\n# username = foo\n# password = bar\n\n# Enable BoltDB TLS connection.\n#\n# Optional\n#\n#    [boltdb.tls]\n#    ca = \n/etc/ssl/ca.crt\n\n#    cert = \n/etc/ssl/boltdb.crt\n\n#    key = \n/etc/ssl/boltdb.key\n\n#    insecureskipverify = true\n\n\n\n\nTo enable constraints see \nbackend-specific constraints section\n.", 
            "title": "Backend: BoltDB"
        }, 
        {
            "location": "/configuration/backends/boltdb/#boltdb-backend", 
            "text": "Tr\u00e6fik can be configured to use BoltDB as a backend configuration.  ################################################################\n# BoltDB configuration backend\n################################################################\n\n# Enable BoltDB configuration backend.\n[boltdb]\n\n# BoltDB file.\n#\n# Required\n# Default:  127.0.0.1:4001 \n#\nendpoint =  /my.db \n\n# Enable watch BoltDB changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n# Default:  /traefik \n#\nprefix =  /traefik \n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\nfilename =  boltdb.tmpl \n\n# Use BoltDB user/pass authentication.\n#\n# Optional\n#\n# username = foo\n# password = bar\n\n# Enable BoltDB TLS connection.\n#\n# Optional\n#\n#    [boltdb.tls]\n#    ca =  /etc/ssl/ca.crt \n#    cert =  /etc/ssl/boltdb.crt \n#    key =  /etc/ssl/boltdb.key \n#    insecureskipverify = true  To enable constraints see  backend-specific constraints section .", 
            "title": "BoltDB Backend"
        }, 
        {
            "location": "/configuration/backends/consul/", 
            "text": "Consul Backend\n\n\nConsul Key-Value backend\n\n\nTr\u00e6fik can be configured to use Consul as a backend configuration.\n\n\n################################################################\n# Consul KV configuration backend\n################################################################\n\n# Enable Consul KV configuration backend.\n[consul]\n\n# Consul server endpoint.\n#\n# Required\n# Default: \n127.0.0.1:8500\n\n#\nendpoint = \n127.0.0.1:8500\n\n\n# Enable watch Consul changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n# Default: traefik\n#\nprefix = \ntraefik\n\n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename = \nconsul.tmpl\n\n\n# Use Consul user/pass authentication.\n#\n# Optional\n#\n# username = foo\n# password = bar\n\n# Enable Consul TLS connection.\n#\n# Optional\n#\n#    [consul.tls]\n#    ca = \n/etc/ssl/ca.crt\n\n#    cert = \n/etc/ssl/consul.crt\n\n#    key = \n/etc/ssl/consul.key\n\n#    insecureskipverify = true\n\n\n\n\nTo enable constraints see \nbackend-specific constraints section\n.\n\n\nPlease refer to the \nKey Value storage structure\n section to get documentation on Traefik KV structure.\n\n\nConsul Catalog backend\n\n\nTr\u00e6fik can be configured to use service discovery catalog of Consul as a backend configuration.\n\n\n################################################################\n# Consul Catalog configuration backend\n################################################################\n\n# Enable Consul Catalog configuration backend.\n[consulCatalog]\n\n# Consul server endpoint.\n#\n# Required\n# Default: \n127.0.0.1:8500\n\n#\nendpoint = \n127.0.0.1:8500\n\n\n# Expose Consul catalog services by default in Traefik.\n#\n# Optional\n# Default: true\n#\nexposedByDefault = false\n\n# Prefix for Consul catalog tags.\n#\n# Optional\n# Default: \ntraefik\n\n#\nprefix = \ntraefik\n\n\n# Default frontEnd Rule for Consul services.\n#\n# The format is a Go Template with:\n# - \n.ServiceName\n, \n.Domain\n and \n.Attributes\n available\n# - \ngetTag(name, tags, defaultValue)\n, \nhasTag(name, tags)\n and \ngetAttribute(name, tags, defaultValue)\n functions are available\n# - \ngetAttribute(...)\n function uses prefixed tag names based on \nprefix\n value\n#\n# Optional\n# Default: \nHost:{{.ServiceName}}.{{.Domain}}\n\n#\n#frontEndRule = \nHost:{{.ServiceName}}.{{Domain}}\n\n\n\n\n\nThis backend will create routes matching on hostname based on the service name used in Consul.\n\n\nTo enable constraints see \nbackend-specific constraints section\n.\n\n\nTags\n\n\nAdditional settings can be defined using Consul Catalog tags.\n\n\n\n\n\n\n\n\nTag\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntraefik.enable=false\n\n\nDisable this container in Tr\u00e6fik\n\n\n\n\n\n\ntraefik.protocol=https\n\n\nOverride the default \nhttp\n protocol\n\n\n\n\n\n\ntraefik.backend.weight=10\n\n\nAssign this weight to the container\n\n\n\n\n\n\ntraefik.backend.circuitbreaker=EXPR\n\n\nCreate a \ncircuit breaker\n to be used against the backend, ex: \nNetworkErrorRatio() \n 0.\n\n\n\n\n\n\ntraefik.backend.maxconn.amount=10\n\n\nSet a maximum number of connections to the backend. Must be used in conjunction with the below label to take effect.\n\n\n\n\n\n\ntraefik.backend.maxconn.extractorfunc=client.ip\n\n\nSet the function to be used against the request to determine what to limit maximum connections to the backend by. Must be used in conjunction with the above label to take effect.\n\n\n\n\n\n\ntraefik.frontend.rule=Host:test.traefik.io\n\n\nOverride the default frontend rule (Default: \nHost:{{.ServiceName}}.{{.Domain}}\n).\n\n\n\n\n\n\ntraefik.frontend.passHostHeader=true\n\n\nForward client \nHost\n header to the backend.\n\n\n\n\n\n\ntraefik.frontend.priority=10\n\n\nOverride default frontend priority\n\n\n\n\n\n\ntraefik.frontend.entryPoints=http,https\n\n\nAssign this frontend to entry points \nhttp\n and \nhttps\n. Overrides \ndefaultEntryPoints\n.\n\n\n\n\n\n\ntraefik.frontend.auth.basic=EXPR\n\n\nSets basic authentication for that frontend in CSV format: \nUser:Hash,User:Hash\n\n\n\n\n\n\ntraefik.backend.loadbalancer=drr\n\n\noverride the default \nwrr\n load balancer algorithm\n\n\n\n\n\n\ntraefik.backend.loadbalancer.stickiness=true\n\n\nenable backend sticky sessions\n\n\n\n\n\n\ntraefik.backend.loadbalancer.stickiness.cookieName=NAME\n\n\nManually set the cookie name for sticky sessions\n\n\n\n\n\n\ntraefik.backend.loadbalancer.sticky=true\n\n\nenable backend sticky sessions (DEPRECATED)", 
            "title": "Backend: Consul"
        }, 
        {
            "location": "/configuration/backends/consul/#consul-backend", 
            "text": "", 
            "title": "Consul Backend"
        }, 
        {
            "location": "/configuration/backends/consul/#consul-key-value-backend", 
            "text": "Tr\u00e6fik can be configured to use Consul as a backend configuration.  ################################################################\n# Consul KV configuration backend\n################################################################\n\n# Enable Consul KV configuration backend.\n[consul]\n\n# Consul server endpoint.\n#\n# Required\n# Default:  127.0.0.1:8500 \n#\nendpoint =  127.0.0.1:8500 \n\n# Enable watch Consul changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n# Default: traefik\n#\nprefix =  traefik \n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename =  consul.tmpl \n\n# Use Consul user/pass authentication.\n#\n# Optional\n#\n# username = foo\n# password = bar\n\n# Enable Consul TLS connection.\n#\n# Optional\n#\n#    [consul.tls]\n#    ca =  /etc/ssl/ca.crt \n#    cert =  /etc/ssl/consul.crt \n#    key =  /etc/ssl/consul.key \n#    insecureskipverify = true  To enable constraints see  backend-specific constraints section .  Please refer to the  Key Value storage structure  section to get documentation on Traefik KV structure.", 
            "title": "Consul Key-Value backend"
        }, 
        {
            "location": "/configuration/backends/consul/#consul-catalog-backend", 
            "text": "Tr\u00e6fik can be configured to use service discovery catalog of Consul as a backend configuration.  ################################################################\n# Consul Catalog configuration backend\n################################################################\n\n# Enable Consul Catalog configuration backend.\n[consulCatalog]\n\n# Consul server endpoint.\n#\n# Required\n# Default:  127.0.0.1:8500 \n#\nendpoint =  127.0.0.1:8500 \n\n# Expose Consul catalog services by default in Traefik.\n#\n# Optional\n# Default: true\n#\nexposedByDefault = false\n\n# Prefix for Consul catalog tags.\n#\n# Optional\n# Default:  traefik \n#\nprefix =  traefik \n\n# Default frontEnd Rule for Consul services.\n#\n# The format is a Go Template with:\n# -  .ServiceName ,  .Domain  and  .Attributes  available\n# -  getTag(name, tags, defaultValue) ,  hasTag(name, tags)  and  getAttribute(name, tags, defaultValue)  functions are available\n# -  getAttribute(...)  function uses prefixed tag names based on  prefix  value\n#\n# Optional\n# Default:  Host:{{.ServiceName}}.{{.Domain}} \n#\n#frontEndRule =  Host:{{.ServiceName}}.{{Domain}}   This backend will create routes matching on hostname based on the service name used in Consul.  To enable constraints see  backend-specific constraints section .", 
            "title": "Consul Catalog backend"
        }, 
        {
            "location": "/configuration/backends/consul/#tags", 
            "text": "Additional settings can be defined using Consul Catalog tags.     Tag  Description      traefik.enable=false  Disable this container in Tr\u00e6fik    traefik.protocol=https  Override the default  http  protocol    traefik.backend.weight=10  Assign this weight to the container    traefik.backend.circuitbreaker=EXPR  Create a  circuit breaker  to be used against the backend, ex:  NetworkErrorRatio()   0.    traefik.backend.maxconn.amount=10  Set a maximum number of connections to the backend. Must be used in conjunction with the below label to take effect.    traefik.backend.maxconn.extractorfunc=client.ip  Set the function to be used against the request to determine what to limit maximum connections to the backend by. Must be used in conjunction with the above label to take effect.    traefik.frontend.rule=Host:test.traefik.io  Override the default frontend rule (Default:  Host:{{.ServiceName}}.{{.Domain}} ).    traefik.frontend.passHostHeader=true  Forward client  Host  header to the backend.    traefik.frontend.priority=10  Override default frontend priority    traefik.frontend.entryPoints=http,https  Assign this frontend to entry points  http  and  https . Overrides  defaultEntryPoints .    traefik.frontend.auth.basic=EXPR  Sets basic authentication for that frontend in CSV format:  User:Hash,User:Hash    traefik.backend.loadbalancer=drr  override the default  wrr  load balancer algorithm    traefik.backend.loadbalancer.stickiness=true  enable backend sticky sessions    traefik.backend.loadbalancer.stickiness.cookieName=NAME  Manually set the cookie name for sticky sessions    traefik.backend.loadbalancer.sticky=true  enable backend sticky sessions (DEPRECATED)", 
            "title": "Tags"
        }, 
        {
            "location": "/configuration/backends/docker/", 
            "text": "Docker Backend\n\n\nTr\u00e6fik can be configured to use Docker as a backend configuration.\n\n\nDocker\n\n\n################################################################\n# Docker configuration backend\n################################################################\n\n# Enable Docker configuration backend.\n[docker]\n\n# Docker server endpoint. Can be a tcp or a unix socket endpoint.\n#\n# Required\n#\nendpoint = \nunix:///var/run/docker.sock\n\n\n# Default domain used.\n# Can be overridden by setting the \ntraefik.domain\n label on a container.\n#\n# Required\n#\ndomain = \ndocker.localhost\n\n\n# Enable watch docker changes.\n#\n# Optional\n#\nwatch = true\n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename = \ndocker.tmpl\n\n\n# Expose containers by default in Traefik.\n# If set to false, containers that don't have `traefik.enable=true` will be ignored.\n#\n# Optional\n# Default: true\n#\nexposedbydefault = true\n\n# Use the IP address from the binded port instead of the inner network one.\n# For specific use-case :)\n#\n# Optional\n# Default: false\n#\nusebindportip = true\n\n# Use Swarm Mode services as data provider.\n#\n# Optional\n# Default: false\n#\nswarmmode = false\n\n# Enable docker TLS connection.\n#\n# Optional\n#\n#  [docker.tls]\n#  ca = \n/etc/ssl/ca.crt\n\n#  cert = \n/etc/ssl/docker.crt\n\n#  key = \n/etc/ssl/docker.key\n\n#  insecureskipverify = true\n\n\n\n\nTo enable constraints see \nbackend-specific constraints section\n.\n\n\nDocker Swarm Mode\n\n\n################################################################\n# Docker Swarmmode configuration backend\n################################################################\n\n# Enable Docker configuration backend.\n[docker]\n\n# Docker server endpoint.\n# Can be a tcp or a unix socket endpoint.\n#\n# Required\n# Default: \nunix:///var/run/docker.sock\n\n#\nendpoint = \ntcp://127.0.0.1:2375\n\n\n# Default domain used.\n# Can be overridden by setting the \ntraefik.domain\n label on a services.\n#\n# Optional\n# Default: \n\n#\ndomain = \ndocker.localhost\n\n\n# Enable watch docker changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Use Docker Swarm Mode as data provider.\n#\n# Optional\n# Default: false\n#\nswarmmode = true\n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename = \ndocker.tmpl\n\n\n# Expose services by default in Traefik.\n#\n# Optional\n# Default: true\n#\nexposedbydefault = false\n\n# Enable docker TLS connection.\n#\n# Optional\n#\n#  [docker.tls]\n#  ca = \n/etc/ssl/ca.crt\n\n#  cert = \n/etc/ssl/docker.crt\n\n#  key = \n/etc/ssl/docker.key\n\n#  insecureskipverify = true\n\n\n\n\nTo enable constraints see \nbackend-specific constraints section\n.\n\n\nLabels: overriding default behaviour\n\n\nOn Containers\n\n\nLabels can be used on containers to override default behaviour.\n\n\n\n\n\n\n\n\nLabel\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntraefik.backend=foo\n\n\nGive the name \nfoo\n to the generated backend for this container.\n\n\n\n\n\n\ntraefik.backend.maxconn.amount=10\n\n\nSet a maximum number of connections to the backend. Must be used in conjunction with the below label to take effect.\n\n\n\n\n\n\ntraefik.backend.maxconn.extractorfunc=client.ip\n\n\nSet the function to be used against the request to determine what to limit maximum connections to the backend by. Must be used in conjunction with the above label to take effect.\n\n\n\n\n\n\ntraefik.backend.loadbalancer.method=drr\n\n\nOverride the default \nwrr\n load balancer algorithm\n\n\n\n\n\n\ntraefik.backend.loadbalancer.stickiness=true\n\n\nEnable backend sticky sessions\n\n\n\n\n\n\ntraefik.backend.loadbalancer.stickiness.cookieName=NAME\n\n\nManually set the cookie name for sticky sessions\n\n\n\n\n\n\ntraefik.backend.loadbalancer.sticky=true\n\n\nEnable backend sticky sessions (DEPRECATED)\n\n\n\n\n\n\ntraefik.backend.loadbalancer.swarm=true\n\n\nUse Swarm's inbuilt load balancer (only relevant under Swarm Mode).\n\n\n\n\n\n\ntraefik.backend.circuitbreaker.expression=EXPR\n\n\nCreate a \ncircuit breaker\n to be used against the backend\n\n\n\n\n\n\ntraefik.port=80\n\n\nRegister this port. Useful when the container exposes multiples ports.\n\n\n\n\n\n\ntraefik.protocol=https\n\n\nOverride the default \nhttp\n protocol\n\n\n\n\n\n\ntraefik.weight=10\n\n\nAssign this weight to the container\n\n\n\n\n\n\ntraefik.enable=false\n\n\nDisable this container in Tr\u00e6fik\n\n\n\n\n\n\ntraefik.frontend.rule=EXPR\n\n\nOverride the default frontend rule. Default: \nHost:{containerName}.{domain}\n or \nHost:{service}.{project_name}.{domain}\n if you are using \ndocker-compose\n.\n\n\n\n\n\n\ntraefik.frontend.passHostHeader=true\n\n\nForward client \nHost\n header to the backend.\n\n\n\n\n\n\ntraefik.frontend.priority=10\n\n\nOverride default frontend priority\n\n\n\n\n\n\ntraefik.frontend.entryPoints=http,https\n\n\nAssign this frontend to entry points \nhttp\n and \nhttps\n. Overrides \ndefaultEntryPoints\n\n\n\n\n\n\ntraefik.frontend.auth.basic=EXPR\n\n\nSets basic authentication for that frontend in CSV format: \nUser:Hash,User:Hash\n\n\n\n\n\n\ntraefik.frontend.whitelistSourceRange:RANGE\n\n\nList of IP-Ranges which are allowed to access. An unset or empty list allows all Source-IPs to access. If one of the Net-Specifications are invalid, the whole list is invalid and allows all Source-IPs to access.\n\n\n\n\n\n\ntraefik.docker.network\n\n\nSet the docker network to use for connections to this container. If a container is linked to several networks, be sure to set the proper network name (you can check with \ndocker inspect \ncontainer_id\n) otherwise it will randomly pick one (depending on how docker is returning them). For instance when deploying docker \nstack\n from compose files, the compose defined networks will be prefixed with the \nstack\n name.\n\n\n\n\n\n\n\n\nOn Service\n\n\nServices labels can be used for overriding default behaviour\n\n\n\n\n\n\n\n\nLabel\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntraefik.\nservice-name\n.port=PORT\n\n\nOverrides \ntraefik.port\n. If several ports need to be exposed, the service labels could be used.\n\n\n\n\n\n\ntraefik.\nservice-name\n.protocol\n\n\nOverrides \ntraefik.protocol\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.weight\n\n\nAssign this service weight. Overrides \ntraefik.weight\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.backend=BACKEND\n\n\nAssign this service frontend to \nBACKEND\n. Default is to assign to the service backend.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.entryPoints\n\n\nOverrides \ntraefik.frontend.entrypoints\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.auth.basic\n\n\nSets a Basic Auth for that frontend\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.passHostHeader\n\n\nOverrides \ntraefik.frontend.passHostHeader\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.priority\n\n\nOverrides \ntraefik.frontend.priority\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.rule\n\n\nOverrides \ntraefik.frontend.rule\n.\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nif a label is defined both as a \ncontainer label\n and a \nservice label\n (for example \ntraefik.\nservice-name\n.port=PORT\n and \ntraefik.port=PORT\n ), the \nservice label\n is used to defined the \nservice-name\n property (\nport\n in the example).\nIt's possible to mix \ncontainer labels\n and \nservice labels\n, in this case \ncontainer labels\n are used as default value for missing \nservice labels\n but no frontends are going to be created with the \ncontainer labels\n.\nMore details in this \nexample\n.\n\n\n\n\n\n\nWarning\n\n\nwhen running inside a container, Tr\u00e6fik will need network access through:\n\n\ndocker network connect \nnetwork\n \ntraefik-container", 
            "title": "Backend: Docker"
        }, 
        {
            "location": "/configuration/backends/docker/#docker-backend", 
            "text": "Tr\u00e6fik can be configured to use Docker as a backend configuration.", 
            "title": "Docker Backend"
        }, 
        {
            "location": "/configuration/backends/docker/#docker", 
            "text": "################################################################\n# Docker configuration backend\n################################################################\n\n# Enable Docker configuration backend.\n[docker]\n\n# Docker server endpoint. Can be a tcp or a unix socket endpoint.\n#\n# Required\n#\nendpoint =  unix:///var/run/docker.sock \n\n# Default domain used.\n# Can be overridden by setting the  traefik.domain  label on a container.\n#\n# Required\n#\ndomain =  docker.localhost \n\n# Enable watch docker changes.\n#\n# Optional\n#\nwatch = true\n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename =  docker.tmpl \n\n# Expose containers by default in Traefik.\n# If set to false, containers that don't have `traefik.enable=true` will be ignored.\n#\n# Optional\n# Default: true\n#\nexposedbydefault = true\n\n# Use the IP address from the binded port instead of the inner network one.\n# For specific use-case :)\n#\n# Optional\n# Default: false\n#\nusebindportip = true\n\n# Use Swarm Mode services as data provider.\n#\n# Optional\n# Default: false\n#\nswarmmode = false\n\n# Enable docker TLS connection.\n#\n# Optional\n#\n#  [docker.tls]\n#  ca =  /etc/ssl/ca.crt \n#  cert =  /etc/ssl/docker.crt \n#  key =  /etc/ssl/docker.key \n#  insecureskipverify = true  To enable constraints see  backend-specific constraints section .", 
            "title": "Docker"
        }, 
        {
            "location": "/configuration/backends/docker/#docker-swarm-mode", 
            "text": "################################################################\n# Docker Swarmmode configuration backend\n################################################################\n\n# Enable Docker configuration backend.\n[docker]\n\n# Docker server endpoint.\n# Can be a tcp or a unix socket endpoint.\n#\n# Required\n# Default:  unix:///var/run/docker.sock \n#\nendpoint =  tcp://127.0.0.1:2375 \n\n# Default domain used.\n# Can be overridden by setting the  traefik.domain  label on a services.\n#\n# Optional\n# Default:  \n#\ndomain =  docker.localhost \n\n# Enable watch docker changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Use Docker Swarm Mode as data provider.\n#\n# Optional\n# Default: false\n#\nswarmmode = true\n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename =  docker.tmpl \n\n# Expose services by default in Traefik.\n#\n# Optional\n# Default: true\n#\nexposedbydefault = false\n\n# Enable docker TLS connection.\n#\n# Optional\n#\n#  [docker.tls]\n#  ca =  /etc/ssl/ca.crt \n#  cert =  /etc/ssl/docker.crt \n#  key =  /etc/ssl/docker.key \n#  insecureskipverify = true  To enable constraints see  backend-specific constraints section .", 
            "title": "Docker Swarm Mode"
        }, 
        {
            "location": "/configuration/backends/docker/#labels-overriding-default-behaviour", 
            "text": "", 
            "title": "Labels: overriding default behaviour"
        }, 
        {
            "location": "/configuration/backends/docker/#on-containers", 
            "text": "Labels can be used on containers to override default behaviour.     Label  Description      traefik.backend=foo  Give the name  foo  to the generated backend for this container.    traefik.backend.maxconn.amount=10  Set a maximum number of connections to the backend. Must be used in conjunction with the below label to take effect.    traefik.backend.maxconn.extractorfunc=client.ip  Set the function to be used against the request to determine what to limit maximum connections to the backend by. Must be used in conjunction with the above label to take effect.    traefik.backend.loadbalancer.method=drr  Override the default  wrr  load balancer algorithm    traefik.backend.loadbalancer.stickiness=true  Enable backend sticky sessions    traefik.backend.loadbalancer.stickiness.cookieName=NAME  Manually set the cookie name for sticky sessions    traefik.backend.loadbalancer.sticky=true  Enable backend sticky sessions (DEPRECATED)    traefik.backend.loadbalancer.swarm=true  Use Swarm's inbuilt load balancer (only relevant under Swarm Mode).    traefik.backend.circuitbreaker.expression=EXPR  Create a  circuit breaker  to be used against the backend    traefik.port=80  Register this port. Useful when the container exposes multiples ports.    traefik.protocol=https  Override the default  http  protocol    traefik.weight=10  Assign this weight to the container    traefik.enable=false  Disable this container in Tr\u00e6fik    traefik.frontend.rule=EXPR  Override the default frontend rule. Default:  Host:{containerName}.{domain}  or  Host:{service}.{project_name}.{domain}  if you are using  docker-compose .    traefik.frontend.passHostHeader=true  Forward client  Host  header to the backend.    traefik.frontend.priority=10  Override default frontend priority    traefik.frontend.entryPoints=http,https  Assign this frontend to entry points  http  and  https . Overrides  defaultEntryPoints    traefik.frontend.auth.basic=EXPR  Sets basic authentication for that frontend in CSV format:  User:Hash,User:Hash    traefik.frontend.whitelistSourceRange:RANGE  List of IP-Ranges which are allowed to access. An unset or empty list allows all Source-IPs to access. If one of the Net-Specifications are invalid, the whole list is invalid and allows all Source-IPs to access.    traefik.docker.network  Set the docker network to use for connections to this container. If a container is linked to several networks, be sure to set the proper network name (you can check with  docker inspect  container_id ) otherwise it will randomly pick one (depending on how docker is returning them). For instance when deploying docker  stack  from compose files, the compose defined networks will be prefixed with the  stack  name.", 
            "title": "On Containers"
        }, 
        {
            "location": "/configuration/backends/docker/#on-service", 
            "text": "Services labels can be used for overriding default behaviour     Label  Description      traefik. service-name .port=PORT  Overrides  traefik.port . If several ports need to be exposed, the service labels could be used.    traefik. service-name .protocol  Overrides  traefik.protocol .    traefik. service-name .weight  Assign this service weight. Overrides  traefik.weight .    traefik. service-name .frontend.backend=BACKEND  Assign this service frontend to  BACKEND . Default is to assign to the service backend.    traefik. service-name .frontend.entryPoints  Overrides  traefik.frontend.entrypoints    traefik. service-name .frontend.auth.basic  Sets a Basic Auth for that frontend    traefik. service-name .frontend.passHostHeader  Overrides  traefik.frontend.passHostHeader .    traefik. service-name .frontend.priority  Overrides  traefik.frontend.priority .    traefik. service-name .frontend.rule  Overrides  traefik.frontend.rule .      Note  if a label is defined both as a  container label  and a  service label  (for example  traefik. service-name .port=PORT  and  traefik.port=PORT  ), the  service label  is used to defined the  service-name  property ( port  in the example).\nIt's possible to mix  container labels  and  service labels , in this case  container labels  are used as default value for missing  service labels  but no frontends are going to be created with the  container labels .\nMore details in this  example .    Warning  when running inside a container, Tr\u00e6fik will need network access through:  docker network connect  network   traefik-container", 
            "title": "On Service"
        }, 
        {
            "location": "/configuration/backends/dynamodb/", 
            "text": "DynamoDB Backend\n\n\nTr\u00e6fik can be configured to use Amazon DynamoDB as a backend configuration.\n\n\nConfiguration\n\n\n################################################################\n# DynamoDB configuration backend\n################################################################\n\n# Enable DynamoDB configuration backend.\n[dynamodb]\n\n# Region to use when connecting to AWS.\n#\n# Required\n#\nregion = \nus-west-1\n\n\n# DyanmoDB Table Name.\n#\n# Optional\n# Default: \ntraefik\n\n#\ntableName = \ntraefik\n\n\n# Enable watch DynamoDB changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Polling interval (in seconds).\n#\n# Optional\n# Default: 15\n#\nrefreshSeconds = 15\n\n# AccessKeyID to use when connecting to AWS.\n#\n# Optional\n#\naccessKeyID = \nabc\n\n\n# SecretAccessKey to use when connecting to AWS.\n#\n# Optional\n#\nsecretAccessKey = \n123\n\n\n# Endpoint of local dynamodb instance for testing?\n#\n# Optional\n#\nendpoint = \nhttp://localhost:8080\n\n\n\n\n\nTable Items\n\n\nItems in the \ndynamodb\n table must have three attributes:\n\n\n\n\nid\n (string): The id is the primary key.\n\n\nname\n(string): The name is used as the name of the frontend or backend.\n\n\nfrontend\n or \nbackend\n (map): This attribute's structure matches exactly the structure of a Frontend or Backend type in Traefik.\n\n    See \ntypes/types.go\n for details.\n\n    The presence or absence of this attribute determines its type.\n    So an item should never have both a \nfrontend\n and a \nbackend\n attribute.", 
            "title": "Backend: DynamoDB"
        }, 
        {
            "location": "/configuration/backends/dynamodb/#dynamodb-backend", 
            "text": "Tr\u00e6fik can be configured to use Amazon DynamoDB as a backend configuration.", 
            "title": "DynamoDB Backend"
        }, 
        {
            "location": "/configuration/backends/dynamodb/#configuration", 
            "text": "################################################################\n# DynamoDB configuration backend\n################################################################\n\n# Enable DynamoDB configuration backend.\n[dynamodb]\n\n# Region to use when connecting to AWS.\n#\n# Required\n#\nregion =  us-west-1 \n\n# DyanmoDB Table Name.\n#\n# Optional\n# Default:  traefik \n#\ntableName =  traefik \n\n# Enable watch DynamoDB changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Polling interval (in seconds).\n#\n# Optional\n# Default: 15\n#\nrefreshSeconds = 15\n\n# AccessKeyID to use when connecting to AWS.\n#\n# Optional\n#\naccessKeyID =  abc \n\n# SecretAccessKey to use when connecting to AWS.\n#\n# Optional\n#\nsecretAccessKey =  123 \n\n# Endpoint of local dynamodb instance for testing?\n#\n# Optional\n#\nendpoint =  http://localhost:8080", 
            "title": "Configuration"
        }, 
        {
            "location": "/configuration/backends/dynamodb/#table-items", 
            "text": "Items in the  dynamodb  table must have three attributes:   id  (string): The id is the primary key.  name (string): The name is used as the name of the frontend or backend.  frontend  or  backend  (map): This attribute's structure matches exactly the structure of a Frontend or Backend type in Traefik. \n    See  types/types.go  for details. \n    The presence or absence of this attribute determines its type.\n    So an item should never have both a  frontend  and a  backend  attribute.", 
            "title": "Table Items"
        }, 
        {
            "location": "/configuration/backends/ecs/", 
            "text": "ECS Backend\n\n\nTr\u00e6fik can be configured to use Amazon ECS as a backend configuration.\n\n\nConfiguration\n\n\n################################################################\n# ECS configuration backend\n################################################################\n\n# Enable ECS configuration backend.\n[ecs]\n\n# ECS Cluster Name.\n#\n# DEPRECATED - Please use `clusters`.\n#\ncluster = \ndefault\n\n\n# ECS Clusters Name.\n#\n# Optional\n# Default: [\ndefault\n]\n#\nclusters = [\ndefault\n]\n\n# Enable watch ECS changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Default domain used.\n#\n# Optional\n# Default: \n\n#\ndomain = \necs.localhost\n\n\n# Enable auto discover ECS clusters.\n#\n# Optional\n# Default: false\n#\nautoDiscoverClusters = false\n\n# Polling interval (in seconds).\n#\n# Optional\n# Default: 15\n#\nrefreshSeconds = 15\n\n# Expose ECS services by default in Traefik.\n#\n# Optional\n# Default: true\n#\nexposedByDefault = false\n\n# Region to use when connecting to AWS.\n#\n# Optional\n#\nregion = \nus-east-1\n\n\n# AccessKeyID to use when connecting to AWS.\n#\n# Optional\n#\naccessKeyID = \nabc\n\n\n# SecretAccessKey to use when connecting to AWS.\n#\n# Optional\n#\nsecretAccessKey = \n123\n\n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename = \necs.tmpl\n\n\n\n\n\nIf \nAccessKeyID\n/\nSecretAccessKey\n is not given credentials will be resolved in the following order:\n\n\n\n\nFrom environment variables; \nAWS_ACCESS_KEY_ID\n, \nAWS_SECRET_ACCESS_KEY\n, and \nAWS_SESSION_TOKEN\n.\n\n\nShared credentials, determined by \nAWS_PROFILE\n and \nAWS_SHARED_CREDENTIALS_FILE\n, defaults to \ndefault\n and \n~/.aws/credentials\n.\n\n\nEC2 instance role or ECS task role\n\n\n\n\nPolicy\n\n\nTr\u00e6fik needs the following policy to read ECS information:\n\n\n{\n    \nVersion\n: \n2012-10-17\n,\n    \nStatement\n: [\n        {\n            \nSid\n: \nTraefikECSReadAccess\n,\n            \nEffect\n: \nAllow\n,\n            \nAction\n: [\n                \necs:ListClusters\n,\n                \necs:DescribeClusters\n,\n                \necs:ListTasks\n,\n                \necs:DescribeTasks\n,\n                \necs:DescribeContainerInstances\n,\n                \necs:DescribeTaskDefinition\n,\n                \nec2:DescribeInstances\n\n            ],\n            \nResource\n: [\n                \n*\n\n            ]\n        }\n    ]\n}\n\n\n\n\nLabels: overriding default behaviour\n\n\nLabels can be used on task containers to override default behaviour:\n\n\n\n\n\n\n\n\nLabel\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntraefik.protocol=https\n\n\noverride the default \nhttp\n protocol\n\n\n\n\n\n\ntraefik.weight=10\n\n\nassign this weight to the container\n\n\n\n\n\n\ntraefik.enable=false\n\n\ndisable this container in Tr\u00e6fik\n\n\n\n\n\n\ntraefik.backend.loadbalancer.method=drr\n\n\noverride the default \nwrr\n load balancer algorithm\n\n\n\n\n\n\ntraefik.backend.loadbalancer.stickiness=true\n\n\nenable backend sticky sessions\n\n\n\n\n\n\ntraefik.backend.loadbalancer.stickiness.cookieName=NAME\n\n\nManually set the cookie name for sticky sessions\n\n\n\n\n\n\ntraefik.backend.loadbalancer.sticky=true\n\n\nenable backend sticky sessions (DEPRECATED)\n\n\n\n\n\n\ntraefik.frontend.rule=Host:test.traefik.io\n\n\noverride the default frontend rule (Default: \nHost:{containerName}.{domain}\n).\n\n\n\n\n\n\ntraefik.frontend.passHostHeader=true\n\n\nforward client \nHost\n header to the backend.\n\n\n\n\n\n\ntraefik.frontend.priority=10\n\n\noverride default frontend priority\n\n\n\n\n\n\ntraefik.frontend.entryPoints=http,https\n\n\nassign this frontend to entry points \nhttp\n and \nhttps\n. Overrides \ndefaultEntryPoints\n.\n\n\n\n\n\n\ntraefik.frontend.auth.basic=EXPR\n\n\nSets basic authentication for that frontend in CSV format: \nUser:Hash,User:Hash", 
            "title": "Backend: ECS"
        }, 
        {
            "location": "/configuration/backends/ecs/#ecs-backend", 
            "text": "Tr\u00e6fik can be configured to use Amazon ECS as a backend configuration.", 
            "title": "ECS Backend"
        }, 
        {
            "location": "/configuration/backends/ecs/#configuration", 
            "text": "################################################################\n# ECS configuration backend\n################################################################\n\n# Enable ECS configuration backend.\n[ecs]\n\n# ECS Cluster Name.\n#\n# DEPRECATED - Please use `clusters`.\n#\ncluster =  default \n\n# ECS Clusters Name.\n#\n# Optional\n# Default: [ default ]\n#\nclusters = [ default ]\n\n# Enable watch ECS changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Default domain used.\n#\n# Optional\n# Default:  \n#\ndomain =  ecs.localhost \n\n# Enable auto discover ECS clusters.\n#\n# Optional\n# Default: false\n#\nautoDiscoverClusters = false\n\n# Polling interval (in seconds).\n#\n# Optional\n# Default: 15\n#\nrefreshSeconds = 15\n\n# Expose ECS services by default in Traefik.\n#\n# Optional\n# Default: true\n#\nexposedByDefault = false\n\n# Region to use when connecting to AWS.\n#\n# Optional\n#\nregion =  us-east-1 \n\n# AccessKeyID to use when connecting to AWS.\n#\n# Optional\n#\naccessKeyID =  abc \n\n# SecretAccessKey to use when connecting to AWS.\n#\n# Optional\n#\nsecretAccessKey =  123 \n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename =  ecs.tmpl   If  AccessKeyID / SecretAccessKey  is not given credentials will be resolved in the following order:   From environment variables;  AWS_ACCESS_KEY_ID ,  AWS_SECRET_ACCESS_KEY , and  AWS_SESSION_TOKEN .  Shared credentials, determined by  AWS_PROFILE  and  AWS_SHARED_CREDENTIALS_FILE , defaults to  default  and  ~/.aws/credentials .  EC2 instance role or ECS task role", 
            "title": "Configuration"
        }, 
        {
            "location": "/configuration/backends/ecs/#policy", 
            "text": "Tr\u00e6fik needs the following policy to read ECS information:  {\n     Version :  2012-10-17 ,\n     Statement : [\n        {\n             Sid :  TraefikECSReadAccess ,\n             Effect :  Allow ,\n             Action : [\n                 ecs:ListClusters ,\n                 ecs:DescribeClusters ,\n                 ecs:ListTasks ,\n                 ecs:DescribeTasks ,\n                 ecs:DescribeContainerInstances ,\n                 ecs:DescribeTaskDefinition ,\n                 ec2:DescribeInstances \n            ],\n             Resource : [\n                 * \n            ]\n        }\n    ]\n}", 
            "title": "Policy"
        }, 
        {
            "location": "/configuration/backends/ecs/#labels-overriding-default-behaviour", 
            "text": "Labels can be used on task containers to override default behaviour:     Label  Description      traefik.protocol=https  override the default  http  protocol    traefik.weight=10  assign this weight to the container    traefik.enable=false  disable this container in Tr\u00e6fik    traefik.backend.loadbalancer.method=drr  override the default  wrr  load balancer algorithm    traefik.backend.loadbalancer.stickiness=true  enable backend sticky sessions    traefik.backend.loadbalancer.stickiness.cookieName=NAME  Manually set the cookie name for sticky sessions    traefik.backend.loadbalancer.sticky=true  enable backend sticky sessions (DEPRECATED)    traefik.frontend.rule=Host:test.traefik.io  override the default frontend rule (Default:  Host:{containerName}.{domain} ).    traefik.frontend.passHostHeader=true  forward client  Host  header to the backend.    traefik.frontend.priority=10  override default frontend priority    traefik.frontend.entryPoints=http,https  assign this frontend to entry points  http  and  https . Overrides  defaultEntryPoints .    traefik.frontend.auth.basic=EXPR  Sets basic authentication for that frontend in CSV format:  User:Hash,User:Hash", 
            "title": "Labels: overriding default behaviour"
        }, 
        {
            "location": "/configuration/backends/etcd/", 
            "text": "Etcd Backend\n\n\nTr\u00e6fik can be configured to use Etcd as a backend configuration.\n\n\n################################################################\n# Etcd configuration backend\n################################################################\n\n# Enable Etcd configuration backend.\n[etcd]\n\n# Etcd server endpoint.\n#\n# Required\n# Default: \n127.0.0.1:2379\n\n#\nendpoint = \n127.0.0.1:2379\n\n\n# Enable watch Etcd changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n# Default: \n/traefik\n\n#\nprefix = \n/traefik\n\n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename = \netcd.tmpl\n\n\n# Use etcd user/pass authentication.\n#\n# Optional\n#\n# username = foo\n# password = bar\n\n# Enable etcd TLS connection.\n#\n# Optional\n#\n#    [etcd.tls]\n#    ca = \n/etc/ssl/ca.crt\n\n#    cert = \n/etc/ssl/etcd.crt\n\n#    key = \n/etc/ssl/etcd.key\n\n#    insecureskipverify = true\n\n\n\n\nTo enable constraints see \nbackend-specific constraints section\n.\n\n\nPlease refer to the \nKey Value storage structure\n section to get documentation on Traefik KV structure.", 
            "title": "Backend: Etcd"
        }, 
        {
            "location": "/configuration/backends/etcd/#etcd-backend", 
            "text": "Tr\u00e6fik can be configured to use Etcd as a backend configuration.  ################################################################\n# Etcd configuration backend\n################################################################\n\n# Enable Etcd configuration backend.\n[etcd]\n\n# Etcd server endpoint.\n#\n# Required\n# Default:  127.0.0.1:2379 \n#\nendpoint =  127.0.0.1:2379 \n\n# Enable watch Etcd changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n# Default:  /traefik \n#\nprefix =  /traefik \n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename =  etcd.tmpl \n\n# Use etcd user/pass authentication.\n#\n# Optional\n#\n# username = foo\n# password = bar\n\n# Enable etcd TLS connection.\n#\n# Optional\n#\n#    [etcd.tls]\n#    ca =  /etc/ssl/ca.crt \n#    cert =  /etc/ssl/etcd.crt \n#    key =  /etc/ssl/etcd.key \n#    insecureskipverify = true  To enable constraints see  backend-specific constraints section .  Please refer to the  Key Value storage structure  section to get documentation on Traefik KV structure.", 
            "title": "Etcd Backend"
        }, 
        {
            "location": "/configuration/backends/eureka/", 
            "text": "Eureka Backend\n\n\nTr\u00e6fik can be configured to use Eureka as a backend configuration.\n\n\n################################################################\n# Eureka configuration backend\n################################################################\n\n# Enable Eureka configuration backend.\n[eureka]\n\n# Eureka server endpoint.\n#\n# Required\n#\nendpoint = \nhttp://my.eureka.server/eureka\n\n\n# Override default configuration time between refresh.\n#\n# Optional\n# Default: 30s\n#\ndelay = \n1m\n\n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename = \neureka.tmpl", 
            "title": "Backend: Eureka"
        }, 
        {
            "location": "/configuration/backends/eureka/#eureka-backend", 
            "text": "Tr\u00e6fik can be configured to use Eureka as a backend configuration.  ################################################################\n# Eureka configuration backend\n################################################################\n\n# Enable Eureka configuration backend.\n[eureka]\n\n# Eureka server endpoint.\n#\n# Required\n#\nendpoint =  http://my.eureka.server/eureka \n\n# Override default configuration time between refresh.\n#\n# Optional\n# Default: 30s\n#\ndelay =  1m \n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename =  eureka.tmpl", 
            "title": "Eureka Backend"
        }, 
        {
            "location": "/configuration/backends/file/", 
            "text": "File Backends\n\n\nLike any other reverse proxy, Tr\u00e6fik can be configured with a file.\n\n\nYou have three choices:\n\n\n\n\nSimple\n\n\nRules in a Separate File\n\n\nMultiple \n.toml\n Files\n\n\n\n\nTo enable the file backend, you must either pass the \n--file\n option to the Tr\u00e6fik binary or put the \n[file]\n section (with or without inner settings) in the configuration file.\n\n\nSimple\n\n\nAdd your configuration at the end of the global configuration file \ntraefik.toml\n:\n\n\ndefaultEntryPoints = [\nhttp\n, \nhttps\n]\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n    [entryPoints.http.redirect]\n    entryPoint = \nhttps\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \nintegration/fixtures/https/snitest.com.cert\n\n      KeyFile = \nintegration/fixtures/https/snitest.com.key\n\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \nintegration/fixtures/https/snitest.org.cert\n\n      KeyFile = \nintegration/fixtures/https/snitest.org.key\n\n\n[file]\n\n# rules\n[backends]\n  [backends.backend1]\n    [backends.backend1.circuitbreaker]\n    expression = \nNetworkErrorRatio() \n 0.5\n\n    [backends.backend1.servers.server1]\n    url = \nhttp://172.17.0.2:80\n\n    weight = 10\n    [backends.backend1.servers.server2]\n    url = \nhttp://172.17.0.3:80\n\n    weight = 1\n  [backends.backend2]\n    [backends.backend2.maxconn]\n    amount = 10\n    extractorfunc = \nrequest.host\n\n    [backends.backend2.LoadBalancer]\n    method = \ndrr\n\n    [backends.backend2.servers.server1]\n    url = \nhttp://172.17.0.4:80\n\n    weight = 1\n    [backends.backend2.servers.server2]\n    url = \nhttp://172.17.0.5:80\n\n    weight = 2\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend2\n\n    [frontends.frontend1.routes.test_1]\n    rule = \nHost:test.localhost\n\n\n  [frontends.frontend2]\n  backend = \nbackend1\n\n  passHostHeader = true\n  priority = 10\n\n  # restrict access to this frontend to the specified list of IPv4/IPv6 CIDR Nets\n  # an unset or empty list allows all Source-IPs to access\n  # if one of the Net-Specifications are invalid, the whole list is invalid\n  # and allows all Source-IPs to access.\n  whitelistSourceRange = [\n10.42.0.0/16\n, \n152.89.1.33/32\n, \nafed:be44::/16\n]\n\n  entrypoints = [\nhttps\n] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule = \nHost:{subdomain:[a-z]+}.localhost\n\n\n  [frontends.frontend3]\n  entrypoints = [\nhttp\n, \nhttps\n] # overrides defaultEntryPoints\n  backend = \nbackend2\n\n  rule = \nPath:/test\n\n\n\n\n\nRules in a Separate File\n\n\nPut your rules in a separate file, for example \nrules.toml\n:\n\n\n# traefik.toml\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n    [entryPoints.http.redirect]\n      entryPoint = \nhttps\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \nintegration/fixtures/https/snitest.com.cert\n\n      KeyFile = \nintegration/fixtures/https/snitest.com.key\n\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \nintegration/fixtures/https/snitest.org.cert\n\n      KeyFile = \nintegration/fixtures/https/snitest.org.key\n\n\n[file]\nfilename = \nrules.toml\n\n\n\n\n\n# rules.toml\n[backends]\n  [backends.backend1]\n    [backends.backend1.circuitbreaker]\n    expression = \nNetworkErrorRatio() \n 0.5\n\n    [backends.backend1.servers.server1]\n    url = \nhttp://172.17.0.2:80\n\n    weight = 10\n    [backends.backend1.servers.server2]\n    url = \nhttp://172.17.0.3:80\n\n    weight = 1\n  [backends.backend2]\n    [backends.backend2.maxconn]\n    amount = 10\n    extractorfunc = \nrequest.host\n\n    [backends.backend2.LoadBalancer]\n    method = \ndrr\n\n    [backends.backend2.servers.server1]\n    url = \nhttp://172.17.0.4:80\n\n    weight = 1\n    [backends.backend2.servers.server2]\n    url = \nhttp://172.17.0.5:80\n\n    weight = 2\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend2\n\n    [frontends.frontend1.routes.test_1]\n    rule = \nHost:test.localhost\n\n  [frontends.frontend2]\n  backend = \nbackend1\n\n  passHostHeader = true\n  priority = 10\n  entrypoints = [\nhttps\n] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule = \nHost:{subdomain:[a-z]+}.localhost\n\n  [frontends.frontend3]\n  entrypoints = [\nhttp\n, \nhttps\n] # overrides defaultEntryPoints\n  backend = \nbackend2\n\n  rule = \nPath:/test\n\n\n\n\n\nMultiple \n.toml\n Files\n\n\nYou could have multiple \n.toml\n files in a directory:\n\n\n[file]\ndirectory = \n/path/to/config/\n\n\n\n\n\nIf you want Tr\u00e6fik to watch file changes automatically, just add:\n\n\n[file]\nwatch = true", 
            "title": "Backend: File"
        }, 
        {
            "location": "/configuration/backends/file/#file-backends", 
            "text": "Like any other reverse proxy, Tr\u00e6fik can be configured with a file.  You have three choices:   Simple  Rules in a Separate File  Multiple  .toml  Files   To enable the file backend, you must either pass the  --file  option to the Tr\u00e6fik binary or put the  [file]  section (with or without inner settings) in the configuration file.", 
            "title": "File Backends"
        }, 
        {
            "location": "/configuration/backends/file/#simple", 
            "text": "Add your configuration at the end of the global configuration file  traefik.toml :  defaultEntryPoints = [ http ,  https ]\n\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n    [entryPoints.http.redirect]\n    entryPoint =  https \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile =  integration/fixtures/https/snitest.com.cert \n      KeyFile =  integration/fixtures/https/snitest.com.key \n      [[entryPoints.https.tls.certificates]]\n      CertFile =  integration/fixtures/https/snitest.org.cert \n      KeyFile =  integration/fixtures/https/snitest.org.key \n\n[file]\n\n# rules\n[backends]\n  [backends.backend1]\n    [backends.backend1.circuitbreaker]\n    expression =  NetworkErrorRatio()   0.5 \n    [backends.backend1.servers.server1]\n    url =  http://172.17.0.2:80 \n    weight = 10\n    [backends.backend1.servers.server2]\n    url =  http://172.17.0.3:80 \n    weight = 1\n  [backends.backend2]\n    [backends.backend2.maxconn]\n    amount = 10\n    extractorfunc =  request.host \n    [backends.backend2.LoadBalancer]\n    method =  drr \n    [backends.backend2.servers.server1]\n    url =  http://172.17.0.4:80 \n    weight = 1\n    [backends.backend2.servers.server2]\n    url =  http://172.17.0.5:80 \n    weight = 2\n\n[frontends]\n  [frontends.frontend1]\n  backend =  backend2 \n    [frontends.frontend1.routes.test_1]\n    rule =  Host:test.localhost \n\n  [frontends.frontend2]\n  backend =  backend1 \n  passHostHeader = true\n  priority = 10\n\n  # restrict access to this frontend to the specified list of IPv4/IPv6 CIDR Nets\n  # an unset or empty list allows all Source-IPs to access\n  # if one of the Net-Specifications are invalid, the whole list is invalid\n  # and allows all Source-IPs to access.\n  whitelistSourceRange = [ 10.42.0.0/16 ,  152.89.1.33/32 ,  afed:be44::/16 ]\n\n  entrypoints = [ https ] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule =  Host:{subdomain:[a-z]+}.localhost \n\n  [frontends.frontend3]\n  entrypoints = [ http ,  https ] # overrides defaultEntryPoints\n  backend =  backend2 \n  rule =  Path:/test", 
            "title": "Simple"
        }, 
        {
            "location": "/configuration/backends/file/#rules-in-a-separate-file", 
            "text": "Put your rules in a separate file, for example  rules.toml :  # traefik.toml\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n    [entryPoints.http.redirect]\n      entryPoint =  https \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile =  integration/fixtures/https/snitest.com.cert \n      KeyFile =  integration/fixtures/https/snitest.com.key \n      [[entryPoints.https.tls.certificates]]\n      CertFile =  integration/fixtures/https/snitest.org.cert \n      KeyFile =  integration/fixtures/https/snitest.org.key \n\n[file]\nfilename =  rules.toml   # rules.toml\n[backends]\n  [backends.backend1]\n    [backends.backend1.circuitbreaker]\n    expression =  NetworkErrorRatio()   0.5 \n    [backends.backend1.servers.server1]\n    url =  http://172.17.0.2:80 \n    weight = 10\n    [backends.backend1.servers.server2]\n    url =  http://172.17.0.3:80 \n    weight = 1\n  [backends.backend2]\n    [backends.backend2.maxconn]\n    amount = 10\n    extractorfunc =  request.host \n    [backends.backend2.LoadBalancer]\n    method =  drr \n    [backends.backend2.servers.server1]\n    url =  http://172.17.0.4:80 \n    weight = 1\n    [backends.backend2.servers.server2]\n    url =  http://172.17.0.5:80 \n    weight = 2\n\n[frontends]\n  [frontends.frontend1]\n  backend =  backend2 \n    [frontends.frontend1.routes.test_1]\n    rule =  Host:test.localhost \n  [frontends.frontend2]\n  backend =  backend1 \n  passHostHeader = true\n  priority = 10\n  entrypoints = [ https ] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule =  Host:{subdomain:[a-z]+}.localhost \n  [frontends.frontend3]\n  entrypoints = [ http ,  https ] # overrides defaultEntryPoints\n  backend =  backend2 \n  rule =  Path:/test", 
            "title": "Rules in a Separate File"
        }, 
        {
            "location": "/configuration/backends/file/#multiple-toml-files", 
            "text": "You could have multiple  .toml  files in a directory:  [file]\ndirectory =  /path/to/config/   If you want Tr\u00e6fik to watch file changes automatically, just add:  [file]\nwatch = true", 
            "title": "Multiple .toml Files"
        }, 
        {
            "location": "/configuration/backends/kubernetes/", 
            "text": "Kubernetes Ingress Backend\n\n\nTr\u00e6fik can be configured to use Kubernetes Ingress as a backend configuration.\n\n\nSee also \nKubernetes user guide\n. \n\n\nConfiguration\n\n\n################################################################\n# Kubernetes Ingress configuration backend\n################################################################\n\n# Enable Kubernetes Ingress configuration backend.\n[kubernetes]\n\n# Kubernetes server endpoint.\n#\n# Optional for in-cluster configuration, required otherwise.\n# Default: empty\n#\n# endpoint = \nhttp://localhost:8080\n\n\n# Bearer token used for the Kubernetes client configuration.\n#\n# Optional\n# Default: empty\n#\n# token = \nmy token\n\n\n# Path to the certificate authority file.\n# Used for the Kubernetes client configuration.\n#\n# Optional\n# Default: empty\n#\n# certAuthFilePath = \n/my/ca.crt\n\n\n# Array of namespaces to watch.\n#\n# Optional\n# Default: all namespaces (empty array).\n#\n# namespaces = [\ndefault\n, \nproduction\n]\n\n# Ingress label selector to identify Ingress objects that should be processed.\n#\n# Optional\n# Default: empty (process all Ingresses)\n#\n# labelselector = \nA and not B\n\n\n# Disable PassHost Headers.\n#\n# Optional\n# Default: false\n#\n# disablePassHostHeaders = true\n\n\n\n\nendpoint\n\n\nThe Kubernetes server endpoint.\n\n\nWhen deployed as a replication controller in Kubernetes, Traefik will use the environment variables \nKUBERNETES_SERVICE_HOST\n and \nKUBERNETES_SERVICE_PORT\n to construct the endpoint.\n\n\nSecure token will be found in \n/var/run/secrets/kubernetes.io/serviceaccount/token\n and SSL CA cert in \n/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n\n\nThe endpoint may be given to override the environment variable values.\n\n\nWhen the environment variables are not found, Traefik will try to connect to the Kubernetes API server with an external-cluster client.\nIn this case, the endpoint is required.\nSpecifically, it may be set to the URL used by \nkubectl proxy\n to connect to a Kubernetes cluster from localhost.\n\n\nlabelselector\n\n\nIngress label selector to identify Ingress objects that should be processed.\n\n\nSee \nlabel-selectors\n for details.\n\n\nAnnotations\n\n\nAnnotations can be used on containers to override default behaviour for the whole Ingress resource:\n\n\n\n\ntraefik.frontend.rule.type: PathPrefixStrip\n\n    Override the default frontend rule type. Default: \nPathPrefix\n.\n\n\ntraefik.frontend.priority: \"3\"\n\n    Override the default frontend rule priority.\n\n\n\n\nAnnotations can be used on the Kubernetes service to override default behaviour:\n\n\n\n\ntraefik.backend.loadbalancer.method=drr\n\n    Override the default \nwrr\n load balancer algorithm\n\n\ntraefik.backend.loadbalancer.stickiness=true\n    \n\n    Enable backend sticky sessions\n\n\ntraefik.backend.loadbalancer.stickiness.cookieName=NAME\n    \n\n    Manually set the cookie name for sticky sessions\n\n\ntraefik.backend.loadbalancer.sticky=true\n    \n\n    Enable backend sticky sessions (DEPRECATED)\n\n\n\n\nYou can find here an example \ningress\n and \nreplication controller\n.\n\n\nAdditionally, an annotation can be used on Kubernetes services to set the \ncircuit breaker expression\n for a backend.\n\n\n\n\ntraefik.backend.circuitbreaker: \nexpression\n\n    Set the circuit breaker expression for the backend. Default: \nnil\n.\n\n\n\n\nAs known from nginx when used as Kubernetes Ingress Controller, a list of IP-Ranges which are allowed to access can be configured by using an ingress annotation:\n\n\n\n\ningress.kubernetes.io/whitelist-source-range: \"1.2.3.0/24, fe80::/16\"\n\n\n\n\nAn unset or empty list allows all Source-IPs to access.\nIf one of the Net-Specifications are invalid, the whole list is invalid and allows all Source-IPs to access.\n\n\nAuthentication\n\n\nIs possible to add additional authentication annotations in the Ingress rule.\nThe source of the authentication is a secret that contains usernames and passwords inside the key auth.\n\n\n\n\ningress.kubernetes.io/auth-type\n: \nbasic\n\n\ningress.kubernetes.io/auth-secret\n: \nmysecret\n\n    Contains the usernames and passwords with access to the paths defined in the Ingress Rule.\n\n\n\n\nThe secret must be created in the same namespace as the Ingress rule.\n\n\nLimitations:\n\n\n\n\nBasic authentication only.\n\n\nRealm not configurable; only \ntraefik\n default.\n\n\nSecret must contain only single file.", 
            "title": "Backend: Kubernetes Ingress"
        }, 
        {
            "location": "/configuration/backends/kubernetes/#kubernetes-ingress-backend", 
            "text": "Tr\u00e6fik can be configured to use Kubernetes Ingress as a backend configuration.  See also  Kubernetes user guide .", 
            "title": "Kubernetes Ingress Backend"
        }, 
        {
            "location": "/configuration/backends/kubernetes/#configuration", 
            "text": "################################################################\n# Kubernetes Ingress configuration backend\n################################################################\n\n# Enable Kubernetes Ingress configuration backend.\n[kubernetes]\n\n# Kubernetes server endpoint.\n#\n# Optional for in-cluster configuration, required otherwise.\n# Default: empty\n#\n# endpoint =  http://localhost:8080 \n\n# Bearer token used for the Kubernetes client configuration.\n#\n# Optional\n# Default: empty\n#\n# token =  my token \n\n# Path to the certificate authority file.\n# Used for the Kubernetes client configuration.\n#\n# Optional\n# Default: empty\n#\n# certAuthFilePath =  /my/ca.crt \n\n# Array of namespaces to watch.\n#\n# Optional\n# Default: all namespaces (empty array).\n#\n# namespaces = [ default ,  production ]\n\n# Ingress label selector to identify Ingress objects that should be processed.\n#\n# Optional\n# Default: empty (process all Ingresses)\n#\n# labelselector =  A and not B \n\n# Disable PassHost Headers.\n#\n# Optional\n# Default: false\n#\n# disablePassHostHeaders = true", 
            "title": "Configuration"
        }, 
        {
            "location": "/configuration/backends/kubernetes/#endpoint", 
            "text": "The Kubernetes server endpoint.  When deployed as a replication controller in Kubernetes, Traefik will use the environment variables  KUBERNETES_SERVICE_HOST  and  KUBERNETES_SERVICE_PORT  to construct the endpoint.  Secure token will be found in  /var/run/secrets/kubernetes.io/serviceaccount/token  and SSL CA cert in  /var/run/secrets/kubernetes.io/serviceaccount/ca.crt  The endpoint may be given to override the environment variable values.  When the environment variables are not found, Traefik will try to connect to the Kubernetes API server with an external-cluster client.\nIn this case, the endpoint is required.\nSpecifically, it may be set to the URL used by  kubectl proxy  to connect to a Kubernetes cluster from localhost.", 
            "title": "endpoint"
        }, 
        {
            "location": "/configuration/backends/kubernetes/#labelselector", 
            "text": "Ingress label selector to identify Ingress objects that should be processed.  See  label-selectors  for details.", 
            "title": "labelselector"
        }, 
        {
            "location": "/configuration/backends/kubernetes/#annotations", 
            "text": "Annotations can be used on containers to override default behaviour for the whole Ingress resource:   traefik.frontend.rule.type: PathPrefixStrip \n    Override the default frontend rule type. Default:  PathPrefix .  traefik.frontend.priority: \"3\" \n    Override the default frontend rule priority.   Annotations can be used on the Kubernetes service to override default behaviour:   traefik.backend.loadbalancer.method=drr \n    Override the default  wrr  load balancer algorithm  traefik.backend.loadbalancer.stickiness=true      \n    Enable backend sticky sessions  traefik.backend.loadbalancer.stickiness.cookieName=NAME      \n    Manually set the cookie name for sticky sessions  traefik.backend.loadbalancer.sticky=true      \n    Enable backend sticky sessions (DEPRECATED)   You can find here an example  ingress  and  replication controller .  Additionally, an annotation can be used on Kubernetes services to set the  circuit breaker expression  for a backend.   traefik.backend.circuitbreaker:  expression \n    Set the circuit breaker expression for the backend. Default:  nil .   As known from nginx when used as Kubernetes Ingress Controller, a list of IP-Ranges which are allowed to access can be configured by using an ingress annotation:   ingress.kubernetes.io/whitelist-source-range: \"1.2.3.0/24, fe80::/16\"   An unset or empty list allows all Source-IPs to access.\nIf one of the Net-Specifications are invalid, the whole list is invalid and allows all Source-IPs to access.", 
            "title": "Annotations"
        }, 
        {
            "location": "/configuration/backends/kubernetes/#authentication", 
            "text": "Is possible to add additional authentication annotations in the Ingress rule.\nThe source of the authentication is a secret that contains usernames and passwords inside the key auth.   ingress.kubernetes.io/auth-type :  basic  ingress.kubernetes.io/auth-secret :  mysecret \n    Contains the usernames and passwords with access to the paths defined in the Ingress Rule.   The secret must be created in the same namespace as the Ingress rule.  Limitations:   Basic authentication only.  Realm not configurable; only  traefik  default.  Secret must contain only single file.", 
            "title": "Authentication"
        }, 
        {
            "location": "/configuration/backends/marathon/", 
            "text": "Marathon Backend\n\n\nTr\u00e6fik can be configured to use Marathon as a backend configuration.\n\n\nSee also \nMarathon user guide\n.\n\n\nConfiguration\n\n\n################################################################\n# Mesos/Marathon configuration backend\n################################################################\n\n# Enable Marathon configuration backend.\n[marathon]\n\n# Marathon server endpoint.\n# You can also specify multiple endpoint for Marathon:\n# endpoint = \nhttp://10.241.1.71:8080,10.241.1.72:8080,10.241.1.73:8080\n\n#\n# Required\n# Default: \nhttp://127.0.0.1:8080\n\n#\nendpoint = \nhttp://127.0.0.1:8080\n\n\n# Enable watch Marathon changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Default domain used.\n# Can be overridden by setting the \ntraefik.domain\n label on an application.\n#\n# Required\n#\ndomain = \nmarathon.localhost\n\n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename = \nmarathon.tmpl\n\n\n# Expose Marathon apps by default in Traefik.\n#\n# Optional\n# Default: true\n#\n# exposedByDefault = false\n\n# Convert Marathon groups to subdomains.\n# Default behavior: /foo/bar/myapp =\n foo-bar-myapp.{defaultDomain}\n# with groupsAsSubDomains enabled: /foo/bar/myapp =\n myapp.bar.foo.{defaultDomain}\n#\n# Optional\n# Default: false\n#\n# groupsAsSubDomains = true\n\n# Enable compatibility with marathon-lb labels.\n#\n# Optional\n# Default: false\n#\n# marathonLBCompatibility = true\n\n# Enable Marathon basic authentication.\n#\n# Optional\n#\n#    [marathon.basic]\n#    httpBasicAuthUser = \nfoo\n\n#    httpBasicPassword = \nbar\n\n\n# TLS client configuration. https://golang.org/pkg/crypto/tls/#Config\n#\n# Optional\n#\n#    [marathon.TLS]\n#    CA = \n/etc/ssl/ca.crt\n\n#    Cert = \n/etc/ssl/marathon.cert\n\n#    Key = \n/etc/ssl/marathon.key\n\n#    InsecureSkipVerify = true\n\n# DCOSToken for DCOS environment.\n# This will override the Authorization header.\n#\n# Optional\n#\n# dcosToken = \nxxxxxx\n\n\n# Override DialerTimeout.\n# Amount of time to allow the Marathon provider to wait to open a TCP connection\n# to a Marathon master.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits).\n# If no units are provided, the value is parsed assuming seconds.\n#\n# Optional\n# Default: \n60s\n\n#\n# dialerTimeout = \n60s\n\n\n# Set the TCP Keep Alive interval for the Marathon HTTP Client.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits).\n# If no units are provided, the value is parsed assuming seconds.\n#\n# Optional\n# Default: \n10s\n\n#\n# keepAlive = \n10s\n\n\n# By default, a task's IP address (as returned by the Marathon API) is used as\n# backend server if an IP-per-task configuration can be found; otherwise, the\n# name of the host running the task is used.\n# The latter behavior can be enforced by enabling this switch.\n#\n# Optional\n# Default: false\n#\n# forceTaskHostname = true\n\n# Applications may define readiness checks which are probed by Marathon during\n# deployments periodically and the results exposed via the API.\n# Enabling the following parameter causes Traefik to filter out tasks\n# whose readiness checks have not succeeded.\n# Note that the checks are only valid at deployment times.\n# See the Marathon guide for details.\n#\n# Optional\n# Default: false\n#\n# respectReadinessChecks = true\n\n\n\n\nTo enable constraints see \nbackend-specific constraints section\n.\n\n\nLabels: overriding default behaviour\n\n\nOn Containers\n\n\nLabels can be used on containers to override default behaviour:\n\n\n\n\n\n\n\n\nLabel\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntraefik.backend=foo\n\n\nassign the application to \nfoo\n backend\n\n\n\n\n\n\ntraefik.backend.maxconn.amount=10\n\n\nset a maximum number of connections to the backend. Must be used in conjunction with the below label to take effect.\n\n\n\n\n\n\ntraefik.backend.maxconn.extractorfunc=client.ip\n\n\nset the function to be used against the request to determine what to limit maximum connections to the backend by. Must be used in conjunction with the above label to take effect.\n\n\n\n\n\n\ntraefik.backend.loadbalancer.method=drr\n\n\noverride the default \nwrr\n load balancer algorithm\n\n\n\n\n\n\ntraefik.backend.loadbalancer.sticky=true\n\n\nenable backend sticky sessions (DEPRECATED)\n\n\n\n\n\n\ntraefik.backend.loadbalancer.stickiness=true\n\n\nenable backend sticky sessions\n\n\n\n\n\n\ntraefik.backend.loadbalancer.stickiness.cookieName=NAME\n\n\nManually set the cookie name for sticky sessions\n\n\n\n\n\n\ntraefik.backend.circuitbreaker.expression=NetworkErrorRatio() \n 0.5\n\n\ncreate a \ncircuit breaker\n to be used against the backend\n\n\n\n\n\n\ntraefik.backend.healthcheck.path=/health\n\n\nset the Traefik health check path [default: no health checks]\n\n\n\n\n\n\ntraefik.backend.healthcheck.interval=5s\n\n\nsets a custom health check interval in Go-parseable (\ntime.ParseDuration\n) format [default: 30s]\n\n\n\n\n\n\ntraefik.portIndex=1\n\n\nregister port by index in the application's ports array. Useful when the application exposes multiple ports.\n\n\n\n\n\n\ntraefik.port=80\n\n\nregister the explicit application port value. Cannot be used alongside \ntraefik.portIndex\n.\n\n\n\n\n\n\ntraefik.protocol=https\n\n\noverride the default \nhttp\n protocol\n\n\n\n\n\n\ntraefik.weight=10\n\n\nassign this weight to the application\n\n\n\n\n\n\ntraefik.enable=false\n\n\ndisable this application in Tr\u00e6fik\n\n\n\n\n\n\ntraefik.frontend.rule=Host:test.traefik.io\n\n\noverride the default frontend rule (Default: \nHost:{containerName}.{domain}\n).\n\n\n\n\n\n\ntraefik.frontend.passHostHeader=true\n\n\nforward client \nHost\n header to the backend.\n\n\n\n\n\n\ntraefik.frontend.priority=10\n\n\noverride default frontend priority\n\n\n\n\n\n\ntraefik.frontend.entryPoints=http,https\n\n\nassign this frontend to entry points \nhttp\n and \nhttps\n. Overrides \ndefaultEntryPoints\n.\n\n\n\n\n\n\ntraefik.frontend.auth.basic=EXPR\n\n\nSets basic authentication for that frontend in CSV format: \nUser:Hash,User:Hash\n.\n\n\n\n\n\n\n\n\nOn Services\n\n\nIf several ports need to be exposed from a container, the services labels can be used:\n\n\n\n\n\n\n\n\nLabel\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntraefik.\nservice-name\n.port=443\n\n\ncreate a service binding with frontend/backend using this port. Overrides \ntraefik.port\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.portIndex=1\n\n\ncreate a service binding with frontend/backend using this port index. Overrides \ntraefik.portIndex\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.protocol=https\n\n\nassign \nhttps\n protocol. Overrides \ntraefik.protocol\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.weight=10\n\n\nassign this service weight. Overrides \ntraefik.weight\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.backend=fooBackend\n\n\nassign this service frontend to \nfoobackend\n. Default is to assign to the service backend.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.entryPoints=http\n\n\nassign this service entrypoints. Overrides \ntraefik.frontend.entrypoints\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.auth.basic=test:EXPR\n\n\nSets basic authentication for that frontend in CSV format: \nUser:Hash,User:Hash\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.passHostHeader=true\n\n\nForward client \nHost\n header to the backend. Overrides \ntraefik.frontend.passHostHeader\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.priority=10\n\n\nassign the service frontend priority. Overrides \ntraefik.frontend.priority\n.\n\n\n\n\n\n\ntraefik.\nservice-name\n.frontend.rule=Path:/foo\n\n\nassign the service frontend rule. Overrides \ntraefik.frontend.rule\n.", 
            "title": "Backend: Marathon"
        }, 
        {
            "location": "/configuration/backends/marathon/#marathon-backend", 
            "text": "Tr\u00e6fik can be configured to use Marathon as a backend configuration.  See also  Marathon user guide .", 
            "title": "Marathon Backend"
        }, 
        {
            "location": "/configuration/backends/marathon/#configuration", 
            "text": "################################################################\n# Mesos/Marathon configuration backend\n################################################################\n\n# Enable Marathon configuration backend.\n[marathon]\n\n# Marathon server endpoint.\n# You can also specify multiple endpoint for Marathon:\n# endpoint =  http://10.241.1.71:8080,10.241.1.72:8080,10.241.1.73:8080 \n#\n# Required\n# Default:  http://127.0.0.1:8080 \n#\nendpoint =  http://127.0.0.1:8080 \n\n# Enable watch Marathon changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Default domain used.\n# Can be overridden by setting the  traefik.domain  label on an application.\n#\n# Required\n#\ndomain =  marathon.localhost \n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename =  marathon.tmpl \n\n# Expose Marathon apps by default in Traefik.\n#\n# Optional\n# Default: true\n#\n# exposedByDefault = false\n\n# Convert Marathon groups to subdomains.\n# Default behavior: /foo/bar/myapp =  foo-bar-myapp.{defaultDomain}\n# with groupsAsSubDomains enabled: /foo/bar/myapp =  myapp.bar.foo.{defaultDomain}\n#\n# Optional\n# Default: false\n#\n# groupsAsSubDomains = true\n\n# Enable compatibility with marathon-lb labels.\n#\n# Optional\n# Default: false\n#\n# marathonLBCompatibility = true\n\n# Enable Marathon basic authentication.\n#\n# Optional\n#\n#    [marathon.basic]\n#    httpBasicAuthUser =  foo \n#    httpBasicPassword =  bar \n\n# TLS client configuration. https://golang.org/pkg/crypto/tls/#Config\n#\n# Optional\n#\n#    [marathon.TLS]\n#    CA =  /etc/ssl/ca.crt \n#    Cert =  /etc/ssl/marathon.cert \n#    Key =  /etc/ssl/marathon.key \n#    InsecureSkipVerify = true\n\n# DCOSToken for DCOS environment.\n# This will override the Authorization header.\n#\n# Optional\n#\n# dcosToken =  xxxxxx \n\n# Override DialerTimeout.\n# Amount of time to allow the Marathon provider to wait to open a TCP connection\n# to a Marathon master.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits).\n# If no units are provided, the value is parsed assuming seconds.\n#\n# Optional\n# Default:  60s \n#\n# dialerTimeout =  60s \n\n# Set the TCP Keep Alive interval for the Marathon HTTP Client.\n# Can be provided in a format supported by [time.ParseDuration](https://golang.org/pkg/time/#ParseDuration) or as raw\n# values (digits).\n# If no units are provided, the value is parsed assuming seconds.\n#\n# Optional\n# Default:  10s \n#\n# keepAlive =  10s \n\n# By default, a task's IP address (as returned by the Marathon API) is used as\n# backend server if an IP-per-task configuration can be found; otherwise, the\n# name of the host running the task is used.\n# The latter behavior can be enforced by enabling this switch.\n#\n# Optional\n# Default: false\n#\n# forceTaskHostname = true\n\n# Applications may define readiness checks which are probed by Marathon during\n# deployments periodically and the results exposed via the API.\n# Enabling the following parameter causes Traefik to filter out tasks\n# whose readiness checks have not succeeded.\n# Note that the checks are only valid at deployment times.\n# See the Marathon guide for details.\n#\n# Optional\n# Default: false\n#\n# respectReadinessChecks = true  To enable constraints see  backend-specific constraints section .", 
            "title": "Configuration"
        }, 
        {
            "location": "/configuration/backends/marathon/#labels-overriding-default-behaviour", 
            "text": "", 
            "title": "Labels: overriding default behaviour"
        }, 
        {
            "location": "/configuration/backends/marathon/#on-containers", 
            "text": "Labels can be used on containers to override default behaviour:     Label  Description      traefik.backend=foo  assign the application to  foo  backend    traefik.backend.maxconn.amount=10  set a maximum number of connections to the backend. Must be used in conjunction with the below label to take effect.    traefik.backend.maxconn.extractorfunc=client.ip  set the function to be used against the request to determine what to limit maximum connections to the backend by. Must be used in conjunction with the above label to take effect.    traefik.backend.loadbalancer.method=drr  override the default  wrr  load balancer algorithm    traefik.backend.loadbalancer.sticky=true  enable backend sticky sessions (DEPRECATED)    traefik.backend.loadbalancer.stickiness=true  enable backend sticky sessions    traefik.backend.loadbalancer.stickiness.cookieName=NAME  Manually set the cookie name for sticky sessions    traefik.backend.circuitbreaker.expression=NetworkErrorRatio()   0.5  create a  circuit breaker  to be used against the backend    traefik.backend.healthcheck.path=/health  set the Traefik health check path [default: no health checks]    traefik.backend.healthcheck.interval=5s  sets a custom health check interval in Go-parseable ( time.ParseDuration ) format [default: 30s]    traefik.portIndex=1  register port by index in the application's ports array. Useful when the application exposes multiple ports.    traefik.port=80  register the explicit application port value. Cannot be used alongside  traefik.portIndex .    traefik.protocol=https  override the default  http  protocol    traefik.weight=10  assign this weight to the application    traefik.enable=false  disable this application in Tr\u00e6fik    traefik.frontend.rule=Host:test.traefik.io  override the default frontend rule (Default:  Host:{containerName}.{domain} ).    traefik.frontend.passHostHeader=true  forward client  Host  header to the backend.    traefik.frontend.priority=10  override default frontend priority    traefik.frontend.entryPoints=http,https  assign this frontend to entry points  http  and  https . Overrides  defaultEntryPoints .    traefik.frontend.auth.basic=EXPR  Sets basic authentication for that frontend in CSV format:  User:Hash,User:Hash .", 
            "title": "On Containers"
        }, 
        {
            "location": "/configuration/backends/marathon/#on-services", 
            "text": "If several ports need to be exposed from a container, the services labels can be used:     Label  Description      traefik. service-name .port=443  create a service binding with frontend/backend using this port. Overrides  traefik.port .    traefik. service-name .portIndex=1  create a service binding with frontend/backend using this port index. Overrides  traefik.portIndex .    traefik. service-name .protocol=https  assign  https  protocol. Overrides  traefik.protocol .    traefik. service-name .weight=10  assign this service weight. Overrides  traefik.weight .    traefik. service-name .frontend.backend=fooBackend  assign this service frontend to  foobackend . Default is to assign to the service backend.    traefik. service-name .frontend.entryPoints=http  assign this service entrypoints. Overrides  traefik.frontend.entrypoints .    traefik. service-name .frontend.auth.basic=test:EXPR  Sets basic authentication for that frontend in CSV format:  User:Hash,User:Hash    traefik. service-name .frontend.passHostHeader=true  Forward client  Host  header to the backend. Overrides  traefik.frontend.passHostHeader .    traefik. service-name .frontend.priority=10  assign the service frontend priority. Overrides  traefik.frontend.priority .    traefik. service-name .frontend.rule=Path:/foo  assign the service frontend rule. Overrides  traefik.frontend.rule .", 
            "title": "On Services"
        }, 
        {
            "location": "/configuration/backends/mesos/", 
            "text": "Mesos Generic Backend\n\n\nTr\u00e6fik can be configured to use Mesos as a backend configuration.\n\n\n################################################################\n# Mesos configuration backend\n################################################################\n\n# Enable Mesos configuration backend.\n[mesos]\n\n# Mesos server endpoint.\n# You can also specify multiple endpoint for Mesos:\n# endpoint = \n192.168.35.40:5050,192.168.35.41:5050,192.168.35.42:5050\n\n# endpoint = \nzk://192.168.35.20:2181,192.168.35.21:2181,192.168.35.22:2181/mesos\n\n#\n# Required\n# Default: \nhttp://127.0.0.1:5050\n\n#\nendpoint = \nhttp://127.0.0.1:8080\n\n\n# Enable watch Mesos changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Default domain used.\n# Can be overridden by setting the \ntraefik.domain\n label on an application.\n#\n# Required\n#\ndomain = \nmesos.localhost\n\n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename = \nmesos.tmpl\n\n\n# Expose Mesos apps by default in Traefik.\n#\n# Optional\n# Default: true\n#\n# ExposedByDefault = false\n\n# TLS client configuration. https://golang.org/pkg/crypto/tls/#Config\n#\n# Optional\n#\n# [mesos.TLS]\n# InsecureSkipVerify = true\n\n# Zookeeper timeout (in seconds).\n#\n# Optional\n# Default: 30\n#\n# ZkDetectionTimeout = 30\n\n# Polling interval (in seconds).\n#\n# Optional\n# Default: 30\n#\n# RefreshSeconds = 30\n\n# IP sources (e.g. host, docker, mesos, rkt).\n#\n# Optional\n#\n# IPSources = \nhost\n\n\n# HTTP Timeout (in seconds).\n#\n# Optional\n# Default: 30\n#\n# StateTimeoutSecond = \n30\n\n\n# Convert groups to subdomains.\n# Default behavior: /foo/bar/myapp =\n foo-bar-myapp.{defaultDomain}\n# with groupsAsSubDomains enabled: /foo/bar/myapp =\n myapp.bar.foo.{defaultDomain}\n#\n# Optional\n# Default: false\n#\n# groupsAsSubDomains = true", 
            "title": "Backend: Mesos"
        }, 
        {
            "location": "/configuration/backends/mesos/#mesos-generic-backend", 
            "text": "Tr\u00e6fik can be configured to use Mesos as a backend configuration.  ################################################################\n# Mesos configuration backend\n################################################################\n\n# Enable Mesos configuration backend.\n[mesos]\n\n# Mesos server endpoint.\n# You can also specify multiple endpoint for Mesos:\n# endpoint =  192.168.35.40:5050,192.168.35.41:5050,192.168.35.42:5050 \n# endpoint =  zk://192.168.35.20:2181,192.168.35.21:2181,192.168.35.22:2181/mesos \n#\n# Required\n# Default:  http://127.0.0.1:5050 \n#\nendpoint =  http://127.0.0.1:8080 \n\n# Enable watch Mesos changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Default domain used.\n# Can be overridden by setting the  traefik.domain  label on an application.\n#\n# Required\n#\ndomain =  mesos.localhost \n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename =  mesos.tmpl \n\n# Expose Mesos apps by default in Traefik.\n#\n# Optional\n# Default: true\n#\n# ExposedByDefault = false\n\n# TLS client configuration. https://golang.org/pkg/crypto/tls/#Config\n#\n# Optional\n#\n# [mesos.TLS]\n# InsecureSkipVerify = true\n\n# Zookeeper timeout (in seconds).\n#\n# Optional\n# Default: 30\n#\n# ZkDetectionTimeout = 30\n\n# Polling interval (in seconds).\n#\n# Optional\n# Default: 30\n#\n# RefreshSeconds = 30\n\n# IP sources (e.g. host, docker, mesos, rkt).\n#\n# Optional\n#\n# IPSources =  host \n\n# HTTP Timeout (in seconds).\n#\n# Optional\n# Default: 30\n#\n# StateTimeoutSecond =  30 \n\n# Convert groups to subdomains.\n# Default behavior: /foo/bar/myapp =  foo-bar-myapp.{defaultDomain}\n# with groupsAsSubDomains enabled: /foo/bar/myapp =  myapp.bar.foo.{defaultDomain}\n#\n# Optional\n# Default: false\n#\n# groupsAsSubDomains = true", 
            "title": "Mesos Generic Backend"
        }, 
        {
            "location": "/configuration/backends/rancher/", 
            "text": "Rancher Backend\n\n\nTr\u00e6fik can be configured to use Rancher as a backend configuration.\n\n\nGlobal Configuration\n\n\n################################################################\n# Rancher configuration backend\n################################################################\n\n# Enable Rancher configuration backend.\n[rancher]\n\n# Default domain used.\n# Can be overridden by setting the \ntraefik.domain\n label on an service.\n#\n# Required\n#\ndomain = \nrancher.localhost\n\n\n# Enable watch Rancher changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Polling interval (in seconds).\n#\n# Optional\n# Default: 15\n#\nrefreshSeconds = 15\n\n# Expose Rancher services by default in Traefik.\n#\n# Optional\n# Default: true\n#\nexposedByDefault = false\n\n# Filter services with unhealthy states and inactive states.\n#\n# Optional\n# Default: false\n#\nenableServiceHealthFilter = true\n\n\n\n\nTo enable constraints see \nbackend-specific constraints section\n.\n\n\nRancher Metadata Service\n\n\n# Enable Rancher metadata service configuration backend instead of the API\n# configuration backend.\n#\n# Optional\n# Default: false\n#\n[rancher.metadata]\n\n# Poll the Rancher metadata service for changes every `rancher.RefreshSeconds`.\n# NOTE: this is less accurate than the default long polling technique which\n# will provide near instantaneous updates to Traefik\n#\n# Optional\n# Default: false\n#\nintervalPoll = true\n\n# Prefix used for accessing the Rancher metadata service.\n#\n# Optional\n# Default: \n/latest\n\n#\nprefix = \n/2016-07-29\n\n\n\n\n\nRancher API\n\n\n# Enable Rancher API configuration backend.\n#\n# Optional\n# Default: true\n#\n[rancher.api]\n\n# Endpoint to use when connecting to the Rancher API.\n#\n# Required\nendpoint = \nhttp://rancherserver.example.com/v1\n\n\n# AccessKey to use when connecting to the Rancher API.\n#\n# Required\naccessKey = \nXXXXXXXXXXXXXXXXXXXX\n\n\n# SecretKey to use when connecting to the Rancher API.\n#\n# Required\nsecretKey = \nxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n\n\n\n\n\n\n\nNote\n\n\nIf Traefik needs access to the Rancher API, you need to set the \nendpoint\n, \naccesskey\n and \nsecretkey\n parameters.\n\n\nTo enable Traefik to fetch information about the Environment it's deployed in only, you need to create an \nEnvironment API Key\n.\nThis can be found within the API Key advanced options.\n\n\n\n\nLabels: overriding default behaviour\n\n\nLabels can be used on task containers to override default behaviour:\n\n\n\n\n\n\n\n\nLabel\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\ntraefik.protocol=https\n\n\nOverride the default \nhttp\n protocol\n\n\n\n\n\n\ntraefik.weight=10\n\n\nAssign this weight to the container\n\n\n\n\n\n\ntraefik.enable=false\n\n\nDisable this container in Tr\u00e6fik\n\n\n\n\n\n\ntraefik.frontend.rule=Host:test.traefik.io\n\n\nOverride the default frontend rule (Default: \nHost:{containerName}.{domain}\n).\n\n\n\n\n\n\ntraefik.frontend.passHostHeader=true\n\n\nForward client \nHost\n header to the backend.\n\n\n\n\n\n\ntraefik.frontend.priority=10\n\n\nOverride default frontend priority\n\n\n\n\n\n\ntraefik.frontend.entryPoints=http,https\n\n\nAssign this frontend to entry points \nhttp\n and \nhttps\n. Overrides \ndefaultEntryPoints\n.\n\n\n\n\n\n\ntraefik.frontend.auth.basic=EXPR\n\n\nSets basic authentication for that frontend in CSV format: \nUser:Hash,User:Hash\n.\n\n\n\n\n\n\ntraefik.backend.circuitbreaker.expression=NetworkErrorRatio() \n 0.5\n\n\nCreate a \ncircuit breaker\n to be used against the backend\n\n\n\n\n\n\ntraefik.backend.loadbalancer.method=drr\n\n\nOverride the default \nwrr\n load balancer algorithm\n\n\n\n\n\n\ntraefik.backend.loadbalancer.stickiness=true\n\n\nEnable backend sticky sessions\n\n\n\n\n\n\ntraefik.backend.loadbalancer.stickiness.cookieName=NAME\n\n\nManually set the cookie name for sticky sessions\n\n\n\n\n\n\ntraefik.backend.loadbalancer.sticky=true\n\n\nEnable backend sticky sessions (DEPRECATED)", 
            "title": "Backend: Rancher"
        }, 
        {
            "location": "/configuration/backends/rancher/#rancher-backend", 
            "text": "Tr\u00e6fik can be configured to use Rancher as a backend configuration.", 
            "title": "Rancher Backend"
        }, 
        {
            "location": "/configuration/backends/rancher/#global-configuration", 
            "text": "################################################################\n# Rancher configuration backend\n################################################################\n\n# Enable Rancher configuration backend.\n[rancher]\n\n# Default domain used.\n# Can be overridden by setting the  traefik.domain  label on an service.\n#\n# Required\n#\ndomain =  rancher.localhost \n\n# Enable watch Rancher changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Polling interval (in seconds).\n#\n# Optional\n# Default: 15\n#\nrefreshSeconds = 15\n\n# Expose Rancher services by default in Traefik.\n#\n# Optional\n# Default: true\n#\nexposedByDefault = false\n\n# Filter services with unhealthy states and inactive states.\n#\n# Optional\n# Default: false\n#\nenableServiceHealthFilter = true  To enable constraints see  backend-specific constraints section .", 
            "title": "Global Configuration"
        }, 
        {
            "location": "/configuration/backends/rancher/#rancher-metadata-service", 
            "text": "# Enable Rancher metadata service configuration backend instead of the API\n# configuration backend.\n#\n# Optional\n# Default: false\n#\n[rancher.metadata]\n\n# Poll the Rancher metadata service for changes every `rancher.RefreshSeconds`.\n# NOTE: this is less accurate than the default long polling technique which\n# will provide near instantaneous updates to Traefik\n#\n# Optional\n# Default: false\n#\nintervalPoll = true\n\n# Prefix used for accessing the Rancher metadata service.\n#\n# Optional\n# Default:  /latest \n#\nprefix =  /2016-07-29", 
            "title": "Rancher Metadata Service"
        }, 
        {
            "location": "/configuration/backends/rancher/#rancher-api", 
            "text": "# Enable Rancher API configuration backend.\n#\n# Optional\n# Default: true\n#\n[rancher.api]\n\n# Endpoint to use when connecting to the Rancher API.\n#\n# Required\nendpoint =  http://rancherserver.example.com/v1 \n\n# AccessKey to use when connecting to the Rancher API.\n#\n# Required\naccessKey =  XXXXXXXXXXXXXXXXXXXX \n\n# SecretKey to use when connecting to the Rancher API.\n#\n# Required\nsecretKey =  xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx    Note  If Traefik needs access to the Rancher API, you need to set the  endpoint ,  accesskey  and  secretkey  parameters.  To enable Traefik to fetch information about the Environment it's deployed in only, you need to create an  Environment API Key .\nThis can be found within the API Key advanced options.", 
            "title": "Rancher API"
        }, 
        {
            "location": "/configuration/backends/rancher/#labels-overriding-default-behaviour", 
            "text": "Labels can be used on task containers to override default behaviour:     Label  Description      traefik.protocol=https  Override the default  http  protocol    traefik.weight=10  Assign this weight to the container    traefik.enable=false  Disable this container in Tr\u00e6fik    traefik.frontend.rule=Host:test.traefik.io  Override the default frontend rule (Default:  Host:{containerName}.{domain} ).    traefik.frontend.passHostHeader=true  Forward client  Host  header to the backend.    traefik.frontend.priority=10  Override default frontend priority    traefik.frontend.entryPoints=http,https  Assign this frontend to entry points  http  and  https . Overrides  defaultEntryPoints .    traefik.frontend.auth.basic=EXPR  Sets basic authentication for that frontend in CSV format:  User:Hash,User:Hash .    traefik.backend.circuitbreaker.expression=NetworkErrorRatio()   0.5  Create a  circuit breaker  to be used against the backend    traefik.backend.loadbalancer.method=drr  Override the default  wrr  load balancer algorithm    traefik.backend.loadbalancer.stickiness=true  Enable backend sticky sessions    traefik.backend.loadbalancer.stickiness.cookieName=NAME  Manually set the cookie name for sticky sessions    traefik.backend.loadbalancer.sticky=true  Enable backend sticky sessions (DEPRECATED)", 
            "title": "Labels: overriding default behaviour"
        }, 
        {
            "location": "/configuration/backends/zookeeper/", 
            "text": "Zookeeper Backend\n\n\nTr\u00e6fik can be configured to use Zookeeper as a backend configuration.\n\n\n################################################################\n# Zookeeper configuration backend\n################################################################\n\n# Enable Zookeeperconfiguration backend.\n[zookeeper]\n\n# Zookeeper server endpoint.\n#\n# Required\n# Default: \n127.0.0.1:2181\n\n#\nendpoint = \n127.0.0.1:2181\n\n\n# Enable watch Zookeeper changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n# Default: \n/traefik\n\n#\nprefix = \n/traefik\n\n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename = \nzookeeper.tmpl\n\n\n# Use Zookeeper user/pass authentication.\n#\n# Optional\n#\n# username = foo\n# password = bar\n\n# Enable Zookeeper TLS connection.\n#\n# Optional\n#\n#    [zookeeper.tls]\n#    ca = \n/etc/ssl/ca.crt\n\n#    cert = \n/etc/ssl/zookeeper.crt\n\n#    key = \n/etc/ssl/zookeeper.key\n\n#    insecureskipverify = true\n\n\n\n\nTo enable constraints see \nbackend-specific constraints section\n.\n\n\nPlease refer to the \nKey Value storage structure\n section to get documentation on Traefik KV structure.", 
            "title": "Backend: Zookeeper"
        }, 
        {
            "location": "/configuration/backends/zookeeper/#zookeeper-backend", 
            "text": "Tr\u00e6fik can be configured to use Zookeeper as a backend configuration.  ################################################################\n# Zookeeper configuration backend\n################################################################\n\n# Enable Zookeeperconfiguration backend.\n[zookeeper]\n\n# Zookeeper server endpoint.\n#\n# Required\n# Default:  127.0.0.1:2181 \n#\nendpoint =  127.0.0.1:2181 \n\n# Enable watch Zookeeper changes.\n#\n# Optional\n# Default: true\n#\nwatch = true\n\n# Prefix used for KV store.\n#\n# Optional\n# Default:  /traefik \n#\nprefix =  /traefik \n\n# Override default configuration template.\n# For advanced users :)\n#\n# Optional\n#\n# filename =  zookeeper.tmpl \n\n# Use Zookeeper user/pass authentication.\n#\n# Optional\n#\n# username = foo\n# password = bar\n\n# Enable Zookeeper TLS connection.\n#\n# Optional\n#\n#    [zookeeper.tls]\n#    ca =  /etc/ssl/ca.crt \n#    cert =  /etc/ssl/zookeeper.crt \n#    key =  /etc/ssl/zookeeper.key \n#    insecureskipverify = true  To enable constraints see  backend-specific constraints section .  Please refer to the  Key Value storage structure  section to get documentation on Traefik KV structure.", 
            "title": "Zookeeper Backend"
        }, 
        {
            "location": "/user-guide/examples/", 
            "text": "Examples\n\n\nYou will find here some configuration examples of Tr\u00e6fik.\n\n\nHTTP only\n\n\ndefaultEntryPoints = [\nhttp\n]\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n\n\n\n\nHTTP + HTTPS (with SNI)\n\n\ndefaultEntryPoints = [\nhttp\n, \nhttps\n]\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile = \nintegration/fixtures/https/snitest.com.cert\n\n      keyFile = \nintegration/fixtures/https/snitest.com.key\n\n      [[entryPoints.https.tls.certificates]]\n      certFile = \nintegration/fixtures/https/snitest.org.cert\n\n      keyFile = \nintegration/fixtures/https/snitest.org.key\n\n\n\n\n\nNote that we can either give path to certificate file or directly the file content itself (\nlike in this TOML example\n).\n\n\nHTTP redirect on HTTPS\n\n\ndefaultEntryPoints = [\nhttp\n, \nhttps\n]\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n    [entryPoints.http.redirect]\n    entryPoint = \nhttps\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile = \nexamples/traefik.crt\n\n      keyFile = \nexamples/traefik.key\n\n\n\n\n\nLet's Encrypt support\n\n\nBasic example\n\n\n[entryPoints]\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n\n[acme]\nemail = \ntest@traefik.io\n\nstorage = \nacme.json\n\ncaServer = \nhttp://172.18.0.1:4000/directory\n\nentryPoint = \nhttps\n\n\n[[acme.domains]]\n  main = \nlocal1.com\n\n  sans = [\ntest1.local1.com\n, \ntest2.local1.com\n]\n[[acme.domains]]\n  main = \nlocal2.com\n\n  sans = [\ntest1.local2.com\n, \ntest2x.local2.com\n]\n[[acme.domains]]\n  main = \nlocal3.com\n\n[[acme.domains]]\n  main = \nlocal4.com\n\n\n\n\n\nThis configuration allows generating Let's Encrypt certificates for the four domains \nlocal[1-4].com\n with described SANs.\n\n\nTraefik generates these certificates when it starts and it needs to be restart if new domains are added.\n\n\nOnHostRule option\n\n\n[entryPoints]\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n\n[acme]\nemail = \ntest@traefik.io\n\nstorage = \nacme.json\n\nonHostRule = true\ncaServer = \nhttp://172.18.0.1:4000/directory\n\nentryPoint = \nhttps\n\n\n[[acme.domains]]\n  main = \nlocal1.com\n\n  sans = [\ntest1.local1.com\n, \ntest2.local1.com\n]\n[[acme.domains]]\n  main = \nlocal2.com\n\n  sans = [\ntest1.local2.com\n, \ntest2x.local2.com\n]\n[[acme.domains]]\n  main = \nlocal3.com\n\n[[acme.domains]]\n  main = \nlocal4.com\n\n\n\n\n\nThis configuration allows generating Let's Encrypt certificates for the four domains \nlocal[1-4].com\n.\n\n\nTraefik generates these certificates when it starts.\n\n\nIf a backend is added with a \nonHost\n rule, Traefik will automatically generate the Let's Encrypt certificate for the new domain.\n\n\nOnDemand option\n\n\n[entryPoints]\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n\n[acme]\nemail = \ntest@traefik.io\n\nstorage = \nacme.json\n\nonDemand = true\ncaServer = \nhttp://172.18.0.1:4000/directory\n\nentryPoint = \nhttps\n\n\n\n\n\nThis configuration allows generating a Let's Encrypt certificate during the first HTTPS request on a new domain.\n\n\n\n\nNote\n\n\nThis option simplifies the configuration but :\n\n\n\n\nTLS handshakes will be slow when requesting a hostname certificate for the first time, this can leads to DDoS attacks.\n\n\nLet's Encrypt have rate limiting: https://letsencrypt.org/docs/rate-limits\n\n\n\n\nThat's why, it's better to use the \nonHostRule\n option if possible.\n\n\n\n\nDNS challenge\n\n\n[entryPoints]\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n\n[acme]\nemail = \ntest@traefik.io\n\nstorage = \nacme.json\n\ndnsProvider = \ndigitalocean\n # DNS Provider name (cloudflare, OVH, gandi...)\ndelayDontCheckDNS = 0\ncaServer = \nhttp://172.18.0.1:4000/directory\n\nentryPoint = \nhttps\n\n\n[[acme.domains]]\n  main = \nlocal1.com\n\n  sans = [\ntest1.local1.com\n, \ntest2.local1.com\n]\n[[acme.domains]]\n  main = \nlocal2.com\n\n  sans = [\ntest1.local2.com\n, \ntest2x.local2.com\n]\n[[acme.domains]]\n  main = \nlocal3.com\n\n[[acme.domains]]\n  main = \nlocal4.com\n\n\n\n\n\nDNS challenge needs environment variables to be executed.\nThis variables have to be set on the machine/container which host Traefik.\n\n\nThese variables are described \nin this section\n.\n\n\nOnHostRule option and provided certificates\n\n\n[entryPoints]\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile = \nexamples/traefik.crt\n\n      keyFile = \nexamples/traefik.key\n\n\n[acme]\nemail = \ntest@traefik.io\n\nstorage = \nacme.json\n\nonHostRule = true\ncaServer = \nhttp://172.18.0.1:4000/directory\n\nentryPoint = \nhttps\n\n\n\n\n\n\nTraefik will only try to generate a Let's encrypt certificate if the domain cannot be checked by the provided certificates.\n\n\nCluster mode\n\n\nPrerequisites\n\n\nBefore you use Let's Encrypt in a Traefik cluster, take a look to \nthe key-value store explanations\n and more precisely at \nthis section\n, which will describe how to migrate from a acme local storage \n(acme.json file)\n to a key-value store configuration.\n\n\nConfiguration\n\n\n[entryPoints]\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n\n[acme]\nemail = \ntest@traefik.io\n\nstorage = \ntraefik/acme/account\n\ncaServer = \nhttp://172.18.0.1:4000/directory\n\nentryPoint = \nhttps\n\n\n[[acme.domains]]\n  main = \nlocal1.com\n\n  sans = [\ntest1.local1.com\n, \ntest2.local1.com\n]\n[[acme.domains]]\n  main = \nlocal2.com\n\n  sans = [\ntest1.local2.com\n, \ntest2x.local2.com\n]\n[[acme.domains]]\n  main = \nlocal3.com\n\n[[acme.domains]]\n  main = \nlocal4.com\n\n\n[consul]\n  endpoint = \n127.0.0.1:8500\n\n  watch = true\n  prefix = \ntraefik\n\n\n\n\n\nThis configuration allows to use the key \ntraefik/acme/account\n to get/set Let's Encrypt certificates content.\nThe \nconsul\n provider contains the configuration.\n\n\n\n\nNote\n\n\nIt's possible to use others key-value store providers as described \nhere\n.\n\n\n\n\nOverride entrypoints in frontends\n\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend2\n\n    [frontends.frontend1.routes.test_1]\n    rule = \nHost:test.localhost\n\n  [frontends.frontend2]\n  backend = \nbackend1\n\n  passHostHeader = true\n  passTLSCert = true\n  entrypoints = [\nhttps\n] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule = \nHost:{subdomain:[a-z]+}.localhost\n\n  [frontends.frontend3]\n  entrypoints = [\nhttp\n, \nhttps\n] # overrides defaultEntryPoints\n  backend = \nbackend2\n\n    rule = \nPath:/test\n\n\n\n\n\nEnable Basic authentication in an entrypoint\n\n\nWith two user/pass:\n\n\n\n\ntest\n:\ntest\n\n\ntest2\n:\ntest2\n\n\n\n\nPasswords are encoded in MD5: you can use htpasswd to generate those ones.\n\n\ndefaultEntryPoints = [\nhttp\n]\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.http.auth.basic]\n  users = [\ntest:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/\n, \ntest2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0\n]\n\n\n\n\nPass Authenticated user to application via headers\n\n\nProviding an authentication method as described above, it is possible to pass the user to the application\nvia a configurable header value.\n\n\ndefaultEntryPoints = [\nhttp\n]\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.http.auth]\n    headerField = \nX-WebAuth-User\n\n    [entryPoints.http.auth.basic]\n    users = [\ntest:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/\n, \ntest2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0\n]\n\n\n\n\nOverride the Traefik HTTP server IdleTimeout and/or throttle configurations from re-loading too quickly\n\n\nprovidersThrottleDuration = \n5s\n\n\n[respondingTimeouts]\nidleTimeout = \n360s\n\n\n\n\n\nSecuring Ping Health Check\n\n\nThe \n/ping\n health-check URL is enabled together with the web admin panel, enabled with the command-line \n--web\n or config file option \n[web]\n.\nThus, if you have a regular path for \n/foo\n and an entrypoint on \n:80\n, you would access them as follows:\n\n\n\n\nRegular path: \nhttp://hostname:80/foo\n\n\nAdmin panel: \nhttp://hostname:8080/\n\n\nPing URL: \nhttp://hostname:8080/ping\n\n\n\n\nHowever, for security reasons, you may want to be able to expose the \n/ping\n health-check URL to outside health-checkers, e.g. an Internet service or cloud load-balancer, \nwithout\n exposing your admin panel's port.\nIn many environments, the security staff may not \nallow\n you to expose it.\n\n\nYou have two options:\n\n\n\n\nEnable \n/ping\n on a regular entrypoint\n\n\nEnable \n/ping\n on a dedicated port\n\n\n\n\nEnable ping health check on a regular entrypoint\n\n\nTo proxy \n/ping\n from a regular entrypoint to the admin one without exposing the panel, do the following:\n\n\n[backends]\n  [backends.traefik]\n    [backends.traefik.servers.server1]\n    url = \nhttp://localhost:8080\n\n    weight = 10\n\n[frontends]\n  [frontends.traefikadmin]\n  backend = \ntraefik\n\n    [frontends.traefikadmin.routes.ping]\n    rule = \nPath:/ping\n\n\n\n\n\nThe above creates a new backend called \ntraefik\n, listening on \nhttp://localhost:8080\n, i.e. the local admin port.\nWe only expose the admin panel via the \nfrontend\n named \ntraefikadmin\n, and only expose the \n/ping\n Path.\nBe careful with the \ntraefikadmin\n frontend. If you do \nnot\n specify a \nPath:\n rule, you would expose the entire dashboard.\n\n\nEnable ping health check on dedicated port\n\n\nIf you do not want to or cannot expose the health-check on a regular entrypoint - e.g. your security rules do not allow it, or you have a conflicting path - then you can enable health-check on its own entrypoint.\nUse the following config:\n\n\ndefaultEntryPoints = [\nhttp\n]\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.ping]\n  address = \n:8082\n\n\n[backends]\n  [backends.traefik]\n    [backends.traefik.servers.server1]\n    url = \nhttp://localhost:8080\n\n    weight = 10\n\n[frontends]\n  [frontends.traefikadmin]\n  backend = \ntraefik\n\n  entrypoints = [\nping\n]\n    [frontends.traefikadmin.routes.ping]\n    rule = \nPath:/ping\n\n\n\n\n\nThe above is similar to the previous example, but instead of enabling \n/ping\n on the \ndefault\n entrypoint, we enable it on a \ndedicated\n entrypoint.\n\n\nIn the above example, you would access a regular path, admin panel and health-check as follows:\n\n\n\n\nRegular path: \nhttp://hostname:80/foo\n\n\nAdmin panel: \nhttp://hostname:8080/\n\n\nPing URL: \nhttp://hostname:8082/ping\n\n\n\n\nNote the dedicated port \n:8082\n for \n/ping\n.\n\n\nIn the above example, it is \nvery\n important to create a named dedicated entrypoint, and do \nnot\n include it in \ndefaultEntryPoints\n.\nOtherwise, you are likely to expose \nall\n services via that entrypoint.\n\n\nIn the above example, we have two entrypoints, \nhttp\n and \nping\n, but we only included \nhttp\n in \ndefaultEntryPoints\n, while explicitly tying \nfrontend.traefikadmin\n to the \nping\n entrypoint.\nThis ensures that all the \"normal\" frontends will be exposed via entrypoint \nhttp\n and \nnot\n via entrypoint \nping\n.", 
            "title": "Configuration Examples"
        }, 
        {
            "location": "/user-guide/examples/#examples", 
            "text": "You will find here some configuration examples of Tr\u00e6fik.", 
            "title": "Examples"
        }, 
        {
            "location": "/user-guide/examples/#http-only", 
            "text": "defaultEntryPoints = [ http ]\n[entryPoints]\n  [entryPoints.http]\n  address =  :80", 
            "title": "HTTP only"
        }, 
        {
            "location": "/user-guide/examples/#http-https-with-sni", 
            "text": "defaultEntryPoints = [ http ,  https ]\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile =  integration/fixtures/https/snitest.com.cert \n      keyFile =  integration/fixtures/https/snitest.com.key \n      [[entryPoints.https.tls.certificates]]\n      certFile =  integration/fixtures/https/snitest.org.cert \n      keyFile =  integration/fixtures/https/snitest.org.key   Note that we can either give path to certificate file or directly the file content itself ( like in this TOML example ).", 
            "title": "HTTP + HTTPS (with SNI)"
        }, 
        {
            "location": "/user-guide/examples/#http-redirect-on-https", 
            "text": "defaultEntryPoints = [ http ,  https ]\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n    [entryPoints.http.redirect]\n    entryPoint =  https \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile =  examples/traefik.crt \n      keyFile =  examples/traefik.key", 
            "title": "HTTP redirect on HTTPS"
        }, 
        {
            "location": "/user-guide/examples/#lets-encrypt-support", 
            "text": "", 
            "title": "Let's Encrypt support"
        }, 
        {
            "location": "/user-guide/examples/#basic-example", 
            "text": "[entryPoints]\n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n\n[acme]\nemail =  test@traefik.io \nstorage =  acme.json \ncaServer =  http://172.18.0.1:4000/directory \nentryPoint =  https \n\n[[acme.domains]]\n  main =  local1.com \n  sans = [ test1.local1.com ,  test2.local1.com ]\n[[acme.domains]]\n  main =  local2.com \n  sans = [ test1.local2.com ,  test2x.local2.com ]\n[[acme.domains]]\n  main =  local3.com \n[[acme.domains]]\n  main =  local4.com   This configuration allows generating Let's Encrypt certificates for the four domains  local[1-4].com  with described SANs.  Traefik generates these certificates when it starts and it needs to be restart if new domains are added.", 
            "title": "Basic example"
        }, 
        {
            "location": "/user-guide/examples/#onhostrule-option", 
            "text": "[entryPoints]\n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n\n[acme]\nemail =  test@traefik.io \nstorage =  acme.json \nonHostRule = true\ncaServer =  http://172.18.0.1:4000/directory \nentryPoint =  https \n\n[[acme.domains]]\n  main =  local1.com \n  sans = [ test1.local1.com ,  test2.local1.com ]\n[[acme.domains]]\n  main =  local2.com \n  sans = [ test1.local2.com ,  test2x.local2.com ]\n[[acme.domains]]\n  main =  local3.com \n[[acme.domains]]\n  main =  local4.com   This configuration allows generating Let's Encrypt certificates for the four domains  local[1-4].com .  Traefik generates these certificates when it starts.  If a backend is added with a  onHost  rule, Traefik will automatically generate the Let's Encrypt certificate for the new domain.", 
            "title": "OnHostRule option"
        }, 
        {
            "location": "/user-guide/examples/#ondemand-option", 
            "text": "[entryPoints]\n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n\n[acme]\nemail =  test@traefik.io \nstorage =  acme.json \nonDemand = true\ncaServer =  http://172.18.0.1:4000/directory \nentryPoint =  https   This configuration allows generating a Let's Encrypt certificate during the first HTTPS request on a new domain.   Note  This option simplifies the configuration but :   TLS handshakes will be slow when requesting a hostname certificate for the first time, this can leads to DDoS attacks.  Let's Encrypt have rate limiting: https://letsencrypt.org/docs/rate-limits   That's why, it's better to use the  onHostRule  option if possible.", 
            "title": "OnDemand option"
        }, 
        {
            "location": "/user-guide/examples/#dns-challenge", 
            "text": "[entryPoints]\n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n\n[acme]\nemail =  test@traefik.io \nstorage =  acme.json \ndnsProvider =  digitalocean  # DNS Provider name (cloudflare, OVH, gandi...)\ndelayDontCheckDNS = 0\ncaServer =  http://172.18.0.1:4000/directory \nentryPoint =  https \n\n[[acme.domains]]\n  main =  local1.com \n  sans = [ test1.local1.com ,  test2.local1.com ]\n[[acme.domains]]\n  main =  local2.com \n  sans = [ test1.local2.com ,  test2x.local2.com ]\n[[acme.domains]]\n  main =  local3.com \n[[acme.domains]]\n  main =  local4.com   DNS challenge needs environment variables to be executed.\nThis variables have to be set on the machine/container which host Traefik.  These variables are described  in this section .", 
            "title": "DNS challenge"
        }, 
        {
            "location": "/user-guide/examples/#onhostrule-option-and-provided-certificates", 
            "text": "[entryPoints]\n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      certFile =  examples/traefik.crt \n      keyFile =  examples/traefik.key \n\n[acme]\nemail =  test@traefik.io \nstorage =  acme.json \nonHostRule = true\ncaServer =  http://172.18.0.1:4000/directory \nentryPoint =  https   Traefik will only try to generate a Let's encrypt certificate if the domain cannot be checked by the provided certificates.", 
            "title": "OnHostRule option and provided certificates"
        }, 
        {
            "location": "/user-guide/examples/#cluster-mode", 
            "text": "", 
            "title": "Cluster mode"
        }, 
        {
            "location": "/user-guide/examples/#prerequisites", 
            "text": "Before you use Let's Encrypt in a Traefik cluster, take a look to  the key-value store explanations  and more precisely at  this section , which will describe how to migrate from a acme local storage  (acme.json file)  to a key-value store configuration.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/user-guide/examples/#configuration", 
            "text": "[entryPoints]\n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n\n[acme]\nemail =  test@traefik.io \nstorage =  traefik/acme/account \ncaServer =  http://172.18.0.1:4000/directory \nentryPoint =  https \n\n[[acme.domains]]\n  main =  local1.com \n  sans = [ test1.local1.com ,  test2.local1.com ]\n[[acme.domains]]\n  main =  local2.com \n  sans = [ test1.local2.com ,  test2x.local2.com ]\n[[acme.domains]]\n  main =  local3.com \n[[acme.domains]]\n  main =  local4.com \n\n[consul]\n  endpoint =  127.0.0.1:8500 \n  watch = true\n  prefix =  traefik   This configuration allows to use the key  traefik/acme/account  to get/set Let's Encrypt certificates content.\nThe  consul  provider contains the configuration.   Note  It's possible to use others key-value store providers as described  here .", 
            "title": "Configuration"
        }, 
        {
            "location": "/user-guide/examples/#override-entrypoints-in-frontends", 
            "text": "[frontends]\n  [frontends.frontend1]\n  backend =  backend2 \n    [frontends.frontend1.routes.test_1]\n    rule =  Host:test.localhost \n  [frontends.frontend2]\n  backend =  backend1 \n  passHostHeader = true\n  passTLSCert = true\n  entrypoints = [ https ] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule =  Host:{subdomain:[a-z]+}.localhost \n  [frontends.frontend3]\n  entrypoints = [ http ,  https ] # overrides defaultEntryPoints\n  backend =  backend2 \n    rule =  Path:/test", 
            "title": "Override entrypoints in frontends"
        }, 
        {
            "location": "/user-guide/examples/#enable-basic-authentication-in-an-entrypoint", 
            "text": "With two user/pass:   test : test  test2 : test2   Passwords are encoded in MD5: you can use htpasswd to generate those ones.  defaultEntryPoints = [ http ]\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.http.auth.basic]\n  users = [ test:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/ ,  test2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0 ]", 
            "title": "Enable Basic authentication in an entrypoint"
        }, 
        {
            "location": "/user-guide/examples/#pass-authenticated-user-to-application-via-headers", 
            "text": "Providing an authentication method as described above, it is possible to pass the user to the application\nvia a configurable header value.  defaultEntryPoints = [ http ]\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.http.auth]\n    headerField =  X-WebAuth-User \n    [entryPoints.http.auth.basic]\n    users = [ test:$apr1$H6uskkkW$IgXLP6ewTrSuBkTrqE8wj/ ,  test2:$apr1$d9hr9HBB$4HxwgUir3HP4EsggP/QNo0 ]", 
            "title": "Pass Authenticated user to application via headers"
        }, 
        {
            "location": "/user-guide/examples/#override-the-traefik-http-server-idletimeout-andor-throttle-configurations-from-re-loading-too-quickly", 
            "text": "providersThrottleDuration =  5s \n\n[respondingTimeouts]\nidleTimeout =  360s", 
            "title": "Override the Traefik HTTP server IdleTimeout and/or throttle configurations from re-loading too quickly"
        }, 
        {
            "location": "/user-guide/examples/#securing-ping-health-check", 
            "text": "The  /ping  health-check URL is enabled together with the web admin panel, enabled with the command-line  --web  or config file option  [web] .\nThus, if you have a regular path for  /foo  and an entrypoint on  :80 , you would access them as follows:   Regular path:  http://hostname:80/foo  Admin panel:  http://hostname:8080/  Ping URL:  http://hostname:8080/ping   However, for security reasons, you may want to be able to expose the  /ping  health-check URL to outside health-checkers, e.g. an Internet service or cloud load-balancer,  without  exposing your admin panel's port.\nIn many environments, the security staff may not  allow  you to expose it.  You have two options:   Enable  /ping  on a regular entrypoint  Enable  /ping  on a dedicated port", 
            "title": "Securing Ping Health Check"
        }, 
        {
            "location": "/user-guide/examples/#enable-ping-health-check-on-a-regular-entrypoint", 
            "text": "To proxy  /ping  from a regular entrypoint to the admin one without exposing the panel, do the following:  [backends]\n  [backends.traefik]\n    [backends.traefik.servers.server1]\n    url =  http://localhost:8080 \n    weight = 10\n\n[frontends]\n  [frontends.traefikadmin]\n  backend =  traefik \n    [frontends.traefikadmin.routes.ping]\n    rule =  Path:/ping   The above creates a new backend called  traefik , listening on  http://localhost:8080 , i.e. the local admin port.\nWe only expose the admin panel via the  frontend  named  traefikadmin , and only expose the  /ping  Path.\nBe careful with the  traefikadmin  frontend. If you do  not  specify a  Path:  rule, you would expose the entire dashboard.", 
            "title": "Enable ping health check on a regular entrypoint"
        }, 
        {
            "location": "/user-guide/examples/#enable-ping-health-check-on-dedicated-port", 
            "text": "If you do not want to or cannot expose the health-check on a regular entrypoint - e.g. your security rules do not allow it, or you have a conflicting path - then you can enable health-check on its own entrypoint.\nUse the following config:  defaultEntryPoints = [ http ]\n\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.ping]\n  address =  :8082 \n\n[backends]\n  [backends.traefik]\n    [backends.traefik.servers.server1]\n    url =  http://localhost:8080 \n    weight = 10\n\n[frontends]\n  [frontends.traefikadmin]\n  backend =  traefik \n  entrypoints = [ ping ]\n    [frontends.traefikadmin.routes.ping]\n    rule =  Path:/ping   The above is similar to the previous example, but instead of enabling  /ping  on the  default  entrypoint, we enable it on a  dedicated  entrypoint.  In the above example, you would access a regular path, admin panel and health-check as follows:   Regular path:  http://hostname:80/foo  Admin panel:  http://hostname:8080/  Ping URL:  http://hostname:8082/ping   Note the dedicated port  :8082  for  /ping .  In the above example, it is  very  important to create a named dedicated entrypoint, and do  not  include it in  defaultEntryPoints .\nOtherwise, you are likely to expose  all  services via that entrypoint.  In the above example, we have two entrypoints,  http  and  ping , but we only included  http  in  defaultEntryPoints , while explicitly tying  frontend.traefikadmin  to the  ping  entrypoint.\nThis ensures that all the \"normal\" frontends will be exposed via entrypoint  http  and  not  via entrypoint  ping .", 
            "title": "Enable ping health check on dedicated port"
        }, 
        {
            "location": "/user-guide/swarm-mode/", 
            "text": "Docker Swarm (mode) cluster\n\n\nThis section explains how to create a multi-host docker cluster with swarm mode using \ndocker-machine\n and how to deploy Tr\u00e6fik on it.\n\n\nThe cluster consists of:\n\n\n\n\n3 servers\n\n\n1 manager\n\n\n2 workers\n\n\n1 \noverlay\n network (multi-host networking)\n\n\n\n\nPrerequisites\n\n\n\n\nYou will need to install \ndocker-machine\n\n\nYou will need the latest \nVirtualBox\n\n\n\n\nCluster provisioning\n\n\nFirst, let's create all the required nodes.\nIt's a shorter version of the \nswarm tutorial\n.\n\n\ndocker-machine create -d virtualbox manager\ndocker-machine create -d virtualbox worker1\ndocker-machine create -d virtualbox worker2\n\n\n\n\nThen, let's setup the cluster, in order:\n\n\n\n\ninitialize the cluster\n\n\nget the token for other host to join\n\n\non both workers, join the cluster with the token\n\n\n\n\ndocker-machine ssh manager \ndocker swarm init \\\n    --listen-addr $(docker-machine ip manager) \\\n    --advertise-addr $(docker-machine ip manager)\n\n\nexport worker_token=$(docker-machine ssh manager \ndocker swarm \\\njoin-token worker -q\n)\n\ndocker-machine ssh worker1 \ndocker swarm join \\\n    --token=${worker_token} \\\n    --listen-addr $(docker-machine ip worker1) \\\n    --advertise-addr $(docker-machine ip worker1) \\\n    $(docker-machine ip manager)\n\n\ndocker-machine ssh worker2 \ndocker swarm join \\\n    --token=${worker_token} \\\n    --listen-addr $(docker-machine ip worker2) \\\n    --advertise-addr $(docker-machine ip worker2) \\\n    $(docker-machine ip manager)\n\n\n\n\n\nLet's validate the cluster is up and running.\n\n\ndocker-machine ssh manager docker node ls\n\n\n\n\nID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS\n013v16l1sbuwjqcn7ucbu4jwt    worker1   Ready   Active\n8buzkquycd17jqjber0mo2gn8    worker2   Ready   Active\nfnpj8ozfc85zvahx2r540xfcf *  manager   Ready   Active        Leader\n\n\n\n\nFinally, let's create a network for Tr\u00e6fik to use.\n\n\ndocker-machine ssh manager \ndocker network create --driver=overlay traefik-net\n\n\n\n\n\nDeploy Tr\u00e6fik\n\n\nLet's deploy Tr\u00e6fik as a docker service in our cluster.\nThe only requirement for Tr\u00e6fik to work with swarm mode is that it needs to run on a manager node - we are going to use a \nconstraint\n for that.\n\n\ndocker-machine ssh manager \ndocker service create \\\n    --name traefik \\\n    --constraint=node.role==manager \\\n    --publish 80:80 --publish 8080:8080 \\\n    --mount type=bind,source=/var/run/docker.sock,target=/var/run/docker.sock \\\n    --network traefik-net \\\n    traefik \\\n    --docker \\\n    --docker.swarmmode \\\n    --docker.domain=traefik \\\n    --docker.watch \\\n    --web\n\n\n\n\n\nLet's explain this command:\n\n\n\n\n\n\n\n\nOption\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n--publish 80:80 --publish 8080:8080\n\n\nwe publish port \n80\n and \n8080\n on the cluster.\n\n\n\n\n\n\n--constraint=node.role==manager\n\n\nwe ask docker to schedule Tr\u00e6fik on a manager node.\n\n\n\n\n\n\n--mount type=bind,source=/var/run/docker.sock,target=/var/run/docker.sock\n\n\nwe bind mount the docker socket where Tr\u00e6fik is scheduled to be able to speak to the daemon.\n\n\n\n\n\n\n--network traefik-net\n\n\nwe attach the Tr\u00e6fik service (and thus the underlying container) to the \ntraefik-net\n network.\n\n\n\n\n\n\n--docker\n\n\nenable docker backend, and \n--docker.swarmmode\n to enable the swarm mode on Tr\u00e6fik.\n\n\n\n\n\n\n--web\n\n\nactivate the webUI on port 8080\n\n\n\n\n\n\n\n\nDeploy your apps\n\n\nWe can now deploy our app on the cluster, here \nwhoami\n, a simple web server in Go.\nWe start 2 services, on the \ntraefik-net\n network.\n\n\ndocker-machine ssh manager \ndocker service create \\\n    --name whoami0 \\\n    --label traefik.port=80 \\\n    --network traefik-net \\\n    emilevauge/whoami\n\n\ndocker-machine ssh manager \ndocker service create \\\n    --name whoami1 \\\n    --label traefik.port=80 \\\n    --network traefik-net \\\n    --label traefik.backend.loadbalancer.sticky=true \\\n    emilevauge/whoami\n\n\n\n\n\n\n\nNote\n\n\nWe set \nwhoami1\n to use sticky sessions (\n--label traefik.backend.loadbalancer.stickiness=true\n).\nWe'll demonstrate that later.\n\n\n\n\n\n\nNote\n\n\nIf using \ndocker stack deploy\n, there is \na specific way that the labels must be defined in the docker-compose file\n.\n\n\n\n\nCheck that everything is scheduled and started:\n\n\ndocker-machine ssh manager \ndocker service ls\n\n\n\n\n\nID            NAME     MODE        REPLICAS  IMAGE                     PORTS\nmoq3dq4xqv6t  traefik  replicated  1/1       traefik:latest            *:80-\n80/tcp,*:8080-\n8080/tcp\nysil6oto1wim  whoami0  replicated  1/1       emilevauge/whoami:latest\nz9re2mnl34k4  whoami1  replicated  1/1       emilevauge/whoami:latest\n\n\n\n\nAccess to your apps through Tr\u00e6fik\n\n\ncurl -H Host:whoami0.traefik http://$(docker-machine ip manager)\n\n\n\n\nHostname: 5b0b3d148359\nIP: 127.0.0.1\nIP: 10.0.0.8\nIP: 10.0.0.4\nIP: 172.18.0.5\nGET / HTTP/1.1\nHost: whoami0.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 10.255.0.2\nX-Forwarded-Host: whoami0.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4\n\n\n\n\ncurl -H Host:whoami1.traefik http://$(docker-machine ip manager)\n\n\n\n\nHostname: 3633163970f6\nIP: 127.0.0.1\nIP: 10.0.0.14\nIP: 10.0.0.6\nIP: 172.18.0.5\nGET / HTTP/1.1\nHost: whoami1.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 10.255.0.2\nX-Forwarded-Host: whoami1.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4\n\n\n\n\n\n\nNote\n\n\nAs Tr\u00e6fik is published, you can access it from any machine and not only the manager.\n\n\n\n\ncurl -H Host:whoami0.traefik http://$(docker-machine ip worker1)\n\n\n\n\nHostname: 5b0b3d148359\nIP: 127.0.0.1\nIP: 10.0.0.8\nIP: 10.0.0.4\nIP: 172.18.0.5\nGET / HTTP/1.1\nHost: whoami0.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 10.255.0.3\nX-Forwarded-Host: whoami0.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4\n\n\n\n\ncurl -H Host:whoami1.traefik http://$(docker-machine ip worker2)\n\n\n\n\nHostname: 3633163970f6\nIP: 127.0.0.1\nIP: 10.0.0.14\nIP: 10.0.0.6\nIP: 172.18.0.5\nGET / HTTP/1.1\nHost: whoami1.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 10.255.0.4\nX-Forwarded-Host: whoami1.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4\n\n\n\n\nScale both services\n\n\ndocker-machine ssh manager \ndocker service scale whoami0=5\n\ndocker-machine ssh manager \ndocker service scale whoami1=5\n\n\n\n\n\nCheck that we now have 5 replicas of each \nwhoami\n service:\n\n\ndocker-machine ssh manager \ndocker service ls\n\n\n\n\n\nID            NAME     MODE        REPLICAS  IMAGE                     PORTS\nmoq3dq4xqv6t  traefik  replicated  1/1       traefik:latest            *:80-\n80/tcp,*:8080-\n8080/tcp\nysil6oto1wim  whoami0  replicated  5/5       emilevauge/whoami:latest\nz9re2mnl34k4  whoami1  replicated  5/5       emilevauge/whoami:latest\n\n\n\n\nAccess to your \nwhoami0\n through Tr\u00e6fik multiple times.\n\n\nRepeat the following command multiple times and note that the Hostname changes each time as Traefik load balances each request against the 5 tasks:\n\n\ncurl -H Host:whoami0.traefik http://$(docker-machine ip manager)\n\n\n\n\nHostname: f3138d15b567\nIP: 127.0.0.1\nIP: 10.0.0.5\nIP: 10.0.0.4\nIP: 172.18.0.3\nGET / HTTP/1.1\nHost: whoami0.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 10.255.0.2\nX-Forwarded-Host: whoami0.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4\n\n\n\n\nDo the same against \nwhoami1\n:\n\n\ncurl -c cookies.txt -H Host:whoami1.traefik http://$(docker-machine ip manager)\n\n\n\n\nHostname: 348e2f7bf432\nIP: 127.0.0.1\nIP: 10.0.0.15\nIP: 10.0.0.6\nIP: 172.18.0.6\nGET / HTTP/1.1\nHost: whoami1.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 10.255.0.2\nX-Forwarded-Host: whoami1.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4\n\n\n\n\nBecause the sticky sessions require cookies to work, we used the \n-c cookies.txt\n option to store the cookie into a file.\nThe cookie contains the IP of the container to which the session sticks:\n\n\ncat ./cookies.txt\n\n\n\n\n# Netscape HTTP Cookie File\n# https://curl.haxx.se/docs/http-cookies.html\n# This file was generated by libcurl! Edit at your own risk.\n\nwhoami1.traefik FALSE  /  FALSE  0  _TRAEFIK_BACKEND  http://10.0.0.15:80\n\n\n\n\nIf you load the cookies file (\n-b cookies.txt\n) for the next request, you will see that stickiness is maintained:\n\n\ncurl -b cookies.txt -H Host:whoami1.traefik http://$(docker-machine ip manager)\n\n\n\n\nHostname: 348e2f7bf432\nIP: 127.0.0.1\nIP: 10.0.0.15\nIP: 10.0.0.6\nIP: 172.18.0.6\nGET / HTTP/1.1\nHost: whoami1.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nCookie: _TRAEFIK_BACKEND=http://10.0.0.15:80\nX-Forwarded-For: 10.255.0.2\nX-Forwarded-Host: whoami1.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4", 
            "title": "Swarm Mode Cluster"
        }, 
        {
            "location": "/user-guide/swarm-mode/#docker-swarm-mode-cluster", 
            "text": "This section explains how to create a multi-host docker cluster with swarm mode using  docker-machine  and how to deploy Tr\u00e6fik on it.  The cluster consists of:   3 servers  1 manager  2 workers  1  overlay  network (multi-host networking)", 
            "title": "Docker Swarm (mode) cluster"
        }, 
        {
            "location": "/user-guide/swarm-mode/#prerequisites", 
            "text": "You will need to install  docker-machine  You will need the latest  VirtualBox", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/user-guide/swarm-mode/#cluster-provisioning", 
            "text": "First, let's create all the required nodes.\nIt's a shorter version of the  swarm tutorial .  docker-machine create -d virtualbox manager\ndocker-machine create -d virtualbox worker1\ndocker-machine create -d virtualbox worker2  Then, let's setup the cluster, in order:   initialize the cluster  get the token for other host to join  on both workers, join the cluster with the token   docker-machine ssh manager  docker swarm init \\\n    --listen-addr $(docker-machine ip manager) \\\n    --advertise-addr $(docker-machine ip manager) \n\nexport worker_token=$(docker-machine ssh manager  docker swarm \\\njoin-token worker -q )\n\ndocker-machine ssh worker1  docker swarm join \\\n    --token=${worker_token} \\\n    --listen-addr $(docker-machine ip worker1) \\\n    --advertise-addr $(docker-machine ip worker1) \\\n    $(docker-machine ip manager) \n\ndocker-machine ssh worker2  docker swarm join \\\n    --token=${worker_token} \\\n    --listen-addr $(docker-machine ip worker2) \\\n    --advertise-addr $(docker-machine ip worker2) \\\n    $(docker-machine ip manager)   Let's validate the cluster is up and running.  docker-machine ssh manager docker node ls  ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS\n013v16l1sbuwjqcn7ucbu4jwt    worker1   Ready   Active\n8buzkquycd17jqjber0mo2gn8    worker2   Ready   Active\nfnpj8ozfc85zvahx2r540xfcf *  manager   Ready   Active        Leader  Finally, let's create a network for Tr\u00e6fik to use.  docker-machine ssh manager  docker network create --driver=overlay traefik-net", 
            "title": "Cluster provisioning"
        }, 
        {
            "location": "/user-guide/swarm-mode/#deploy-trfik", 
            "text": "Let's deploy Tr\u00e6fik as a docker service in our cluster.\nThe only requirement for Tr\u00e6fik to work with swarm mode is that it needs to run on a manager node - we are going to use a  constraint  for that.  docker-machine ssh manager  docker service create \\\n    --name traefik \\\n    --constraint=node.role==manager \\\n    --publish 80:80 --publish 8080:8080 \\\n    --mount type=bind,source=/var/run/docker.sock,target=/var/run/docker.sock \\\n    --network traefik-net \\\n    traefik \\\n    --docker \\\n    --docker.swarmmode \\\n    --docker.domain=traefik \\\n    --docker.watch \\\n    --web   Let's explain this command:     Option  Description      --publish 80:80 --publish 8080:8080  we publish port  80  and  8080  on the cluster.    --constraint=node.role==manager  we ask docker to schedule Tr\u00e6fik on a manager node.    --mount type=bind,source=/var/run/docker.sock,target=/var/run/docker.sock  we bind mount the docker socket where Tr\u00e6fik is scheduled to be able to speak to the daemon.    --network traefik-net  we attach the Tr\u00e6fik service (and thus the underlying container) to the  traefik-net  network.    --docker  enable docker backend, and  --docker.swarmmode  to enable the swarm mode on Tr\u00e6fik.    --web  activate the webUI on port 8080", 
            "title": "Deploy Tr\u00e6fik"
        }, 
        {
            "location": "/user-guide/swarm-mode/#deploy-your-apps", 
            "text": "We can now deploy our app on the cluster, here  whoami , a simple web server in Go.\nWe start 2 services, on the  traefik-net  network.  docker-machine ssh manager  docker service create \\\n    --name whoami0 \\\n    --label traefik.port=80 \\\n    --network traefik-net \\\n    emilevauge/whoami \n\ndocker-machine ssh manager  docker service create \\\n    --name whoami1 \\\n    --label traefik.port=80 \\\n    --network traefik-net \\\n    --label traefik.backend.loadbalancer.sticky=true \\\n    emilevauge/whoami    Note  We set  whoami1  to use sticky sessions ( --label traefik.backend.loadbalancer.stickiness=true ).\nWe'll demonstrate that later.    Note  If using  docker stack deploy , there is  a specific way that the labels must be defined in the docker-compose file .   Check that everything is scheduled and started:  docker-machine ssh manager  docker service ls   ID            NAME     MODE        REPLICAS  IMAGE                     PORTS\nmoq3dq4xqv6t  traefik  replicated  1/1       traefik:latest            *:80- 80/tcp,*:8080- 8080/tcp\nysil6oto1wim  whoami0  replicated  1/1       emilevauge/whoami:latest\nz9re2mnl34k4  whoami1  replicated  1/1       emilevauge/whoami:latest", 
            "title": "Deploy your apps"
        }, 
        {
            "location": "/user-guide/swarm-mode/#access-to-your-apps-through-trfik", 
            "text": "curl -H Host:whoami0.traefik http://$(docker-machine ip manager)  Hostname: 5b0b3d148359\nIP: 127.0.0.1\nIP: 10.0.0.8\nIP: 10.0.0.4\nIP: 172.18.0.5\nGET / HTTP/1.1\nHost: whoami0.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 10.255.0.2\nX-Forwarded-Host: whoami0.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4  curl -H Host:whoami1.traefik http://$(docker-machine ip manager)  Hostname: 3633163970f6\nIP: 127.0.0.1\nIP: 10.0.0.14\nIP: 10.0.0.6\nIP: 172.18.0.5\nGET / HTTP/1.1\nHost: whoami1.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 10.255.0.2\nX-Forwarded-Host: whoami1.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4   Note  As Tr\u00e6fik is published, you can access it from any machine and not only the manager.   curl -H Host:whoami0.traefik http://$(docker-machine ip worker1)  Hostname: 5b0b3d148359\nIP: 127.0.0.1\nIP: 10.0.0.8\nIP: 10.0.0.4\nIP: 172.18.0.5\nGET / HTTP/1.1\nHost: whoami0.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 10.255.0.3\nX-Forwarded-Host: whoami0.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4  curl -H Host:whoami1.traefik http://$(docker-machine ip worker2)  Hostname: 3633163970f6\nIP: 127.0.0.1\nIP: 10.0.0.14\nIP: 10.0.0.6\nIP: 172.18.0.5\nGET / HTTP/1.1\nHost: whoami1.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 10.255.0.4\nX-Forwarded-Host: whoami1.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4", 
            "title": "Access to your apps through Tr\u00e6fik"
        }, 
        {
            "location": "/user-guide/swarm-mode/#scale-both-services", 
            "text": "docker-machine ssh manager  docker service scale whoami0=5 \ndocker-machine ssh manager  docker service scale whoami1=5   Check that we now have 5 replicas of each  whoami  service:  docker-machine ssh manager  docker service ls   ID            NAME     MODE        REPLICAS  IMAGE                     PORTS\nmoq3dq4xqv6t  traefik  replicated  1/1       traefik:latest            *:80- 80/tcp,*:8080- 8080/tcp\nysil6oto1wim  whoami0  replicated  5/5       emilevauge/whoami:latest\nz9re2mnl34k4  whoami1  replicated  5/5       emilevauge/whoami:latest", 
            "title": "Scale both services"
        }, 
        {
            "location": "/user-guide/swarm-mode/#access-to-your-whoami0-through-trfik-multiple-times", 
            "text": "Repeat the following command multiple times and note that the Hostname changes each time as Traefik load balances each request against the 5 tasks:  curl -H Host:whoami0.traefik http://$(docker-machine ip manager)  Hostname: f3138d15b567\nIP: 127.0.0.1\nIP: 10.0.0.5\nIP: 10.0.0.4\nIP: 172.18.0.3\nGET / HTTP/1.1\nHost: whoami0.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 10.255.0.2\nX-Forwarded-Host: whoami0.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4  Do the same against  whoami1 :  curl -c cookies.txt -H Host:whoami1.traefik http://$(docker-machine ip manager)  Hostname: 348e2f7bf432\nIP: 127.0.0.1\nIP: 10.0.0.15\nIP: 10.0.0.6\nIP: 172.18.0.6\nGET / HTTP/1.1\nHost: whoami1.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 10.255.0.2\nX-Forwarded-Host: whoami1.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4  Because the sticky sessions require cookies to work, we used the  -c cookies.txt  option to store the cookie into a file.\nThe cookie contains the IP of the container to which the session sticks:  cat ./cookies.txt  # Netscape HTTP Cookie File\n# https://curl.haxx.se/docs/http-cookies.html\n# This file was generated by libcurl! Edit at your own risk.\n\nwhoami1.traefik FALSE  /  FALSE  0  _TRAEFIK_BACKEND  http://10.0.0.15:80  If you load the cookies file ( -b cookies.txt ) for the next request, you will see that stickiness is maintained:  curl -b cookies.txt -H Host:whoami1.traefik http://$(docker-machine ip manager)  Hostname: 348e2f7bf432\nIP: 127.0.0.1\nIP: 10.0.0.15\nIP: 10.0.0.6\nIP: 172.18.0.6\nGET / HTTP/1.1\nHost: whoami1.traefik\nUser-Agent: curl/7.55.1\nAccept: */*\nAccept-Encoding: gzip\nCookie: _TRAEFIK_BACKEND=http://10.0.0.15:80\nX-Forwarded-For: 10.255.0.2\nX-Forwarded-Host: whoami1.traefik\nX-Forwarded-Proto: http\nX-Forwarded-Server: 77fc29c69fe4", 
            "title": "Access to your whoami0 through Tr\u00e6fik multiple times."
        }, 
        {
            "location": "/user-guide/swarm/", 
            "text": "Swarm cluster\n\n\nThis section explains how to create a multi-host \nswarm\n cluster using \ndocker-machine\n and how to deploy Tr\u00e6fik on it.\n\n\nThe cluster consists of:\n\n\n\n\n2 servers\n\n\n1 swarm master\n\n\n2 swarm nodes\n\n\n1 \noverlay\n network (multi-host networking)\n\n\n\n\nPrerequisites\n\n\n\n\nYou need to install \ndocker-machine\n\n\nYou need the latest \nVirtualBox\n\n\n\n\nCluster provisioning\n\n\nWe first follow \nthis guide\n to create the cluster.\n\n\nCreate machine \nmh-keystore\n\n\nThis machine is the service registry of our cluster.\n\n\ndocker-machine create -d virtualbox mh-keystore\n\n\n\n\nThen we install the service registry \nConsul\n on this machine:\n\n\neval \n$(docker-machine env mh-keystore)\n\ndocker run -d \\\n    -p \n8500:8500\n \\\n    -h \nconsul\n \\\n    progrium/consul -server -bootstrap\n\n\n\n\nCreate machine \nmhs-demo0\n\n\nThis machine is a swarm master and a swarm agent on it.\n\n\ndocker-machine create -d virtualbox \\\n    --swarm --swarm-master \\\n    --swarm-discovery=\nconsul://$(docker-machine ip mh-keystore):8500\n \\\n    --engine-opt=\ncluster-store=consul://$(docker-machine ip mh-keystore):8500\n \\\n    --engine-opt=\ncluster-advertise=eth1:2376\n \\\n    mhs-demo0\n\n\n\n\nCreate machine \nmhs-demo1\n\n\nThis machine have a swarm agent on it.\n\n\ndocker-machine create -d virtualbox \\\n    --swarm \\\n    --swarm-discovery=\nconsul://$(docker-machine ip mh-keystore):8500\n \\\n    --engine-opt=\ncluster-store=consul://$(docker-machine ip mh-keystore):8500\n \\\n    --engine-opt=\ncluster-advertise=eth1:2376\n \\\n    mhs-demo1\n\n\n\n\nCreate the overlay Network\n\n\nCreate the overlay network on the swarm master:\n\n\neval $(docker-machine env --swarm mhs-demo0)\ndocker network create --driver overlay --subnet=10.0.9.0/24 my-net\n\n\n\n\nDeploy Tr\u00e6fik\n\n\nDeploy Tr\u00e6fik:\n\n\ndocker $(docker-machine config mhs-demo0) run \\\n    -d \\\n    -p 80:80 -p 8080:8080 \\\n    --net=my-net \\\n    -v /var/lib/boot2docker/:/ssl \\\n    traefik \\\n    -l DEBUG \\\n    -c /dev/null \\\n    --docker \\\n    --docker.domain=traefik \\\n    --docker.endpoint=tcp://$(docker-machine ip mhs-demo0):3376 \\\n    --docker.tls \\\n    --docker.tls.ca=/ssl/ca.pem \\\n    --docker.tls.cert=/ssl/server.pem \\\n    --docker.tls.key=/ssl/server-key.pem \\\n    --docker.tls.insecureSkipVerify \\\n    --docker.watch \\\n    --web\n\n\n\n\nLet's explain this command:\n\n\n\n\n\n\n\n\nOption\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n-p 80:80 -p 8080:8080\n\n\nwe bind ports 80 and 8080\n\n\n\n\n\n\n--net=my-net\n\n\nrun the container on the network my-net\n\n\n\n\n\n\n-v /var/lib/boot2docker/:/ssl\n\n\nmount the ssl keys generated by docker-machine\n\n\n\n\n\n\n-c /dev/null\n\n\nempty config file\n\n\n\n\n\n\n--docker\n\n\nenable docker backend\n\n\n\n\n\n\n--docker.endpoint=tcp://172.18.0.1:3376\n\n\nconnect to the swarm master using the docker_gwbridge network\n\n\n\n\n\n\n--docker.tls\n\n\nenable TLS using the docker-machine keys\n\n\n\n\n\n\n--web\n\n\nactivate the webUI on port 8080\n\n\n\n\n\n\n\n\nDeploy your apps\n\n\nWe can now deploy our app on the cluster, here \nwhoami\n, a simple web server in GO, on the network \nmy-net\n:\n\n\neval $(docker-machine env --swarm mhs-demo0)\ndocker run -d --name=whoami0 --net=my-net --env=\nconstraint:node==mhs-demo0\n emilevauge/whoami\ndocker run -d --name=whoami1 --net=my-net --env=\nconstraint:node==mhs-demo1\n emilevauge/whoami\n\n\n\n\nCheck that everything is started:\n\n\ndocker ps\n\n\n\n\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                                      NAMES\nba2c21488299        emilevauge/whoami   \n/whoamI\n                8 seconds ago       Up 9 seconds        80/tcp                                                     mhs-demo1/whoami1\n8147a7746e7a        emilevauge/whoami   \n/whoamI\n                19 seconds ago      Up 20 seconds       80/tcp                                                     mhs-demo0/whoami0\n8fbc39271b4c        traefik             \n/traefik -l DEBUG -c\n   36 seconds ago      Up 37 seconds       192.168.99.101:80-\n80/tcp, 192.168.99.101:8080-\n8080/tcp   mhs-demo0/serene_bhabha\n\n\n\n\nAccess to your apps through Tr\u00e6fik\n\n\ncurl -H Host:whoami0.traefik http://$(docker-machine ip mhs-demo0)\n\n\n\n\nHostname: 8147a7746e7a\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.3\nIP: fe80::42:aff:fe00:903\nIP: 172.18.0.3\nIP: fe80::42:acff:fe12:3\nGET / HTTP/1.1\nHost: 10.0.9.3:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.3:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c\n\n\n\n\ncurl -H Host:whoami1.traefik http://$(docker-machine ip mhs-demo0)\n\n\n\n\nHostname: ba2c21488299\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.4\nIP: fe80::42:aff:fe00:904\nIP: 172.18.0.2\nIP: fe80::42:acff:fe12:2\nGET / HTTP/1.1\nHost: 10.0.9.4:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.4:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c", 
            "title": "Swarm Cluster"
        }, 
        {
            "location": "/user-guide/swarm/#swarm-cluster", 
            "text": "This section explains how to create a multi-host  swarm  cluster using  docker-machine  and how to deploy Tr\u00e6fik on it.  The cluster consists of:   2 servers  1 swarm master  2 swarm nodes  1  overlay  network (multi-host networking)", 
            "title": "Swarm cluster"
        }, 
        {
            "location": "/user-guide/swarm/#prerequisites", 
            "text": "You need to install  docker-machine  You need the latest  VirtualBox", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/user-guide/swarm/#cluster-provisioning", 
            "text": "We first follow  this guide  to create the cluster.", 
            "title": "Cluster provisioning"
        }, 
        {
            "location": "/user-guide/swarm/#create-machine-mh-keystore", 
            "text": "This machine is the service registry of our cluster.  docker-machine create -d virtualbox mh-keystore  Then we install the service registry  Consul  on this machine:  eval  $(docker-machine env mh-keystore) \ndocker run -d \\\n    -p  8500:8500  \\\n    -h  consul  \\\n    progrium/consul -server -bootstrap", 
            "title": "Create machine mh-keystore"
        }, 
        {
            "location": "/user-guide/swarm/#create-machine-mhs-demo0", 
            "text": "This machine is a swarm master and a swarm agent on it.  docker-machine create -d virtualbox \\\n    --swarm --swarm-master \\\n    --swarm-discovery= consul://$(docker-machine ip mh-keystore):8500  \\\n    --engine-opt= cluster-store=consul://$(docker-machine ip mh-keystore):8500  \\\n    --engine-opt= cluster-advertise=eth1:2376  \\\n    mhs-demo0", 
            "title": "Create machine mhs-demo0"
        }, 
        {
            "location": "/user-guide/swarm/#create-machine-mhs-demo1", 
            "text": "This machine have a swarm agent on it.  docker-machine create -d virtualbox \\\n    --swarm \\\n    --swarm-discovery= consul://$(docker-machine ip mh-keystore):8500  \\\n    --engine-opt= cluster-store=consul://$(docker-machine ip mh-keystore):8500  \\\n    --engine-opt= cluster-advertise=eth1:2376  \\\n    mhs-demo1", 
            "title": "Create machine mhs-demo1"
        }, 
        {
            "location": "/user-guide/swarm/#create-the-overlay-network", 
            "text": "Create the overlay network on the swarm master:  eval $(docker-machine env --swarm mhs-demo0)\ndocker network create --driver overlay --subnet=10.0.9.0/24 my-net", 
            "title": "Create the overlay Network"
        }, 
        {
            "location": "/user-guide/swarm/#deploy-trfik", 
            "text": "Deploy Tr\u00e6fik:  docker $(docker-machine config mhs-demo0) run \\\n    -d \\\n    -p 80:80 -p 8080:8080 \\\n    --net=my-net \\\n    -v /var/lib/boot2docker/:/ssl \\\n    traefik \\\n    -l DEBUG \\\n    -c /dev/null \\\n    --docker \\\n    --docker.domain=traefik \\\n    --docker.endpoint=tcp://$(docker-machine ip mhs-demo0):3376 \\\n    --docker.tls \\\n    --docker.tls.ca=/ssl/ca.pem \\\n    --docker.tls.cert=/ssl/server.pem \\\n    --docker.tls.key=/ssl/server-key.pem \\\n    --docker.tls.insecureSkipVerify \\\n    --docker.watch \\\n    --web  Let's explain this command:     Option  Description      -p 80:80 -p 8080:8080  we bind ports 80 and 8080    --net=my-net  run the container on the network my-net    -v /var/lib/boot2docker/:/ssl  mount the ssl keys generated by docker-machine    -c /dev/null  empty config file    --docker  enable docker backend    --docker.endpoint=tcp://172.18.0.1:3376  connect to the swarm master using the docker_gwbridge network    --docker.tls  enable TLS using the docker-machine keys    --web  activate the webUI on port 8080", 
            "title": "Deploy Tr\u00e6fik"
        }, 
        {
            "location": "/user-guide/swarm/#deploy-your-apps", 
            "text": "We can now deploy our app on the cluster, here  whoami , a simple web server in GO, on the network  my-net :  eval $(docker-machine env --swarm mhs-demo0)\ndocker run -d --name=whoami0 --net=my-net --env= constraint:node==mhs-demo0  emilevauge/whoami\ndocker run -d --name=whoami1 --net=my-net --env= constraint:node==mhs-demo1  emilevauge/whoami  Check that everything is started:  docker ps  CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                                      NAMES\nba2c21488299        emilevauge/whoami    /whoamI                 8 seconds ago       Up 9 seconds        80/tcp                                                     mhs-demo1/whoami1\n8147a7746e7a        emilevauge/whoami    /whoamI                 19 seconds ago      Up 20 seconds       80/tcp                                                     mhs-demo0/whoami0\n8fbc39271b4c        traefik              /traefik -l DEBUG -c    36 seconds ago      Up 37 seconds       192.168.99.101:80- 80/tcp, 192.168.99.101:8080- 8080/tcp   mhs-demo0/serene_bhabha", 
            "title": "Deploy your apps"
        }, 
        {
            "location": "/user-guide/swarm/#access-to-your-apps-through-trfik", 
            "text": "curl -H Host:whoami0.traefik http://$(docker-machine ip mhs-demo0)  Hostname: 8147a7746e7a\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.3\nIP: fe80::42:aff:fe00:903\nIP: 172.18.0.3\nIP: fe80::42:acff:fe12:3\nGET / HTTP/1.1\nHost: 10.0.9.3:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.3:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c  curl -H Host:whoami1.traefik http://$(docker-machine ip mhs-demo0)  Hostname: ba2c21488299\nIP: 127.0.0.1\nIP: ::1\nIP: 10.0.9.4\nIP: fe80::42:aff:fe00:904\nIP: 172.18.0.2\nIP: fe80::42:acff:fe12:2\nGET / HTTP/1.1\nHost: 10.0.9.4:80\nUser-Agent: curl/7.35.0\nAccept: */*\nAccept-Encoding: gzip\nX-Forwarded-For: 192.168.99.1\nX-Forwarded-Host: 10.0.9.4:80\nX-Forwarded-Proto: http\nX-Forwarded-Server: 8fbc39271b4c", 
            "title": "Access to your apps through Tr\u00e6fik"
        }, 
        {
            "location": "/user-guide/docker-and-lets-encrypt/", 
            "text": "Docker \n Traefik\n\n\nIn this use case, we want to use Tr\u00e6fik as a \nlayer-7\n load balancer with SSL termination for a set of micro-services used to run a web application.\n\n\nWe also want to automatically \ndiscover any services\n on the Docker host and let Tr\u00e6fik reconfigure itself automatically when containers get created (or shut down) so HTTP traffic can be routed accordingly.\n\n\nIn addition, we want to use Let's Encrypt to automatically generate and renew SSL certificates per hostname.\n\n\nSetting Up\n\n\nIn order for this to work, you'll need a server with a public IP address, with Docker installed on it.\n\n\nIn this example, we're using the fictitious domain \nmy-awesome-app.org\n.\n\n\nIn real-life, you'll want to use your own domain and have the DNS configured accordingly so the hostname records you'll want to use point to the aforementioned public IP address.\n\n\nNetworking\n\n\nDocker containers can only communicate with each other over TCP when they share at least one network.\nThis makes sense from a topological point of view in the context of networking, since Docker under the hood creates IPTable rules so containers can't reach other containers \nunless you'd want to\n.\n\n\nIn this example, we're going to use a single network called \nweb\n where all containers that are handling HTTP traffic (including Tr\u00e6fik) will reside in.\n\n\nOn the Docker host, run the following command:\n\n\ndocker network create web\n\n\n\n\nNow, let's create a directory on the server where we will configure the rest of Tr\u00e6fik:\n\n\nmkdir -p /opt/traefik\n\n\n\n\nWithin this directory, we're going to create 3 empty files:\n\n\ntouch /opt/traefik/docker-compose.yml\ntouch /opt/traefik/acme.json \n chmod 600 /opt/traefik/acme.json\ntouch /opt/traefik/traefik.toml\n\n\n\n\nThe \ndocker-compose.yml\n file will provide us with a simple, consistent and more importantly, a deterministic way to create Tr\u00e6fik.\n\n\nThe contents of the file is as follows:\n\n\nversion: '2'\n\nservices:\n  traefik:\n    image: traefik:1.3.5\n    restart: always\n    ports:\n      - 80:80\n      - 443:443\n    networks:\n      - web\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n      - /opt/traefik/traefik.toml:/traefik.toml\n      - /opt/traefik/acme.json:/acme.json\n    container_name: traefik\n\nnetworks:\n  web:\n    external: true\n\n\n\n\nAs you can see, we're mounting the \ntraefik.toml\n file as well as the (empty) \nacme.json\n file in the container.\n\nAlso, we're mounting the \n/var/run/docker.sock\n Docker socket in the container as well, so Tr\u00e6fik can listen to Docker events and reconfigure it's own internal configuration when containers are created (or shut down).\n\nAlso, we're making sure the container is automatically restarted by the Docker engine in case of problems (or: if the server is rebooted).\nWe're publishing the default HTTP ports \n80\n and \n443\n on the host, and making sure the container is placed within the \nweb\n network we've created earlier on.\n\nFinally, we're giving this container a static name called \ntraefik\n.\n\n\nLet's take a look at a simple \ntraefik.toml\n configuration as well before we'll create the Tr\u00e6fik container:\n\n\ndebug = false\ncheckNewVersion = true\nlogLevel = \nERROR\n\ndefaultEntryPoints = [\nhttps\n,\nhttp\n]\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n    [entryPoints.http.redirect]\n    entryPoint = \nhttps\n\n  [entryPoints.https]\n  address = \n:443\n\n  [entryPoints.https.tls]\n\n[retry]\n\n[docker]\nendpoint = \nunix:///var/run/docker.sock\n\ndomain = \nmy-awesome-app.org\n\nwatch = true\nexposedbydefault = false\n\n[acme]\nemail = \nyour-email-here@my-awesome-app.org\n\nstorage = \nacme.json\n\nentryPoint = \nhttps\n\nOnHostRule = true\n\n\n\n\nThis is the minimum configuration required to do the following:\n\n\n\n\nLog \nERROR\n-level messages (or more severe) to the console, but silence \nDEBUG\n-level messagse\n\n\nCheck for new versions of Tr\u00e6fik periodically\n\n\nCreate two entry points, namely an \nHTTP\n endpoint on port \n80\n, and an \nHTTPS\n endpoint on port \n443\n where all incoming traffic on port \n80\n will immediately get redirected to \nHTTPS\n.\n\n\nEnable the Docker configuration backend and listen for container events on the Docker unix socket we've mounted earlier. However, \nnew containers will not be exposed by Tr\u00e6fik by default, we'll get into this in a bit!\n\n\nEnable automatic request and configuration of SSL certificates using Let's Encrypt.\n    These certificates will be stored in the \nacme.json\n file, which you can back-up yourself and store off-premises.\n\n\n\n\nAlright, let's boot the container. From the \n/opt/traefik\n directory, run \ndocker-compose up -d\n which will create and start the Tr\u00e6fik container.\n\n\nExposing Web Services to the Outside World\n\n\nNow that we've fully configured and started Tr\u00e6fik, it's time to get our applications running!\n\n\nLet's take a simple example of a micro-service project consisting of various services, where some will be exposed to the outside world and some will not. \n\n\nThe \ndocker-compose.yml\n of our project looks like this:\n\n\nversion: \n2.1\n\n\nservices:\n  app:\n    image: my-docker-registry.com/my-awesome-app/app:latest\n    depends_on:\n      db:\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    restart: always\n    networks:\n      - web\n      - default\n    expose:\n      - \n9000\n\n    labels:\n      - \ntraefik.backend=my-awesome-app-app\n\n      - \ntraefik.docker.network=web\n\n      - \ntraefik.frontend.rule=Host:app.my-awesome-app.org\n\n      - \ntraefik.enable=true\n\n      - \ntraefik.port=9000\n\n      - \ntraefik.default.protocol=http\n\n      - \ntraefik.admin.frontend.rule=Host:admin-app.my-awesome-app.org\n\n      - \ntraefik.admin.protocol=https\n\n      - \ntraefik.admin.port=9443\n\n\n  db:\n    image: my-docker-registry.com/back-end/5.7\n    restart: always\n\n  redis:\n    image: my-docker-registry.com/back-end/redis:4-alpine\n    restart: always\n\n  events:\n    image: my-docker-registry.com/my-awesome-app/events:latest\n    depends_on:\n      db:\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    restart: always\n    networks:\n      - web\n      - default\n    expose:\n      - \n3000\n\n    labels:\n      - \ntraefik.backend=my-awesome-app-events\n\n      - \ntraefik.docker.network=web\n\n      - \ntraefik.frontend.rule=Host:events.my-awesome-app.org\n\n      - \ntraefik.enable=true\n\n      - \ntraefik.port=3000\n\n\nnetworks:\n  web:\n    external: true\n\n\n\n\nHere, we can see a set of services with two applications that we're actually exposing to the outside world.\n\nNotice how there isn't a single container that has any published ports to the host -- everything is routed through Docker networks.\n\nAlso, only the containers that we want traffic to get routed to are attached to the \nweb\n network we created at the start of this document.\n\n\nSince the \ntraefik\n container we've created and started earlier is also attached to this network, HTTP requests can now get routed to these containers.\n\n\nLabels\n\n\nAs mentioned earlier, we don't want containers exposed automatically by Tr\u00e6fik.\n\n\nThe reason behind this is simple: we want to have control over this process ourselves.\nThanks to Docker labels, we can tell Tr\u00e6fik how to create it's internal routing configuration.\n\n\nLet's take a look at the labels themselves for the \napp\n service, which is a HTTP webservice listing on port 9000:\n\n\n- \ntraefik.backend=my-awesome-app-app\n\n- \ntraefik.docker.network=web\n\n- \ntraefik.frontend.rule=Host:app.my-awesome-app.org\n\n- \ntraefik.enable=true\n\n- \ntraefik.port=9000\n\n- \ntraefik.default.protocol=http\n\n- \ntraefik.admin.frontend.rule=Host:admin-app.my-awesome-app.org\n\n- \ntraefik.admin.protocol=https\n\n- \ntraefik.admin.port=9443\n\n\n\n\n\nWe use both \ncontainer labels\n and \nservice labels\n.\n\n\nContainer labels\n\n\nFirst, we specify the \nbackend\n name which corresponds to the actual service we're routing \nto\n.\n\n\nWe also tell Tr\u00e6fik to use the \nweb\n network to route HTTP traffic to this container. \nWith the \ntraefik.enable\n label, we tell Tr\u00e6fik to include this container in it's internal configuration.\n\n\nWith the \nfrontend.rule\n label, we tell Tr\u00e6fik that we want to route to this container if the incoming HTTP request contains the \nHost\n \napp.my-awesome-app.org\n.\nEssentially, this is the actual rule used for Layer-7 load balancing. \n\n\nFinally but not unimportantly, we tell Tr\u00e6fik to route \nto\n port \n9000\n, since that is the actual TCP/IP port the container actually listens on.\n\n\nService labels\n\n\nService labels\n allow managing many routes for the same container.\n\n\nWhen both \ncontainer labels\n and \nservice labels\n are defined, \ncontainer labels\n are just used as default values for missing \nservice labels\n but no frontend/backend are going to be defined only with these labels.\nObviously, labels \ntraefik.frontend.rule\n and \ntraefik.port\n described above, will only be used to complete information set in \nservice labels\n during the container frontends/bakends creation.\n\n\nIn the example, two service names are defined : \ndefault\n and \nadmin\n.\nThey allow creating two frontends and two backends.\n\n\n\n\ndefault\n has only one \nservice label\n : \ntraefik.default.protocol\n.\nTr\u00e6fik will use values set in \ntraefik.frontend.rule\n and \ntraefik.port\n to create the \ndefault\n frontend and backend.\nThe frontend listens to incoming HTTP requests which contain the \nHost\n \napp.my-awesome-app.org\n and redirect them in \nHTTP\n to the port \n9000\n of the backend.\n\n\nadmin\n has all the \nservices labels\n needed to create the \nadmin\n frontend and backend (\ntraefik.admin.frontend.rule\n, \ntraefik.admin.protocol\n, \ntraefik.admin.port\n).\nTr\u00e6fik will create a frontend to listen to incoming HTTP requests which contain the \nHost\n \nadmin-app.my-awesome-app.org\n and redirect them in \nHTTPS\n to the port \n9443\n of the backend.\n\n\n\n\nGotchas and tips\n\n\n\n\nAlways specify the correct port where the container expects HTTP traffic using \ntraefik.port\n label.\n\n    If a container exposes multiple ports, Tr\u00e6fik may forward traffic to the wrong port.\n    Even if a container only exposes one port, you should always write configuration defensively and explicitly.\n\n\nShould you choose to enable the \nexposedbydefault\n flag in the \ntraefik.toml\n configuration, be aware that all containers that are placed in the same network as Tr\u00e6fik will automatically be reachable from the outside world, for everyone and everyone to see.\n    Usually, this is a bad idea.\n\n\nWith the \ntraefik.frontend.auth.basic\n label, it's possible for Tr\u00e6fik to provide a HTTP basic-auth challenge for the endpoints you provide the label for.\n\n\nTr\u00e6fik has built-in support to automatically export \nPrometheus\n metrics\n\n\nTr\u00e6fik supports websockets out of the box. In the example above, the \nevents\n-service could be a NodeJS-based application which allows clients to connect using websocket protocol.\n    Thanks to the fact that HTTPS in our example is enforced, these websockets are automatically secure as well (WSS)\n\n\n\n\nFinal thoughts\n\n\nUsing Tr\u00e6fik as a Layer-7 load balancer in combination with both Docker and Let's Encrypt provides you with an extremely flexible, powerful and self-configuring solution for your projects.\n\n\nWith Let's Encrypt, your endpoints are automatically secured with production-ready SSL certificates that are renewed automatically as well.", 
            "title": "Let's Encrypt & Docker"
        }, 
        {
            "location": "/user-guide/docker-and-lets-encrypt/#docker-traefik", 
            "text": "In this use case, we want to use Tr\u00e6fik as a  layer-7  load balancer with SSL termination for a set of micro-services used to run a web application.  We also want to automatically  discover any services  on the Docker host and let Tr\u00e6fik reconfigure itself automatically when containers get created (or shut down) so HTTP traffic can be routed accordingly.  In addition, we want to use Let's Encrypt to automatically generate and renew SSL certificates per hostname.", 
            "title": "Docker &amp; Traefik"
        }, 
        {
            "location": "/user-guide/docker-and-lets-encrypt/#setting-up", 
            "text": "In order for this to work, you'll need a server with a public IP address, with Docker installed on it.  In this example, we're using the fictitious domain  my-awesome-app.org .  In real-life, you'll want to use your own domain and have the DNS configured accordingly so the hostname records you'll want to use point to the aforementioned public IP address.", 
            "title": "Setting Up"
        }, 
        {
            "location": "/user-guide/docker-and-lets-encrypt/#networking", 
            "text": "Docker containers can only communicate with each other over TCP when they share at least one network.\nThis makes sense from a topological point of view in the context of networking, since Docker under the hood creates IPTable rules so containers can't reach other containers  unless you'd want to .  In this example, we're going to use a single network called  web  where all containers that are handling HTTP traffic (including Tr\u00e6fik) will reside in.  On the Docker host, run the following command:  docker network create web  Now, let's create a directory on the server where we will configure the rest of Tr\u00e6fik:  mkdir -p /opt/traefik  Within this directory, we're going to create 3 empty files:  touch /opt/traefik/docker-compose.yml\ntouch /opt/traefik/acme.json   chmod 600 /opt/traefik/acme.json\ntouch /opt/traefik/traefik.toml  The  docker-compose.yml  file will provide us with a simple, consistent and more importantly, a deterministic way to create Tr\u00e6fik.  The contents of the file is as follows:  version: '2'\n\nservices:\n  traefik:\n    image: traefik:1.3.5\n    restart: always\n    ports:\n      - 80:80\n      - 443:443\n    networks:\n      - web\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n      - /opt/traefik/traefik.toml:/traefik.toml\n      - /opt/traefik/acme.json:/acme.json\n    container_name: traefik\n\nnetworks:\n  web:\n    external: true  As you can see, we're mounting the  traefik.toml  file as well as the (empty)  acme.json  file in the container. \nAlso, we're mounting the  /var/run/docker.sock  Docker socket in the container as well, so Tr\u00e6fik can listen to Docker events and reconfigure it's own internal configuration when containers are created (or shut down). \nAlso, we're making sure the container is automatically restarted by the Docker engine in case of problems (or: if the server is rebooted).\nWe're publishing the default HTTP ports  80  and  443  on the host, and making sure the container is placed within the  web  network we've created earlier on. \nFinally, we're giving this container a static name called  traefik .  Let's take a look at a simple  traefik.toml  configuration as well before we'll create the Tr\u00e6fik container:  debug = false\ncheckNewVersion = true\nlogLevel =  ERROR \ndefaultEntryPoints = [ https , http ]\n\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n    [entryPoints.http.redirect]\n    entryPoint =  https \n  [entryPoints.https]\n  address =  :443 \n  [entryPoints.https.tls]\n\n[retry]\n\n[docker]\nendpoint =  unix:///var/run/docker.sock \ndomain =  my-awesome-app.org \nwatch = true\nexposedbydefault = false\n\n[acme]\nemail =  your-email-here@my-awesome-app.org \nstorage =  acme.json \nentryPoint =  https \nOnHostRule = true  This is the minimum configuration required to do the following:   Log  ERROR -level messages (or more severe) to the console, but silence  DEBUG -level messagse  Check for new versions of Tr\u00e6fik periodically  Create two entry points, namely an  HTTP  endpoint on port  80 , and an  HTTPS  endpoint on port  443  where all incoming traffic on port  80  will immediately get redirected to  HTTPS .  Enable the Docker configuration backend and listen for container events on the Docker unix socket we've mounted earlier. However,  new containers will not be exposed by Tr\u00e6fik by default, we'll get into this in a bit!  Enable automatic request and configuration of SSL certificates using Let's Encrypt.\n    These certificates will be stored in the  acme.json  file, which you can back-up yourself and store off-premises.   Alright, let's boot the container. From the  /opt/traefik  directory, run  docker-compose up -d  which will create and start the Tr\u00e6fik container.", 
            "title": "Networking"
        }, 
        {
            "location": "/user-guide/docker-and-lets-encrypt/#exposing-web-services-to-the-outside-world", 
            "text": "Now that we've fully configured and started Tr\u00e6fik, it's time to get our applications running!  Let's take a simple example of a micro-service project consisting of various services, where some will be exposed to the outside world and some will not.   The  docker-compose.yml  of our project looks like this:  version:  2.1 \n\nservices:\n  app:\n    image: my-docker-registry.com/my-awesome-app/app:latest\n    depends_on:\n      db:\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    restart: always\n    networks:\n      - web\n      - default\n    expose:\n      -  9000 \n    labels:\n      -  traefik.backend=my-awesome-app-app \n      -  traefik.docker.network=web \n      -  traefik.frontend.rule=Host:app.my-awesome-app.org \n      -  traefik.enable=true \n      -  traefik.port=9000 \n      -  traefik.default.protocol=http \n      -  traefik.admin.frontend.rule=Host:admin-app.my-awesome-app.org \n      -  traefik.admin.protocol=https \n      -  traefik.admin.port=9443 \n\n  db:\n    image: my-docker-registry.com/back-end/5.7\n    restart: always\n\n  redis:\n    image: my-docker-registry.com/back-end/redis:4-alpine\n    restart: always\n\n  events:\n    image: my-docker-registry.com/my-awesome-app/events:latest\n    depends_on:\n      db:\n        condition: service_healthy\n      redis:\n        condition: service_healthy\n    restart: always\n    networks:\n      - web\n      - default\n    expose:\n      -  3000 \n    labels:\n      -  traefik.backend=my-awesome-app-events \n      -  traefik.docker.network=web \n      -  traefik.frontend.rule=Host:events.my-awesome-app.org \n      -  traefik.enable=true \n      -  traefik.port=3000 \n\nnetworks:\n  web:\n    external: true  Here, we can see a set of services with two applications that we're actually exposing to the outside world. \nNotice how there isn't a single container that has any published ports to the host -- everything is routed through Docker networks. \nAlso, only the containers that we want traffic to get routed to are attached to the  web  network we created at the start of this document.  Since the  traefik  container we've created and started earlier is also attached to this network, HTTP requests can now get routed to these containers.", 
            "title": "Exposing Web Services to the Outside World"
        }, 
        {
            "location": "/user-guide/docker-and-lets-encrypt/#labels", 
            "text": "As mentioned earlier, we don't want containers exposed automatically by Tr\u00e6fik.  The reason behind this is simple: we want to have control over this process ourselves.\nThanks to Docker labels, we can tell Tr\u00e6fik how to create it's internal routing configuration.  Let's take a look at the labels themselves for the  app  service, which is a HTTP webservice listing on port 9000:  -  traefik.backend=my-awesome-app-app \n-  traefik.docker.network=web \n-  traefik.frontend.rule=Host:app.my-awesome-app.org \n-  traefik.enable=true \n-  traefik.port=9000 \n-  traefik.default.protocol=http \n-  traefik.admin.frontend.rule=Host:admin-app.my-awesome-app.org \n-  traefik.admin.protocol=https \n-  traefik.admin.port=9443   We use both  container labels  and  service labels .", 
            "title": "Labels"
        }, 
        {
            "location": "/user-guide/docker-and-lets-encrypt/#container-labels", 
            "text": "First, we specify the  backend  name which corresponds to the actual service we're routing  to .  We also tell Tr\u00e6fik to use the  web  network to route HTTP traffic to this container. \nWith the  traefik.enable  label, we tell Tr\u00e6fik to include this container in it's internal configuration.  With the  frontend.rule  label, we tell Tr\u00e6fik that we want to route to this container if the incoming HTTP request contains the  Host   app.my-awesome-app.org .\nEssentially, this is the actual rule used for Layer-7 load balancing.   Finally but not unimportantly, we tell Tr\u00e6fik to route  to  port  9000 , since that is the actual TCP/IP port the container actually listens on.", 
            "title": "Container labels"
        }, 
        {
            "location": "/user-guide/docker-and-lets-encrypt/#service-labels", 
            "text": "Service labels  allow managing many routes for the same container.  When both  container labels  and  service labels  are defined,  container labels  are just used as default values for missing  service labels  but no frontend/backend are going to be defined only with these labels.\nObviously, labels  traefik.frontend.rule  and  traefik.port  described above, will only be used to complete information set in  service labels  during the container frontends/bakends creation.  In the example, two service names are defined :  default  and  admin .\nThey allow creating two frontends and two backends.   default  has only one  service label  :  traefik.default.protocol .\nTr\u00e6fik will use values set in  traefik.frontend.rule  and  traefik.port  to create the  default  frontend and backend.\nThe frontend listens to incoming HTTP requests which contain the  Host   app.my-awesome-app.org  and redirect them in  HTTP  to the port  9000  of the backend.  admin  has all the  services labels  needed to create the  admin  frontend and backend ( traefik.admin.frontend.rule ,  traefik.admin.protocol ,  traefik.admin.port ).\nTr\u00e6fik will create a frontend to listen to incoming HTTP requests which contain the  Host   admin-app.my-awesome-app.org  and redirect them in  HTTPS  to the port  9443  of the backend.", 
            "title": "Service labels"
        }, 
        {
            "location": "/user-guide/docker-and-lets-encrypt/#gotchas-and-tips", 
            "text": "Always specify the correct port where the container expects HTTP traffic using  traefik.port  label. \n    If a container exposes multiple ports, Tr\u00e6fik may forward traffic to the wrong port.\n    Even if a container only exposes one port, you should always write configuration defensively and explicitly.  Should you choose to enable the  exposedbydefault  flag in the  traefik.toml  configuration, be aware that all containers that are placed in the same network as Tr\u00e6fik will automatically be reachable from the outside world, for everyone and everyone to see.\n    Usually, this is a bad idea.  With the  traefik.frontend.auth.basic  label, it's possible for Tr\u00e6fik to provide a HTTP basic-auth challenge for the endpoints you provide the label for.  Tr\u00e6fik has built-in support to automatically export  Prometheus  metrics  Tr\u00e6fik supports websockets out of the box. In the example above, the  events -service could be a NodeJS-based application which allows clients to connect using websocket protocol.\n    Thanks to the fact that HTTPS in our example is enforced, these websockets are automatically secure as well (WSS)", 
            "title": "Gotchas and tips"
        }, 
        {
            "location": "/user-guide/docker-and-lets-encrypt/#final-thoughts", 
            "text": "Using Tr\u00e6fik as a Layer-7 load balancer in combination with both Docker and Let's Encrypt provides you with an extremely flexible, powerful and self-configuring solution for your projects.  With Let's Encrypt, your endpoints are automatically secured with production-ready SSL certificates that are renewed automatically as well.", 
            "title": "Final thoughts"
        }, 
        {
            "location": "/user-guide/kubernetes/", 
            "text": "Kubernetes Ingress Controller\n\n\nThis guide explains how to use Tr\u00e6fik as an Ingress controller in a Kubernetes cluster.\n\n\nIf you are not familiar with Ingresses in Kubernetes you might want to read the \nKubernetes user guide\n\n\nThe config files used in this guide can be found in the \nexamples directory\n\n\nPrerequisites\n\n\n\n\n\n\nA working Kubernetes cluster. If you want to follow along with this guide, you should setup \nminikube\n\non your machine, as it is the quickest way to get a local Kubernetes cluster setup for experimentation and development.\n\n\n\n\n\n\nThe \nkubectl\n binary should be \ninstalled on your workstation\n.\n\n\n\n\n\n\nRole Based Access Control configuration (Kubernetes 1.6+ only)\n\n\nKubernetes introduces \nRole Based Access Control (RBAC)\n in 1.6+ to allow fine-grained control of Kubernetes resources and api.\n\n\nIf your cluster is configured with RBAC, you may need to authorize Tr\u00e6fik to use the Kubernetes API using ClusterRole and ClusterRoleBinding resources:\n\n\n\n\nNote\n\n\nyour cluster may have suitable ClusterRoles already setup, but the following should work everywhere\n\n\n\n\n---\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: traefik-ingress-controller\nrules:\n  - apiGroups:\n      - \n\n    resources:\n      - services\n      - endpoints\n      - secrets\n    verbs:\n      - get\n      - list\n      - watch\n  - apiGroups:\n      - extensions\n    resources:\n      - ingresses\n    verbs:\n      - get\n      - list\n      - watch\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: traefik-ingress-controller\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: traefik-ingress-controller\nsubjects:\n- kind: ServiceAccount\n  name: traefik-ingress-controller\n  namespace: kube-system\n\n\n\n\nexamples/k8s/traefik-rbac.yaml\n\n\nkubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-rbac.yaml\n\n\n\n\nDeploy Tr\u00e6fik using a Deployment or DaemonSet\n\n\nIt is possible to use Tr\u00e6fik with a \nDeployment\n or a \nDaemonSet\n object,\n whereas both options have their own pros and cons:\n\n\n\n\nThe scalability is much better when using a Deployment, because you will have a Single-Pod-per-Node model when using the DeaemonSet.  \n\n\nIt is possible to exclusively run a Service on a dedicated set of machines using taints and tolerations with a DaemonSet.  \n\n\nOn the other hand the DaemonSet allows you to access any Node directly on Port 80 and 443, where you have to setup a \nService\n object with a Deployment.\n\n\n\n\nThe Deployment objects looks like this:\n\n\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: traefik-ingress-controller\n  namespace: kube-system\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  name: traefik-ingress-controller\n  namespace: kube-system\n  labels:\n    k8s-app: traefik-ingress-lb\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: traefik-ingress-lb\n  template:\n    metadata:\n      labels:\n        k8s-app: traefik-ingress-lb\n        name: traefik-ingress-lb\n    spec:\n      serviceAccountName: traefik-ingress-controller\n      terminationGracePeriodSeconds: 60\n      containers:\n      - image: traefik\n        name: traefik-ingress-lb\n        args:\n        - --web\n        - --kubernetes\n---\nkind: Service\napiVersion: v1\nmetadata:\n  name: traefik-ingress-service\n  namespace: kube-system\nspec:\n  selector:\n    k8s-app: traefik-ingress-lb\n  ports:\n    - protocol: TCP\n      port: 80\n      name: web\n    - protocol: TCP\n      port: 8080\n      name: admin\n  type: NodePort\n\n\n\n\nexamples/k8s/traefik-deployment.yaml\n\n\n\n\nNote\n\n\nThe Service will expose two NodePorts which allow access to the ingress and the web interface.\n\n\n\n\nThe DaemonSet objects looks not much different:\n\n\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: traefik-ingress-controller\n  namespace: kube-system\n---\nkind: DaemonSet\napiVersion: extensions/v1beta1\nmetadata:\n  name: traefik-ingress-controller\n  namespace: kube-system\n  labels:\n    k8s-app: traefik-ingress-lb\nspec:\n  template:\n    metadata:\n      labels:\n        k8s-app: traefik-ingress-lb\n        name: traefik-ingress-lb\n    spec:\n      serviceAccountName: traefik-ingress-controller\n      terminationGracePeriodSeconds: 60\n      hostNetwork: true\n      containers:\n      - image: traefik\n        name: traefik-ingress-lb\n        ports:\n        - name: http\n          containerPort: 80\n          hostPort: 80\n        - name: admin\n          containerPort: 8080\n        securityContext:\n          privileged: true\n        args:\n        - -d\n        - --web\n        - --kubernetes\n---\nkind: Service\napiVersion: v1\nmetadata:\n  name: traefik-ingress-service\n  namespace: kube-system\nspec:\n  selector:\n    k8s-app: traefik-ingress-lb\n  ports:\n    - protocol: TCP\n      port: 80\n      name: web\n    - protocol: TCP\n      port: 8080\n      name: admin\n  type: NodePort\n\n\n\n\nexamples/k8s/traefik-ds.yaml\n\n\nTo deploy Tr\u00e6fik to your cluster start by submitting one of the YAML files to the cluster with \nkubectl\n:\n\n\nkubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-deployment.yaml\n\n\n\n\nkubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-ds.yaml\n\n\n\n\nThere are some significant differences between using Deployments and DaemonSets:\n\n\n\n\nThe Deployment has easier up and down scaling possibilities.\n    It can implement full pod lifecycle and supports rolling updates from Kubernetes 1.2.\n    At least one Pod is needed to run the Deployment.\n\n\nThe DaemonSet automatically scales to all nodes that meets a specific selector and guarantees to fill nodes one at a time.\n    Rolling updates are fully supported from Kubernetes 1.7 for DaemonSets as well.\n\n\n\n\nCheck the Pods\n\n\nNow lets check if our command was successful.\n\n\nStart by listing the pods in the \nkube-system\n namespace:\n\n\nkubectl --namespace=kube-system get pods\n\n\n\n\nNAME                                         READY     STATUS    RESTARTS   AGE\nkube-addon-manager-minikubevm                1/1       Running   0          4h\nkubernetes-dashboard-s8krj                   1/1       Running   0          4h\ntraefik-ingress-controller-678226159-eqseo   1/1       Running   0          7m\n\n\n\n\nYou should see that after submitting the Deployment or DaemonSet to Kubernetes it has launched a Pod, and it is now running.\n\nIt might take a few moments for kubernetes to pull the Tr\u00e6fik image and start the container.\n\n\n\n\nNote\n\n\nYou could also check the deployment with the Kubernetes dashboard, run\n\nminikube dashboard\n to open it in your browser, then choose the \nkube-system\n\nnamespace from the menu at the top right of the screen.\n\n\n\n\nYou should now be able to access Tr\u00e6fik on port 80 of your Minikube instance when using the DaemonSet:\n\n\ncurl $(minikube ip)\n\n\n\n\n404 page not found\n\n\n\n\nIf you decided to use the deployment, then you need to target the correct NodePort, which can be seen then you execute \nkubectl get services --namespace=kube-system\n.\n\n\ncurl $(minikube ip):\nNODEPORT\n\n\n\n\n\n404 page not found\n\n\n\n\n\n\nNote\n\n\nWe expect to see a 404 response here as we haven't yet given Tr\u00e6fik any configuration.\n\n\n\n\nDeploy Tr\u00e6fik using Helm Chart\n\n\nInstead of installing Tr\u00e6fik via an own object, you can also use the Tr\u00e6fik Helm chart.\n\n\nThis allows more complex configuration via Kubernetes \nConfigMap\n and enabled TLS certificates.\n\n\nInstall Tr\u00e6fik chart by:\n\n\nhelm install stable/traefik\n\n\n\n\nFor more information, check out \nthe doc\n.\n\n\nSubmitting An Ingress to the cluster.\n\n\nLets start by creating a Service and an Ingress that will expose the \nTr\u00e6fik Web UI\n.\n\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: traefik-web-ui\n  namespace: kube-system\nspec:\n  selector:\n    k8s-app: traefik-ingress-lb\n  ports:\n  - port: 80\n    targetPort: 8080\n---\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: traefik-web-ui\n  namespace: kube-system\n  annotations:\n    kubernetes.io/ingress.class: traefik\nspec:\n  rules:\n  - host: traefik-ui.minikube\n    http:\n      paths:\n      - backend:\n          serviceName: traefik-web-ui\n          servicePort: 80\n\n\n\n\nexamples/k8s/ui.yaml\n\n\nkubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/ui.yaml\n\n\n\n\nNow lets setup an entry in our /etc/hosts file to route \ntraefik-ui.minikube\n to our cluster.\n\n\nIn production you would want to set up real dns entries.\n\nYou can get the ip address of your minikube instance by running \nminikube ip\n\n\necho \n$(minikube ip) traefik-ui.minikube\n | sudo tee -a /etc/hosts\n\n\n\n\nWe should now be able to visit \ntraefik-ui.minikube\n in the browser and view the Tr\u00e6fik Web UI.\n\n\nBasic Authentication\n\n\nIt's possible to add additional authentication annotations in the Ingress rule.\nThe source of the authentication is a secret that contains usernames and passwords inside the key auth.\nTo read about basic auth limitations see the \nKubernetes Ingress\n configuration page.\n\n\nCreating the Secret\n\n\nA. Use \nhtpasswd\n to create a file containing the username and the base64-encoded password:\n\n\nhtpasswd -c ./auth myusername\n\n\n\n\nYou will be prompted for a password which you will have to enter twice.\n\nhtpasswd\n will create a file with the following:\n\n\ncat auth\n\n\n\n\nmyusername:$apr1$78Jyn/1K$ERHKVRPPlzAX8eBtLuvRZ0\n\n\n\n\nB. Now use \nkubectl\n to create a secret in the monitoring namespace using the file created by \nhtpasswd\n.\n\n\nkubectl create secret generic mysecret --from-file auth --namespace=monitoring\n\n\n\n\n\n\nNote\n\n\nSecret must be in same namespace as the ingress rule.\n\n\n\n\nC. Create the ingress using the following annotations to specify basic auth and that the username and password is stored in \nmysecret\n.\n\n\n\n\ningress.kubernetes.io/auth-type: \"basic\"\n\n\ningress.kubernetes.io/auth-secret: \"mysecret\"\n\n\n\n\nFollowing is a full ingress example based on Prometheus:\n\n\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n name: prometheus-dashboard\n namespace: monitoring\n annotations:\n   kubernetes.io/ingress.class: traefik\n   ingress.kubernetes.io/auth-type: \nbasic\n\n   ingress.kubernetes.io/auth-secret: \nmysecret\n\nspec:\n rules:\n - host: dashboard.prometheus.example.com\n   http:\n     paths:\n     - backend:\n         serviceName: prometheus\n         servicePort: 9090\n\n\n\n\nYou can apply the example ingress as following:\n\n\nkubectl create -f prometheus-ingress.yaml -n monitoring\n\n\n\n\nName based routing\n\n\nIn this example we are going to setup websites for 3 of the United Kingdoms best loved cheeses, Cheddar, Stilton and Wensleydale.\n\n\nFirst lets start by launching the 3 pods for the cheese websites.\n\n\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  name: stilton\n  labels:\n    app: cheese\n    cheese: stilton\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: cheese\n      task: stilton\n  template:\n    metadata:\n      labels:\n        app: cheese\n        task: stilton\n        version: v0.0.1\n    spec:\n      containers:\n      - name: cheese\n        image: errm/cheese:stilton\n        ports:\n        - containerPort: 80\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  name: cheddar\n  labels:\n    app: cheese\n    cheese: cheddar\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: cheese\n      task: cheddar\n  template:\n    metadata:\n      labels:\n        app: cheese\n        task: cheddar\n        version: v0.0.1\n    spec:\n      containers:\n      - name: cheese\n        image: errm/cheese:cheddar\n        ports:\n        - containerPort: 80\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  name: wensleydale\n  labels:\n    app: cheese\n    cheese: wensleydale\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: cheese\n      task: wensleydale\n  template:\n    metadata:\n      labels:\n        app: cheese\n        task: wensleydale\n        version: v0.0.1\n    spec:\n      containers:\n      - name: cheese\n        image: errm/cheese:wensleydale\n        ports:\n        - containerPort: 80\n\n\n\n\nexamples/k8s/cheese-deployments.yaml\n\n\nkubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/cheese-deployments.yaml\n\n\n\n\nNext we need to setup a service for each of the cheese pods.\n\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: stilton\nspec:\n  ports:\n  - name: http\n    targetPort: 80\n    port: 80\n  selector:\n    app: cheese\n    task: stilton\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: cheddar\nspec:\n  ports:\n  - name: http\n    targetPort: 80\n    port: 80\n  selector:\n    app: cheese\n    task: cheddar\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: wensleydale\n  annotations:\n    traefik.backend.circuitbreaker: \nNetworkErrorRatio() \n 0.5\n\nspec:\n  ports:\n  - name: http\n    targetPort: 80\n    port: 80\n  selector:\n    app: cheese\n    task: wensleydale\n\n\n\n\n\n\nNote\n\n\nWe also set a \ncircuit breaker expression\n for one of the backends by setting the \ntraefik.backend.circuitbreaker\n annotation on the service.\n\n\n\n\nexamples/k8s/cheese-services.yaml\n\n\nkubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/cheese-services.yaml\n\n\n\n\nNow we can submit an ingress for the cheese websites.\n\n\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: cheese\n  annotations:\n    kubernetes.io/ingress.class: traefik\nspec:\n  rules:\n  - host: stilton.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: stilton\n          servicePort: http\n  - host: cheddar.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: cheddar\n          servicePort: http\n  - host: wensleydale.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: wensleydale\n          servicePort: http\n\n\n\n\nexamples/k8s/cheese-ingress.yaml\n\n\n\n\nNote\n\n\nwe list each hostname, and add a backend service.\n\n\n\n\nkubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/cheese-ingress.yaml\n\n\n\n\nNow visit the \nTr\u00e6fik dashboard\n and you should see a frontend for each host.\nAlong with a backend listing for each service with a Server set up for each pod.\n\n\nIf you edit your \n/etc/hosts\n again you should be able to access the cheese websites in your browser.\n\n\necho \n$(minikube ip) stilton.minikube cheddar.minikube wensleydale.minikube\n | sudo tee -a /etc/hosts\n\n\n\n\n\n\nStilton\n\n\nCheddar\n\n\nWensleydale\n\n\n\n\nPath based routing\n\n\nNow lets suppose that our fictional client has decided that while they are super happy about our cheesy web design, when they asked for 3 websites they had not really bargained on having to buy 3 domain names.\n\n\nNo problem, we say, why don't we reconfigure the sites to host all 3 under one domain.\n\n\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: cheeses\n  annotations:\n    kubernetes.io/ingress.class: traefik\n    traefik.frontend.rule.type: PathPrefixStrip\nspec:\n  rules:\n  - host: cheeses.minikube\n    http:\n      paths:\n      - path: /stilton\n        backend:\n          serviceName: stilton\n          servicePort: http\n      - path: /cheddar\n        backend:\n          serviceName: cheddar\n          servicePort: http\n      - path: /wensleydale\n        backend:\n          serviceName: wensleydale\n          servicePort: http\n\n\n\n\nexamples/k8s/cheeses-ingress.yaml\n\n\n\n\nNote\n\n\nwe are configuring Tr\u00e6fik to strip the prefix from the url path with the \ntraefik.frontend.rule.type\n annotation so that we can use the containers from the previous example without modification.\n\n\n\n\nkubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/cheeses-ingress.yaml\n\n\n\n\necho \n$(minikube ip) cheeses.minikube\n | sudo tee -a /etc/hosts\n\n\n\n\nYou should now be able to visit the websites in your browser.\n\n\n\n\ncheeses.minikube/stilton\n\n\ncheeses.minikube/cheddar\n\n\ncheeses.minikube/wensleydale\n\n\n\n\nSpecifying priority for routing\n\n\nSometimes you need to specify priority for ingress route, especially when handling wildcard routes.\nThis can be done by adding annotation \ntraefik.frontend.priority\n, i.e.:\n\n\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: wildcard-cheeses\n  annotations:\n    traefik.frontend.priority: \n1\n\nspec:\n  rules:\n  - host: *.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: stilton\n          servicePort: http\n\nkind: Ingress\nmetadata:\n  name: specific-cheeses\n  annotations:\n    traefik.frontend.priority: \n2\n\nspec:\n  rules:\n  - host: specific.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: stilton\n          servicePort: http\n\n\n\n\nNote that priority values must be quoted to avoid them being interpreted as numbers (which are illegal for annotations).\n\n\nForwarding to ExternalNames\n\n\nWhen specifying an \nExternalName\n,\nTr\u00e6fik will forward requests to the given host accordingly and use HTTPS when the Service port matches 443.\n\nThis still requires setting up a proper port mapping on the Service from the Ingress port to the (external) Service port.\n\n\nDisable passing the Host header\n\n\nBy default Tr\u00e6fik will pass the incoming Host header on to the upstream resource.\n\n\nThere are times however where you may not want this to be the case.\nFor example if your service is of the ExternalName type.\n\n\nDisable entirely\n\n\nAdd the following to your toml config:\n\n\ndisablePassHostHeaders = true\n\n\n\n\nDisable per ingress\n\n\nTo disable passing the Host header per ingress resource set the \ntraefik.frontend.passHostHeader\n annotation on your ingress to \nfalse\n.\n\n\nHere is an example ingress definition:\n\n\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: example\n  annotations:\n    kubernetes.io/ingress.class: traefik\n    traefik.frontend.passHostHeader: \nfalse\n\nspec:\n  rules:\n  - host: example.com\n    http:\n      paths:\n      - path: /static\n        backend:\n          serviceName: static\n          servicePort: https\n\n\n\n\nAnd an example service definition:\n\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: static\nspec:\n  ports:\n  - name: https\n    port: 443\n  type: ExternalName\n  externalName: static.otherdomain.com\n\n\n\n\nIf you were to visit \nexample.com/static\n the request would then be passed onto \nstatic.otherdomain.com/static\n and s\ntatic.otherdomain.com\n would receive the request with the Host header being \nstatic.otherdomain.com\n.\n\n\n\n\nNote\n\n\nThe per ingress annotation overides whatever the global value is set to.\nSo you could set \ndisablePassHostHeaders\n to \ntrue\n in your toml file and then enable passing\nthe host header per ingress if you wanted.\n\n\n\n\nPartitioning the Ingress object space\n\n\nBy default, Tr\u00e6fik processes every Ingress objects it observes. At times, however, it may be desirable to ignore certain objects. The following sub-sections describe common use cases and how they can be handled with Tr\u00e6fik.\n\n\nBetween Tr\u00e6fik and other Ingress controller implementations\n\n\nSometimes Tr\u00e6fik runs along other Ingress controller implementations. One such example is when both Tr\u00e6fik and a cloud provider Ingress controller are active.\n\n\nThe \nkubernetes.io/ingress.class\n annotation can be attached to any Ingress object in order to control whether Tr\u00e6fik should handle it.\n\n\nIf the annotation is missing, contains an empty value, or the value \ntraefik\n, then the Tr\u00e6fik controller will take responsibility and process the associated Ingress object. If the annotation contains any other value (usually the name of a different Ingress controller), Tr\u00e6fik will ignore the object.\n\n\nBetween multiple Tr\u00e6fik Deployments\n\n\nSometimes multiple Tr\u00e6fik Deployments are supposed to run concurrently. For instance, it is conceivable to have one Deployment deal with internal and another one with external traffic.\n\n\nFor such cases, it is advisable to classify Ingress objects through a label and configure the \nlabelSelector\n option per each Tr\u00e6fik Deployment accordingly. To stick with the internal/external example above, all Ingress objects meant for internal traffic could receive a \ntraffic-type: internal\n label while objects designated for external traffic receive a \ntraffic-type: external\n label. The label selectors on the Tr\u00e6fik Deployments would then be \ntraffic-type=internal\n and \ntraffic-type=external\n, respectively.\n\n\nProduction advice\n\n\nResource limitations\n\n\nThe examples shown deliberately do not specify any \nresource limitations\n as there is no one size fits all.\n\n\nIn a production environment, however, it is important to set proper bounds, especially with regards to CPU:\n\n\n\n\ntoo strict and Traefik will be throttled while serving requests (as Kubernetes imposes hard quotas)\n\n\ntoo loose and Traefik may waste resources not available for other containers\n\n\n\n\nWhen in doubt, you should measure your resource needs, and adjust requests and limits accordingly.", 
            "title": "Kubernetes"
        }, 
        {
            "location": "/user-guide/kubernetes/#kubernetes-ingress-controller", 
            "text": "This guide explains how to use Tr\u00e6fik as an Ingress controller in a Kubernetes cluster.  If you are not familiar with Ingresses in Kubernetes you might want to read the  Kubernetes user guide  The config files used in this guide can be found in the  examples directory", 
            "title": "Kubernetes Ingress Controller"
        }, 
        {
            "location": "/user-guide/kubernetes/#prerequisites", 
            "text": "A working Kubernetes cluster. If you want to follow along with this guide, you should setup  minikube \non your machine, as it is the quickest way to get a local Kubernetes cluster setup for experimentation and development.    The  kubectl  binary should be  installed on your workstation .", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/user-guide/kubernetes/#role-based-access-control-configuration-kubernetes-16-only", 
            "text": "Kubernetes introduces  Role Based Access Control (RBAC)  in 1.6+ to allow fine-grained control of Kubernetes resources and api.  If your cluster is configured with RBAC, you may need to authorize Tr\u00e6fik to use the Kubernetes API using ClusterRole and ClusterRoleBinding resources:   Note  your cluster may have suitable ClusterRoles already setup, but the following should work everywhere   ---\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: traefik-ingress-controller\nrules:\n  - apiGroups:\n      -  \n    resources:\n      - services\n      - endpoints\n      - secrets\n    verbs:\n      - get\n      - list\n      - watch\n  - apiGroups:\n      - extensions\n    resources:\n      - ingresses\n    verbs:\n      - get\n      - list\n      - watch\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1beta1\nmetadata:\n  name: traefik-ingress-controller\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: traefik-ingress-controller\nsubjects:\n- kind: ServiceAccount\n  name: traefik-ingress-controller\n  namespace: kube-system  examples/k8s/traefik-rbac.yaml  kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-rbac.yaml", 
            "title": "Role Based Access Control configuration (Kubernetes 1.6+ only)"
        }, 
        {
            "location": "/user-guide/kubernetes/#deploy-trfik-using-a-deployment-or-daemonset", 
            "text": "It is possible to use Tr\u00e6fik with a  Deployment  or a  DaemonSet  object,\n whereas both options have their own pros and cons:   The scalability is much better when using a Deployment, because you will have a Single-Pod-per-Node model when using the DeaemonSet.    It is possible to exclusively run a Service on a dedicated set of machines using taints and tolerations with a DaemonSet.    On the other hand the DaemonSet allows you to access any Node directly on Port 80 and 443, where you have to setup a  Service  object with a Deployment.   The Deployment objects looks like this:  ---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: traefik-ingress-controller\n  namespace: kube-system\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  name: traefik-ingress-controller\n  namespace: kube-system\n  labels:\n    k8s-app: traefik-ingress-lb\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      k8s-app: traefik-ingress-lb\n  template:\n    metadata:\n      labels:\n        k8s-app: traefik-ingress-lb\n        name: traefik-ingress-lb\n    spec:\n      serviceAccountName: traefik-ingress-controller\n      terminationGracePeriodSeconds: 60\n      containers:\n      - image: traefik\n        name: traefik-ingress-lb\n        args:\n        - --web\n        - --kubernetes\n---\nkind: Service\napiVersion: v1\nmetadata:\n  name: traefik-ingress-service\n  namespace: kube-system\nspec:\n  selector:\n    k8s-app: traefik-ingress-lb\n  ports:\n    - protocol: TCP\n      port: 80\n      name: web\n    - protocol: TCP\n      port: 8080\n      name: admin\n  type: NodePort  examples/k8s/traefik-deployment.yaml   Note  The Service will expose two NodePorts which allow access to the ingress and the web interface.   The DaemonSet objects looks not much different:  ---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: traefik-ingress-controller\n  namespace: kube-system\n---\nkind: DaemonSet\napiVersion: extensions/v1beta1\nmetadata:\n  name: traefik-ingress-controller\n  namespace: kube-system\n  labels:\n    k8s-app: traefik-ingress-lb\nspec:\n  template:\n    metadata:\n      labels:\n        k8s-app: traefik-ingress-lb\n        name: traefik-ingress-lb\n    spec:\n      serviceAccountName: traefik-ingress-controller\n      terminationGracePeriodSeconds: 60\n      hostNetwork: true\n      containers:\n      - image: traefik\n        name: traefik-ingress-lb\n        ports:\n        - name: http\n          containerPort: 80\n          hostPort: 80\n        - name: admin\n          containerPort: 8080\n        securityContext:\n          privileged: true\n        args:\n        - -d\n        - --web\n        - --kubernetes\n---\nkind: Service\napiVersion: v1\nmetadata:\n  name: traefik-ingress-service\n  namespace: kube-system\nspec:\n  selector:\n    k8s-app: traefik-ingress-lb\n  ports:\n    - protocol: TCP\n      port: 80\n      name: web\n    - protocol: TCP\n      port: 8080\n      name: admin\n  type: NodePort  examples/k8s/traefik-ds.yaml  To deploy Tr\u00e6fik to your cluster start by submitting one of the YAML files to the cluster with  kubectl :  kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-deployment.yaml  kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-ds.yaml  There are some significant differences between using Deployments and DaemonSets:   The Deployment has easier up and down scaling possibilities.\n    It can implement full pod lifecycle and supports rolling updates from Kubernetes 1.2.\n    At least one Pod is needed to run the Deployment.  The DaemonSet automatically scales to all nodes that meets a specific selector and guarantees to fill nodes one at a time.\n    Rolling updates are fully supported from Kubernetes 1.7 for DaemonSets as well.", 
            "title": "Deploy Tr\u00e6fik using a Deployment or DaemonSet"
        }, 
        {
            "location": "/user-guide/kubernetes/#check-the-pods", 
            "text": "Now lets check if our command was successful.  Start by listing the pods in the  kube-system  namespace:  kubectl --namespace=kube-system get pods  NAME                                         READY     STATUS    RESTARTS   AGE\nkube-addon-manager-minikubevm                1/1       Running   0          4h\nkubernetes-dashboard-s8krj                   1/1       Running   0          4h\ntraefik-ingress-controller-678226159-eqseo   1/1       Running   0          7m  You should see that after submitting the Deployment or DaemonSet to Kubernetes it has launched a Pod, and it is now running. It might take a few moments for kubernetes to pull the Tr\u00e6fik image and start the container.   Note  You could also check the deployment with the Kubernetes dashboard, run minikube dashboard  to open it in your browser, then choose the  kube-system \nnamespace from the menu at the top right of the screen.   You should now be able to access Tr\u00e6fik on port 80 of your Minikube instance when using the DaemonSet:  curl $(minikube ip)  404 page not found  If you decided to use the deployment, then you need to target the correct NodePort, which can be seen then you execute  kubectl get services --namespace=kube-system .  curl $(minikube ip): NODEPORT   404 page not found   Note  We expect to see a 404 response here as we haven't yet given Tr\u00e6fik any configuration.", 
            "title": "Check the Pods"
        }, 
        {
            "location": "/user-guide/kubernetes/#deploy-trfik-using-helm-chart", 
            "text": "Instead of installing Tr\u00e6fik via an own object, you can also use the Tr\u00e6fik Helm chart.  This allows more complex configuration via Kubernetes  ConfigMap  and enabled TLS certificates.  Install Tr\u00e6fik chart by:  helm install stable/traefik  For more information, check out  the doc .", 
            "title": "Deploy Tr\u00e6fik using Helm Chart"
        }, 
        {
            "location": "/user-guide/kubernetes/#submitting-an-ingress-to-the-cluster", 
            "text": "Lets start by creating a Service and an Ingress that will expose the  Tr\u00e6fik Web UI .  apiVersion: v1\nkind: Service\nmetadata:\n  name: traefik-web-ui\n  namespace: kube-system\nspec:\n  selector:\n    k8s-app: traefik-ingress-lb\n  ports:\n  - port: 80\n    targetPort: 8080\n---\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: traefik-web-ui\n  namespace: kube-system\n  annotations:\n    kubernetes.io/ingress.class: traefik\nspec:\n  rules:\n  - host: traefik-ui.minikube\n    http:\n      paths:\n      - backend:\n          serviceName: traefik-web-ui\n          servicePort: 80  examples/k8s/ui.yaml  kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/ui.yaml  Now lets setup an entry in our /etc/hosts file to route  traefik-ui.minikube  to our cluster.  In production you would want to set up real dns entries. \nYou can get the ip address of your minikube instance by running  minikube ip  echo  $(minikube ip) traefik-ui.minikube  | sudo tee -a /etc/hosts  We should now be able to visit  traefik-ui.minikube  in the browser and view the Tr\u00e6fik Web UI.", 
            "title": "Submitting An Ingress to the cluster."
        }, 
        {
            "location": "/user-guide/kubernetes/#basic-authentication", 
            "text": "It's possible to add additional authentication annotations in the Ingress rule.\nThe source of the authentication is a secret that contains usernames and passwords inside the key auth.\nTo read about basic auth limitations see the  Kubernetes Ingress  configuration page.", 
            "title": "Basic Authentication"
        }, 
        {
            "location": "/user-guide/kubernetes/#creating-the-secret", 
            "text": "A. Use  htpasswd  to create a file containing the username and the base64-encoded password:  htpasswd -c ./auth myusername  You will be prompted for a password which you will have to enter twice. htpasswd  will create a file with the following:  cat auth  myusername:$apr1$78Jyn/1K$ERHKVRPPlzAX8eBtLuvRZ0  B. Now use  kubectl  to create a secret in the monitoring namespace using the file created by  htpasswd .  kubectl create secret generic mysecret --from-file auth --namespace=monitoring   Note  Secret must be in same namespace as the ingress rule.   C. Create the ingress using the following annotations to specify basic auth and that the username and password is stored in  mysecret .   ingress.kubernetes.io/auth-type: \"basic\"  ingress.kubernetes.io/auth-secret: \"mysecret\"   Following is a full ingress example based on Prometheus:  apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n name: prometheus-dashboard\n namespace: monitoring\n annotations:\n   kubernetes.io/ingress.class: traefik\n   ingress.kubernetes.io/auth-type:  basic \n   ingress.kubernetes.io/auth-secret:  mysecret \nspec:\n rules:\n - host: dashboard.prometheus.example.com\n   http:\n     paths:\n     - backend:\n         serviceName: prometheus\n         servicePort: 9090  You can apply the example ingress as following:  kubectl create -f prometheus-ingress.yaml -n monitoring", 
            "title": "Creating the Secret"
        }, 
        {
            "location": "/user-guide/kubernetes/#name-based-routing", 
            "text": "In this example we are going to setup websites for 3 of the United Kingdoms best loved cheeses, Cheddar, Stilton and Wensleydale.  First lets start by launching the 3 pods for the cheese websites.  ---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  name: stilton\n  labels:\n    app: cheese\n    cheese: stilton\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: cheese\n      task: stilton\n  template:\n    metadata:\n      labels:\n        app: cheese\n        task: stilton\n        version: v0.0.1\n    spec:\n      containers:\n      - name: cheese\n        image: errm/cheese:stilton\n        ports:\n        - containerPort: 80\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  name: cheddar\n  labels:\n    app: cheese\n    cheese: cheddar\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: cheese\n      task: cheddar\n  template:\n    metadata:\n      labels:\n        app: cheese\n        task: cheddar\n        version: v0.0.1\n    spec:\n      containers:\n      - name: cheese\n        image: errm/cheese:cheddar\n        ports:\n        - containerPort: 80\n---\nkind: Deployment\napiVersion: extensions/v1beta1\nmetadata:\n  name: wensleydale\n  labels:\n    app: cheese\n    cheese: wensleydale\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: cheese\n      task: wensleydale\n  template:\n    metadata:\n      labels:\n        app: cheese\n        task: wensleydale\n        version: v0.0.1\n    spec:\n      containers:\n      - name: cheese\n        image: errm/cheese:wensleydale\n        ports:\n        - containerPort: 80  examples/k8s/cheese-deployments.yaml  kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/cheese-deployments.yaml  Next we need to setup a service for each of the cheese pods.  ---\napiVersion: v1\nkind: Service\nmetadata:\n  name: stilton\nspec:\n  ports:\n  - name: http\n    targetPort: 80\n    port: 80\n  selector:\n    app: cheese\n    task: stilton\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: cheddar\nspec:\n  ports:\n  - name: http\n    targetPort: 80\n    port: 80\n  selector:\n    app: cheese\n    task: cheddar\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: wensleydale\n  annotations:\n    traefik.backend.circuitbreaker:  NetworkErrorRatio()   0.5 \nspec:\n  ports:\n  - name: http\n    targetPort: 80\n    port: 80\n  selector:\n    app: cheese\n    task: wensleydale   Note  We also set a  circuit breaker expression  for one of the backends by setting the  traefik.backend.circuitbreaker  annotation on the service.   examples/k8s/cheese-services.yaml  kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/cheese-services.yaml  Now we can submit an ingress for the cheese websites.  apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: cheese\n  annotations:\n    kubernetes.io/ingress.class: traefik\nspec:\n  rules:\n  - host: stilton.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: stilton\n          servicePort: http\n  - host: cheddar.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: cheddar\n          servicePort: http\n  - host: wensleydale.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: wensleydale\n          servicePort: http  examples/k8s/cheese-ingress.yaml   Note  we list each hostname, and add a backend service.   kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/cheese-ingress.yaml  Now visit the  Tr\u00e6fik dashboard  and you should see a frontend for each host.\nAlong with a backend listing for each service with a Server set up for each pod.  If you edit your  /etc/hosts  again you should be able to access the cheese websites in your browser.  echo  $(minikube ip) stilton.minikube cheddar.minikube wensleydale.minikube  | sudo tee -a /etc/hosts   Stilton  Cheddar  Wensleydale", 
            "title": "Name based routing"
        }, 
        {
            "location": "/user-guide/kubernetes/#path-based-routing", 
            "text": "Now lets suppose that our fictional client has decided that while they are super happy about our cheesy web design, when they asked for 3 websites they had not really bargained on having to buy 3 domain names.  No problem, we say, why don't we reconfigure the sites to host all 3 under one domain.  apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: cheeses\n  annotations:\n    kubernetes.io/ingress.class: traefik\n    traefik.frontend.rule.type: PathPrefixStrip\nspec:\n  rules:\n  - host: cheeses.minikube\n    http:\n      paths:\n      - path: /stilton\n        backend:\n          serviceName: stilton\n          servicePort: http\n      - path: /cheddar\n        backend:\n          serviceName: cheddar\n          servicePort: http\n      - path: /wensleydale\n        backend:\n          serviceName: wensleydale\n          servicePort: http  examples/k8s/cheeses-ingress.yaml   Note  we are configuring Tr\u00e6fik to strip the prefix from the url path with the  traefik.frontend.rule.type  annotation so that we can use the containers from the previous example without modification.   kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/cheeses-ingress.yaml  echo  $(minikube ip) cheeses.minikube  | sudo tee -a /etc/hosts  You should now be able to visit the websites in your browser.   cheeses.minikube/stilton  cheeses.minikube/cheddar  cheeses.minikube/wensleydale", 
            "title": "Path based routing"
        }, 
        {
            "location": "/user-guide/kubernetes/#specifying-priority-for-routing", 
            "text": "Sometimes you need to specify priority for ingress route, especially when handling wildcard routes.\nThis can be done by adding annotation  traefik.frontend.priority , i.e.:  apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: wildcard-cheeses\n  annotations:\n    traefik.frontend.priority:  1 \nspec:\n  rules:\n  - host: *.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: stilton\n          servicePort: http\n\nkind: Ingress\nmetadata:\n  name: specific-cheeses\n  annotations:\n    traefik.frontend.priority:  2 \nspec:\n  rules:\n  - host: specific.minikube\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: stilton\n          servicePort: http  Note that priority values must be quoted to avoid them being interpreted as numbers (which are illegal for annotations).", 
            "title": "Specifying priority for routing"
        }, 
        {
            "location": "/user-guide/kubernetes/#forwarding-to-externalnames", 
            "text": "When specifying an  ExternalName ,\nTr\u00e6fik will forward requests to the given host accordingly and use HTTPS when the Service port matches 443. \nThis still requires setting up a proper port mapping on the Service from the Ingress port to the (external) Service port.", 
            "title": "Forwarding to ExternalNames"
        }, 
        {
            "location": "/user-guide/kubernetes/#disable-passing-the-host-header", 
            "text": "By default Tr\u00e6fik will pass the incoming Host header on to the upstream resource.  There are times however where you may not want this to be the case.\nFor example if your service is of the ExternalName type.", 
            "title": "Disable passing the Host header"
        }, 
        {
            "location": "/user-guide/kubernetes/#disable-entirely", 
            "text": "Add the following to your toml config:  disablePassHostHeaders = true", 
            "title": "Disable entirely"
        }, 
        {
            "location": "/user-guide/kubernetes/#disable-per-ingress", 
            "text": "To disable passing the Host header per ingress resource set the  traefik.frontend.passHostHeader  annotation on your ingress to  false .  Here is an example ingress definition:  apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: example\n  annotations:\n    kubernetes.io/ingress.class: traefik\n    traefik.frontend.passHostHeader:  false \nspec:\n  rules:\n  - host: example.com\n    http:\n      paths:\n      - path: /static\n        backend:\n          serviceName: static\n          servicePort: https  And an example service definition:  apiVersion: v1\nkind: Service\nmetadata:\n  name: static\nspec:\n  ports:\n  - name: https\n    port: 443\n  type: ExternalName\n  externalName: static.otherdomain.com  If you were to visit  example.com/static  the request would then be passed onto  static.otherdomain.com/static  and s tatic.otherdomain.com  would receive the request with the Host header being  static.otherdomain.com .   Note  The per ingress annotation overides whatever the global value is set to.\nSo you could set  disablePassHostHeaders  to  true  in your toml file and then enable passing\nthe host header per ingress if you wanted.", 
            "title": "Disable per ingress"
        }, 
        {
            "location": "/user-guide/kubernetes/#partitioning-the-ingress-object-space", 
            "text": "By default, Tr\u00e6fik processes every Ingress objects it observes. At times, however, it may be desirable to ignore certain objects. The following sub-sections describe common use cases and how they can be handled with Tr\u00e6fik.", 
            "title": "Partitioning the Ingress object space"
        }, 
        {
            "location": "/user-guide/kubernetes/#between-trfik-and-other-ingress-controller-implementations", 
            "text": "Sometimes Tr\u00e6fik runs along other Ingress controller implementations. One such example is when both Tr\u00e6fik and a cloud provider Ingress controller are active.  The  kubernetes.io/ingress.class  annotation can be attached to any Ingress object in order to control whether Tr\u00e6fik should handle it.  If the annotation is missing, contains an empty value, or the value  traefik , then the Tr\u00e6fik controller will take responsibility and process the associated Ingress object. If the annotation contains any other value (usually the name of a different Ingress controller), Tr\u00e6fik will ignore the object.", 
            "title": "Between Tr\u00e6fik and other Ingress controller implementations"
        }, 
        {
            "location": "/user-guide/kubernetes/#between-multiple-trfik-deployments", 
            "text": "Sometimes multiple Tr\u00e6fik Deployments are supposed to run concurrently. For instance, it is conceivable to have one Deployment deal with internal and another one with external traffic.  For such cases, it is advisable to classify Ingress objects through a label and configure the  labelSelector  option per each Tr\u00e6fik Deployment accordingly. To stick with the internal/external example above, all Ingress objects meant for internal traffic could receive a  traffic-type: internal  label while objects designated for external traffic receive a  traffic-type: external  label. The label selectors on the Tr\u00e6fik Deployments would then be  traffic-type=internal  and  traffic-type=external , respectively.", 
            "title": "Between multiple Tr\u00e6fik Deployments"
        }, 
        {
            "location": "/user-guide/kubernetes/#production-advice", 
            "text": "", 
            "title": "Production advice"
        }, 
        {
            "location": "/user-guide/kubernetes/#resource-limitations", 
            "text": "The examples shown deliberately do not specify any  resource limitations  as there is no one size fits all.  In a production environment, however, it is important to set proper bounds, especially with regards to CPU:   too strict and Traefik will be throttled while serving requests (as Kubernetes imposes hard quotas)  too loose and Traefik may waste resources not available for other containers   When in doubt, you should measure your resource needs, and adjust requests and limits accordingly.", 
            "title": "Resource limitations"
        }, 
        {
            "location": "/user-guide/marathon/", 
            "text": "Marathon\n\n\nThis guide explains how to integrate Marathon and operate the cluster in a reliable way from Traefik's standpoint.\n\n\nHost detection\n\n\nMarathon offers multiple ways to run (Docker-containerized) applications, the most popular ones being\n\n\n\n\nBRIDGE-networked containers with dynamic high ports exposed\n\n\nHOST-networked containers with host machine ports\n\n\ncontainers with dedicated IP addresses (\nIP-per-task\n).\n\n\n\n\nTraefik tries to detect the configured mode and route traffic to the right IP addresses. It is possible to force using task hosts with the \nforceTaskHostname\n option.\n\n\nGiven the complexity of the subject, it is possible that the heuristic fails.\nApart from filing an issue and waiting for the feature request / bug report to get addressed, one workaround for such situations is to customize the Marathon template file to the individual needs.\n\n\n\n\nNote\n\n\nThis does \nnot\n require rebuilding Traefik but only to point the \nfilename\n configuration parameter to a customized version of the \nmarathon.tmpl\n file on Traefik startup.\n\n\n\n\nPort detection\n\n\nTraefik also attempts to determine the right port (which is a \nnon-trivial matter in Marathon\n).\nFollowing is the order by which Traefik tries to identify the port (the first one that yields a positive result will be used):\n\n\n\n\nA arbitrary port specified through the \ntraefik.port\n label.\n\n\nThe task port (possibly indexed through the \ntraefik.portIndex\n label, otherwise the first one).\n\n\nThe port from the application's \nportDefinitions\n field (possibly indexed through the \ntraefik.portIndex\n label, otherwise the first one).\n\n\nThe port from the application's \nipAddressPerTask\n field (possibly indexed through the \ntraefik.portIndex\n label, otherwise the first one).\n\n\n\n\nAchieving high availability\n\n\nScenarios\n\n\nThere are three scenarios where the availability of a Marathon application could be impaired along with the risk of losing or failing requests:\n\n\n\n\nDuring the startup phase when Traefik already routes requests to the backend even though it has not completed its bootstrapping process yet.\n\n\nDuring the shutdown phase when Traefik still routes requests to the backend while the backend is already terminating.\n\n\nDuring a failure of the application when Traefik has not yet identified the backend as being erroneous.\n\n\n\n\nThe first two scenarios are common with every rolling upgrade of an application (i.e. a new version release or configuration update).\n\n\nThe following sub-sections describe how to resolve or mitigate each scenario.\n\n\nStartup\n\n\nIt is possible to define \nreadiness checks\n (available since Marathon version 1.1) per application and have Marathon take these into account during the startup phase.\n\n\nThe idea is that each application provides an HTTP endpoint that Marathon queries periodically during an ongoing deployment in order to mark the associated readiness check result as successful if and only if the endpoint returns a response within the configured HTTP code range.\n\nAs long as the check keeps failing, Marathon will not proceed with the deployment (within the configured upgrade strategy bounds).\n\n\nBeginning with version 1.4, Traefik respects readiness check results if the Traefik option is set and checks are configured on the applications accordingly.\n\n\n\n\nNote\n\n\nDue to the way readiness check results are currently exposed by the Marathon API, ready tasks may be taken into rotation with a small delay.\nIt is on the order of one readiness check timeout interval (as configured on the application specifiation) and guarantees that non-ready tasks do not receive traffic prematurely.\n\n\n\n\nIf readiness checks are not possible, a current mitigation strategy is to enable \nretries\n and make sure that a sufficient number of healthy application tasks exist so that one retry will likely hit one of those.\nApart from its probabilistic nature, the workaround comes at the price of increased latency.\n\n\nShutdown\n\n\nIt is possible to install a \ntermination handler\n (available since Marathon version 1.3) with each application whose responsibility it is to delay the shutdown process long enough until the backend has been taken out of load-balancing rotation with reasonable confidence (i.e., Traefik has received an update from the Marathon event bus, recomputes the available Marathon backends, and applies the new configuration).\n\nSpecifically, each termination handler should install a signal handler listening for a SIGTERM signal and implement the following steps on signal reception:\n\n\n\n\nDisable Keep-Alive HTTP connections.\n\n\nKeep accepting HTTP requests for a certain period of time.\n\n\nStop accepting new connections.\n\n\nFinish serving any in-flight requests.\n\n\nShut down.\n\n\n\n\nTraefik already ignores Marathon tasks whose state does not match \nTASK_RUNNING\n; since terminating tasks transition into the \nTASK_KILLING\n and eventually \nTASK_KILLED\n state, there is nothing further that needs to be done on Traefik's end.\n\n\nHow long HTTP requests should continue to be accepted in step 2 depends on how long Traefik needs to receive and process the Marathon configuration update.\nUnder regular operational conditions, it should be on the order of seconds, with 10 seconds possibly being a good default value.\n\n\nAgain, configuring Traefik to do retries (as discussed in the previous section) can serve as a decent workaround strategy.\n\nPaired with termination handlers, they would cover for those cases where either the termination sequence or Traefik cannot complete their part of the orchestration process in time.\n\n\nFailure\n\n\nA failing application always happens unexpectedly, and hence, it is very difficult or even impossible to rule out the adversal effects categorically.\n\n\nFailure reasons vary broadly and could stretch from unacceptable slowness, a task crash, or a network split.\n\n\nThere are two mitigaton efforts:\n\n\n\n\nConfigure \nMarathon health checks\n on each application.\n\n\nConfigure Traefik health checks (possibly via the \ntraefik.backend.healthcheck.*\n labels) and make sure they probe with proper frequency.\n\n\n\n\nThe Marathon health check makes sure that applications once deemed dysfunctional are being rescheduled to different slaves.\nHowever, they might take a while to get triggered and the follow-up processes to complete.\n\n\nFor that reason, the Treafik health check provides an additional check that responds more rapidly and does not require a configuration reload to happen.\nAdditionally, it protects from cases that the Marathon health check may not be able to cover, such as a network split.\n\n\n(Non-)Alternatives\n\n\nThere are a few alternatives of varying quality that are frequently asked for.\n\n\nThe remaining section is going to explore them along with a benefit/cost trade-off.\n\n\nReusing Marathon health checks\n\n\nIt may seem obvious to reuse the Marathon health checks as a signal to Traefik whether an application should be taken into load-balancing rotation or not.\n\n\nApart from the increased latency a failing health check may have, a major problem with this is is that Marathon does not persist the health check results.\nConsequently, if a master re-election occurs in the Marathon clusters, all health check results will revert to the \nunknown\n state, effectively causing all applications inside the cluster to become unavailable and leading to a complete cluster failure.\n\nRe-elections do not only happen during regular maintenance work (often requiring rolling upgrades of the Marathon nodes) but also when the Marathon leader fails spontaneously.\nAs such, there is no way to handle this situation deterministically.\n\n\nFinally, Marathon health checks are not mandatory (the default is to use the task state as reported by Mesos), so requiring them for Traefik would raise the entry barrier for Marathon users.\n\n\nTraefik used to use the health check results as a strict requirement but moved away from it as \nusers reported the dramatic consequences\n.\nIf health check results are known to exist, however, they will be used to signal task availability.\n\n\nDraining\n\n\nAnother common approach is to let a proxy drain backends that are supposed to shut down.\nThat is, once a backend is supposed to shut down, Traefik would stop forwarding requests.\n\n\nOn the plus side, this would not require any modifications to the application in question.\nHowever, implementing this fully within Traefik seems like a non-trivial undertaking.\n\n\nAdditionally, the approach is less flexible compared to a custom termination handler since only the latter allows for the implementation of custom termination sequences that go beyond simple request draining (e.g., persisting a snapshot state to disk prior to terminating).\n\n\nThe feature is currently not implemented; a request for draining in general is at \nissue 41\n.", 
            "title": "Marathon"
        }, 
        {
            "location": "/user-guide/marathon/#marathon", 
            "text": "This guide explains how to integrate Marathon and operate the cluster in a reliable way from Traefik's standpoint.", 
            "title": "Marathon"
        }, 
        {
            "location": "/user-guide/marathon/#host-detection", 
            "text": "Marathon offers multiple ways to run (Docker-containerized) applications, the most popular ones being   BRIDGE-networked containers with dynamic high ports exposed  HOST-networked containers with host machine ports  containers with dedicated IP addresses ( IP-per-task ).   Traefik tries to detect the configured mode and route traffic to the right IP addresses. It is possible to force using task hosts with the  forceTaskHostname  option.  Given the complexity of the subject, it is possible that the heuristic fails.\nApart from filing an issue and waiting for the feature request / bug report to get addressed, one workaround for such situations is to customize the Marathon template file to the individual needs.   Note  This does  not  require rebuilding Traefik but only to point the  filename  configuration parameter to a customized version of the  marathon.tmpl  file on Traefik startup.", 
            "title": "Host detection"
        }, 
        {
            "location": "/user-guide/marathon/#port-detection", 
            "text": "Traefik also attempts to determine the right port (which is a  non-trivial matter in Marathon ).\nFollowing is the order by which Traefik tries to identify the port (the first one that yields a positive result will be used):   A arbitrary port specified through the  traefik.port  label.  The task port (possibly indexed through the  traefik.portIndex  label, otherwise the first one).  The port from the application's  portDefinitions  field (possibly indexed through the  traefik.portIndex  label, otherwise the first one).  The port from the application's  ipAddressPerTask  field (possibly indexed through the  traefik.portIndex  label, otherwise the first one).", 
            "title": "Port detection"
        }, 
        {
            "location": "/user-guide/marathon/#achieving-high-availability", 
            "text": "", 
            "title": "Achieving high availability"
        }, 
        {
            "location": "/user-guide/marathon/#scenarios", 
            "text": "There are three scenarios where the availability of a Marathon application could be impaired along with the risk of losing or failing requests:   During the startup phase when Traefik already routes requests to the backend even though it has not completed its bootstrapping process yet.  During the shutdown phase when Traefik still routes requests to the backend while the backend is already terminating.  During a failure of the application when Traefik has not yet identified the backend as being erroneous.   The first two scenarios are common with every rolling upgrade of an application (i.e. a new version release or configuration update).  The following sub-sections describe how to resolve or mitigate each scenario.", 
            "title": "Scenarios"
        }, 
        {
            "location": "/user-guide/marathon/#startup", 
            "text": "It is possible to define  readiness checks  (available since Marathon version 1.1) per application and have Marathon take these into account during the startup phase.  The idea is that each application provides an HTTP endpoint that Marathon queries periodically during an ongoing deployment in order to mark the associated readiness check result as successful if and only if the endpoint returns a response within the configured HTTP code range. \nAs long as the check keeps failing, Marathon will not proceed with the deployment (within the configured upgrade strategy bounds).  Beginning with version 1.4, Traefik respects readiness check results if the Traefik option is set and checks are configured on the applications accordingly.   Note  Due to the way readiness check results are currently exposed by the Marathon API, ready tasks may be taken into rotation with a small delay.\nIt is on the order of one readiness check timeout interval (as configured on the application specifiation) and guarantees that non-ready tasks do not receive traffic prematurely.   If readiness checks are not possible, a current mitigation strategy is to enable  retries  and make sure that a sufficient number of healthy application tasks exist so that one retry will likely hit one of those.\nApart from its probabilistic nature, the workaround comes at the price of increased latency.", 
            "title": "Startup"
        }, 
        {
            "location": "/user-guide/marathon/#shutdown", 
            "text": "It is possible to install a  termination handler  (available since Marathon version 1.3) with each application whose responsibility it is to delay the shutdown process long enough until the backend has been taken out of load-balancing rotation with reasonable confidence (i.e., Traefik has received an update from the Marathon event bus, recomputes the available Marathon backends, and applies the new configuration). \nSpecifically, each termination handler should install a signal handler listening for a SIGTERM signal and implement the following steps on signal reception:   Disable Keep-Alive HTTP connections.  Keep accepting HTTP requests for a certain period of time.  Stop accepting new connections.  Finish serving any in-flight requests.  Shut down.   Traefik already ignores Marathon tasks whose state does not match  TASK_RUNNING ; since terminating tasks transition into the  TASK_KILLING  and eventually  TASK_KILLED  state, there is nothing further that needs to be done on Traefik's end.  How long HTTP requests should continue to be accepted in step 2 depends on how long Traefik needs to receive and process the Marathon configuration update.\nUnder regular operational conditions, it should be on the order of seconds, with 10 seconds possibly being a good default value.  Again, configuring Traefik to do retries (as discussed in the previous section) can serve as a decent workaround strategy. \nPaired with termination handlers, they would cover for those cases where either the termination sequence or Traefik cannot complete their part of the orchestration process in time.", 
            "title": "Shutdown"
        }, 
        {
            "location": "/user-guide/marathon/#failure", 
            "text": "A failing application always happens unexpectedly, and hence, it is very difficult or even impossible to rule out the adversal effects categorically.  Failure reasons vary broadly and could stretch from unacceptable slowness, a task crash, or a network split.  There are two mitigaton efforts:   Configure  Marathon health checks  on each application.  Configure Traefik health checks (possibly via the  traefik.backend.healthcheck.*  labels) and make sure they probe with proper frequency.   The Marathon health check makes sure that applications once deemed dysfunctional are being rescheduled to different slaves.\nHowever, they might take a while to get triggered and the follow-up processes to complete.  For that reason, the Treafik health check provides an additional check that responds more rapidly and does not require a configuration reload to happen.\nAdditionally, it protects from cases that the Marathon health check may not be able to cover, such as a network split.", 
            "title": "Failure"
        }, 
        {
            "location": "/user-guide/marathon/#non-alternatives", 
            "text": "There are a few alternatives of varying quality that are frequently asked for.  The remaining section is going to explore them along with a benefit/cost trade-off.", 
            "title": "(Non-)Alternatives"
        }, 
        {
            "location": "/user-guide/marathon/#reusing-marathon-health-checks", 
            "text": "It may seem obvious to reuse the Marathon health checks as a signal to Traefik whether an application should be taken into load-balancing rotation or not.  Apart from the increased latency a failing health check may have, a major problem with this is is that Marathon does not persist the health check results.\nConsequently, if a master re-election occurs in the Marathon clusters, all health check results will revert to the  unknown  state, effectively causing all applications inside the cluster to become unavailable and leading to a complete cluster failure. \nRe-elections do not only happen during regular maintenance work (often requiring rolling upgrades of the Marathon nodes) but also when the Marathon leader fails spontaneously.\nAs such, there is no way to handle this situation deterministically.  Finally, Marathon health checks are not mandatory (the default is to use the task state as reported by Mesos), so requiring them for Traefik would raise the entry barrier for Marathon users.  Traefik used to use the health check results as a strict requirement but moved away from it as  users reported the dramatic consequences .\nIf health check results are known to exist, however, they will be used to signal task availability.", 
            "title": "Reusing Marathon health checks"
        }, 
        {
            "location": "/user-guide/marathon/#draining", 
            "text": "Another common approach is to let a proxy drain backends that are supposed to shut down.\nThat is, once a backend is supposed to shut down, Traefik would stop forwarding requests.  On the plus side, this would not require any modifications to the application in question.\nHowever, implementing this fully within Traefik seems like a non-trivial undertaking.  Additionally, the approach is less flexible compared to a custom termination handler since only the latter allows for the implementation of custom termination sequences that go beyond simple request draining (e.g., persisting a snapshot state to disk prior to terminating).  The feature is currently not implemented; a request for draining in general is at  issue 41 .", 
            "title": "Draining"
        }, 
        {
            "location": "/user-guide/kv-config/", 
            "text": "Key-value store configuration\n\n\nBoth \nstatic global configuration\n and \ndynamic\n configuration can be sorted in a Key-value store.\n\n\nThis section explains how to launch Tr\u00e6fik using a configuration loaded from a Key-value store.\n\n\nTr\u00e6fik supports several Key-value stores:\n\n\n\n\nConsul\n\n\netcd\n\n\nZooKeeper\n\n\nboltdb\n\n\n\n\nStatic configuration in Key-value store\n\n\nWe will see the steps to set it up with an easy example.\n\n\n\n\nNote\n\n\nWe could do the same with any other Key-value Store.\n\n\n\n\ndocker-compose file for Consul\n\n\nThe Tr\u00e6fik global configuration will be retrieved from a \nConsul\n store.\n\n\nFirst we have to launch Consul in a container.\n\n\nThe \ndocker-compose file\n allows us to launch Consul and four instances of the trivial app \nemilevauge/whoamI\n :\n\n\nconsul:\n  image: progrium/consul\n  command: -server -bootstrap -log-level debug -ui-dir /ui\n  ports:\n    - \n8400:8400\n\n    - \n8500:8500\n\n    - \n8600:53/udp\n\n  expose:\n    - \n8300\n\n    - \n8301\n\n    - \n8301/udp\n\n    - \n8302\n\n    - \n8302/udp\n\n\nwhoami1:\n  image: emilevauge/whoami\n\nwhoami2:\n  image: emilevauge/whoami\n\nwhoami3:\n  image: emilevauge/whoami\n\nwhoami4:\n  image: emilevauge/whoami\n\n\n\n\nUpload the configuration in the Key-value store\n\n\nWe should now fill the store with the Tr\u00e6fik global configuration, as we do with a \nTOML file configuration\n.\n\nTo do that, we can send the Key-value pairs via \ncurl commands\n or via the \nWeb UI\n.\n\n\nFortunately, Tr\u00e6fik allows automation of this process using the \nstoreconfig\n subcommand.\n\nPlease refer to the \nstore Tr\u00e6fik configuration\n section to get documentation on it.\n\n\nHere is the toml configuration we would like to store in the Key-value Store  :\n\n\nlogLevel = \nDEBUG\n\n\ndefaultEntryPoints = [\nhttp\n, \nhttps\n]\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:80\n\n  [entryPoints.https]\n  address = \n:443\n\n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \nintegration/fixtures/https/snitest.com.cert\n\n      KeyFile = \nintegration/fixtures/https/snitest.com.key\n\n      [[entryPoints.https.tls.certificates]]\n      CertFile = \n-----BEGIN CERTIFICATE-----\n                      \ncert file content\n\n                      -----END CERTIFICATE-----\n\n      KeyFile = \n-----BEGIN CERTIFICATE-----\n                      \nkey file content\n\n                      -----END CERTIFICATE-----\n\n\n[consul]\n  endpoint = \n127.0.0.1:8500\n\n  watch = true\n  prefix = \ntraefik\n\n\n[web]\n  address = \n:8081\n\n\n\n\n\nAnd there, the same global configuration in the Key-value Store (using \nprefix = \"traefik\"\n):\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/loglevel\n\n\nDEBUG\n\n\n\n\n\n\n/traefik/defaultentrypoints/0\n\n\nhttp\n\n\n\n\n\n\n/traefik/defaultentrypoints/1\n\n\nhttps\n\n\n\n\n\n\n/traefik/entrypoints/http/address\n\n\n:80\n\n\n\n\n\n\n/traefik/entrypoints/https/address\n\n\n:443\n\n\n\n\n\n\n/traefik/entrypoints/https/tls/certificates/0/certfile\n\n\nintegration/fixtures/https/snitest.com.cert\n\n\n\n\n\n\n/traefik/entrypoints/https/tls/certificates/0/keyfile\n\n\nintegration/fixtures/https/snitest.com.key\n\n\n\n\n\n\n/traefik/entrypoints/https/tls/certificates/1/certfile\n\n\n--BEGIN CERTIFICATE--\ncert file content\n--END CERTIFICATE--\n\n\n\n\n\n\n/traefik/entrypoints/https/tls/certificates/1/keyfile\n\n\n--BEGIN CERTIFICATE--\nkey file content\n--END CERTIFICATE--\n\n\n\n\n\n\n/traefik/consul/endpoint\n\n\n127.0.0.1:8500\n\n\n\n\n\n\n/traefik/consul/watch\n\n\ntrue\n\n\n\n\n\n\n/traefik/consul/prefix\n\n\ntraefik\n\n\n\n\n\n\n/traefik/web/address\n\n\n:8081\n\n\n\n\n\n\n\n\nIn case you are setting key values manually:\n\n\n\n\nRemember to specify the indexes (\n0\n,\n1\n, \n2\n, ... ) under prefixes \n/traefik/defaultentrypoints/\n and \n/traefik/entrypoints/https/tls/certificates/\n in order to match the global configuration structure.\n\n\nBe careful to give the correct IP address and port on the key \n/traefik/consul/endpoint\n.\n\n\n\n\nNote that we can either give path to certificate file or directly the file content itself.\n\n\nLaunch Tr\u00e6fik\n\n\nWe will now launch Tr\u00e6fik in a container.\n\n\nWe use CLI flags to setup the connection between Tr\u00e6fik and Consul.\nAll the rest of the global configuration is stored in Consul.\n\n\nHere is the \ndocker-compose file\n :\n\n\ntraefik:\n  image: traefik\n  command: --consul --consul.endpoint=127.0.0.1:8500\n  ports:\n    - \n80:80\n\n    - \n8080:8080\n\n\n\n\n\n\n\nWarning\n\n\nBe careful to give the correct IP address and port in the flag \n--consul.endpoint\n.\n\n\n\n\nConsul ACL Token support\n\n\nTo specify a Consul ACL token for Traefik, we have to set a System Environment variable named \nCONSUL_HTTP_TOKEN\n prior to starting Traefik.\nThis variable must be initialized with the ACL token value.\n\n\nIf Traefik is launched into a Docker container, the variable \nCONSUL_HTTP_TOKEN\n can be initialized with the \n-e\n Docker option : \n-e \"CONSUL_HTTP_TOKEN=[consul-acl-token-value]\"\n\n\nIf a Consul ACL is used to restrict Tr\u00e6fik read/write access, one of the following configurations is needed.\n\n\n\n\nHCL format :\n\n\n\n\n    key \ntraefik\n {\n        policy = \nwrite\n\n    },\n\n    session \n {\n        policy = \nwrite\n\n    }\n\n\n\n\n\n\nJSON format :\n\n\n\n\n{\n    \nkey\n: {\n        \ntraefik\n: {\n          \npolicy\n: \nwrite\n\n        }\n    },\n    \nsession\n: {\n        \n: {\n        \npolicy\n: \nwrite\n\n        }\n    }\n}\n\n\n\n\nTLS support\n\n\nTo connect to a Consul endpoint using SSL, simply specify \nhttps://\n in the \nconsul.endpoint\n property\n\n\n\n\n--consul.endpoint=https://[consul-host]:[consul-ssl-port]\n\n\n\n\nTLS support with client certificates\n\n\nSo far, only \nConsul\n and \netcd\n support TLS connections with client certificates.\n\n\nTo set it up, we should enable \nconsul security\n (or \netcd security\n).\n\n\nThen, we have to provide CA, Cert and Key to Tr\u00e6fik using \nconsul\n flags :\n\n\n\n\n--consul.tls\n\n\n--consul.tls.ca=path/to/the/file\n\n\n--consul.tls.cert=path/to/the/file\n\n\n--consul.tls.key=path/to/the/file\n\n\n\n\nOr etcd flags :\n\n\n\n\n--etcd.tls\n\n\n--etcd.tls.ca=path/to/the/file\n\n\n--etcd.tls.cert=path/to/the/file\n\n\n--etcd.tls.key=path/to/the/file\n\n\n\n\n!! note\n    We can either give directly directly the file content itself (instead of the path to certificate) in a TOML file configuration.\n\n\nRemember the command \ntraefik --help\n to display the updated list of flags.\n\n\nDynamic configuration in Key-value store\n\n\nFollowing our example, we will provide backends/frontends rules to Tr\u00e6fik.\n\n\n\n\nNote\n\n\nThis section is independent of the way Tr\u00e6fik got its static configuration.\nIt means that the static configuration can either come from the same Key-value store or from any other sources.\n\n\n\n\nKey-value storage structure\n\n\nHere is the toml configuration we would like to store in the store :\n\n\n[file]\n\n# rules\n[backends]\n  [backends.backend1]\n    [backends.backend1.circuitbreaker]\n    expression = \nNetworkErrorRatio() \n 0.5\n\n    [backends.backend1.servers.server1]\n    url = \nhttp://172.17.0.2:80\n\n    weight = 10\n    [backends.backend1.servers.server2]\n    url = \nhttp://172.17.0.3:80\n\n    weight = 1\n  [backends.backend2]\n    [backends.backend1.maxconn]\n    amount = 10\n    extractorfunc = \nrequest.host\n\n    [backends.backend2.LoadBalancer]\n    method = \ndrr\n\n    [backends.backend2.servers.server1]\n    url = \nhttp://172.17.0.4:80\n\n    weight = 1\n    [backends.backend2.servers.server2]\n    url = \nhttp://172.17.0.5:80\n\n    weight = 2\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend2\n\n    [frontends.frontend1.routes.test_1]\n    rule = \nHost:test.localhost\n\n  [frontends.frontend2]\n  backend = \nbackend1\n\n  passHostHeader = true\n  priority = 10\n  entrypoints = [\nhttps\n] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule = \nHost:{subdomain:[a-z]+}.localhost\n\n  [frontends.frontend3]\n  entrypoints = [\nhttp\n, \nhttps\n] # overrides defaultEntryPoints\n  backend = \nbackend2\n\n  rule = \nPath:/test\n\n\n\n\n\nAnd there, the same dynamic configuration in a KV Store (using \nprefix = \"traefik\"\n):\n\n\n\n\nbackend 1\n\n\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/backends/backend1/circuitbreaker/expression\n\n\nNetworkErrorRatio() \n 0.5\n\n\n\n\n\n\n/traefik/backends/backend1/servers/server1/url\n\n\nhttp://172.17.0.2:80\n\n\n\n\n\n\n/traefik/backends/backend1/servers/server1/weight\n\n\n10\n\n\n\n\n\n\n/traefik/backends/backend1/servers/server2/url\n\n\nhttp://172.17.0.3:80\n\n\n\n\n\n\n/traefik/backends/backend1/servers/server2/weight\n\n\n1\n\n\n\n\n\n\n/traefik/backends/backend1/servers/server2/tags\n\n\napi,helloworld\n\n\n\n\n\n\n\n\n\n\nbackend 2\n\n\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/backends/backend2/maxconn/amount\n\n\n10\n\n\n\n\n\n\n/traefik/backends/backend2/maxconn/extractorfunc\n\n\nrequest.host\n\n\n\n\n\n\n/traefik/backends/backend2/loadbalancer/method\n\n\ndrr\n\n\n\n\n\n\n/traefik/backends/backend2/servers/server1/url\n\n\nhttp://172.17.0.4:80\n\n\n\n\n\n\n/traefik/backends/backend2/servers/server1/weight\n\n\n1\n\n\n\n\n\n\n/traefik/backends/backend2/servers/server2/url\n\n\nhttp://172.17.0.5:80\n\n\n\n\n\n\n/traefik/backends/backend2/servers/server2/weight\n\n\n2\n\n\n\n\n\n\n/traefik/backends/backend2/servers/server2/tags\n\n\nweb\n\n\n\n\n\n\n\n\n\n\nfrontend 1\n\n\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/frontends/frontend1/backend\n\n\nbackend2\n\n\n\n\n\n\n/traefik/frontends/frontend1/routes/test_1/rule\n\n\nHost:test.localhost\n\n\n\n\n\n\n\n\n\n\nfrontend 2\n\n\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/frontends/frontend2/backend\n\n\nbackend1\n\n\n\n\n\n\n/traefik/frontends/frontend2/passHostHeader\n\n\ntrue\n\n\n\n\n\n\n/traefik/frontends/frontend2/priority\n\n\n10\n\n\n\n\n\n\n/traefik/frontends/frontend2/entrypoints\n\n\nhttp,https\n\n\n\n\n\n\n/traefik/frontends/frontend2/routes/test_2/rule\n\n\nPathPrefix:/test\n\n\n\n\n\n\n\n\nAtomic configuration changes\n\n\nTr\u00e6fik can watch the backends/frontends configuration changes and generate its configuration automatically.\n\n\n\n\nNote\n\n\nOnly backends/frontends rules are dynamic, the rest of the Tr\u00e6fik configuration stay static.\n\n\n\n\nThe \nEtcd\n and \nConsul\n backends do not support updating multiple keys atomically.\n\nAs a result, it may be possible for Tr\u00e6fik to read an intermediate configuration state despite judicious use of the \n--providersThrottleDuration\n flag.\n\nTo solve this problem, Tr\u00e6fik supports a special key called \n/traefik/alias\n.\nIf set, Tr\u00e6fik use the value as an alternative key prefix.\n\n\nGiven the key structure below, Tr\u00e6fik will use the \nhttp://172.17.0.2:80\n as its only backend (frontend keys have been omitted for brevity).\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/alias\n\n\n/traefik_configurations/1\n\n\n\n\n\n\n/traefik_configurations/1/backends/backend1/servers/server1/url\n\n\nhttp://172.17.0.2:80\n\n\n\n\n\n\n/traefik_configurations/1/backends/backend1/servers/server1/weight\n\n\n10\n\n\n\n\n\n\n\n\nWhen an atomic configuration change is required, you may write a new configuration at an alternative prefix.\n\n\nHere, although the \n/traefik_configurations/2/...\n keys have been set, the old configuration is still active because the \n/traefik/alias\n key still points to \n/traefik_configurations/1\n:\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/alias\n\n\n/traefik_configurations/1\n\n\n\n\n\n\n/traefik_configurations/1/backends/backend1/servers/server1/url\n\n\nhttp://172.17.0.2:80\n\n\n\n\n\n\n/traefik_configurations/1/backends/backend1/servers/server1/weight\n\n\n10\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server1/url\n\n\nhttp://172.17.0.2:80\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server1/weight\n\n\n5\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server2/url\n\n\nhttp://172.17.0.3:80\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server2/weight\n\n\n5\n\n\n\n\n\n\n\n\nOnce the \n/traefik/alias\n key is updated, the new \n/traefik_configurations/2\n configuration becomes active atomically.\n\n\nHere, we have a 50% balance between the \nhttp://172.17.0.3:80\n and the \nhttp://172.17.0.4:80\n hosts while no traffic is sent to the \n172.17.0.2:80\n host:\n\n\n\n\n\n\n\n\nKey\n\n\nValue\n\n\n\n\n\n\n\n\n\n\n/traefik/alias\n\n\n/traefik_configurations/2\n\n\n\n\n\n\n/traefik_configurations/1/backends/backend1/servers/server1/url\n\n\nhttp://172.17.0.2:80\n\n\n\n\n\n\n/traefik_configurations/1/backends/backend1/servers/server1/weight\n\n\n10\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server1/url\n\n\nhttp://172.17.0.3:80\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server1/weight\n\n\n5\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server2/url\n\n\nhttp://172.17.0.4:80\n\n\n\n\n\n\n/traefik_configurations/2/backends/backend1/servers/server2/weight\n\n\n5\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nTr\u00e6fik \nwill not watch for key changes in the \n/traefik_configurations\n prefix\n. It will only watch for changes in the \n/traefik/alias\n.\n\nFurther, if the \n/traefik/alias\n key is set, all other configuration with \n/traefik/backends\n or \n/traefik/frontends\n prefix are ignored.\n\n\n\n\nStore configuration in Key-value store\n\n\n\n\nNote\n\n\nDon't forget to \nsetup the connection between Tr\u00e6fik and Key-value store\n.\n\n\n\n\nThe static Tr\u00e6fik configuration in a key-value store can be automatically created and updated, using the \nstoreconfig\n subcommand\n.\n\n\ntraefik storeconfig [flags] ...\n\n\n\n\nThis command is here only to automate the \nprocess which upload the configuration into the Key-value store\n.\nTr\u00e6fik will not start but the \nstatic configuration\n will be uploaded into the Key-value store.\n\nIf you configured ACME (Let's Encrypt), your registration account and your certificates will also be uploaded.\n\n\nTo upload your ACME certificates to the KV store, get your Traefik TOML file and add the new \nstorage\n option in the \nacme\n section:\n\n\n[acme]\nemail = \ntest@traefik.io\n\nstorage = \ntraefik/acme/account\n # the key where to store your certificates in the KV store\nstorageFile = \nacme.json\n # your old certificates store\n\n\n\n\nCall \ntraefik\u00a0storeconfig\n to upload your config in the KV store.\nThen remove the line \nstorageFile = \"acme.json\"\n from your TOML config file.\n\n\nThat's it!", 
            "title": "Key-value Store Configuration"
        }, 
        {
            "location": "/user-guide/kv-config/#key-value-store-configuration", 
            "text": "Both  static global configuration  and  dynamic  configuration can be sorted in a Key-value store.  This section explains how to launch Tr\u00e6fik using a configuration loaded from a Key-value store.  Tr\u00e6fik supports several Key-value stores:   Consul  etcd  ZooKeeper  boltdb", 
            "title": "Key-value store configuration"
        }, 
        {
            "location": "/user-guide/kv-config/#static-configuration-in-key-value-store", 
            "text": "We will see the steps to set it up with an easy example.   Note  We could do the same with any other Key-value Store.", 
            "title": "Static configuration in Key-value store"
        }, 
        {
            "location": "/user-guide/kv-config/#docker-compose-file-for-consul", 
            "text": "The Tr\u00e6fik global configuration will be retrieved from a  Consul  store.  First we have to launch Consul in a container.  The  docker-compose file  allows us to launch Consul and four instances of the trivial app  emilevauge/whoamI  :  consul:\n  image: progrium/consul\n  command: -server -bootstrap -log-level debug -ui-dir /ui\n  ports:\n    -  8400:8400 \n    -  8500:8500 \n    -  8600:53/udp \n  expose:\n    -  8300 \n    -  8301 \n    -  8301/udp \n    -  8302 \n    -  8302/udp \n\nwhoami1:\n  image: emilevauge/whoami\n\nwhoami2:\n  image: emilevauge/whoami\n\nwhoami3:\n  image: emilevauge/whoami\n\nwhoami4:\n  image: emilevauge/whoami", 
            "title": "docker-compose file for Consul"
        }, 
        {
            "location": "/user-guide/kv-config/#upload-the-configuration-in-the-key-value-store", 
            "text": "We should now fill the store with the Tr\u00e6fik global configuration, as we do with a  TOML file configuration . \nTo do that, we can send the Key-value pairs via  curl commands  or via the  Web UI .  Fortunately, Tr\u00e6fik allows automation of this process using the  storeconfig  subcommand. \nPlease refer to the  store Tr\u00e6fik configuration  section to get documentation on it.  Here is the toml configuration we would like to store in the Key-value Store  :  logLevel =  DEBUG \n\ndefaultEntryPoints = [ http ,  https ]\n\n[entryPoints]\n  [entryPoints.http]\n  address =  :80 \n  [entryPoints.https]\n  address =  :443 \n    [entryPoints.https.tls]\n      [[entryPoints.https.tls.certificates]]\n      CertFile =  integration/fixtures/https/snitest.com.cert \n      KeyFile =  integration/fixtures/https/snitest.com.key \n      [[entryPoints.https.tls.certificates]]\n      CertFile =  -----BEGIN CERTIFICATE-----\n                       cert file content \n                      -----END CERTIFICATE----- \n      KeyFile =  -----BEGIN CERTIFICATE-----\n                       key file content \n                      -----END CERTIFICATE----- \n\n[consul]\n  endpoint =  127.0.0.1:8500 \n  watch = true\n  prefix =  traefik \n\n[web]\n  address =  :8081   And there, the same global configuration in the Key-value Store (using  prefix = \"traefik\" ):     Key  Value      /traefik/loglevel  DEBUG    /traefik/defaultentrypoints/0  http    /traefik/defaultentrypoints/1  https    /traefik/entrypoints/http/address  :80    /traefik/entrypoints/https/address  :443    /traefik/entrypoints/https/tls/certificates/0/certfile  integration/fixtures/https/snitest.com.cert    /traefik/entrypoints/https/tls/certificates/0/keyfile  integration/fixtures/https/snitest.com.key    /traefik/entrypoints/https/tls/certificates/1/certfile  --BEGIN CERTIFICATE-- cert file content --END CERTIFICATE--    /traefik/entrypoints/https/tls/certificates/1/keyfile  --BEGIN CERTIFICATE-- key file content --END CERTIFICATE--    /traefik/consul/endpoint  127.0.0.1:8500    /traefik/consul/watch  true    /traefik/consul/prefix  traefik    /traefik/web/address  :8081     In case you are setting key values manually:   Remember to specify the indexes ( 0 , 1 ,  2 , ... ) under prefixes  /traefik/defaultentrypoints/  and  /traefik/entrypoints/https/tls/certificates/  in order to match the global configuration structure.  Be careful to give the correct IP address and port on the key  /traefik/consul/endpoint .   Note that we can either give path to certificate file or directly the file content itself.", 
            "title": "Upload the configuration in the Key-value store"
        }, 
        {
            "location": "/user-guide/kv-config/#launch-trfik", 
            "text": "We will now launch Tr\u00e6fik in a container.  We use CLI flags to setup the connection between Tr\u00e6fik and Consul.\nAll the rest of the global configuration is stored in Consul.  Here is the  docker-compose file  :  traefik:\n  image: traefik\n  command: --consul --consul.endpoint=127.0.0.1:8500\n  ports:\n    -  80:80 \n    -  8080:8080    Warning  Be careful to give the correct IP address and port in the flag  --consul.endpoint .", 
            "title": "Launch Tr\u00e6fik"
        }, 
        {
            "location": "/user-guide/kv-config/#consul-acl-token-support", 
            "text": "To specify a Consul ACL token for Traefik, we have to set a System Environment variable named  CONSUL_HTTP_TOKEN  prior to starting Traefik.\nThis variable must be initialized with the ACL token value.  If Traefik is launched into a Docker container, the variable  CONSUL_HTTP_TOKEN  can be initialized with the  -e  Docker option :  -e \"CONSUL_HTTP_TOKEN=[consul-acl-token-value]\"  If a Consul ACL is used to restrict Tr\u00e6fik read/write access, one of the following configurations is needed.   HCL format :       key  traefik  {\n        policy =  write \n    },\n\n    session   {\n        policy =  write \n    }   JSON format :   {\n     key : {\n         traefik : {\n           policy :  write \n        }\n    },\n     session : {\n         : {\n         policy :  write \n        }\n    }\n}", 
            "title": "Consul ACL Token support"
        }, 
        {
            "location": "/user-guide/kv-config/#tls-support", 
            "text": "To connect to a Consul endpoint using SSL, simply specify  https://  in the  consul.endpoint  property   --consul.endpoint=https://[consul-host]:[consul-ssl-port]", 
            "title": "TLS support"
        }, 
        {
            "location": "/user-guide/kv-config/#tls-support-with-client-certificates", 
            "text": "So far, only  Consul  and  etcd  support TLS connections with client certificates.  To set it up, we should enable  consul security  (or  etcd security ).  Then, we have to provide CA, Cert and Key to Tr\u00e6fik using  consul  flags :   --consul.tls  --consul.tls.ca=path/to/the/file  --consul.tls.cert=path/to/the/file  --consul.tls.key=path/to/the/file   Or etcd flags :   --etcd.tls  --etcd.tls.ca=path/to/the/file  --etcd.tls.cert=path/to/the/file  --etcd.tls.key=path/to/the/file   !! note\n    We can either give directly directly the file content itself (instead of the path to certificate) in a TOML file configuration.  Remember the command  traefik --help  to display the updated list of flags.", 
            "title": "TLS support with client certificates"
        }, 
        {
            "location": "/user-guide/kv-config/#dynamic-configuration-in-key-value-store", 
            "text": "Following our example, we will provide backends/frontends rules to Tr\u00e6fik.   Note  This section is independent of the way Tr\u00e6fik got its static configuration.\nIt means that the static configuration can either come from the same Key-value store or from any other sources.", 
            "title": "Dynamic configuration in Key-value store"
        }, 
        {
            "location": "/user-guide/kv-config/#key-value-storage-structure", 
            "text": "Here is the toml configuration we would like to store in the store :  [file]\n\n# rules\n[backends]\n  [backends.backend1]\n    [backends.backend1.circuitbreaker]\n    expression =  NetworkErrorRatio()   0.5 \n    [backends.backend1.servers.server1]\n    url =  http://172.17.0.2:80 \n    weight = 10\n    [backends.backend1.servers.server2]\n    url =  http://172.17.0.3:80 \n    weight = 1\n  [backends.backend2]\n    [backends.backend1.maxconn]\n    amount = 10\n    extractorfunc =  request.host \n    [backends.backend2.LoadBalancer]\n    method =  drr \n    [backends.backend2.servers.server1]\n    url =  http://172.17.0.4:80 \n    weight = 1\n    [backends.backend2.servers.server2]\n    url =  http://172.17.0.5:80 \n    weight = 2\n\n[frontends]\n  [frontends.frontend1]\n  backend =  backend2 \n    [frontends.frontend1.routes.test_1]\n    rule =  Host:test.localhost \n  [frontends.frontend2]\n  backend =  backend1 \n  passHostHeader = true\n  priority = 10\n  entrypoints = [ https ] # overrides defaultEntryPoints\n    [frontends.frontend2.routes.test_1]\n    rule =  Host:{subdomain:[a-z]+}.localhost \n  [frontends.frontend3]\n  entrypoints = [ http ,  https ] # overrides defaultEntryPoints\n  backend =  backend2 \n  rule =  Path:/test   And there, the same dynamic configuration in a KV Store (using  prefix = \"traefik\" ):   backend 1      Key  Value      /traefik/backends/backend1/circuitbreaker/expression  NetworkErrorRatio()   0.5    /traefik/backends/backend1/servers/server1/url  http://172.17.0.2:80    /traefik/backends/backend1/servers/server1/weight  10    /traefik/backends/backend1/servers/server2/url  http://172.17.0.3:80    /traefik/backends/backend1/servers/server2/weight  1    /traefik/backends/backend1/servers/server2/tags  api,helloworld      backend 2      Key  Value      /traefik/backends/backend2/maxconn/amount  10    /traefik/backends/backend2/maxconn/extractorfunc  request.host    /traefik/backends/backend2/loadbalancer/method  drr    /traefik/backends/backend2/servers/server1/url  http://172.17.0.4:80    /traefik/backends/backend2/servers/server1/weight  1    /traefik/backends/backend2/servers/server2/url  http://172.17.0.5:80    /traefik/backends/backend2/servers/server2/weight  2    /traefik/backends/backend2/servers/server2/tags  web      frontend 1      Key  Value      /traefik/frontends/frontend1/backend  backend2    /traefik/frontends/frontend1/routes/test_1/rule  Host:test.localhost      frontend 2      Key  Value      /traefik/frontends/frontend2/backend  backend1    /traefik/frontends/frontend2/passHostHeader  true    /traefik/frontends/frontend2/priority  10    /traefik/frontends/frontend2/entrypoints  http,https    /traefik/frontends/frontend2/routes/test_2/rule  PathPrefix:/test", 
            "title": "Key-value storage structure"
        }, 
        {
            "location": "/user-guide/kv-config/#atomic-configuration-changes", 
            "text": "Tr\u00e6fik can watch the backends/frontends configuration changes and generate its configuration automatically.   Note  Only backends/frontends rules are dynamic, the rest of the Tr\u00e6fik configuration stay static.   The  Etcd  and  Consul  backends do not support updating multiple keys atomically. \nAs a result, it may be possible for Tr\u00e6fik to read an intermediate configuration state despite judicious use of the  --providersThrottleDuration  flag. \nTo solve this problem, Tr\u00e6fik supports a special key called  /traefik/alias .\nIf set, Tr\u00e6fik use the value as an alternative key prefix.  Given the key structure below, Tr\u00e6fik will use the  http://172.17.0.2:80  as its only backend (frontend keys have been omitted for brevity).     Key  Value      /traefik/alias  /traefik_configurations/1    /traefik_configurations/1/backends/backend1/servers/server1/url  http://172.17.0.2:80    /traefik_configurations/1/backends/backend1/servers/server1/weight  10     When an atomic configuration change is required, you may write a new configuration at an alternative prefix.  Here, although the  /traefik_configurations/2/...  keys have been set, the old configuration is still active because the  /traefik/alias  key still points to  /traefik_configurations/1 :     Key  Value      /traefik/alias  /traefik_configurations/1    /traefik_configurations/1/backends/backend1/servers/server1/url  http://172.17.0.2:80    /traefik_configurations/1/backends/backend1/servers/server1/weight  10    /traefik_configurations/2/backends/backend1/servers/server1/url  http://172.17.0.2:80    /traefik_configurations/2/backends/backend1/servers/server1/weight  5    /traefik_configurations/2/backends/backend1/servers/server2/url  http://172.17.0.3:80    /traefik_configurations/2/backends/backend1/servers/server2/weight  5     Once the  /traefik/alias  key is updated, the new  /traefik_configurations/2  configuration becomes active atomically.  Here, we have a 50% balance between the  http://172.17.0.3:80  and the  http://172.17.0.4:80  hosts while no traffic is sent to the  172.17.0.2:80  host:     Key  Value      /traefik/alias  /traefik_configurations/2    /traefik_configurations/1/backends/backend1/servers/server1/url  http://172.17.0.2:80    /traefik_configurations/1/backends/backend1/servers/server1/weight  10    /traefik_configurations/2/backends/backend1/servers/server1/url  http://172.17.0.3:80    /traefik_configurations/2/backends/backend1/servers/server1/weight  5    /traefik_configurations/2/backends/backend1/servers/server2/url  http://172.17.0.4:80    /traefik_configurations/2/backends/backend1/servers/server2/weight  5      Note  Tr\u00e6fik  will not watch for key changes in the  /traefik_configurations  prefix . It will only watch for changes in the  /traefik/alias . \nFurther, if the  /traefik/alias  key is set, all other configuration with  /traefik/backends  or  /traefik/frontends  prefix are ignored.", 
            "title": "Atomic configuration changes"
        }, 
        {
            "location": "/user-guide/kv-config/#store-configuration-in-key-value-store", 
            "text": "Note  Don't forget to  setup the connection between Tr\u00e6fik and Key-value store .   The static Tr\u00e6fik configuration in a key-value store can be automatically created and updated, using the  storeconfig  subcommand .  traefik storeconfig [flags] ...  This command is here only to automate the  process which upload the configuration into the Key-value store .\nTr\u00e6fik will not start but the  static configuration  will be uploaded into the Key-value store. \nIf you configured ACME (Let's Encrypt), your registration account and your certificates will also be uploaded.  To upload your ACME certificates to the KV store, get your Traefik TOML file and add the new  storage  option in the  acme  section:  [acme]\nemail =  test@traefik.io \nstorage =  traefik/acme/account  # the key where to store your certificates in the KV store\nstorageFile =  acme.json  # your old certificates store  Call  traefik\u00a0storeconfig  to upload your config in the KV store.\nThen remove the line  storageFile = \"acme.json\"  from your TOML config file.  That's it!", 
            "title": "Store configuration in Key-value store"
        }, 
        {
            "location": "/user-guide/cluster/", 
            "text": "Clustering / High Availability (beta)\n\n\nThis guide explains how to use Tr\u00e6fik in high availability mode.\n\n\nIn order to deploy and configure multiple Tr\u00e6fik instances, without copying the same configuration file on each instance, we will use a distributed Key-Value store.\n\n\nPrerequisites\n\n\nYou will need a working KV store cluster.\n\n(Currently, we recommend \nConsul\n .)\n\n\nFile configuration to KV store migration\n\n\nWe created a special Tr\u00e6fik command to help configuring your Key Value store from a Tr\u00e6fik TOML configuration file.\n\n\nPlease refer to \nthis section\n to get more details.\n\n\nDeploy a Tr\u00e6fik cluster\n\n\nOnce your Tr\u00e6fik configuration is uploaded on your KV store, you can start each Tr\u00e6fik instance.\n\n\nA Tr\u00e6fik cluster is based on a manager/worker model.\n\n\nWhen starting, Tr\u00e6fik will elect a manager.\nIf this instance fails, another manager will be automatically elected.", 
            "title": "Clustering/HA"
        }, 
        {
            "location": "/user-guide/cluster/#clustering-high-availability-beta", 
            "text": "This guide explains how to use Tr\u00e6fik in high availability mode.  In order to deploy and configure multiple Tr\u00e6fik instances, without copying the same configuration file on each instance, we will use a distributed Key-Value store.", 
            "title": "Clustering / High Availability (beta)"
        }, 
        {
            "location": "/user-guide/cluster/#prerequisites", 
            "text": "You will need a working KV store cluster. (Currently, we recommend  Consul  .)", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/user-guide/cluster/#file-configuration-to-kv-store-migration", 
            "text": "We created a special Tr\u00e6fik command to help configuring your Key Value store from a Tr\u00e6fik TOML configuration file.  Please refer to  this section  to get more details.", 
            "title": "File configuration to KV store migration"
        }, 
        {
            "location": "/user-guide/cluster/#deploy-a-trfik-cluster", 
            "text": "Once your Tr\u00e6fik configuration is uploaded on your KV store, you can start each Tr\u00e6fik instance.  A Tr\u00e6fik cluster is based on a manager/worker model.  When starting, Tr\u00e6fik will elect a manager.\nIf this instance fails, another manager will be automatically elected.", 
            "title": "Deploy a Tr\u00e6fik cluster"
        }, 
        {
            "location": "/user-guide/grpc/", 
            "text": "gRPC example\n\n\nThis section explains how to use Traefik as reverse proxy for gRPC application with self-signed certificates.\n\n\n\n\nWarning\n\n\nAs gRPC needs HTTP2, we need HTTPS certificates on both gRPC Server and Tr\u00e6fik.\n\n\n\n\n\n\n\n\n\n\n\ngRPC Server certificate\n\n\nIn order to secure the gRPC server, we generate a self-signed certificate for backend url:\n\n\nopenssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout ./backend.key -out ./backend.cert\n\n\n\n\nThat will prompt for information, the important answer is:\n\n\nCommon Name (e.g. server FQDN or YOUR name) []: backend.local\n\n\n\n\ngRPC Client certificate\n\n\nGenerate your self-signed certificate for frontend url:\n\n\nopenssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout ./frontend.key -out ./frontend.cert\n\n\n\n\nwith\n\n\nCommon Name (e.g. server FQDN or YOUR name) []: frontend.local\n\n\n\n\nTr\u00e6fik configuration\n\n\nAt last, we configure our Tr\u00e6fik instance to use both self-signed certificates.\n\n\ndefaultEntryPoints = [\nhttps\n]\n\n# For secure connection on backend.local\nRootCAs = [ \n./backend.cert\n ]\n\n[entryPoints]\n  [entryPoints.https]\n  address = \n:4443\n\n    [entryPoints.https.tls]\n     # For secure connection on frontend.local\n     [[entryPoints.https.tls.certificates]]\n     certFile = \n./frontend.cert\n\n     keyFile  = \n./frontend.key\n\n\n\n[web]\n  address = \n:8080\n\n\n[file]\n\n[backends]\n  [backends.backend1]\n    [backends.backend1.servers.server1]\n    # Access on backend with HTTPS\n    url = \nhttps://backend.local:8080\n\n\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend1\n\n    [frontends.frontend1.routes.test_1]\n    rule = \nHost:frontend.local\n\n\n\n\n\n\n\nWarning\n\n\nWith some backends, the server URLs use the IP, so you may need to configure \nInsecureSkipVerify\n instead of the \nRootCAS\n to activate HTTPS without hostname verification.\n\n\n\n\nConclusion\n\n\nWe don't need specific configuration to use gRPC in Tr\u00e6fik, we just need to be careful that all the exchanges (between client and Tr\u00e6fik, and between Tr\u00e6fik and backend) are HTTPS communications because gRPC uses HTTP2.\n\n\nA gRPC example in go\n\n\nWe will use the gRPC greeter example in \ngrpc-go\n\n\n\n\nWarning\n\n\nIn order to use this gRPC example, we need to modify it to use HTTPS\n\n\n\n\nSo we modify the \"gRPC server example\" to use our own self-signed certificate:\n\n\n// ...\n\n// Read cert and key file\nBackendCert, _ := ioutil.ReadFile(\n./backend.cert\n)\nBackendKey, _ := ioutil.ReadFile(\n./backend.key\n)\n\n// Generate Certificate struct\ncert, err := tls.X509KeyPair(BackendCert, BackendKey)\nif err != nil {\n  log.Fatalf(\nfailed to parse certificate: %v\n, err)\n}\n\n// Create credentials\ncreds := credentials.NewServerTLSFromCert(\ncert)\n\n// Use Credentials in gRPC server options\nserverOption := grpc.Creds(creds)\nvar s *grpc.Server = grpc.NewServer(serverOption)\ndefer s.Stop()\n\npb.RegisterGreeterServer(s, \nserver{})\nerr := s.Serve(lis)\n\n// ...\n\n\n\n\nNext we will modify gRPC Client to use our Tr\u00e6fik self-signed certificate:\n\n\n// ...\n\n// Read cert file\nFrontendCert, _ := ioutil.ReadFile(\n./frontend.cert\n)\n\n// Create CertPool\nroots := x509.NewCertPool()\nroots.AppendCertsFromPEM(FrontendCert)\n\n// Create credentials\ncredsClient := credentials.NewClientTLSFromCert(roots, \n)\n\n// Dial with specific Transport (with credentials)\nconn, err := grpc.Dial(\nfrontend.local:4443\n, grpc.WithTransportCredentials(credsClient))\nif err != nil {\n    log.Fatalf(\ndid not connect: %v\n, err)\n}\n\ndefer conn.Close()\nclient := pb.NewGreeterClient(conn)\n\nname := \nWorld\n\nr, err := client.SayHello(context.Background(), \npb.HelloRequest{Name: name})\n\n// ...", 
            "title": "gRPC Example"
        }, 
        {
            "location": "/user-guide/grpc/#grpc-example", 
            "text": "This section explains how to use Traefik as reverse proxy for gRPC application with self-signed certificates.   Warning  As gRPC needs HTTP2, we need HTTPS certificates on both gRPC Server and Tr\u00e6fik.", 
            "title": "gRPC example"
        }, 
        {
            "location": "/user-guide/grpc/#grpc-server-certificate", 
            "text": "In order to secure the gRPC server, we generate a self-signed certificate for backend url:  openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout ./backend.key -out ./backend.cert  That will prompt for information, the important answer is:  Common Name (e.g. server FQDN or YOUR name) []: backend.local", 
            "title": "gRPC Server certificate"
        }, 
        {
            "location": "/user-guide/grpc/#grpc-client-certificate", 
            "text": "Generate your self-signed certificate for frontend url:  openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout ./frontend.key -out ./frontend.cert  with  Common Name (e.g. server FQDN or YOUR name) []: frontend.local", 
            "title": "gRPC Client certificate"
        }, 
        {
            "location": "/user-guide/grpc/#trfik-configuration", 
            "text": "At last, we configure our Tr\u00e6fik instance to use both self-signed certificates.  defaultEntryPoints = [ https ]\n\n# For secure connection on backend.local\nRootCAs = [  ./backend.cert  ]\n\n[entryPoints]\n  [entryPoints.https]\n  address =  :4443 \n    [entryPoints.https.tls]\n     # For secure connection on frontend.local\n     [[entryPoints.https.tls.certificates]]\n     certFile =  ./frontend.cert \n     keyFile  =  ./frontend.key \n\n\n[web]\n  address =  :8080 \n\n[file]\n\n[backends]\n  [backends.backend1]\n    [backends.backend1.servers.server1]\n    # Access on backend with HTTPS\n    url =  https://backend.local:8080 \n\n\n[frontends]\n  [frontends.frontend1]\n  backend =  backend1 \n    [frontends.frontend1.routes.test_1]\n    rule =  Host:frontend.local    Warning  With some backends, the server URLs use the IP, so you may need to configure  InsecureSkipVerify  instead of the  RootCAS  to activate HTTPS without hostname verification.", 
            "title": "Tr\u00e6fik configuration"
        }, 
        {
            "location": "/user-guide/grpc/#conclusion", 
            "text": "We don't need specific configuration to use gRPC in Tr\u00e6fik, we just need to be careful that all the exchanges (between client and Tr\u00e6fik, and between Tr\u00e6fik and backend) are HTTPS communications because gRPC uses HTTP2.", 
            "title": "Conclusion"
        }, 
        {
            "location": "/user-guide/grpc/#a-grpc-example-in-go", 
            "text": "We will use the gRPC greeter example in  grpc-go   Warning  In order to use this gRPC example, we need to modify it to use HTTPS   So we modify the \"gRPC server example\" to use our own self-signed certificate:  // ...\n\n// Read cert and key file\nBackendCert, _ := ioutil.ReadFile( ./backend.cert )\nBackendKey, _ := ioutil.ReadFile( ./backend.key )\n\n// Generate Certificate struct\ncert, err := tls.X509KeyPair(BackendCert, BackendKey)\nif err != nil {\n  log.Fatalf( failed to parse certificate: %v , err)\n}\n\n// Create credentials\ncreds := credentials.NewServerTLSFromCert( cert)\n\n// Use Credentials in gRPC server options\nserverOption := grpc.Creds(creds)\nvar s *grpc.Server = grpc.NewServer(serverOption)\ndefer s.Stop()\n\npb.RegisterGreeterServer(s,  server{})\nerr := s.Serve(lis)\n\n// ...  Next we will modify gRPC Client to use our Tr\u00e6fik self-signed certificate:  // ...\n\n// Read cert file\nFrontendCert, _ := ioutil.ReadFile( ./frontend.cert )\n\n// Create CertPool\nroots := x509.NewCertPool()\nroots.AppendCertsFromPEM(FrontendCert)\n\n// Create credentials\ncredsClient := credentials.NewClientTLSFromCert(roots,  )\n\n// Dial with specific Transport (with credentials)\nconn, err := grpc.Dial( frontend.local:4443 , grpc.WithTransportCredentials(credsClient))\nif err != nil {\n    log.Fatalf( did not connect: %v , err)\n}\n\ndefer conn.Close()\nclient := pb.NewGreeterClient(conn)\n\nname :=  World \nr, err := client.SayHello(context.Background(),  pb.HelloRequest{Name: name})\n\n// ...", 
            "title": "A gRPC example in go"
        }, 
        {
            "location": "/benchmarks/", 
            "text": "Benchmarks\n\n\nConfiguration\n\n\nI would like to thanks \nvincentbernat\n from \nexoscale.ch\n who kindly provided the infrastructure needed for the benchmarks.\n\n\nI used 4 VMs for the tests with the following configuration:\n\n\n\n\n32 GB RAM\n\n\n8 CPU Cores\n\n\n10 GB SSD\n\n\nUbuntu 14.04 LTS 64-bit\n\n\n\n\nSetup\n\n\n\n\nOne VM used to launch the benchmarking tool \nwrk\n\n\nOne VM for Traefik (v1.0.0-beta.416) / nginx (v1.4.6)\n\n\nTwo VMs for 2 backend servers in go \nwhoami\n\n\n\n\nEach VM has been tuned using the following limits:\n\n\nsysctl -w fs.file-max=\n9999999\n\nsysctl -w fs.nr_open=\n9999999\n\nsysctl -w net.core.netdev_max_backlog=\n4096\n\nsysctl -w net.core.rmem_max=\n16777216\n\nsysctl -w net.core.somaxconn=\n65535\n\nsysctl -w net.core.wmem_max=\n16777216\n\nsysctl -w net.ipv4.ip_local_port_range=\n1025       65535\n\nsysctl -w net.ipv4.tcp_fin_timeout=\n30\n\nsysctl -w net.ipv4.tcp_keepalive_time=\n30\n\nsysctl -w net.ipv4.tcp_max_syn_backlog=\n20480\n\nsysctl -w net.ipv4.tcp_max_tw_buckets=\n400000\n\nsysctl -w net.ipv4.tcp_no_metrics_save=\n1\n\nsysctl -w net.ipv4.tcp_syn_retries=\n2\n\nsysctl -w net.ipv4.tcp_synack_retries=\n2\n\nsysctl -w net.ipv4.tcp_tw_recycle=\n1\n\nsysctl -w net.ipv4.tcp_tw_reuse=\n1\n\nsysctl -w vm.min_free_kbytes=\n65536\n\nsysctl -w vm.overcommit_memory=\n1\n\nulimit -n 9999999\n\n\n\n\nNginx\n\n\nHere is the config Nginx file use \n/etc/nginx/nginx.conf\n:\n\n\nuser www-data;\nworker_processes auto;\nworker_rlimit_nofile 200000;\npid /var/run/nginx.pid;\n\nevents {\n    worker_connections 10000;\n    use epoll;\n    multi_accept on;\n}\n\nhttp {\n    sendfile on;\n    tcp_nopush on;\n    tcp_nodelay on;\n    keepalive_timeout 300;\n    keepalive_requests 10000;\n    types_hash_max_size 2048;\n\n    open_file_cache max=200000 inactive=300s;\n    open_file_cache_valid 300s;\n    open_file_cache_min_uses 2;\n    open_file_cache_errors on;\n\n    server_tokens off;\n    dav_methods off;\n\n    include /etc/nginx/mime.types;\n    default_type application/octet-stream;\n\n    access_log /var/log/nginx/access.log combined;\n    error_log /var/log/nginx/error.log warn;\n\n    gzip off;\n    gzip_vary off;\n\n    include /etc/nginx/conf.d/*.conf;\n    include /etc/nginx/sites-enabled/*.conf;\n}\n\n\n\n\nHere is the Nginx vhost file used:\n\n\nupstream whoami {\n    server IP-whoami1:80;\n    server IP-whoami2:80;\n    keepalive 300;\n}\n\nserver {\n    listen 8001;\n    server_name test.traefik;\n    access_log off;\n    error_log /dev/null crit;\n    if ($host != \ntest.traefik\n) {\n        return 404;\n    }\n    location / {\n        proxy_pass http://whoami;\n        proxy_http_version 1.1;\n        proxy_set_header Connection \n;\n    proxy_set_header  X-Forwarded-Host $host;\n    }\n}\n\n\n\n\nTraefik\n\n\nHere is the \ntraefik.toml\n file used:\n\n\nMaxIdleConnsPerHost = 100000\ndefaultEntryPoints = [\nhttp\n]\n\n[entryPoints]\n  [entryPoints.http]\n  address = \n:8000\n\n\n[file]\n[backends]\n  [backends.backend1]\n    [backends.backend1.servers.server1]\n    url = \nhttp://IP-whoami1:80\n\n    weight = 1\n    [backends.backend1.servers.server2]\n    url = \nhttp://IP-whoami2:80\n\n    weight = 1\n\n[frontends]\n  [frontends.frontend1]\n  backend = \nbackend1\n\n    [frontends.frontend1.routes.test_1]\n    rule = \nHost: test.traefik\n\n\n\n\n\nResults\n\n\nwhoami:\n\n\nwrk -t20 -c1000 -d60s -H \nHost: test.traefik\n --latency  http://IP-whoami:80/bench\nRunning 1m test @ http://IP-whoami:80/bench\n  20 threads and 1000 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency    70.28ms  134.72ms   1.91s    89.94%\n    Req/Sec     2.92k   742.42     8.78k    68.80%\n  Latency Distribution\n     50%   10.63ms\n     75%   75.64ms\n     90%  205.65ms\n     99%  668.28ms\n  3476705 requests in 1.00m, 384.61MB read\n  Socket errors: connect 0, read 0, write 0, timeout 103\nRequests/sec:  57894.35\nTransfer/sec:      6.40MB\n\n\n\n\nnginx:\n\n\nwrk -t20 -c1000 -d60s -H \nHost: test.traefik\n --latency  http://IP-nginx:8001/bench\nRunning 1m test @ http://IP-nginx:8001/bench\n  20 threads and 1000 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency   101.25ms  180.09ms   1.99s    89.34%\n    Req/Sec     1.69k   567.69     9.39k    72.62%\n  Latency Distribution\n     50%   15.46ms\n     75%  129.11ms\n     90%  302.44ms\n     99%  846.59ms\n  2018427 requests in 1.00m, 298.36MB read\n  Socket errors: connect 0, read 0, write 0, timeout 90\nRequests/sec:  33591.67\nTransfer/sec:      4.97MB\n\n\n\n\nTraefik:\n\n\nwrk -t20 -c1000 -d60s -H \nHost: test.traefik\n --latency  http://IP-traefik:8000/bench\nRunning 1m test @ http://IP-traefik:8000/bench\n  20 threads and 1000 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency    91.72ms  150.43ms   2.00s    90.50%\n    Req/Sec     1.43k   266.37     2.97k    69.77%\n  Latency Distribution\n     50%   19.74ms\n     75%  121.98ms\n     90%  237.39ms\n     99%  687.49ms\n  1705073 requests in 1.00m, 188.63MB read\n  Socket errors: connect 0, read 0, write 0, timeout 7\nRequests/sec:  28392.44\nTransfer/sec:      3.14MB\n\n\n\n\nConclusion\n\n\nTraefik is obviously slower than Nginx, but not so much: Traefik can serve 28392 requests/sec and Nginx 33591 requests/sec which gives a ratio of 85%.\nNot bad for young project :) !\n\n\nSome areas of possible improvements:\n\n\n\n\nUse \nGO_REUSEPORT\n listener\n\n\nRun a separate server instance per CPU core with \nGOMAXPROCS=1\n (it appears during benchmarks that there is a lot more context switches with Traefik than with nginx)", 
            "title": "Benchmarks"
        }, 
        {
            "location": "/benchmarks/#benchmarks", 
            "text": "", 
            "title": "Benchmarks"
        }, 
        {
            "location": "/benchmarks/#configuration", 
            "text": "I would like to thanks  vincentbernat  from  exoscale.ch  who kindly provided the infrastructure needed for the benchmarks.  I used 4 VMs for the tests with the following configuration:   32 GB RAM  8 CPU Cores  10 GB SSD  Ubuntu 14.04 LTS 64-bit", 
            "title": "Configuration"
        }, 
        {
            "location": "/benchmarks/#setup", 
            "text": "One VM used to launch the benchmarking tool  wrk  One VM for Traefik (v1.0.0-beta.416) / nginx (v1.4.6)  Two VMs for 2 backend servers in go  whoami   Each VM has been tuned using the following limits:  sysctl -w fs.file-max= 9999999 \nsysctl -w fs.nr_open= 9999999 \nsysctl -w net.core.netdev_max_backlog= 4096 \nsysctl -w net.core.rmem_max= 16777216 \nsysctl -w net.core.somaxconn= 65535 \nsysctl -w net.core.wmem_max= 16777216 \nsysctl -w net.ipv4.ip_local_port_range= 1025       65535 \nsysctl -w net.ipv4.tcp_fin_timeout= 30 \nsysctl -w net.ipv4.tcp_keepalive_time= 30 \nsysctl -w net.ipv4.tcp_max_syn_backlog= 20480 \nsysctl -w net.ipv4.tcp_max_tw_buckets= 400000 \nsysctl -w net.ipv4.tcp_no_metrics_save= 1 \nsysctl -w net.ipv4.tcp_syn_retries= 2 \nsysctl -w net.ipv4.tcp_synack_retries= 2 \nsysctl -w net.ipv4.tcp_tw_recycle= 1 \nsysctl -w net.ipv4.tcp_tw_reuse= 1 \nsysctl -w vm.min_free_kbytes= 65536 \nsysctl -w vm.overcommit_memory= 1 \nulimit -n 9999999", 
            "title": "Setup"
        }, 
        {
            "location": "/benchmarks/#nginx", 
            "text": "Here is the config Nginx file use  /etc/nginx/nginx.conf :  user www-data;\nworker_processes auto;\nworker_rlimit_nofile 200000;\npid /var/run/nginx.pid;\n\nevents {\n    worker_connections 10000;\n    use epoll;\n    multi_accept on;\n}\n\nhttp {\n    sendfile on;\n    tcp_nopush on;\n    tcp_nodelay on;\n    keepalive_timeout 300;\n    keepalive_requests 10000;\n    types_hash_max_size 2048;\n\n    open_file_cache max=200000 inactive=300s;\n    open_file_cache_valid 300s;\n    open_file_cache_min_uses 2;\n    open_file_cache_errors on;\n\n    server_tokens off;\n    dav_methods off;\n\n    include /etc/nginx/mime.types;\n    default_type application/octet-stream;\n\n    access_log /var/log/nginx/access.log combined;\n    error_log /var/log/nginx/error.log warn;\n\n    gzip off;\n    gzip_vary off;\n\n    include /etc/nginx/conf.d/*.conf;\n    include /etc/nginx/sites-enabled/*.conf;\n}  Here is the Nginx vhost file used:  upstream whoami {\n    server IP-whoami1:80;\n    server IP-whoami2:80;\n    keepalive 300;\n}\n\nserver {\n    listen 8001;\n    server_name test.traefik;\n    access_log off;\n    error_log /dev/null crit;\n    if ($host !=  test.traefik ) {\n        return 404;\n    }\n    location / {\n        proxy_pass http://whoami;\n        proxy_http_version 1.1;\n        proxy_set_header Connection  ;\n    proxy_set_header  X-Forwarded-Host $host;\n    }\n}", 
            "title": "Nginx"
        }, 
        {
            "location": "/benchmarks/#traefik", 
            "text": "Here is the  traefik.toml  file used:  MaxIdleConnsPerHost = 100000\ndefaultEntryPoints = [ http ]\n\n[entryPoints]\n  [entryPoints.http]\n  address =  :8000 \n\n[file]\n[backends]\n  [backends.backend1]\n    [backends.backend1.servers.server1]\n    url =  http://IP-whoami1:80 \n    weight = 1\n    [backends.backend1.servers.server2]\n    url =  http://IP-whoami2:80 \n    weight = 1\n\n[frontends]\n  [frontends.frontend1]\n  backend =  backend1 \n    [frontends.frontend1.routes.test_1]\n    rule =  Host: test.traefik", 
            "title": "Traefik"
        }, 
        {
            "location": "/benchmarks/#results", 
            "text": "", 
            "title": "Results"
        }, 
        {
            "location": "/benchmarks/#whoami", 
            "text": "wrk -t20 -c1000 -d60s -H  Host: test.traefik  --latency  http://IP-whoami:80/bench\nRunning 1m test @ http://IP-whoami:80/bench\n  20 threads and 1000 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency    70.28ms  134.72ms   1.91s    89.94%\n    Req/Sec     2.92k   742.42     8.78k    68.80%\n  Latency Distribution\n     50%   10.63ms\n     75%   75.64ms\n     90%  205.65ms\n     99%  668.28ms\n  3476705 requests in 1.00m, 384.61MB read\n  Socket errors: connect 0, read 0, write 0, timeout 103\nRequests/sec:  57894.35\nTransfer/sec:      6.40MB", 
            "title": "whoami:"
        }, 
        {
            "location": "/benchmarks/#nginx_1", 
            "text": "wrk -t20 -c1000 -d60s -H  Host: test.traefik  --latency  http://IP-nginx:8001/bench\nRunning 1m test @ http://IP-nginx:8001/bench\n  20 threads and 1000 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency   101.25ms  180.09ms   1.99s    89.34%\n    Req/Sec     1.69k   567.69     9.39k    72.62%\n  Latency Distribution\n     50%   15.46ms\n     75%  129.11ms\n     90%  302.44ms\n     99%  846.59ms\n  2018427 requests in 1.00m, 298.36MB read\n  Socket errors: connect 0, read 0, write 0, timeout 90\nRequests/sec:  33591.67\nTransfer/sec:      4.97MB", 
            "title": "nginx:"
        }, 
        {
            "location": "/benchmarks/#traefik_1", 
            "text": "wrk -t20 -c1000 -d60s -H  Host: test.traefik  --latency  http://IP-traefik:8000/bench\nRunning 1m test @ http://IP-traefik:8000/bench\n  20 threads and 1000 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency    91.72ms  150.43ms   2.00s    90.50%\n    Req/Sec     1.43k   266.37     2.97k    69.77%\n  Latency Distribution\n     50%   19.74ms\n     75%  121.98ms\n     90%  237.39ms\n     99%  687.49ms\n  1705073 requests in 1.00m, 188.63MB read\n  Socket errors: connect 0, read 0, write 0, timeout 7\nRequests/sec:  28392.44\nTransfer/sec:      3.14MB", 
            "title": "Traefik:"
        }, 
        {
            "location": "/benchmarks/#conclusion", 
            "text": "Traefik is obviously slower than Nginx, but not so much: Traefik can serve 28392 requests/sec and Nginx 33591 requests/sec which gives a ratio of 85%.\nNot bad for young project :) !  Some areas of possible improvements:   Use  GO_REUSEPORT  listener  Run a separate server instance per CPU core with  GOMAXPROCS=1  (it appears during benchmarks that there is a lot more context switches with Traefik than with nginx)", 
            "title": "Conclusion"
        }, 
        {
            "location": "/archive/", 
            "text": "Current versions documentation\n\n\n\n\n\n\nLatest stable\n\n\n\n\n\n\nExperimental\n\n\n\n\n\n\nFuture version documentation\n\n\n\n\nv1.5 RC\n \n\n\n\n\nPrevious versions documentation\n\n\n\n\n\n\nv1.4 aka Roquefort\n \n\n\n\n\n\n\nv1.3 aka Raclette\n\n\n\n\n\n\nv1.2 aka Morbier\n\n\n\n\n\n\nv1.1 aka Camembert\n\n\n\n\n\n\nMore\n\n\nChange log", 
            "title": "Archive"
        }, 
        {
            "location": "/archive/#current-versions-documentation", 
            "text": "Latest stable    Experimental", 
            "title": "Current versions documentation"
        }, 
        {
            "location": "/archive/#future-version-documentation", 
            "text": "v1.5 RC", 
            "title": "Future version documentation"
        }, 
        {
            "location": "/archive/#previous-versions-documentation", 
            "text": "v1.4 aka Roquefort      v1.3 aka Raclette    v1.2 aka Morbier    v1.1 aka Camembert", 
            "title": "Previous versions documentation"
        }, 
        {
            "location": "/archive/#more", 
            "text": "Change log", 
            "title": "More"
        }
    ]
}